{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b26e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports to get us started\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Utilities\n",
    "import os \n",
    "import sys\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "random_state = 100 # Ensure reproducible results\n",
    "\n",
    "# DoWhy\n",
    "import pygraphviz\n",
    "from IPython.display import Image, display\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import econml\n",
    "\n",
    "# Generic ML imports\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB\n",
    "from sklearn.linear_model import LassoCV, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, recall_score, f1_score, roc_auc_score, confusion_matrix, plot_roc_curve\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Import custom dowhy helper functions module\n",
    "cwd = Path().resolve()\n",
    "PARENT_DIR = os.path.dirname(cwd)\n",
    "SCRIPT_DIR = os.path.join(PARENT_DIR, 'helpers')\n",
    "sys.path.append(SCRIPT_DIR)\n",
    "import meta_model_helpers as mmh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387ce698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O Stuff\n",
    "DATA_FILENAME = \"csdh_burr.csv\"\n",
    "DATA_FILEPATH = \"/Users/callum/Uni/GitHubRepos/surviving-the-icu/datasets/drain_data/\" + DATA_FILENAME\n",
    "csdh = pd.read_csv(DATA_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e52bf0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCTOR DAG features\n",
    "doc_features = ['age', 'stroke', 'ihd', 'metalvalve', 'antiplatelet', 'warfarin', 'hospital',\n",
    "                'thickness_sum', 'density', 'optype', 'membranes', 'burrhole_num', 'bedrest',\n",
    "                'drain', 'recurrence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c91d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical type conversion\n",
    "categorical_features = ['stroke', 'antiplatelet', 'ihd', 'metalvalve', 'membranes', 'optype', 'recurrence',\n",
    "                        'drain', 'hospital', 'bedrest', 'warfarin', 'density', 'membranes', 'burrhole_num',\n",
    "                        'bedrest']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    col = pd.Categorical(csdh[feature])\n",
    "    csdh[feature] = col.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775efed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csdh_doc = csdh[doc_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d3f8e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_model = CausalModel(data=csdh, \n",
    "                         treatment='drain', \n",
    "                         outcome='recurrence', \n",
    "                         graph='../causal_graphs/doctor_dag.dot'.replace(\"\\n\", \" \"))\n",
    "doc_model.view_model()\n",
    "display(Image(filename=\"causal_model.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52f874",
   "metadata": {},
   "source": [
    "---\n",
    "## Define set of classifiers to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2126c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Dummy', 'LR', 'Linear SVM', 'RBF SVM', 'GB', 'RF', 'XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7138aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes exluded due to mixture of variable types\n",
    "classifiers = [\n",
    "    DummyClassifier(strategy='most_frequent'),\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    SVC(kernel=\"linear\", probability=True, random_state=random_state),\n",
    "    SVC(kernel='rbf', probability=True, random_state=random_state),\n",
    "    GradientBoostingClassifier(random_state=random_state),\n",
    "    RandomForestClassifier(random_state=random_state),\n",
    "    XGBClassifier(random_state=random_state),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66edce",
   "metadata": {},
   "source": [
    "# _Double Machine Learning:_ finding `model_y` and `model_t`.\n",
    "- `model_y` models $\\mathbb{E}[Y \\mid X,W]$ where the treatment variable $T$ is omitted from the covariates\n",
    "- `model_t` is the propensity model and involves estimating $P[T=1\\mid X,W]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbb1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rec_full = csdh_doc['recurrence']\n",
    "X_rec_full = csdh_doc.drop(['drain', 'recurrence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dba5bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation set and rest\n",
    "X_rec_rest, X_rec_val, y_rec_rest, y_rec_val = train_test_split(X_rec_full, y_rec_full, \n",
    "                                                                test_size=0.20,\n",
    "                                                                random_state=random_state,\n",
    "                                                                stratify=y_rec_full)\n",
    "\n",
    "# Split rest into train and test set\n",
    "X_rec_train, X_rec_test, y_rec_train, y_rec_test = train_test_split(X_rec_rest, y_rec_rest, \n",
    "                                                                    test_size=0.20,\n",
    "                                                                    random_state=random_state,\n",
    "                                                                    stratify=y_rec_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bd7a7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:46] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "rec_training_scores, rec_val_scores = mmh.train_and_validate_classifiers(X_rec_train, \n",
    "                                                                         y_rec_train,\n",
    "                                                                         X_rec_val,\n",
    "                                                                         y_rec_val,\n",
    "                                                                         names,\n",
    "                                                                         classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c178639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set: \n",
      "\n",
      "             ----------------Validation-----------------   -----------------Training------------------\n",
      "Method         Acc   AUROC  Recall      F1      LL     Acc   AUROC  Recall      F1      LL\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dummy         0.916    0.500    0.000    0.000   2.902    0.911    0.500    0.000    0.000    3.090\n",
      "LR            0.916    0.500    0.000    0.000   2.902    0.911    0.500    0.000    0.000    3.090\n",
      "Linear SVM    0.916    0.500    0.000    0.000   2.902    0.911    0.500    0.000    0.000    3.090\n",
      "RBF SVM       0.916    0.500    0.000    0.000   2.902    0.911    0.500    0.000    0.000    3.090\n",
      "GB            0.866    0.518    0.100    0.111   4.644    0.968    0.824    0.647    0.786    1.091\n",
      "RF            0.916    0.500    0.000    0.000   2.902    1.000    1.000    1.000    1.000    0.000\n",
      "XGB           0.882    0.482    0.000    0.000   4.063    1.000    1.000    1.000    1.000    0.000\n"
     ]
    }
   ],
   "source": [
    "mmh.print_metrics_table(rec_training_scores, rec_val_scores, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1b2eb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_rec_test = confusion_matrix(y_rec_test, classifiers[4].predict(X_rec_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_rec_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f7901e",
   "metadata": {},
   "source": [
    "## `model_y` K-Fold cross validation for hyperparameter tuning and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbc0128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross-validation structure\n",
    "cv_5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "cv_10 = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "011544a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classifiers and hyperparameters to search over\n",
    "rf = RandomForestClassifier()\n",
    "params_rf = {\n",
    "    # randomly sample numbers from 10 to 200 estimators\n",
    "    'rf__n_estimators':randint(10, 200),\n",
    "    \n",
    "    ### DONT TUNE THESE DUE TO DATASET SIZE ###\n",
    "    # minimum number of samples required to split an internal node\n",
    "    #'rf__min_samples_split':randint(1, 12),\n",
    "    # minimum number of samples required to split a leaf\n",
    "    #'rf__min_samples_leaf':randint(1, 50),\n",
    "    # The maximum depth of the individual regression estimators.\n",
    "    \n",
    "    'rf__max_depth':randint(2, 15),\n",
    "    # The number of features to consider when looking for the best split\n",
    "    'rf__max_features':['sqrt', 'log2', None],\n",
    "    # random seed\n",
    "    'rf__random_state':[random_state],\n",
    "    # Whether bootstrap samples are used when building trees\n",
    "    'rf__bootstrap':[True, False]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "params_gb = {\n",
    "    # randomly sample numbers from 10 to 200 estimators\n",
    "    'gb__n_estimators':randint(10, 200),\n",
    "    # fraction of samples to be used for fitting individual base learners\n",
    "    'gb__subsample':[0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1],\n",
    "    # learning rate\n",
    "    'gb__learning_rate':[0.001, 0.003, 0.01, 0.03, 0.07, 0.1, 0.3, 0.7, 1.0],\n",
    "        \n",
    "    ### DONT TUNE THESE DUE TO DATASET SIZE ###\n",
    "    # minimum number of samples required to split an internal node\n",
    "    #'gb__min_samples_split':randint(1, 12),\n",
    "    # minimum number of samples required to split a leaf\n",
    "    #'gb__min_samples_leaf':randint(1, 50),\n",
    "    # The maximum depth of the individual regression estimators\n",
    "    \n",
    "    'gb__max_depth':randint(2, 15),\n",
    "    # The number of features to consider when looking for the best split\n",
    "    'gb__max_features':['sqrt', 'log2', None],\n",
    "    # random seed\n",
    "    'gb__random_state':[random_state]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "params_xgb = {\n",
    "    # randomly sample numbers from 10 to 200 estimators\n",
    "    'xgb__n_estimators':randint(10, 200),\n",
    "    # fraction of samples to be used for fitting individual base learners\n",
    "    'xgb__subsample':[0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1],\n",
    "    # learning rate\n",
    "    'xgb__learning_rate':[0.001, 0.003, 0.01, 0.03, 0.07, 0.1, 0.3, 0.7, 1],\n",
    "    # min_split_loss\n",
    "    'xgb__gamma':[0.001, 0.003, 0.01, 0.03, 0.07, 0.1, 0.3],\n",
    " \n",
    "    ### DONT TUNE THESE DUE TO DATASET SIZE ###\n",
    "    # minimum number of samples required to split an internal node\n",
    "    #'gb__min_samples_split':randint(1, 12),\n",
    "    # minimum number of samples required to split a leaf\n",
    "    #'gb__min_samples_leaf':randint(1, 50),\n",
    "    # The maximum depth of the individual regression estimators\n",
    "    \n",
    "    'xgb__max_depth':randint(2, 15),\n",
    "    # analagous to max_features in rf and gb\n",
    "    'xgb__colsample_bytree':[0.6, 0.7, 0.8, 0.9, 1],\n",
    "    # random seed\n",
    "    'xgb__random_state':[random_state],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5422b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search spaces for random search tuning\n",
    "search_space = [('rf', rf, params_rf), ('gb', gb, params_gb), ('xgb', xgb, params_xgb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b18ed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv strategy StratifiedKFold(n_splits=10, random_state=100, shuffle=True)\n",
      "----------------------------------------\n",
      "Trial 0\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 198, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=198,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68913043 0.43478261 0.61086957 0.46521739 0.75       0.54076087\n",
      " 0.73097826 0.45923913 0.49728261 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 1\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=51, random_state=100))])\n",
      "cv score: [0.74782609 0.43043478 0.53043478 0.6        0.64673913 0.72826087\n",
      " 0.48369565 0.58152174 0.56521739 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 2\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 192, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=192, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.7        0.4173913  0.5        0.5826087  0.77717391 0.61956522\n",
      " 0.51086957 0.48913043 0.68478261 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 3\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=38,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73913043 0.48043478 0.46956522 0.60434783 0.63043478 0.49456522\n",
      " 0.55434783 0.52173913 0.51630435 0.66304348]\n",
      "----------------------------------------\n",
      "Trial 4\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 114, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=114,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49565217 0.32608696 0.55652174 0.50434783 0.73913043 0.54347826\n",
      " 0.52717391 0.41847826 0.61413043 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 5\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 168, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=168,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6326087  0.29347826 0.58043478 0.77826087 0.39945652 0.39673913\n",
      " 0.64130435 0.61956522 0.48369565 0.47554348]\n",
      "----------------------------------------\n",
      "Trial 6\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 71, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=71, random_state=100))])\n",
      "cv score: [0.73043478 0.47391304 0.46956522 0.49565217 0.60326087 0.52173913\n",
      " 0.5        0.55434783 0.47282609 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 7\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 135, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=135,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.46956522 0.22608696 0.51304348 0.57391304 0.79347826 0.57608696\n",
      " 0.30978261 0.76086957 0.57065217 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 8\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 180, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=180, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.39347826 0.57391304 0.26086957 0.57826087 0.70108696 0.44021739\n",
      " 0.52717391 0.59782609 0.48913043 0.67391304]\n",
      "----------------------------------------\n",
      "Trial 9\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 147, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=147,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75217391 0.37391304 0.46521739 0.53913043 0.73369565 0.64130435\n",
      " 0.4673913  0.40217391 0.67934783 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 10\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 79, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=79,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.73043478 0.3826087  0.47826087 0.63478261 0.69021739 0.66304348\n",
      " 0.48913043 0.26086957 0.64673913 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 11\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 81, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=81,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.7        0.34347826 0.61304348 0.54782609 0.70652174 0.50543478\n",
      " 0.46195652 0.53804348 0.55978261 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 12\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64347826 0.33913043 0.5826087  0.43913043 0.67391304 0.52173913\n",
      " 0.50543478 0.5326087  0.60326087 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 13\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 150, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=150,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57173913 0.39347826 0.60434783 0.43478261 0.5951087  0.49184783\n",
      " 0.64130435 0.45652174 0.57336957 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 14\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 17, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=17,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.75434783 0.46521739 0.45       0.60652174 0.63043478 0.45652174\n",
      " 0.51630435 0.72826087 0.68478261 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 15\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=121,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.7173913  0.48695652 0.41304348 0.56956522 0.73913043 0.55434783\n",
      " 0.49456522 0.36413043 0.64673913 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 16\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 80, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=80, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.56521739 0.46086957 0.32173913 0.53913043 0.64673913 0.63043478\n",
      " 0.41847826 0.33152174 0.64673913 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 17\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 168, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=168,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.74782609 0.42608696 0.42608696 0.6173913  0.66847826 0.59782609\n",
      " 0.47826087 0.46195652 0.70652174 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 18\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 13, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=13, random_state=100))])\n",
      "cv score: [0.62826087 0.32173913 0.41304348 0.48913043 0.4076087  0.50543478\n",
      " 0.58423913 0.50271739 0.57880435 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 19\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 192, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=192,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.59130435 0.26521739 0.63478261 0.42173913 0.80978261 0.60326087\n",
      " 0.52173913 0.5326087  0.58152174 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 20\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 91, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=91,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73913043 0.4        0.48695652 0.63043478 0.69565217 0.64673913\n",
      " 0.47826087 0.29891304 0.6576087  0.64130435]\n",
      "----------------------------------------\n",
      "Trial 21\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 122, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=122, random_state=100))])\n",
      "cv score: [0.48695652 0.3326087  0.51086957 0.45217391 0.60869565 0.45652174\n",
      " 0.48369565 0.32065217 0.74184783 0.64945652]\n",
      "----------------------------------------\n",
      "Trial 22\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 75, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=75,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73913043 0.47391304 0.50869565 0.55652174 0.70652174 0.56521739\n",
      " 0.47826087 0.51086957 0.67934783 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 23\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 108, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=108,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6326087  0.47826087 0.5173913  0.43478261 0.61141304 0.47826087\n",
      " 0.73641304 0.58967391 0.51902174 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 24\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 131, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=131,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60217391 0.45869565 0.59130435 0.45869565 0.38315217 0.52717391\n",
      " 0.66304348 0.48913043 0.58152174 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 25\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 121, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=121, random_state=100))])\n",
      "cv score: [0.74347826 0.42608696 0.44347826 0.56956522 0.6576087  0.70652174\n",
      " 0.46195652 0.35326087 0.68478261 0.66847826]\n",
      "----------------------------------------\n",
      "Trial 26\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 173, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=173,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70869565 0.37391304 0.5826087  0.5173913  0.69021739 0.50543478\n",
      " 0.57065217 0.48913043 0.66304348 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 27\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 193, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=193,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61304348 0.41304348 0.5826087  0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 28\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            n_estimators=101, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.55217391 0.33043478 0.51304348 0.52608696 0.69565217 0.44565217\n",
      " 0.55434783 0.25543478 0.73369565 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 29\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 34, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=34,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.64347826 0.41304348 0.46956522 0.55217391 0.6576087  0.47282609\n",
      " 0.51630435 0.66847826 0.58423913 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 30\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 97, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=97,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.71304348 0.41304348 0.50434783 0.55217391 0.64130435 0.51630435\n",
      " 0.53804348 0.54891304 0.56521739 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 31\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 89, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=89,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.46521739 0.25217391 0.6173913  0.49565217 0.77717391 0.46195652\n",
      " 0.48913043 0.43478261 0.55434783 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 32\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 196, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=196, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.68695652 0.46086957 0.46521739 0.40869565 0.73369565 0.7173913\n",
      " 0.43478261 0.36413043 0.58152174 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 33\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 77, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=77,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47391304 0.30434783 0.46521739 0.61304348 0.54347826 0.45108696\n",
      " 0.33695652 0.60326087 0.3423913  0.48369565]\n",
      "----------------------------------------\n",
      "Trial 34\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 156, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=156,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72608696 0.39565217 0.56956522 0.50434783 0.65217391 0.5\n",
      " 0.60326087 0.47826087 0.625      0.57065217]\n",
      "----------------------------------------\n",
      "Trial 35\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 137, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=137,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43043478 0.2826087  0.5826087  0.44347826 0.66847826 0.54347826\n",
      " 0.4076087  0.63586957 0.60326087 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 36\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 29, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=29, random_state=100))])\n",
      "cv score: [0.88695652 0.41304348 0.51304348 0.52173913 0.5326087  0.52717391\n",
      " 0.48913043 0.35326087 0.77173913 0.47826087]\n",
      "----------------------------------------\n",
      "Trial 37\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=183,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57826087 0.38043478 0.58695652 0.7173913  0.42934783 0.44565217\n",
      " 0.60054348 0.38043478 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 38\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 47, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=47,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58695652 0.42608696 0.47391304 0.5173913  0.71195652 0.47826087\n",
      " 0.43478261 0.40217391 0.70108696 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 39\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=38, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.80434783 0.43478261 0.40869565 0.5        0.5326087  0.51630435\n",
      " 0.47826087 0.46195652 0.54891304 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 40\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 29, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=29, random_state=100))])\n",
      "cv score: [0.8        0.43043478 0.5173913  0.45217391 0.6576087  0.73369565\n",
      " 0.48369565 0.49456522 0.58695652 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 41\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 140, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=140,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.74347826 0.37391304 0.49130435 0.54347826 0.72826087 0.63586957\n",
      " 0.4673913  0.41304348 0.68478261 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 42\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 22, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            n_estimators=22, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.63043478 0.30869565 0.45217391 0.41304348 0.67934783 0.52173913\n",
      " 0.48913043 0.3423913  0.66304348 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 43\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 89, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=89,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73913043 0.39565217 0.5        0.62608696 0.69021739 0.64130435\n",
      " 0.47826087 0.29347826 0.6576087  0.63586957]\n",
      "----------------------------------------\n",
      "Trial 44\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 88, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=88,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72608696 0.46521739 0.50434783 0.5826087  0.67391304 0.52173913\n",
      " 0.51630435 0.42934783 0.66304348 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 45\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 85, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=85,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63913043 0.24782609 0.5173913  0.6        0.76630435 0.3423913\n",
      " 0.375      0.54347826 0.55978261 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 46\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69782609 0.47173913 0.54347826 0.5173913  0.61956522 0.47282609\n",
      " 0.73913043 0.50815217 0.51358696 0.57880435]\n",
      "----------------------------------------\n",
      "Trial 47\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 104, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=104, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.72608696 0.37826087 0.43913043 0.55652174 0.74456522 0.58152174\n",
      " 0.48369565 0.38586957 0.66304348 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 48\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 48, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=4,\n",
      "                                            n_estimators=48, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.54347826 0.38695652 0.36956522 0.68695652 0.76630435 0.42934783\n",
      " 0.36956522 0.41304348 0.65217391 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 49\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 116, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=116,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67826087 0.38478261 0.5673913  0.46521739 0.63043478 0.55163043\n",
      " 0.75815217 0.43206522 0.52717391 0.57880435]\n",
      "----------------------------------------\n",
      "Trial 50\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 128, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt', n_estimators=128,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6173913  0.33043478 0.45217391 0.5        0.77173913 0.66847826\n",
      " 0.44565217 0.33423913 0.66032609 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 51\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52608696 0.30434783 0.56956522 0.53043478 0.70108696 0.5\n",
      " 0.50543478 0.53804348 0.47282609 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 52\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50869565 0.24782609 0.48695652 0.55652174 0.69021739 0.51630435\n",
      " 0.51086957 0.69565217 0.55978261 0.48913043]\n",
      "----------------------------------------\n",
      "Trial 53\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=70,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76521739 0.43043478 0.50434783 0.59130435 0.66847826 0.49184783\n",
      " 0.50543478 0.5326087  0.57065217 0.66304348]\n",
      "----------------------------------------\n",
      "Trial 54\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 50, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=50,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6        0.38913043 0.4173913  0.6173913  0.80434783 0.66847826\n",
      " 0.4076087  0.28804348 0.5951087  0.60326087]\n",
      "----------------------------------------\n",
      "Trial 55\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=171,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66086957 0.38913043 0.57608696 0.73043478 0.45108696 0.57608696\n",
      " 0.47282609 0.30706522 0.57608696 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 56\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51304348 0.3173913  0.60434783 0.61304348 0.77717391 0.45652174\n",
      " 0.5        0.54347826 0.55978261 0.47282609]\n",
      "----------------------------------------\n",
      "Trial 57\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 53, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=53,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.77608696 0.43913043 0.48478261 0.51521739 0.73641304 0.61413043\n",
      " 0.68206522 0.36413043 0.50543478 0.55706522]\n",
      "----------------------------------------\n",
      "Trial 58\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 39, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=39,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.71086957 0.42826087 0.57608696 0.45434783 0.75       0.45380435\n",
      " 0.6576087  0.32608696 0.5923913  0.60869565]\n",
      "----------------------------------------\n",
      "Trial 59\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56521739 0.3173913  0.56086957 0.68695652 0.85869565 0.42391304\n",
      " 0.4076087  0.55978261 0.47282609 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 60\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.64782609 0.49565217 0.42173913 0.54347826 0.72282609 0.63586957\n",
      " 0.48913043 0.3423913  0.625      0.47826087]\n",
      "----------------------------------------\n",
      "Trial 61\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 46, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=46,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.7        0.32608696 0.47391304 0.59565217 0.82608696 0.6576087\n",
      " 0.39673913 0.2201087  0.64945652 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 62\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 80, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, n_estimators=80,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.71304348 0.35217391 0.50869565 0.5826087  0.61413043 0.5\n",
      " 0.48913043 0.41304348 0.64673913 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 63\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=121, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.78695652 0.44347826 0.43478261 0.50869565 0.7826087  0.60869565\n",
      " 0.49456522 0.5        0.56521739 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 64\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 105, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=105,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73478261 0.41086957 0.61086957 0.49782609 0.70108696 0.52445652\n",
      " 0.68206522 0.31793478 0.4673913  0.52445652]\n",
      "----------------------------------------\n",
      "Trial 65\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.73043478 0.38695652 0.47826087 0.52173913 0.80434783 0.5923913\n",
      " 0.47826087 0.54347826 0.57608696 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 66\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 62, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, n_estimators=62,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.53913043 0.31304348 0.61304348 0.39130435 0.7173913  0.4673913\n",
      " 0.46195652 0.29347826 0.70108696 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 67\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 151, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=151, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.63913043 0.35217391 0.46086957 0.5        0.73369565 0.69565217\n",
      " 0.42391304 0.31521739 0.63586957 0.48913043]\n",
      "----------------------------------------\n",
      "Trial 68\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 21, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=21,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.55434783 0.44347826 0.58695652 0.44782609 0.58967391 0.48369565\n",
      " 0.64673913 0.45652174 0.61141304 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 69\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 42, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=42,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72173913 0.38043478 0.56086957 0.4826087  0.57065217 0.56521739\n",
      " 0.69565217 0.32065217 0.60326087 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 70\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 95, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=95,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47391304 0.20434783 0.6173913  0.48695652 0.72826087 0.54891304\n",
      " 0.48913043 0.57065217 0.48913043 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 71\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=70,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61304348 0.41304348 0.5826087  0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 72\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, n_estimators=183,\n",
      "                                            random_state=100, subsample=0.8))])\n",
      "cv score: [0.5        0.42173913 0.45217391 0.58695652 0.67391304 0.38043478\n",
      " 0.4673913  0.36956522 0.64673913 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 73\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=38, random_state=100))])\n",
      "cv score: [0.67391304 0.42608696 0.45217391 0.60434783 0.66304348 0.65217391\n",
      " 0.35869565 0.28804348 0.61956522 0.48913043]\n",
      "----------------------------------------\n",
      "Trial 74\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=133, random_state=100))])\n",
      "cv score: [0.66956522 0.40434783 0.45217391 0.56521739 0.67391304 0.5923913\n",
      " 0.4673913  0.51630435 0.65217391 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 75\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 29, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=29, random_state=100))])\n",
      "cv score: [0.8        0.43043478 0.5173913  0.45217391 0.6576087  0.73369565\n",
      " 0.48369565 0.49456522 0.58695652 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 76\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 11, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=11,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65652174 0.41956522 0.60217391 0.43913043 0.58695652 0.44021739\n",
      " 0.66304348 0.36956522 0.58152174 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 77\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 113, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=113,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40869565 0.2826087  0.54347826 0.53043478 0.71195652 0.4076087\n",
      " 0.47282609 0.58152174 0.51086957 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 78\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            n_estimators=91,\n",
      "                                            random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.55652174 0.48478261 0.61956522 0.80869565 0.41576087 0.44565217\n",
      " 0.57608696 0.38043478 0.49184783 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 79\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 163, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=163, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.61304348 0.43913043 0.4        0.55217391 0.66847826 0.60326087\n",
      " 0.40217391 0.375      0.63586957 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 80\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 141, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            n_estimators=141, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.57826087 0.3826087  0.44782609 0.47391304 0.61413043 0.51086957\n",
      " 0.48369565 0.25543478 0.69565217 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 81\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 188, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, max_features='sqrt',\n",
      "                                            n_estimators=188, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.54782609 0.44782609 0.38695652 0.68695652 0.70652174 0.53804348\n",
      " 0.36956522 0.46195652 0.56521739 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 82\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 119, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            n_estimators=119, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.55217391 0.3826087  0.46956522 0.43913043 0.67934783 0.53804348\n",
      " 0.45108696 0.25543478 0.73913043 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 83\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 130, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=130,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44347826 0.2826087  0.56086957 0.55217391 0.77717391 0.51630435\n",
      " 0.5        0.52717391 0.51630435 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 84\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 196, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=196, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.62608696 0.36521739 0.44347826 0.53913043 0.73913043 0.60326087\n",
      " 0.41304348 0.36413043 0.6576087  0.55978261]\n",
      "----------------------------------------\n",
      "Trial 85\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 27, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=27,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51304348 0.26086957 0.52608696 0.5826087  0.76086957 0.52173913\n",
      " 0.51630435 0.52173913 0.50543478 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 86\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51304348 0.27826087 0.54347826 0.54782609 0.7826087  0.52717391\n",
      " 0.52717391 0.46195652 0.58152174 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 87\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 154, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=154,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.76086957 0.44565217 0.59130435 0.40434783 0.70652174 0.52173913\n",
      " 0.71195652 0.52173913 0.50543478 0.54619565]\n",
      "----------------------------------------\n",
      "Trial 88\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 108, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=108,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44782609 0.2826087  0.61304348 0.53913043 0.70652174 0.36956522\n",
      " 0.44021739 0.52173913 0.67934783 0.48369565]\n",
      "----------------------------------------\n",
      "Trial 89\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 64, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=64, random_state=100))])\n",
      "cv score: [0.55217391 0.36956522 0.47391304 0.49130435 0.57608696 0.48369565\n",
      " 0.47282609 0.29891304 0.73097826 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 90\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 118, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=118,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61304348 0.41304348 0.5826087  0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 91\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=70, random_state=100))])\n",
      "cv score: [0.47826087 0.34565217 0.51304348 0.46956522 0.61956522 0.44293478\n",
      " 0.48913043 0.30434783 0.77173913 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 92\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 151, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=4,\n",
      "                                            n_estimators=151, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.80869565 0.39565217 0.5173913  0.6        0.50543478 0.57608696\n",
      " 0.63586957 0.39673913 0.70652174 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 93\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43043478 0.35652174 0.43913043 0.55217391 0.76086957 0.51630435\n",
      " 0.4076087  0.5923913  0.44021739 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 94\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 16, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=16,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74782609 0.39347826 0.51086957 0.40869565 0.66304348 0.70652174\n",
      " 0.52445652 0.62771739 0.72826087 0.45108696]\n",
      "----------------------------------------\n",
      "Trial 95\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='sqrt',\n",
      "                                            n_estimators=95,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.75652174 0.37826087 0.47391304 0.45217391 0.72282609 0.50543478\n",
      " 0.43478261 0.67391304 0.64130435 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 96\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.46521739 0.3        0.50434783 0.57826087 0.73913043 0.45108696\n",
      " 0.47282609 0.53804348 0.50543478 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 97\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=170, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.57826087 0.52173913 0.39565217 0.60434783 0.77173913 0.58152174\n",
      " 0.45108696 0.47282609 0.61413043 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 98\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 149, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=149,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6173913  0.36086957 0.50434783 0.41304348 0.71195652 0.49456522\n",
      " 0.45652174 0.69565217 0.64673913 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 99\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 145, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=145,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57391304 0.28478261 0.40869565 0.49130435 0.82608696 0.65217391\n",
      " 0.45380435 0.39402174 0.6576087  0.55978261]\n",
      "----------------------------------------\n",
      "Trial 100\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 170, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=170,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72173913 0.37391304 0.5826087  0.54782609 0.69021739 0.52717391\n",
      " 0.5326087  0.54347826 0.59782609 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 101\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 44, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            n_estimators=44, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.54347826 0.36521739 0.54347826 0.52608696 0.75543478 0.54347826\n",
      " 0.4673913  0.23913043 0.75543478 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 102\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 22, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=22, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.56521739 0.3173913  0.51304348 0.62608696 0.86413043 0.7173913\n",
      " 0.51086957 0.4673913  0.57608696 0.35869565]\n",
      "----------------------------------------\n",
      "Trial 103\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=168, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.53043478 0.43478261 0.60869565 0.77391304 0.58152174 0.66847826\n",
      " 0.65217391 0.22282609 0.47826087 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 104\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 111, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=111, random_state=100))])\n",
      "cv score: [0.74347826 0.43043478 0.52173913 0.42608696 0.7173913  0.55978261\n",
      " 0.44565217 0.45108696 0.64130435 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 105\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 136, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=14,\n",
      "                                            n_estimators=136, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.46521739 0.36956522 0.5        0.4173913  0.61413043 0.51630435\n",
      " 0.47282609 0.20108696 0.73913043 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 106\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 68, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=68,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75869565 0.44347826 0.50434783 0.6        0.67934783 0.48641304\n",
      " 0.50543478 0.50543478 0.54347826 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 107\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.42173913 0.46956522 0.46956522 0.47826087 0.80978261 0.30978261\n",
      " 0.48369565 0.23369565 0.73369565 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 108\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 75, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=75,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57173913 0.44130435 0.60434783 0.43478261 0.61684783 0.49184783\n",
      " 0.64130435 0.47826087 0.58423913 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 109\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=115, random_state=100))])\n",
      "cv score: [0.60434783 0.40434783 0.47391304 0.4826087  0.63586957 0.51086957\n",
      " 0.47826087 0.33695652 0.7173913  0.58695652]\n",
      "----------------------------------------\n",
      "Trial 110\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 22, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=22, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.66086957 0.42173913 0.52608696 0.56956522 0.77717391 0.40217391\n",
      " 0.4673913  0.35326087 0.65217391 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 111\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 131, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=131,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59782609 0.46304348 0.58695652 0.42173913 0.61413043 0.44021739\n",
      " 0.64402174 0.32880435 0.53532609 0.54076087]\n",
      "----------------------------------------\n",
      "Trial 112\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 148, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=148,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75434783 0.49782609 0.4826087  0.58478261 0.5923913  0.50271739\n",
      " 0.56521739 0.67391304 0.57336957 0.7173913 ]\n",
      "----------------------------------------\n",
      "Trial 113\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 189, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=10,\n",
      "                                            n_estimators=189, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.55652174 0.39565217 0.52173913 0.60869565 0.73369565 0.49456522\n",
      " 0.49456522 0.25543478 0.69565217 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 114\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 34, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=34, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.61304348 0.28695652 0.35217391 0.61304348 0.7173913  0.69021739\n",
      " 0.52173913 0.33695652 0.54891304 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 115\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 137, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=137, random_state=100))])\n",
      "cv score: [0.75217391 0.43478261 0.5173913  0.49130435 0.74456522 0.55434783\n",
      " 0.46195652 0.46195652 0.64130435 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 116\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52608696 0.25217391 0.54347826 0.52173913 0.78804348 0.39673913\n",
      " 0.50543478 0.45108696 0.57608696 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 117\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 41, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=41, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.58695652 0.43913043 0.43478261 0.55217391 0.60326087 0.56793478\n",
      " 0.43478261 0.52717391 0.64673913 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 118\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 37, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, n_estimators=37,\n",
      "                                            random_state=100, subsample=0.7))])\n",
      "cv score: [0.48695652 0.34347826 0.47826087 0.53913043 0.64673913 0.59782609\n",
      " 0.40217391 0.22826087 0.73369565 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 119\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 99, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=99,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57391304 0.27391304 0.55217391 0.52608696 0.73369565 0.58695652\n",
      " 0.49456522 0.45108696 0.54347826 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 120\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 58, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=58,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57173913 0.44130435 0.60434783 0.43478261 0.61684783 0.49184783\n",
      " 0.64130435 0.47826087 0.57880435 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 121\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 67, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=67,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66086957 0.38913043 0.57608696 0.73043478 0.45108696 0.57608696\n",
      " 0.47282609 0.30706522 0.57608696 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 122\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 46, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt', n_estimators=46,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.7        0.32608696 0.47391304 0.59565217 0.82608696 0.6576087\n",
      " 0.39673913 0.2201087  0.64945652 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 123\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 26, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=26,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.76086957 0.33695652 0.60652174 0.45       0.74456522 0.51358696\n",
      " 0.67934783 0.46195652 0.7173913  0.57608696]\n",
      "----------------------------------------\n",
      "Trial 124\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=115,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73913043 0.43478261 0.50434783 0.57391304 0.64673913 0.51086957\n",
      " 0.51630435 0.46195652 0.6576087  0.63043478]\n",
      "----------------------------------------\n",
      "Trial 125\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 46, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=46,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56304348 0.43913043 0.50217391 0.43478261 0.58152174 0.49456522\n",
      " 0.64673913 0.45652174 0.56521739 0.60597826]\n",
      "----------------------------------------\n",
      "Trial 126\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67391304 0.47173913 0.61304348 0.47826087 0.72826087 0.59782609\n",
      " 0.69293478 0.51358696 0.58695652 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 127\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 28, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            n_estimators=28, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.76956522 0.47826087 0.46521739 0.64347826 0.49184783 0.60326087\n",
      " 0.60869565 0.36956522 0.67934783 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 128\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 156, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            n_estimators=156, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.61304348 0.4173913  0.44782609 0.61304348 0.6576087  0.51630435\n",
      " 0.52173913 0.26086957 0.71195652 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 129\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 117, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=117,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73695652 0.49347826 0.49565217 0.58478261 0.56521739 0.50815217\n",
      " 0.56521739 0.6576087  0.57880435 0.73913043]\n",
      "----------------------------------------\n",
      "Trial 130\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 56, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, max_features='log2',\n",
      "                                            n_estimators=56, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.64347826 0.4826087  0.52173913 0.71304348 0.69021739 0.7173913\n",
      " 0.50543478 0.4076087  0.64130435 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 131\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 153, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            n_estimators=153, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.63478261 0.32608696 0.50869565 0.4        0.64130435 0.60869565\n",
      " 0.44021739 0.29347826 0.7173913  0.60869565]\n",
      "----------------------------------------\n",
      "Trial 132\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 77, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, n_estimators=77,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.83043478 0.44130435 0.52173913 0.62173913 0.48913043 0.55163043\n",
      " 0.59782609 0.48913043 0.71195652 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 133\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 166, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=166, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.56956522 0.54782609 0.49130435 0.40869565 0.70108696 0.65217391\n",
      " 0.16847826 0.66304348 0.58152174 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 134\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 137, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=137,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6173913  0.3173913  0.5826087  0.46086957 0.77173913 0.61413043\n",
      " 0.49456522 0.58152174 0.57608696 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 135\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 60, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=60, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.73043478 0.45217391 0.4826087  0.56086957 0.625      0.55978261\n",
      " 0.50543478 0.51630435 0.55978261 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 136\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 84, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=84, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.5        0.56086957 0.46956522 0.6        0.32608696 0.5923913\n",
      " 0.63586957 0.60869565 0.58695652 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 137\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57391304 0.3173913  0.63043478 0.5        0.80434783 0.57065217\n",
      " 0.54891304 0.47282609 0.58152174 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 138\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73695652 0.4173913  0.60869565 0.4826087  0.71467391 0.60054348\n",
      " 0.67663043 0.4048913  0.52173913 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 139\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70869565 0.43043478 0.56521739 0.47826087 0.69021739 0.54891304\n",
      " 0.625      0.42934783 0.61413043 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 140\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 191, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=191,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76956522 0.43043478 0.47826087 0.6173913  0.74456522 0.59782609\n",
      " 0.46195652 0.33695652 0.6576087  0.61956522]\n",
      "----------------------------------------\n",
      "Trial 141\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 186, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=186, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.73478261 0.52173913 0.34782609 0.64347826 0.71195652 0.60326087\n",
      " 0.43478261 0.33152174 0.50543478 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 142\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 153, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=153, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.63913043 0.50869565 0.42173913 0.56521739 0.69565217 0.60326087\n",
      " 0.43478261 0.32065217 0.60326087 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 143\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 86, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=86, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.67391304 0.46956522 0.41304348 0.57391304 0.7173913  0.63043478\n",
      " 0.49456522 0.35869565 0.63043478 0.48913043]\n",
      "----------------------------------------\n",
      "Trial 144\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 56, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=56,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77826087 0.46086957 0.46086957 0.55652174 0.72282609 0.58152174\n",
      " 0.44565217 0.47282609 0.7173913  0.67934783]\n",
      "----------------------------------------\n",
      "Trial 145\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=101,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76521739 0.40869565 0.45652174 0.61304348 0.67391304 0.58695652\n",
      " 0.47826087 0.51086957 0.71195652 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 146\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 11, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=11,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.59565217 0.46086957 0.45       0.7        0.5298913  0.48913043\n",
      " 0.5326087  0.23369565 0.65217391 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 147\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 12, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=12, random_state=100))])\n",
      "cv score: [0.76521739 0.36086957 0.30434783 0.50434783 0.58152174 0.54076087\n",
      " 0.42391304 0.35869565 0.5923913  0.67934783]\n",
      "----------------------------------------\n",
      "Trial 148\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 102, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=102, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.21086957 0.5173913  0.40869565 0.64347826 0.32608696 0.57608696\n",
      " 0.5923913  0.60326087 0.58152174 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 149\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 122, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='sqrt',\n",
      "                                            n_estimators=122, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.63043478 0.49565217 0.49130435 0.59565217 0.77717391 0.58695652\n",
      " 0.48913043 0.51086957 0.67391304 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 150\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 153, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=153, random_state=100))])\n",
      "cv score: [0.56086957 0.36956522 0.48695652 0.43913043 0.6576087  0.42934783\n",
      " 0.46195652 0.33152174 0.7173913  0.57065217]\n",
      "----------------------------------------\n",
      "Trial 151\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 177, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=177,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73695652 0.5173913  0.47826087 0.60217391 0.61413043 0.49728261\n",
      " 0.54891304 0.63586957 0.56793478 0.7173913 ]\n",
      "----------------------------------------\n",
      "Trial 152\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 10, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=7, max_features='sqrt',\n",
      "                                            n_estimators=10, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.72173913 0.5173913  0.55217391 0.32608696 0.7826087  0.63586957\n",
      " 0.33152174 0.63043478 0.54347826 0.66304348]\n",
      "----------------------------------------\n",
      "Trial 153\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 169, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=169,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55217391 0.23043478 0.56521739 0.59130435 0.77173913 0.40217391\n",
      " 0.52717391 0.60326087 0.52717391 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 154\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 163, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=163,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.78478261 0.49130435 0.52173913 0.59565217 0.61413043 0.5\n",
      " 0.54891304 0.6576087  0.625      0.67934783]\n",
      "----------------------------------------\n",
      "Trial 155\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 61, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=61,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73478261 0.47391304 0.49130435 0.55217391 0.65217391 0.51086957\n",
      " 0.48913043 0.36956522 0.66847826 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 156\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 186, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=186,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76521739 0.42173913 0.47391304 0.57391304 0.68478261 0.58152174\n",
      " 0.49456522 0.50543478 0.69565217 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 157\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 154, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=154,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53913043 0.27391304 0.54347826 0.59130435 0.72826087 0.36413043\n",
      " 0.45652174 0.5326087  0.51630435 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 158\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 180, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(n_estimators=180, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.58695652 0.32608696 0.41304348 0.53043478 0.7826087  0.38586957\n",
      " 0.47282609 0.48369565 0.54347826 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 159\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 49, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=49, random_state=100))])\n",
      "cv score: [0.65652174 0.43043478 0.52173913 0.53478261 0.68478261 0.52173913\n",
      " 0.42391304 0.48913043 0.60869565 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 160\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 121, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=121,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.63913043 0.47608696 0.56304348 0.43043478 0.72826087 0.45652174\n",
      " 0.7201087  0.63315217 0.52445652 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 161\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=101,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.71086957 0.51086957 0.52173913 0.57391304 0.58967391 0.48369565\n",
      " 0.52717391 0.63043478 0.56521739 0.64673913]\n",
      "----------------------------------------\n",
      "Trial 162\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 177, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=177, random_state=100))])\n",
      "cv score: [0.61304348 0.46086957 0.40434783 0.54782609 0.73913043 0.75\n",
      " 0.44565217 0.32608696 0.59782609 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 163\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 141, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=141,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76086957 0.44782609 0.4826087  0.59565217 0.63586957 0.5\n",
      " 0.51630435 0.5923913  0.65217391 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 164\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 95, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=95,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48695652 0.26521739 0.53043478 0.67391304 0.81521739 0.43478261\n",
      " 0.48913043 0.50543478 0.43478261 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 165\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 186, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, n_estimators=186,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.56086957 0.33043478 0.4173913  0.60434783 0.79891304 0.44565217\n",
      " 0.39130435 0.28804348 0.61956522 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 166\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 151, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=151, random_state=100))])\n",
      "cv score: [0.48478261 0.34565217 0.48043478 0.44130435 0.65217391 0.45380435\n",
      " 0.47282609 0.32608696 0.70923913 0.58967391]\n",
      "----------------------------------------\n",
      "Trial 167\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 60, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=60, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.66956522 0.48695652 0.32173913 0.72173913 0.73369565 0.58695652\n",
      " 0.48369565 0.27173913 0.57608696 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 168\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 24, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=24, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.83478261 0.35217391 0.40869565 0.58695652 0.69021739 0.60869565\n",
      " 0.45652174 0.45108696 0.5        0.61956522]\n",
      "----------------------------------------\n",
      "Trial 169\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 36, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=36,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.56956522 0.40869565 0.40869565 0.63913043 0.71195652 0.5923913\n",
      " 0.36956522 0.29891304 0.68478261 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 170\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 82, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=82, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.7        0.41304348 0.45652174 0.47826087 0.80978261 0.7173913\n",
      " 0.40217391 0.41847826 0.51630435 0.44021739]\n",
      "----------------------------------------\n",
      "Trial 171\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.62608696 0.46521739 0.44347826 0.57391304 0.77173913 0.48369565\n",
      " 0.39130435 0.42391304 0.60869565 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 172\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67391304 0.45217391 0.49565217 0.53913043 0.67934783 0.5326087\n",
      " 0.40217391 0.23369565 0.54891304 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 173\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 128, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            n_estimators=128, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.6173913  0.36521739 0.4        0.46086957 0.73369565 0.45652174\n",
      " 0.42391304 0.27173913 0.70652174 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 174\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 88, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=88,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58695652 0.44347826 0.49130435 0.46956522 0.7826087  0.66847826\n",
      " 0.46195652 0.63043478 0.60326087 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 175\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 134, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=134,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76086957 0.43043478 0.52173913 0.5826087  0.64673913 0.52717391\n",
      " 0.51086957 0.48369565 0.6576087  0.63043478]\n",
      "----------------------------------------\n",
      "Trial 176\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 195, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=195,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52608696 0.32173913 0.50869565 0.59565217 0.96195652 0.47282609\n",
      " 0.50543478 0.65217391 0.55978261 0.44565217]\n",
      "----------------------------------------\n",
      "Trial 177\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=5,\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.53043478 0.34782609 0.41304348 0.42173913 0.71195652 0.42934783\n",
      " 0.47826087 0.3423913  0.66847826 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 178\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 19, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=19, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.64782609 0.27391304 0.28695652 0.2826087  0.5923913  0.41847826\n",
      " 0.49456522 0.47282609 0.50543478 0.36956522]\n",
      "----------------------------------------\n",
      "Trial 179\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 22, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=22,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6326087  0.35869565 0.59565217 0.7326087  0.40217391 0.42119565\n",
      " 0.60597826 0.41032609 0.50815217 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 180\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 182, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            n_estimators=182, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.59130435 0.40869565 0.50434783 0.57391304 0.66304348 0.52173913\n",
      " 0.45108696 0.16304348 0.75543478 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 181\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 128, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=128,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53478261 0.29782609 0.43913043 0.49130435 0.7826087  0.66304348\n",
      " 0.44836957 0.38586957 0.6576087  0.57608696]\n",
      "----------------------------------------\n",
      "Trial 182\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 42, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            n_estimators=42, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.77391304 0.49130435 0.46956522 0.66086957 0.44836957 0.5923913\n",
      " 0.61956522 0.3423913  0.69021739 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 183\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 42, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=42, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.68695652 0.3173913  0.27826087 0.63043478 0.83152174 0.49456522\n",
      " 0.41847826 0.44565217 0.54891304 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 184\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 31, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=31,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62391304 0.22826087 0.55       0.77826087 0.4673913  0.32608696\n",
      " 0.61684783 0.55434783 0.60326087 0.50271739]\n",
      "----------------------------------------\n",
      "Trial 185\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 147, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=147,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76521739 0.42173913 0.43478261 0.6173913  0.67391304 0.59782609\n",
      " 0.48913043 0.47282609 0.69565217 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 186\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47391304 0.27826087 0.47826087 0.54347826 0.81521739 0.4673913\n",
      " 0.47282609 0.48369565 0.56521739 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 187\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=183,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61304348 0.41304348 0.5826087  0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 188\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 85, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            n_estimators=85, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.59565217 0.34782609 0.3826087  0.43478261 0.64673913 0.41304348\n",
      " 0.47826087 0.29891304 0.67934783 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 189\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 165, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=165, random_state=100))])\n",
      "cv score: [0.76956522 0.43913043 0.49130435 0.5173913  0.76086957 0.52173913\n",
      " 0.4673913  0.46195652 0.64130435 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 190\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 136, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=136,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75217391 0.45217391 0.5        0.57391304 0.70108696 0.57065217\n",
      " 0.49456522 0.5        0.68478261 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 191\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 62, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=62,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60217391 0.41304348 0.57826087 0.50869565 0.45652174 0.36956522\n",
      " 0.60869565 0.36956522 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 192\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 36, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=36, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.76521739 0.39130435 0.41304348 0.58695652 0.76630435 0.64673913\n",
      " 0.4673913  0.29891304 0.69565217 0.44565217]\n",
      "----------------------------------------\n",
      "Trial 193\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 116, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=116, random_state=100))])\n",
      "cv score: [0.64782609 0.34782609 0.49130435 0.5173913  0.63586957 0.47282609\n",
      " 0.47826087 0.42391304 0.74456522 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 194\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 186, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=186, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.36521739 0.52391304 0.61521739 0.4326087  0.54347826 0.56521739\n",
      " 0.5951087  0.28532609 0.54347826 0.72282609]\n",
      "----------------------------------------\n",
      "Trial 195\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 32, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=32,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.47391304 0.19130435 0.46956522 0.56956522 0.70108696 0.43478261\n",
      " 0.5326087  0.60326087 0.48913043 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 196\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 64, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            n_estimators=64, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.56521739 0.34347826 0.46956522 0.39565217 0.69565217 0.43478261\n",
      " 0.48913043 0.24456522 0.60869565 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 197\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 160, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=160, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.57826087 0.45217391 0.36956522 0.63913043 0.79347826 0.6576087\n",
      " 0.47282609 0.27173913 0.5326087  0.53804348]\n",
      "----------------------------------------\n",
      "Trial 198\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 41, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=41, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.62173913 0.37391304 0.42173913 0.63478261 0.75       0.57065217\n",
      " 0.4673913  0.33152174 0.60869565 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 199\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 82, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=82,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69565217 0.32173913 0.5826087  0.51304348 0.69021739 0.5\n",
      " 0.50543478 0.5326087  0.53804348 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 200\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 29, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=29,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.8        0.46956522 0.42608696 0.61304348 0.70108696 0.52717391\n",
      " 0.48913043 0.4673913  0.70652174 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 201\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 155, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=2,\n",
      "                                            n_estimators=155, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.53913043 0.47826087 0.4173913  0.50434783 0.61413043 0.50543478\n",
      " 0.47282609 0.56521739 0.51086957 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 202\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 24, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=24,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62826087 0.46304348 0.59565217 0.42608696 0.46195652 0.45652174\n",
      " 0.72826087 0.54619565 0.5        0.48913043]\n",
      "----------------------------------------\n",
      "Trial 203\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 143, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=143, random_state=100))])\n",
      "cv score: [0.73478261 0.43043478 0.50434783 0.48695652 0.73369565 0.55434783\n",
      " 0.46195652 0.45652174 0.625      0.54347826]\n",
      "----------------------------------------\n",
      "Trial 204\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 173, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=173,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75652174 0.44782609 0.4826087  0.6        0.63043478 0.48369565\n",
      " 0.51630435 0.58152174 0.64130435 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 205\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 146, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=146, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.6826087  0.46086957 0.30434783 0.73478261 0.69021739 0.54347826\n",
      " 0.27173913 0.36413043 0.45652174 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 206\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 149, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=5, max_features='log2',\n",
      "                                            n_estimators=149, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.63913043 0.53913043 0.33913043 0.59130435 0.78804348 0.5923913\n",
      " 0.5        0.5        0.60326087 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 207\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 34, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=34, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.63043478 0.3173913  0.41304348 0.6826087  0.63043478 0.65217391\n",
      " 0.44021739 0.22282609 0.51086957 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 208\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 155, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=155, random_state=100))])\n",
      "cv score: [0.72608696 0.43478261 0.43478261 0.56956522 0.69565217 0.72282609\n",
      " 0.45108696 0.35869565 0.65217391 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 209\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 175, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=175,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77391304 0.41304348 0.47391304 0.63043478 0.73913043 0.59782609\n",
      " 0.45652174 0.33152174 0.66304348 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 210\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 50, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=50, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.66086957 0.50434783 0.30869565 0.57826087 0.57608696 0.69565217\n",
      " 0.51086957 0.44021739 0.625      0.48913043]\n",
      "----------------------------------------\n",
      "Trial 211\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 97, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=97, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.73913043 0.42608696 0.48695652 0.53478261 0.70652174 0.54891304\n",
      " 0.46195652 0.44565217 0.66304348 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 212\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 111, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=111,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.65217391 0.35652174 0.46086957 0.56086957 0.78804348 0.61956522\n",
      " 0.41304348 0.2826087  0.65217391 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 213\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 173, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=173,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69565217 0.33913043 0.58695652 0.4826087  0.67934783 0.63586957\n",
      " 0.54891304 0.59782609 0.54891304 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 214\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 75, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=75,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.67391304 0.40869565 0.4826087  0.53478261 0.73913043 0.5326087\n",
      " 0.45652174 0.35326087 0.6576087  0.61956522]\n",
      "----------------------------------------\n",
      "Trial 215\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=115, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.69565217 0.5173913  0.46086957 0.56956522 0.60869565 0.55978261\n",
      " 0.54076087 0.69565217 0.22826087 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 216\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 161, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            n_estimators=161, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.56956522 0.34347826 0.44782609 0.46521739 0.69565217 0.49456522\n",
      " 0.44021739 0.35869565 0.73369565 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 217\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 96, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=96,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.51304348 0.25217391 0.55652174 0.43043478 0.79347826 0.61413043\n",
      " 0.5326087  0.42934783 0.60326087 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 218\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 128, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=128, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.76521739 0.42608696 0.49130435 0.52608696 0.69021739 0.57608696\n",
      " 0.51086957 0.47826087 0.66847826 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 219\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 113, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=113, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.5826087  0.12826087 0.25217391 0.40869565 0.32608696 0.51358696\n",
      " 0.52173913 0.31521739 0.42934783 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 220\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 158, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=158,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74782609 0.35217391 0.55652174 0.51304348 0.69021739 0.44565217\n",
      " 0.56521739 0.50543478 0.59782609 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 221\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 139, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=139,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55652174 0.27608696 0.43478261 0.49565217 0.83152174 0.64673913\n",
      " 0.44836957 0.38315217 0.6576087  0.57065217]\n",
      "----------------------------------------\n",
      "Trial 222\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.74782609 0.34782609 0.5        0.51304348 0.54619565 0.57336957\n",
      " 0.54347826 0.5        0.59782609 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 223\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 85, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=85,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54347826 0.32173913 0.55217391 0.60869565 0.76630435 0.54347826\n",
      " 0.5326087  0.51630435 0.46195652 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 224\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 20, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=20,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.79130435 0.3326087  0.55217391 0.49130435 0.77717391 0.61413043\n",
      " 0.59782609 0.44293478 0.58695652 0.57336957]\n",
      "----------------------------------------\n",
      "Trial 225\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 150, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            n_estimators=150,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.56956522 0.28695652 0.46956522 0.66956522 0.45652174 0.36956522\n",
      " 0.4673913  0.39130435 0.67934783 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 226\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 142, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=142, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.7173913  0.70434783 0.48695652 0.33695652 0.5923913  0.4076087\n",
      " 0.29891304 0.5923913  0.5        0.21195652]\n",
      "----------------------------------------\n",
      "Trial 227\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 121, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=121,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.45217391 0.24782609 0.53478261 0.65217391 0.76630435 0.5326087\n",
      " 0.52173913 0.49456522 0.54347826 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 228\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 117, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, max_features='log2',\n",
      "                                            n_estimators=117, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.59130435 0.34782609 0.43043478 0.69130435 0.7173913  0.58695652\n",
      " 0.39673913 0.44021739 0.5326087  0.61413043]\n",
      "----------------------------------------\n",
      "Trial 229\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 54, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=54, random_state=100))])\n",
      "cv score: [0.56086957 0.37173913 0.44565217 0.52173913 0.58152174 0.63315217\n",
      " 0.4673913  0.30163043 0.60326087 0.49728261]\n",
      "----------------------------------------\n",
      "Trial 230\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 136, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=136,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61304348 0.49130435 0.58478261 0.42608696 0.60054348 0.47826087\n",
      " 0.75271739 0.38586957 0.52173913 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 231\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 189, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, max_features='log2',\n",
      "                                            n_estimators=189, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.65217391 0.56086957 0.46521739 0.56521739 0.76630435 0.54347826\n",
      " 0.4673913  0.47282609 0.58152174 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 232\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 81, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=81,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58695652 0.42826087 0.48695652 0.55217391 0.41847826 0.57880435\n",
      " 0.54347826 0.42663043 0.7173913  0.49456522]\n",
      "----------------------------------------\n",
      "Trial 233\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 19, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=19,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.71956522 0.47826087 0.40434783 0.60869565 0.65217391 0.4375\n",
      " 0.51630435 0.48913043 0.50543478 0.64673913]\n",
      "----------------------------------------\n",
      "Trial 234\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 169, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=169, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.55652174 0.49130435 0.40434783 0.56521739 0.64130435 0.625\n",
      " 0.35869565 0.35869565 0.60869565 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 235\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.57391304 0.59565217 0.36086957 0.70869565 0.80434783 0.59782609\n",
      " 0.42934783 0.42391304 0.47826087 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 236\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53913043 0.22173913 0.53478261 0.47391304 0.78804348 0.51630435\n",
      " 0.49456522 0.51086957 0.56521739 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 237\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=108,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75652174 0.44782609 0.52173913 0.56956522 0.6576087  0.51086957\n",
      " 0.51630435 0.46195652 0.66304348 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 238\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 140, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            n_estimators=140, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.55217391 0.42173913 0.44347826 0.56086957 0.72826087 0.47826087\n",
      " 0.45652174 0.26630435 0.74456522 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 239\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 149, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=149, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.58695652 0.4        0.37391304 0.53478261 0.67391304 0.64130435\n",
      " 0.48913043 0.42934783 0.60869565 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 240\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 13, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=4,\n",
      "                                            n_estimators=13, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.72826087 0.49130435 0.36956522 0.62608696 0.50815217 0.53804348\n",
      " 0.47282609 0.48369565 0.66304348 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 241\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 162, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=162, random_state=100))])\n",
      "cv score: [0.86521739 0.42608696 0.49565217 0.56956522 0.67934783 0.57065217\n",
      " 0.52717391 0.5326087  0.63043478 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 242\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 186, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=186,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75217391 0.43043478 0.44347826 0.61304348 0.70108696 0.5923913\n",
      " 0.48369565 0.44021739 0.69021739 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 243\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 23, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=23,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50434783 0.24782609 0.55217391 0.52173913 0.77173913 0.51630435\n",
      " 0.5        0.4076087  0.54347826 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 244\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 127, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=127, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.80434783 0.42608696 0.42173913 0.5173913  0.7173913  0.57608696\n",
      " 0.48369565 0.44021739 0.58695652 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 245\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 74, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=74,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56521739 0.26956522 0.51304348 0.60434783 0.82065217 0.44565217\n",
      " 0.5326087  0.27173913 0.625      0.55434783]\n",
      "----------------------------------------\n",
      "Trial 246\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 194, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=194,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57391304 0.49565217 0.58695652 0.43478261 0.38586957 0.5\n",
      " 0.64673913 0.45652174 0.60597826 0.58423913]\n",
      "----------------------------------------\n",
      "Trial 247\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 181, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=181,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76086957 0.36521739 0.46521739 0.56086957 0.71195652 0.63043478\n",
      " 0.46195652 0.38586957 0.67391304 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 248\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 166, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=166,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.3826087  0.2        0.43043478 0.41304348 0.75       0.49456522\n",
      " 0.2826087  0.63586957 0.57608696 0.48913043]\n",
      "----------------------------------------\n",
      "Trial 249\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=13,\n",
      "                                            n_estimators=115, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.46086957 0.3826087  0.60434783 0.43913043 0.57065217 0.52717391\n",
      " 0.50543478 0.47826087 0.73913043 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 250\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 135, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=135, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.34130435 0.59782609 0.35652174 0.5826087  0.58152174 0.38043478\n",
      " 0.54891304 0.36413043 0.25       0.59782609]\n",
      "----------------------------------------\n",
      "Trial 251\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 175, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, max_features='log2',\n",
      "                                            n_estimators=175, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.63478261 0.4826087  0.37826087 0.59565217 0.73369565 0.63586957\n",
      " 0.47282609 0.35869565 0.64673913 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 252\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=183,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.52173913 0.40869565 0.37826087 0.5173913  0.71195652 0.54891304\n",
      " 0.44021739 0.22826087 0.67391304 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 253\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 140, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=140,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6326087  0.41956522 0.46956522 0.43913043 0.47282609 0.47826087\n",
      " 0.74728261 0.50271739 0.48913043 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 254\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=198, random_state=100))])\n",
      "cv score: [0.6826087  0.42173913 0.43478261 0.54347826 0.73369565 0.71195652\n",
      " 0.44021739 0.38586957 0.64673913 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 255\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 82, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, n_estimators=82,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.67826087 0.30434783 0.3        0.54347826 0.72826087 0.46195652\n",
      " 0.43478261 0.39673913 0.49456522 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 256\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 48, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=48, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.60434783 0.26521739 0.38695652 0.5826087  0.7173913  0.5326087\n",
      " 0.40217391 0.48913043 0.49456522 0.38586957]\n",
      "----------------------------------------\n",
      "Trial 257\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 99, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=99,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.7173913  0.26086957 0.56086957 0.53913043 0.75       0.60869565\n",
      " 0.48913043 0.47282609 0.59782609 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 258\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=102,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76521739 0.4173913  0.46086957 0.61304348 0.66847826 0.58695652\n",
      " 0.47826087 0.50543478 0.71195652 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 259\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 138, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=138, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.73478261 0.35652174 0.50434783 0.56086957 0.76630435 0.6576087\n",
      " 0.45108696 0.32608696 0.60869565 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 260\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 180, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=180,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52173913 0.29130435 0.49565217 0.47826087 0.77717391 0.5326087\n",
      " 0.33152174 0.63043478 0.56521739 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 261\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 84, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=84, random_state=100))])\n",
      "cv score: [0.62173913 0.36956522 0.44347826 0.50217391 0.51086957 0.6576087\n",
      " 0.44293478 0.3423913  0.64945652 0.47282609]\n",
      "----------------------------------------\n",
      "Trial 262\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 111, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=111, random_state=100))])\n",
      "cv score: [0.51304348 0.32391304 0.52826087 0.46304348 0.58695652 0.46195652\n",
      " 0.48097826 0.32880435 0.75543478 0.64402174]\n",
      "----------------------------------------\n",
      "Trial 263\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 172, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=172, random_state=100))])\n",
      "cv score: [0.86521739 0.40869565 0.50434783 0.57391304 0.66847826 0.56521739\n",
      " 0.50543478 0.5326087  0.60869565 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 264\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 184, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=184,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75869565 0.47826087 0.52173913 0.60434783 0.61413043 0.5\n",
      " 0.54891304 0.63043478 0.61956522 0.66847826]\n",
      "----------------------------------------\n",
      "Trial 265\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 74, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=74,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53478261 0.23043478 0.5173913  0.66086957 0.67934783 0.44021739\n",
      " 0.36413043 0.72826087 0.57608696 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 266\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 142, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=142, random_state=100))])\n",
      "cv score: [0.75217391 0.45217391 0.52173913 0.53478261 0.70108696 0.54891304\n",
      " 0.57608696 0.55434783 0.50543478 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 267\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 25, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=25,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6326087  0.35869565 0.59565217 0.7326087  0.40217391 0.42119565\n",
      " 0.60597826 0.41032609 0.50815217 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 268\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 190, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=190, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.62608696 0.3826087  0.43043478 0.46521739 0.80978261 0.67934783\n",
      " 0.46195652 0.31521739 0.66847826 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 269\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 127, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=127, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.75217391 0.40869565 0.53913043 0.53043478 0.73913043 0.5326087\n",
      " 0.49456522 0.4673913  0.56521739 0.64673913]\n",
      "----------------------------------------\n",
      "Trial 270\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 83, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=83, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.69565217 0.42608696 0.45217391 0.57826087 0.73913043 0.59782609\n",
      " 0.47826087 0.47282609 0.64673913 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 271\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 84, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=84,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.53913043 0.2173913  0.54347826 0.47391304 0.80978261 0.60326087\n",
      " 0.46195652 0.47282609 0.57608696 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 272\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 38, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            n_estimators=38, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.52173913 0.4826087  0.40434783 0.45217391 0.52717391 0.43478261\n",
      " 0.30978261 0.60869565 0.45652174 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 273\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 187, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt', n_estimators=187,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64347826 0.3173913  0.4173913  0.49130435 0.79891304 0.64673913\n",
      " 0.44021739 0.33695652 0.66304348 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 274\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 56, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=56,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.67826087 0.32608696 0.5        0.56956522 0.77717391 0.65217391\n",
      " 0.44565217 0.3423913  0.61956522 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 275\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=95, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.51304348 0.37826087 0.4826087  0.59130435 0.875      0.51630435\n",
      " 0.4076087  0.64130435 0.49456522 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 276\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 54, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=54, random_state=100))])\n",
      "cv score: [0.72173913 0.37391304 0.48695652 0.53478261 0.47826087 0.47282609\n",
      " 0.60054348 0.60326087 0.68478261 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 277\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6        0.37826087 0.43913043 0.50869565 0.7173913  0.40217391\n",
      " 0.5326087  0.57065217 0.41847826 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 278\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42173913 0.25217391 0.45217391 0.42608696 0.76086957 0.5326087\n",
      " 0.50543478 0.50543478 0.36413043 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 279\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 141, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=141,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57391304 0.23913043 0.55217391 0.55652174 0.68478261 0.46195652\n",
      " 0.51086957 0.5326087  0.54891304 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 280\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 158, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=158, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.72173913 0.43043478 0.5        0.59565217 0.66847826 0.57065217\n",
      " 0.45652174 0.42391304 0.67934783 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 281\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=38,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61304348 0.41304348 0.58695652 0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 282\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 83, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=83, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.73478261 0.41304348 0.49130435 0.56521739 0.7173913  0.54891304\n",
      " 0.45652174 0.47826087 0.6576087  0.625     ]\n",
      "----------------------------------------\n",
      "Trial 283\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 172, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=172,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57826087 0.3826087  0.43043478 0.64347826 0.77717391 0.5923913\n",
      " 0.46195652 0.375      0.70652174 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 284\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 42, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=42,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66086957 0.32608696 0.51304348 0.56521739 0.76630435 0.57065217\n",
      " 0.41847826 0.38586957 0.61956522 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 285\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=68,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.76521739 0.4173913  0.5        0.45217391 0.61956522 0.50543478\n",
      " 0.43478261 0.5923913  0.63043478 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 286\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 143, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            n_estimators=143, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.56956522 0.45652174 0.43478261 0.74782609 0.66847826 0.44565217\n",
      " 0.5326087  0.21195652 0.63043478 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 287\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 104, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=104,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63043478 0.3        0.55217391 0.49565217 0.77173913 0.5\n",
      " 0.51630435 0.45108696 0.63043478 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 288\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 116, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=116, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.63043478 0.39130435 0.38695652 0.54347826 0.78804348 0.61956522\n",
      " 0.48913043 0.31521739 0.6576087  0.57608696]\n",
      "----------------------------------------\n",
      "Trial 289\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 84, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=84,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59565217 0.33913043 0.40869565 0.56956522 0.5326087  0.50543478\n",
      " 0.375      0.58695652 0.52717391 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 290\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 113, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=113, random_state=100))])\n",
      "cv score: [0.76521739 0.46956522 0.5        0.53913043 0.64673913 0.625\n",
      " 0.57065217 0.57608696 0.47282609 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 291\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 24, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=24,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65217391 0.45217391 0.61086957 0.42173913 0.55163043 0.46195652\n",
      " 0.69565217 0.38043478 0.56521739 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 292\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62173913 0.42826087 0.57173913 0.47173913 0.64402174 0.51630435\n",
      " 0.75543478 0.55163043 0.50815217 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 293\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 60, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=60,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62173913 0.46521739 0.57608696 0.42608696 0.60326087 0.47826087\n",
      " 0.72826087 0.76358696 0.54347826 0.5951087 ]\n",
      "----------------------------------------\n",
      "Trial 294\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 129, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            n_estimators=129, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.75652174 0.39565217 0.47391304 0.52608696 0.72826087 0.56521739\n",
      " 0.54347826 0.35326087 0.65217391 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 295\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=108,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77826087 0.43478261 0.52173913 0.58695652 0.65217391 0.49728261\n",
      " 0.51086957 0.55978261 0.61413043 0.66304348]\n",
      "----------------------------------------\n",
      "Trial 296\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 54, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=54,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66086957 0.4173913  0.48043478 0.5        0.7173913  0.47826087\n",
      " 0.52173913 0.44565217 0.68478261 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 297\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 60, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=60,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60217391 0.41304348 0.57826087 0.50869565 0.45652174 0.36956522\n",
      " 0.60869565 0.36956522 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 298\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 167, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=167,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64347826 0.30869565 0.43043478 0.50869565 0.78804348 0.65217391\n",
      " 0.45108696 0.33695652 0.66847826 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 299\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 176, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=176, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.3173913  0.59130435 0.23043478 0.57826087 0.7173913  0.51630435\n",
      " 0.30434783 0.56521739 0.51630435 0.75      ]\n",
      "----------------------------------------\n",
      "Trial 300\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 173, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=173,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43043478 0.4173913  0.59565217 0.53913043 0.81521739 0.4673913\n",
      " 0.45108696 0.58695652 0.4673913  0.67391304]\n",
      "----------------------------------------\n",
      "Trial 301\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='log2',\n",
      "                                            n_estimators=121, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.72608696 0.42608696 0.47391304 0.5173913  0.81521739 0.55434783\n",
      " 0.4076087  0.625      0.5326087  0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 302\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 137, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=137,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62826087 0.29347826 0.58043478 0.77826087 0.39945652 0.39673913\n",
      " 0.64130435 0.61956522 0.48369565 0.47554348]\n",
      "----------------------------------------\n",
      "Trial 303\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 141, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=141, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.6173913  0.43043478 0.51304348 0.52173913 0.76086957 0.60326087\n",
      " 0.41847826 0.41304348 0.55978261 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 304\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 175, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=175,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49130435 0.2826087  0.46521739 0.55652174 0.91304348 0.4673913\n",
      " 0.38043478 0.65217391 0.49456522 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 305\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 93, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=93, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.7826087  0.5        0.48695652 0.52173913 0.83695652 0.6576087\n",
      " 0.44021739 0.63043478 0.61413043 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 306\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 91, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=91,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66086957 0.39565217 0.53043478 0.51304348 0.67391304 0.45652174\n",
      " 0.54347826 0.40217391 0.63586957 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 307\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 63, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=63, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.7173913  0.26956522 0.62173913 0.43478261 0.69565217 0.68206522\n",
      " 0.42934783 0.39673913 0.875      0.52717391]\n",
      "----------------------------------------\n",
      "Trial 308\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 141, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, max_features='log2',\n",
      "                                            n_estimators=141, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.65652174 0.46521739 0.42608696 0.54347826 0.76086957 0.63043478\n",
      " 0.5        0.375      0.66304348 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 309\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55652174 0.37391304 0.39565217 0.39130435 0.73913043 0.48913043\n",
      " 0.34782609 0.61413043 0.63043478 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 310\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 42, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=42, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65652174 0.66086957 0.39130435 0.6173913  0.7826087  0.39130435\n",
      " 0.5        0.35326087 0.44565217 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 311\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 79, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, max_features='sqrt',\n",
      "                                            n_estimators=79, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.57826087 0.5        0.43043478 0.62173913 0.69021739 0.61413043\n",
      " 0.45652174 0.39673913 0.46195652 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 312\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53913043 0.3        0.54347826 0.50434783 0.75       0.55978261\n",
      " 0.53804348 0.42934783 0.56521739 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 313\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 100, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61086957 0.44347826 0.59565217 0.51304348 0.73913043 0.5326087\n",
      " 0.6548913  0.40217391 0.47282609 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 314\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 112, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            n_estimators=112, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.52173913 0.30869565 0.49565217 0.44782609 0.67391304 0.54891304\n",
      " 0.48913043 0.31521739 0.72826087 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 315\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 194, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=194, random_state=100))])\n",
      "cv score: [0.63478261 0.44782609 0.3826087  0.54782609 0.73913043 0.75\n",
      " 0.44565217 0.3423913  0.60326087 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 316\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 161, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=161,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60217391 0.41304348 0.57826087 0.50869565 0.45652174 0.36956522\n",
      " 0.60326087 0.36956522 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 317\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 96, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            n_estimators=96, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.36521739 0.39130435 0.57391304 0.44782609 0.56521739 0.56521739\n",
      " 0.51630435 0.45652174 0.66304348 0.73913043]\n",
      "----------------------------------------\n",
      "Trial 318\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48695652 0.25652174 0.57826087 0.5826087  0.74456522 0.46195652\n",
      " 0.33695652 0.58695652 0.4076087  0.61413043]\n",
      "----------------------------------------\n",
      "Trial 319\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 120, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=120,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75869565 0.47608696 0.53043478 0.59565217 0.59782609 0.50543478\n",
      " 0.5326087  0.5923913  0.59782609 0.68478261]\n",
      "----------------------------------------\n",
      "Trial 320\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 14, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, max_features='sqrt',\n",
      "                                            n_estimators=14, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.46521739 0.43043478 0.44347826 0.47391304 0.69021739 0.60326087\n",
      " 0.44565217 0.23913043 0.57608696 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 321\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 175, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            n_estimators=175, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.60869565 0.7826087  0.39130435 0.60434783 0.52717391 0.45380435\n",
      " 0.25543478 0.40217391 0.49728261 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 322\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 35, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=35, random_state=100))])\n",
      "cv score: [0.56521739 0.39347826 0.49565217 0.51956522 0.59782609 0.54619565\n",
      " 0.58152174 0.35869565 0.71467391 0.66576087]\n",
      "----------------------------------------\n",
      "Trial 323\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 167, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=167, random_state=100))])\n",
      "cv score: [0.60869565 0.49130435 0.41304348 0.55217391 0.7173913  0.75543478\n",
      " 0.45108696 0.33695652 0.59782609 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 324\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 60, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=60,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76086957 0.43478261 0.49565217 0.61304348 0.64673913 0.67391304\n",
      " 0.47282609 0.24456522 0.68478261 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 325\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.63478261 0.34782609 0.49565217 0.46521739 0.63043478 0.45652174\n",
      " 0.42934783 0.32065217 0.70652174 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 326\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 127, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=127, random_state=100))])\n",
      "cv score: [0.62173913 0.5        0.37391304 0.56086957 0.54347826 0.73913043\n",
      " 0.44565217 0.26086957 0.57608696 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 327\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 23, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=23, random_state=100))])\n",
      "cv score: [0.67391304 0.27391304 0.53043478 0.55217391 0.61956522 0.66847826\n",
      " 0.375      0.23913043 0.58152174 0.46195652]\n",
      "----------------------------------------\n",
      "Trial 328\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 162, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=9,\n",
      "                                            n_estimators=162,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.48695652 0.44782609 0.36956522 0.64782609 0.60869565 0.44565217\n",
      " 0.51630435 0.25543478 0.73913043 0.47282609]\n",
      "----------------------------------------\n",
      "Trial 329\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 89, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=89,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.32173913 0.34782609 0.49565217 0.59130435 0.79347826 0.52173913\n",
      " 0.3423913  0.64130435 0.49456522 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 330\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.63478261 0.33478261 0.3826087  0.62608696 0.72826087 0.6576087\n",
      " 0.45652174 0.29347826 0.60326087 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 331\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 120, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=120,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76521739 0.44782609 0.50869565 0.59130435 0.63586957 0.49728261\n",
      " 0.51630435 0.55978261 0.61956522 0.66304348]\n",
      "----------------------------------------\n",
      "Trial 332\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 111, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=111,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.74782609 0.42608696 0.45217391 0.60869565 0.67934783 0.57608696\n",
      " 0.48369565 0.49456522 0.71195652 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 333\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 16, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=16,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.58478261 0.3326087  0.61086957 0.53913043 0.63586957 0.45108696\n",
      " 0.58695652 0.52717391 0.63043478 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 334\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 63, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=63, random_state=100))])\n",
      "cv score: [0.72608696 0.42608696 0.44347826 0.56956522 0.66304348 0.63586957\n",
      " 0.36956522 0.29347826 0.7173913  0.58152174]\n",
      "----------------------------------------\n",
      "Trial 335\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 20, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=20,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76521739 0.30652174 0.47391304 0.5326087  0.63315217 0.64945652\n",
      " 0.41304348 0.38315217 0.70108696 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 336\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 117, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=117,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63913043 0.30434783 0.56956522 0.55217391 0.68478261 0.60869565\n",
      " 0.44565217 0.57065217 0.58695652 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 337\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 188, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=188, random_state=100))])\n",
      "cv score: [0.65217391 0.44347826 0.40434783 0.51304348 0.72282609 0.69021739\n",
      " 0.44565217 0.41304348 0.59782609 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 338\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 111, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            n_estimators=111, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.7173913  0.53913043 0.56086957 0.75652174 0.63043478 0.57065217\n",
      " 0.56521739 0.36413043 0.69021739 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 339\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 132, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            n_estimators=132, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.56956522 0.35652174 0.47826087 0.61304348 0.73913043 0.52717391\n",
      " 0.49456522 0.26630435 0.71195652 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 340\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 85, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=85, random_state=100))])\n",
      "cv score: [0.65217391 0.33695652 0.43913043 0.54782609 0.57608696 0.63315217\n",
      " 0.47554348 0.35597826 0.61413043 0.47282609]\n",
      "----------------------------------------\n",
      "Trial 341\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 142, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=142, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.76956522 0.4826087  0.4173913  0.54782609 0.7826087  0.54347826\n",
      " 0.42391304 0.27717391 0.57608696 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 342\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 181, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=181, random_state=100))])\n",
      "cv score: [0.56521739 0.4        0.5173913  0.40869565 0.67391304 0.41847826\n",
      " 0.4673913  0.32065217 0.70652174 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 343\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=168, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.5173913  0.46956522 0.39565217 0.4826087  0.76630435 0.60326087\n",
      " 0.43478261 0.66847826 0.49456522 0.66304348]\n",
      "----------------------------------------\n",
      "Trial 344\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 80, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=80,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55652174 0.3173913  0.53043478 0.44347826 0.70652174 0.45652174\n",
      " 0.55434783 0.36956522 0.625      0.58152174]\n",
      "----------------------------------------\n",
      "Trial 345\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 140, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            n_estimators=140, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57826087 0.3826087  0.48695652 0.42608696 0.66304348 0.47826087\n",
      " 0.44021739 0.25543478 0.77717391 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 346\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 139, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=139, random_state=100))])\n",
      "cv score: [0.80434783 0.44782609 0.51304348 0.49565217 0.60869565 0.58152174\n",
      " 0.49456522 0.58695652 0.58152174 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 347\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 45, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=45,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73043478 0.44782609 0.41304348 0.60869565 0.7173913  0.57065217\n",
      " 0.43478261 0.51086957 0.7173913  0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 348\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 32, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=32,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39130435 0.20434783 0.57391304 0.53043478 0.85869565 0.49456522\n",
      " 0.43478261 0.57608696 0.48913043 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 349\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 191, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=191,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.7        0.35652174 0.62173913 0.55217391 0.60326087 0.55434783\n",
      " 0.60869565 0.51630435 0.64673913 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 350\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 110, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=110,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.63913043 0.30434783 0.4173913  0.54347826 0.67934783 0.67934783\n",
      " 0.3423913  0.30978261 0.65217391 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 351\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 32, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=32, random_state=100))])\n",
      "cv score: [0.57173913 0.41521739 0.51086957 0.53913043 0.55978261 0.49728261\n",
      " 0.58423913 0.36956522 0.70652174 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 352\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 193, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=193,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49565217 0.27391304 0.53043478 0.57826087 0.79891304 0.49456522\n",
      " 0.45108696 0.61956522 0.52717391 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 353\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=108,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77826087 0.43478261 0.52173913 0.58695652 0.65217391 0.49728261\n",
      " 0.51086957 0.55978261 0.61413043 0.66304348]\n",
      "----------------------------------------\n",
      "Trial 354\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 26, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=26, random_state=100))])\n",
      "cv score: [0.87826087 0.41521739 0.51304348 0.52173913 0.54347826 0.53804348\n",
      " 0.4673913  0.375      0.77717391 0.48913043]\n",
      "----------------------------------------\n",
      "Trial 355\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 185, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=185, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.59130435 0.47391304 0.40869565 0.59130435 0.76086957 0.53804348\n",
      " 0.43478261 0.33152174 0.47826087 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 356\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 149, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=149, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.71304348 0.46086957 0.49130435 0.59130435 0.63586957 0.55978261\n",
      " 0.51630435 0.60326087 0.55978261 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 357\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 52, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=52,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50869565 0.28695652 0.56956522 0.53913043 0.70652174 0.51086957\n",
      " 0.5        0.43478261 0.57608696 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 358\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 155, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=155, random_state=100))])\n",
      "cv score: [0.77391304 0.46086957 0.47826087 0.56521739 0.64673913 0.57608696\n",
      " 0.60869565 0.58152174 0.57065217 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 359\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64347826 0.4826087  0.56956522 0.4673913  0.7201087  0.60326087\n",
      " 0.7173913  0.48641304 0.55434783 0.4701087 ]\n",
      "----------------------------------------\n",
      "Trial 360\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 95, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=95,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54347826 0.23478261 0.53913043 0.5        0.73913043 0.50543478\n",
      " 0.54347826 0.39673913 0.58695652 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 361\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 120, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, max_features='log2',\n",
      "                                            n_estimators=120, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.59130435 0.4173913  0.49130435 0.59130435 0.72826087 0.61956522\n",
      " 0.3423913  0.35869565 0.60326087 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 362\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 66, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            n_estimators=66, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.57391304 0.33913043 0.54347826 0.42608696 0.76086957 0.41847826\n",
      " 0.39673913 0.29891304 0.74456522 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 363\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 19, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=19,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66086957 0.43695652 0.6826087  0.4173913  0.60597826 0.47282609\n",
      " 0.66847826 0.32608696 0.5        0.63858696]\n",
      "----------------------------------------\n",
      "Trial 364\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 60, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=60, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.73913043 0.42173913 0.46086957 0.56086957 0.58695652 0.52173913\n",
      " 0.47826087 0.625      0.54891304 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 365\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 130, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=130, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57826087 0.55652174 0.36086957 0.7173913  0.79347826 0.57065217\n",
      " 0.41304348 0.42391304 0.50543478 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 366\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=16,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61521739 0.41304348 0.57826087 0.50869565 0.45652174 0.36956522\n",
      " 0.61413043 0.36956522 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 367\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 107, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=107,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73478261 0.41521739 0.5826087  0.46086957 0.50271739 0.39402174\n",
      " 0.62228261 0.3423913  0.625      0.57608696]\n",
      "----------------------------------------\n",
      "Trial 368\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 151, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=9,\n",
      "                                            n_estimators=151, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.67826087 0.33478261 0.41304348 0.47391304 0.71195652 0.55978261\n",
      " 0.45108696 0.23913043 0.72282609 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 369\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 129, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, n_estimators=129,\n",
      "                                            random_state=100, subsample=0.6))])\n",
      "cv score: [0.55217391 0.37391304 0.4826087  0.36521739 0.70652174 0.54347826\n",
      " 0.4076087  0.36413043 0.68478261 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 370\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 31, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=31, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.83043478 0.42173913 0.47826087 0.47391304 0.65217391 0.60054348\n",
      " 0.49456522 0.58695652 0.50543478 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 371\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 134, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=134, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.62608696 0.3826087  0.43913043 0.5173913  0.77173913 0.55434783\n",
      " 0.44565217 0.34782609 0.61956522 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 372\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 59, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=59, random_state=100))])\n",
      "cv score: [0.57391304 0.53478261 0.4        0.54782609 0.5        0.67934783\n",
      " 0.4076087  0.22826087 0.61413043 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 373\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            random_state=100, subsample=0.7))])\n",
      "cv score: [0.58695652 0.43478261 0.41304348 0.53913043 0.71195652 0.63043478\n",
      " 0.45108696 0.375      0.51630435 0.47282609]\n",
      "----------------------------------------\n",
      "Trial 374\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 149, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=149,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39565217 0.37826087 0.59130435 0.6        0.73369565 0.4076087\n",
      " 0.54347826 0.40217391 0.40217391 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 375\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 55, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=55, random_state=100))])\n",
      "cv score: [0.57826087 0.37173913 0.44565217 0.50217391 0.55978261 0.64402174\n",
      " 0.47282609 0.30434783 0.60326087 0.49184783]\n",
      "----------------------------------------\n",
      "Trial 376\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 190, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=190,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75217391 0.43043478 0.43043478 0.63478261 0.70652174 0.59782609\n",
      " 0.47826087 0.44565217 0.68478261 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 377\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=115,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62608696 0.32173913 0.45217391 0.49565217 0.80434783 0.67391304\n",
      " 0.44565217 0.25543478 0.6548913  0.58152174]\n",
      "----------------------------------------\n",
      "Trial 378\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49565217 0.26956522 0.56521739 0.45217391 0.71195652 0.61413043\n",
      " 0.33695652 0.48369565 0.43478261 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 379\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 154, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=154,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60869565 0.47608696 0.56956522 0.42608696 0.64130435 0.45108696\n",
      " 0.78804348 0.33423913 0.51902174 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 380\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 143, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=143,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76086957 0.44782609 0.4826087  0.59565217 0.63586957 0.49456522\n",
      " 0.51630435 0.59782609 0.65217391 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 381\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 47, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=47, random_state=100))])\n",
      "cv score: [0.61304348 0.37826087 0.50434783 0.52608696 0.63043478 0.51630435\n",
      " 0.4673913  0.32065217 0.7201087  0.56521739]\n",
      "----------------------------------------\n",
      "Trial 382\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 117, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=117,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64782609 0.44347826 0.57826087 0.43478261 0.73641304 0.47282609\n",
      " 0.75543478 0.4673913  0.53532609 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 383\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 57, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=57,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53043478 0.29130435 0.58695652 0.56086957 0.86956522 0.42391304\n",
      " 0.47826087 0.74456522 0.42391304 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 384\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 55, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=55, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.64782609 0.49565217 0.51304348 0.48695652 0.68478261 0.57065217\n",
      " 0.48913043 0.52173913 0.64130435 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 385\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 126, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=126,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49565217 0.36086957 0.43043478 0.53043478 0.68478261 0.51630435\n",
      " 0.38043478 0.53804348 0.51630435 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 386\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63043478 0.30869565 0.56521739 0.5        0.69021739 0.51630435\n",
      " 0.55978261 0.47282609 0.63043478 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 387\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 54, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            n_estimators=54, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.74347826 0.35652174 0.50434783 0.57391304 0.56521739 0.5326087\n",
      " 0.51630435 0.42934783 0.60326087 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 388\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 161, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=161, random_state=100))])\n",
      "cv score: [0.59130435 0.38695652 0.47391304 0.48695652 0.65217391 0.52717391\n",
      " 0.48369565 0.35326087 0.70108696 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 389\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 99, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=99,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.75652174 0.35652174 0.56521739 0.58695652 0.58152174 0.49456522\n",
      " 0.5923913  0.52173913 0.5923913  0.63043478]\n",
      "----------------------------------------\n",
      "Trial 390\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 82, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=82, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.71304348 0.44347826 0.46956522 0.51304348 0.67934783 0.58695652\n",
      " 0.48369565 0.57608696 0.51086957 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 391\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=133,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60434783 0.41304348 0.57826087 0.5173913  0.45652174 0.36956522\n",
      " 0.60326087 0.40217391 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 392\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 103, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=103,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61304348 0.41304348 0.5826087  0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 393\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 140, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=140, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.60434783 0.39130435 0.40434783 0.54782609 0.76086957 0.64130435\n",
      " 0.47282609 0.39673913 0.63586957 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 394\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 159, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            n_estimators=159, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.58695652 0.32608696 0.44782609 0.52173913 0.55978261 0.41847826\n",
      " 0.41847826 0.30978261 0.57065217 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 395\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 88, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=88,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65217391 0.36521739 0.49130435 0.62173913 0.82608696 0.63043478\n",
      " 0.4673913  0.41304348 0.69021739 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 396\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 182, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=182, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62608696 0.55652174 0.46956522 0.79130435 0.48913043 0.625\n",
      " 0.61956522 0.44021739 0.51630435 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 397\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 10, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            n_estimators=10, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.74130435 0.45869565 0.57391304 0.61521739 0.45380435 0.58695652\n",
      " 0.63586957 0.30163043 0.67391304 0.69293478]\n",
      "----------------------------------------\n",
      "Trial 398\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 164, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=164,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50869565 0.27391304 0.50434783 0.50434783 0.77717391 0.43478261\n",
      " 0.3423913  0.74456522 0.47826087 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 399\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 41, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=41,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62173913 0.43913043 0.60434783 0.42173913 0.55978261 0.47826087\n",
      " 0.64945652 0.35326087 0.57336957 0.58967391]\n",
      "----------------------------------------\n",
      "Trial 400\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 130, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=130,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44782609 0.27391304 0.53913043 0.54347826 0.73913043 0.51630435\n",
      " 0.51086957 0.51086957 0.48913043 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 401\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 110, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=110,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71521739 0.45652174 0.60869565 0.41304348 0.70652174 0.56793478\n",
      " 0.69293478 0.32336957 0.51086957 0.51358696]\n",
      "----------------------------------------\n",
      "Trial 402\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=197,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.74782609 0.45652174 0.5        0.5826087  0.64673913 0.52173913\n",
      " 0.50543478 0.51086957 0.66304348 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 403\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 186, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=186, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.69565217 0.39565217 0.36956522 0.5        0.7173913  0.61413043\n",
      " 0.48913043 0.41304348 0.6576087  0.64673913]\n",
      "----------------------------------------\n",
      "Trial 404\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 22, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=22, random_state=100))])\n",
      "cv score: [0.48695652 0.39565217 0.42608696 0.4326087  0.70108696 0.63586957\n",
      " 0.57065217 0.28532609 0.5625     0.55434783]\n",
      "----------------------------------------\n",
      "Trial 405\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 155, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=9,\n",
      "                                            n_estimators=155, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61304348 0.37826087 0.46521739 0.52173913 0.75       0.51086957\n",
      " 0.44565217 0.29891304 0.70108696 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 406\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 81, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=81,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71086957 0.35434783 0.59130435 0.55652174 0.70652174 0.68206522\n",
      " 0.64673913 0.36684783 0.50271739 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 407\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 144, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=144,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39130435 0.26086957 0.56086957 0.53043478 0.76086957 0.3423913\n",
      " 0.49456522 0.60326087 0.41304348 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 408\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53478261 0.25217391 0.56956522 0.63478261 0.72826087 0.52717391\n",
      " 0.35869565 0.66304348 0.49456522 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 409\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 91, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=91,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64782609 0.36521739 0.49565217 0.6173913  0.80978261 0.625\n",
      " 0.46195652 0.4076087  0.68478261 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 410\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=178,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73695652 0.5173913  0.47826087 0.60217391 0.61956522 0.49728261\n",
      " 0.54891304 0.63586957 0.56793478 0.7173913 ]\n",
      "----------------------------------------\n",
      "Trial 411\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 90, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=90,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62173913 0.46304348 0.51956522 0.42608696 0.51086957 0.47826087\n",
      " 0.73913043 0.44565217 0.54347826 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 412\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 103, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=103, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.77391304 0.50869565 0.34782609 0.64782609 0.77717391 0.64673913\n",
      " 0.51086957 0.35326087 0.56521739 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 413\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 122, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=122, random_state=100))])\n",
      "cv score: [0.76521739 0.46521739 0.49130435 0.5        0.6576087  0.54347826\n",
      " 0.56521739 0.54347826 0.5        0.61413043]\n",
      "----------------------------------------\n",
      "Trial 414\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 22, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=22,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.6        0.3        0.55652174 0.62173913 0.67934783 0.54347826\n",
      " 0.50543478 0.70652174 0.43478261 0.48913043]\n",
      "----------------------------------------\n",
      "Trial 415\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 104, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=104,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49130435 0.27826087 0.53043478 0.57391304 0.74456522 0.42934783\n",
      " 0.47826087 0.48369565 0.38043478 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 416\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 62, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=62, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.61304348 0.5173913  0.29130435 0.57826087 0.70108696 0.55978261\n",
      " 0.35869565 0.58695652 0.60326087 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 417\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 71, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            n_estimators=71, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.59130435 0.45217391 0.4826087  0.47826087 0.5923913  0.54891304\n",
      " 0.43478261 0.27173913 0.69565217 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 418\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.68695652 0.46956522 0.4826087  0.57391304 0.75       0.64673913\n",
      " 0.4673913  0.44021739 0.58695652 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 419\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 34, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=34,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57826087 0.38043478 0.59130435 0.7173913  0.42934783 0.44565217\n",
      " 0.60869565 0.38043478 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 420\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 16, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            n_estimators=16, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.6        0.49565217 0.49130435 0.60869565 0.66304348 0.49456522\n",
      " 0.46195652 0.36413043 0.67119565 0.5625    ]\n",
      "----------------------------------------\n",
      "Trial 421\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 103, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=103,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66086957 0.38913043 0.57608696 0.73043478 0.45108696 0.57608696\n",
      " 0.47282609 0.30706522 0.57608696 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 422\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 116, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=116,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67173913 0.39782609 0.6173913  0.51521739 0.67391304 0.63586957\n",
      " 0.64673913 0.5625     0.5        0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 423\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49565217 0.31304348 0.53478261 0.53478261 0.81521739 0.4076087\n",
      " 0.51630435 0.43478261 0.59782609 0.47282609]\n",
      "----------------------------------------\n",
      "Trial 424\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 112, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=112, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49130435 0.36956522 0.4        0.58695652 0.77173913 0.47282609\n",
      " 0.39673913 0.72826087 0.55434783 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 425\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 179, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=179,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56521739 0.25652174 0.53913043 0.6173913  0.80978261 0.45108696\n",
      " 0.46195652 0.57065217 0.53804348 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 426\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 25, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=25,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6173913  0.47826087 0.54782609 0.43913043 0.61413043 0.46195652\n",
      " 0.64130435 0.3423913  0.50543478 0.51902174]\n",
      "----------------------------------------\n",
      "Trial 427\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.59130435 0.3826087  0.43913043 0.67391304 0.80434783 0.57065217\n",
      " 0.44565217 0.375      0.58152174 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 428\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 28, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=28,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5826087  0.35217391 0.46521739 0.60434783 0.80978261 0.66304348\n",
      " 0.38586957 0.3125     0.68478261 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 429\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 34, 'gb__subsample': 0.85, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, n_estimators=34,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.59130435 0.40434783 0.56956522 0.4173913  0.66304348 0.53804348\n",
      " 0.47282609 0.16304348 0.76086957 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 430\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 124, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            n_estimators=124, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.64347826 0.33043478 0.40434783 0.57391304 0.61956522 0.57065217\n",
      " 0.48369565 0.25543478 0.72282609 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 431\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 87, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=87, random_state=100))])\n",
      "cv score: [0.70869565 0.3826087  0.44782609 0.52173913 0.49456522 0.46195652\n",
      " 0.5923913  0.52717391 0.66304348 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 432\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 159, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=159, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.76956522 0.43043478 0.54782609 0.55652174 0.69565217 0.5923913\n",
      " 0.51630435 0.56521739 0.67934783 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 433\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 73, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=73,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5826087  0.29565217 0.53478261 0.56521739 0.72282609 0.39130435\n",
      " 0.51630435 0.43478261 0.55434783 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 434\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 75, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=75,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62608696 0.33478261 0.46956522 0.55652174 0.80434783 0.60869565\n",
      " 0.47282609 0.38586957 0.625      0.60869565]\n",
      "----------------------------------------\n",
      "Trial 435\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 132, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=132, random_state=100))])\n",
      "cv score: [0.8        0.45652174 0.47826087 0.46521739 0.60326087 0.58695652\n",
      " 0.5        0.58152174 0.58152174 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 436\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 65, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=65,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77608696 0.44347826 0.49565217 0.59565217 0.69021739 0.48641304\n",
      " 0.51630435 0.52717391 0.54891304 0.66847826]\n",
      "----------------------------------------\n",
      "Trial 437\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=38, random_state=100))])\n",
      "cv score: [0.74347826 0.4826087  0.47826087 0.58695652 0.5923913  0.67391304\n",
      " 0.49456522 0.52717391 0.50543478 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 438\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 67, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=67,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65652174 0.36521739 0.56521739 0.45       0.60054348 0.45923913\n",
      " 0.69565217 0.49456522 0.5        0.61684783]\n",
      "----------------------------------------\n",
      "Trial 439\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 178, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=178,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70869565 0.43695652 0.66521739 0.44782609 0.73913043 0.58423913\n",
      " 0.6875     0.39130435 0.52173913 0.58423913]\n",
      "----------------------------------------\n",
      "Trial 440\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 20, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=20, random_state=100))])\n",
      "cv score: [0.61304348 0.34782609 0.53043478 0.53913043 0.5923913  0.5326087\n",
      " 0.32608696 0.4673913  0.6576087  0.4673913 ]\n",
      "----------------------------------------\n",
      "Trial 441\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=70, random_state=100))])\n",
      "cv score: [0.6        0.33043478 0.38478261 0.46086957 0.44565217 0.6576087\n",
      " 0.45380435 0.36956522 0.63315217 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 442\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 19, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=19,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63913043 0.47826087 0.50434783 0.48695652 0.68478261 0.36413043\n",
      " 0.62771739 0.4375     0.49456522 0.49184783]\n",
      "----------------------------------------\n",
      "Trial 443\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 61, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=61, random_state=100))])\n",
      "cv score: [0.69565217 0.40217391 0.44347826 0.56956522 0.60326087 0.63043478\n",
      " 0.39130435 0.3125     0.59782609 0.35869565]\n",
      "----------------------------------------\n",
      "Trial 444\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 52, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=52,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75       0.4673913  0.47826087 0.59130435 0.58695652 0.48913043\n",
      " 0.53804348 0.52717391 0.52717391 0.67391304]\n",
      "----------------------------------------\n",
      "Trial 445\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 75, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=75,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62173913 0.47391304 0.55217391 0.42608696 0.70380435 0.44565217\n",
      " 0.77173913 0.4048913  0.52445652 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 446\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 173, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, max_features='sqrt',\n",
      "                                            n_estimators=173, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.73043478 0.47826087 0.36956522 0.5826087  0.77717391 0.66847826\n",
      " 0.41304348 0.4076087  0.53804348 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 447\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 130, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=130, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.76521739 0.45217391 0.43478261 0.46086957 0.73369565 0.54347826\n",
      " 0.47826087 0.45108696 0.5923913  0.58152174]\n",
      "----------------------------------------\n",
      "Trial 448\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 189, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=189, random_state=100))])\n",
      "cv score: [0.51304348 0.3826087  0.50217391 0.43913043 0.6576087  0.42934783\n",
      " 0.43478261 0.35326087 0.71195652 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 449\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 88, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=88, random_state=100))])\n",
      "cv score: [0.5826087  0.41304348 0.49565217 0.45217391 0.59782609 0.54347826\n",
      " 0.46195652 0.29891304 0.77717391 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 450\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 164, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=164, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.62608696 0.57826087 0.57391304 0.56956522 0.38586957 0.54891304\n",
      " 0.74456522 0.55434783 0.50543478 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 451\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 104, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=104,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56956522 0.29565217 0.6        0.5        0.77173913 0.55434783\n",
      " 0.48369565 0.4673913  0.55434783 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 452\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 54, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=54, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.50869565 0.42608696 0.47391304 0.82608696 0.66304348 0.57608696\n",
      " 0.58695652 0.41847826 0.54347826 0.39130435]\n",
      "----------------------------------------\n",
      "Trial 453\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 109, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            n_estimators=109,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.55869565 0.61086957 0.44782609 0.77826087 0.58695652 0.49456522\n",
      " 0.54347826 0.25       0.54347826 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 454\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 15, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=15,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66956522 0.32608696 0.46304348 0.58478261 0.57880435 0.4701087\n",
      " 0.45108696 0.40217391 0.67934783 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 455\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 114, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=114, random_state=100))])\n",
      "cv score: [0.68695652 0.39565217 0.4826087  0.42173913 0.75       0.61956522\n",
      " 0.4673913  0.42391304 0.61413043 0.66847826]\n",
      "----------------------------------------\n",
      "Trial 456\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.50434783 0.55652174 0.39565217 0.55652174 0.70652174 0.66847826\n",
      " 0.38586957 0.38043478 0.64673913 0.47282609]\n",
      "----------------------------------------\n",
      "Trial 457\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.4        0.29130435 0.59565217 0.52173913 0.66847826 0.42391304\n",
      " 0.38043478 0.65217391 0.72826087 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 458\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 195, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=195,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75217391 0.44782609 0.4826087  0.59565217 0.61956522 0.47826087\n",
      " 0.51630435 0.58152174 0.65217391 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 459\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 123, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=123, random_state=100))])\n",
      "cv score: [0.62173913 0.49565217 0.37826087 0.55217391 0.54891304 0.75\n",
      " 0.42934783 0.26086957 0.58695652 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 460\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 22, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=22,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70217391 0.5173913  0.42608696 0.60434783 0.66304348 0.45380435\n",
      " 0.51086957 0.47826087 0.51086957 0.64673913]\n",
      "----------------------------------------\n",
      "Trial 461\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 191, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=191,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53043478 0.29130435 0.59565217 0.50434783 0.77717391 0.54347826\n",
      " 0.54347826 0.47282609 0.5923913  0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 462\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 111, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=111,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56521739 0.19130435 0.57391304 0.4826087  0.75       0.54891304\n",
      " 0.52173913 0.56521739 0.56521739 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 463\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 143, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=143, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.69565217 0.42608696 0.50869565 0.60434783 0.61413043 0.48369565\n",
      " 0.53804348 0.55978261 0.58695652 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 464\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 167, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=167,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.64347826 0.33478261 0.42608696 0.59130435 0.76086957 0.57608696\n",
      " 0.44021739 0.32065217 0.64130435 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 465\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 147, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=147,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6173913  0.44782609 0.60652174 0.42608696 0.70380435 0.47826087\n",
      " 0.75       0.58967391 0.54076087 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 466\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 80, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=11,\n",
      "                                            n_estimators=80, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.54782609 0.46521739 0.53478261 0.41304348 0.69021739 0.64130435\n",
      " 0.44021739 0.5326087  0.5        0.35326087]\n",
      "----------------------------------------\n",
      "Trial 467\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.51304348 0.36521739 0.43913043 0.45652174 0.67391304 0.42934783\n",
      " 0.47282609 0.69565217 0.48369565 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 468\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 167, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=167,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70434783 0.4173913  0.63913043 0.43913043 0.73369565 0.58423913\n",
      " 0.64945652 0.375      0.51086957 0.57880435]\n",
      "----------------------------------------\n",
      "Trial 469\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.46956522 0.37391304 0.56956522 0.52608696 0.78804348 0.50543478\n",
      " 0.44021739 0.57608696 0.43478261 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 470\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6173913  0.46956522 0.53913043 0.42608696 0.70380435 0.46195652\n",
      " 0.6548913  0.4048913  0.51902174 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 471\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 157, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=157,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6326087  0.29347826 0.58043478 0.77826087 0.39945652 0.39673913\n",
      " 0.64130435 0.61956522 0.48369565 0.47554348]\n",
      "----------------------------------------\n",
      "Trial 472\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 61, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=8, n_estimators=61,\n",
      "                                            random_state=100, subsample=0.6))])\n",
      "cv score: [0.50869565 0.37826087 0.5173913  0.49130435 0.75543478 0.49456522\n",
      " 0.48369565 0.34782609 0.65217391 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 473\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 119, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=119,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50869565 0.27826087 0.60869565 0.54782609 0.79347826 0.59782609\n",
      " 0.55978261 0.4673913  0.60869565 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 474\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 34, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=34,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60869565 0.41304348 0.64130435 0.42608696 0.66304348 0.47826087\n",
      " 0.64673913 0.45652174 0.57608696 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 475\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 112, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=112, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.68695652 0.63913043 0.4        0.67173913 0.54891304 0.42391304\n",
      " 0.5        0.29891304 0.47826087 0.45108696]\n",
      "----------------------------------------\n",
      "Trial 476\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 32, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=32,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53043478 0.38695652 0.50434783 0.59130435 0.70108696 0.60869565\n",
      " 0.49456522 0.35869565 0.69021739 0.72826087]\n",
      "----------------------------------------\n",
      "Trial 477\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 110, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            n_estimators=110, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.33913043 0.47826087 0.37826087 0.67391304 0.72826087 0.33152174\n",
      " 0.20108696 0.26630435 0.42934783 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 478\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 170, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=170,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56521739 0.28695652 0.45217391 0.50434783 0.72282609 0.55434783\n",
      " 0.40217391 0.54347826 0.54891304 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 479\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 34, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=34,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49130435 0.16956522 0.51304348 0.5826087  0.73369565 0.4076087\n",
      " 0.40217391 0.55978261 0.44021739 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 480\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 86, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=86, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.66086957 0.37826087 0.46086957 0.46521739 0.6576087  0.66304348\n",
      " 0.46195652 0.45108696 0.61413043 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 481\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 93, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=93,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60869565 0.42173913 0.59565217 0.5673913  0.39673913 0.57336957\n",
      " 0.63315217 0.34782609 0.61413043 0.5298913 ]\n",
      "----------------------------------------\n",
      "Trial 482\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 55, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=55, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.63043478 0.40869565 0.37826087 0.55217391 0.7173913  0.64673913\n",
      " 0.53804348 0.42934783 0.54891304 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 483\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 19, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=19,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64782609 0.42826087 0.68043478 0.43043478 0.57336957 0.45108696\n",
      " 0.65217391 0.36956522 0.58152174 0.58423913]\n",
      "----------------------------------------\n",
      "Trial 484\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 168, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=168, random_state=100))])\n",
      "cv score: [0.52608696 0.36521739 0.48695652 0.39565217 0.68478261 0.41304348\n",
      " 0.45108696 0.33152174 0.69836957 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 485\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 43, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=43,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60217391 0.45869565 0.59130435 0.45869565 0.38315217 0.52717391\n",
      " 0.66304348 0.48913043 0.58152174 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 486\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 13, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=13,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77608696 0.44130435 0.3826087  0.5173913  0.57608696 0.48913043\n",
      " 0.56793478 0.47826087 0.52717391 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 487\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=133, random_state=100))])\n",
      "cv score: [0.74782609 0.47391304 0.49565217 0.55652174 0.54347826 0.49184783\n",
      " 0.70652174 0.52717391 0.57065217 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 488\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 58, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=58, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.43043478 0.56086957 0.7173913  0.39565217 0.58423913 0.60869565\n",
      " 0.85869565 0.36413043 0.28804348 0.68478261]\n",
      "----------------------------------------\n",
      "Trial 489\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 136, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=136,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51304348 0.2826087  0.61304348 0.56956522 0.71195652 0.54347826\n",
      " 0.41304348 0.54891304 0.53804348 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 490\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 59, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=59, random_state=100))])\n",
      "cv score: [0.78695652 0.33913043 0.52608696 0.55652174 0.48369565 0.51630435\n",
      " 0.51086957 0.49456522 0.72826087 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 491\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 138, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=138,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60869565 0.42173913 0.59565217 0.5673913  0.39673913 0.57336957\n",
      " 0.63315217 0.34782609 0.61413043 0.5298913 ]\n",
      "----------------------------------------\n",
      "Trial 492\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=108,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75217391 0.41304348 0.46521739 0.61304348 0.67391304 0.57065217\n",
      " 0.48913043 0.50543478 0.71195652 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 493\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 181, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=181, random_state=100))])\n",
      "cv score: [0.86956522 0.4173913  0.5        0.57826087 0.66304348 0.54347826\n",
      " 0.50543478 0.53804348 0.63043478 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 494\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55217391 0.26956522 0.58695652 0.53913043 0.79891304 0.46195652\n",
      " 0.49456522 0.45652174 0.55434783 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 495\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 49, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=49,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62391304 0.50217391 0.58043478 0.41521739 0.61956522 0.45652174\n",
      " 0.65217391 0.45652174 0.54891304 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 496\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 56, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=56,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60217391 0.41304348 0.57826087 0.50869565 0.45652174 0.36956522\n",
      " 0.61413043 0.36956522 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 497\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 43, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=11,\n",
      "                                            n_estimators=43, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.63478261 0.37826087 0.51304348 0.64347826 0.54347826 0.51630435\n",
      " 0.36413043 0.33695652 0.66847826 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 498\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 148, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, n_estimators=148,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.52608696 0.37391304 0.5        0.51304348 0.59782609 0.44565217\n",
      " 0.47826087 0.30434783 0.69565217 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 499\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 99, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=99, random_state=100))])\n",
      "cv score: [0.50869565 0.33695652 0.51956522 0.39130435 0.5923913  0.4673913\n",
      " 0.4701087  0.3451087  0.76086957 0.67934783]\n",
      "----------------------------------------\n",
      "Trial 500\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 74, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=74,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63913043 0.2826087  0.53913043 0.5173913  0.79347826 0.53804348\n",
      " 0.53804348 0.5326087  0.55434783 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 501\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=51, random_state=100))])\n",
      "cv score: [0.66086957 0.4        0.48695652 0.56521739 0.63586957 0.51086957\n",
      " 0.48913043 0.32608696 0.72826087 0.47826087]\n",
      "----------------------------------------\n",
      "Trial 502\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 168, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=168,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33043478 0.29130435 0.59565217 0.55217391 0.69565217 0.4673913\n",
      " 0.38586957 0.55978261 0.47826087 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 503\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74565217 0.43695652 0.60434783 0.48043478 0.72554348 0.59782609\n",
      " 0.68478261 0.31793478 0.47826087 0.57880435]\n",
      "----------------------------------------\n",
      "Trial 504\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 91, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=91,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45217391 0.30869565 0.6        0.50434783 0.75       0.4673913\n",
      " 0.5326087  0.35869565 0.63586957 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 505\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 131, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=131, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.6        0.40869565 0.4173913  0.6        0.73913043 0.5923913\n",
      " 0.45108696 0.375      0.52717391 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 506\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 160, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=160,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55217391 0.2826087  0.6173913  0.53913043 0.7173913  0.55978261\n",
      " 0.42934783 0.52173913 0.54347826 0.48913043]\n",
      "----------------------------------------\n",
      "Trial 507\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 18, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=18, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.69565217 0.37391304 0.36521739 0.6        0.72826087 0.53804348\n",
      " 0.46195652 0.57065217 0.55978261 0.67934783]\n",
      "----------------------------------------\n",
      "Trial 508\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 97, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=97, random_state=100))])\n",
      "cv score: [0.68695652 0.3173913  0.5        0.56086957 0.73369565 0.625\n",
      " 0.45652174 0.3423913  0.625      0.53804348]\n",
      "----------------------------------------\n",
      "Trial 509\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 83, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=83, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.7826087  0.36086957 0.45217391 0.49130435 0.70652174 0.4673913\n",
      " 0.48913043 0.47826087 0.6576087  0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 510\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=16,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.71521739 0.49347826 0.45652174 0.60434783 0.65217391 0.45923913\n",
      " 0.54347826 0.48369565 0.51630435 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 511\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 125, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=125,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61304348 0.41304348 0.5826087  0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 512\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 143, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=143,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.46956522 0.23913043 0.42173913 0.51304348 0.77173913 0.47282609\n",
      " 0.55434783 0.72282609 0.5923913  0.43478261]\n",
      "----------------------------------------\n",
      "Trial 513\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 163, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=163, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.57391304 0.39130435 0.37826087 0.54782609 0.80434783 0.47282609\n",
      " 0.44021739 0.73913043 0.55978261 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 514\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 130, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=130, random_state=100))])\n",
      "cv score: [0.86086957 0.41304348 0.49130435 0.56956522 0.66847826 0.60869565\n",
      " 0.52717391 0.58695652 0.61956522 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 515\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 27, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=27,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.4173913  0.36086957 0.33913043 0.50869565 0.70108696 0.49456522\n",
      " 0.5        0.54347826 0.58152174 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 516\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 113, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=113,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57826087 0.38043478 0.58695652 0.7173913  0.42934783 0.44565217\n",
      " 0.60054348 0.38043478 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 517\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 99, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=99,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5826087  0.25217391 0.50434783 0.49565217 0.79891304 0.54347826\n",
      " 0.44021739 0.67391304 0.53804348 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 518\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 178, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=178,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51304348 0.33478261 0.6173913  0.56521739 0.81521739 0.50543478\n",
      " 0.47282609 0.54891304 0.54891304 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 519\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 195, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=195, random_state=100))])\n",
      "cv score: [0.66086957 0.44347826 0.40434783 0.5173913  0.73369565 0.71195652\n",
      " 0.44565217 0.41304348 0.59782609 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 520\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 107, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=107,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.7        0.31304348 0.52173913 0.49565217 0.68478261 0.63043478\n",
      " 0.49456522 0.42391304 0.52717391 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 521\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=51,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60217391 0.45869565 0.59130435 0.45869565 0.38315217 0.52717391\n",
      " 0.66304348 0.48913043 0.58152174 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 522\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 70, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=70,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62826087 0.36956522 0.58913043 0.50434783 0.70652174 0.54347826\n",
      " 0.70923913 0.36141304 0.46195652 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 523\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56956522 0.30869565 0.56086957 0.55652174 0.73913043 0.42934783\n",
      " 0.33695652 0.59782609 0.45652174 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 524\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 195, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=195,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.56521739 0.2826087  0.43043478 0.49565217 0.79347826 0.64673913\n",
      " 0.44565217 0.37228261 0.66847826 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 525\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=91, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.56956522 0.46086957 0.45652174 0.6826087  0.72282609 0.41847826\n",
      " 0.38043478 0.4673913  0.48913043 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 526\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 136, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=136,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58695652 0.30434783 0.5826087  0.50869565 0.81521739 0.64673913\n",
      " 0.48369565 0.50543478 0.55978261 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 527\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 45, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            n_estimators=45,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.56086957 0.48695652 0.5        0.64782609 0.55978261 0.48369565\n",
      " 0.51086957 0.30978261 0.57608696 0.44021739]\n",
      "----------------------------------------\n",
      "Trial 528\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 82, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=82, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.8        0.40434783 0.46086957 0.56086957 0.67934783 0.61413043\n",
      " 0.47282609 0.60326087 0.57065217 0.7173913 ]\n",
      "----------------------------------------\n",
      "Trial 529\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=101,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57826087 0.38043478 0.58695652 0.7173913  0.42934783 0.44565217\n",
      " 0.60054348 0.38043478 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 530\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 196, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=196, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.68695652 0.30217391 0.5173913  0.55       0.66847826 0.68206522\n",
      " 0.33967391 0.58695652 0.82608696 0.54619565]\n",
      "----------------------------------------\n",
      "Trial 531\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 192, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=192, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.75652174 0.44782609 0.50434783 0.57826087 0.64130435 0.53804348\n",
      " 0.5326087  0.5923913  0.55978261 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 532\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            n_estimators=170, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.49565217 0.44782609 0.55652174 0.39130435 0.78804348 0.48913043\n",
      " 0.44021739 0.25543478 0.7173913  0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 533\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 60, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=60, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.52391304 0.53913043 0.76304348 0.50652174 0.56521739 0.57608696\n",
      " 0.55434783 0.55163043 0.4375     0.53804348]\n",
      "----------------------------------------\n",
      "Trial 534\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 43, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=43, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.82173913 0.47826087 0.43043478 0.54782609 0.64673913 0.5\n",
      " 0.5326087  0.61956522 0.50815217 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 535\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 151, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=151, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62173913 0.44347826 0.4173913  0.5        0.68478261 0.6576087\n",
      " 0.45652174 0.36956522 0.63586957 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 536\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 178, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=178,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64782609 0.37173913 0.55434783 0.46304348 0.56793478 0.48369565\n",
      " 0.72554348 0.35054348 0.51630435 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 537\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 137, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=137, random_state=100))])\n",
      "cv score: [0.85652174 0.4173913  0.49565217 0.54782609 0.66847826 0.58695652\n",
      " 0.5326087  0.55434783 0.61956522 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 538\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            n_estimators=170, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.44782609 0.46521739 0.57826087 0.34347826 0.73913043 0.38043478\n",
      " 0.375      0.35326087 0.68478261 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 539\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 39, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=39, random_state=100))])\n",
      "cv score: [0.7326087  0.45652174 0.51304348 0.53913043 0.5        0.48641304\n",
      " 0.62771739 0.54347826 0.64673913 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 540\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 60, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=60,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61304348 0.33478261 0.6173913  0.6173913  0.67391304 0.57065217\n",
      " 0.49456522 0.53804348 0.52717391 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 541\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 55, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=55,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67391304 0.33913043 0.51304348 0.52173913 0.66304348 0.61956522\n",
      " 0.51630435 0.51630435 0.58695652 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 542\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 50, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=50, random_state=100))])\n",
      "cv score: [0.6        0.3826087  0.50869565 0.54782609 0.65217391 0.55434783\n",
      " 0.47826087 0.41847826 0.68478261 0.45652174]\n",
      "----------------------------------------\n",
      "Trial 543\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 21, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=21, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.64782609 0.56956522 0.54347826 0.54782609 0.57608696 0.61956522\n",
      " 0.44021739 0.57608696 0.6576087  0.70652174]\n",
      "----------------------------------------\n",
      "Trial 544\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 64, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=64,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.50434783 0.23478261 0.64347826 0.56521739 0.66304348 0.4076087\n",
      " 0.48913043 0.69021739 0.50543478 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 545\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 17, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=17,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59565217 0.38478261 0.47826087 0.46086957 0.4673913  0.45652174\n",
      " 0.48913043 0.47826087 0.60054348 0.48913043]\n",
      "----------------------------------------\n",
      "Trial 546\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 28, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=28,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62826087 0.43913043 0.66304348 0.42608696 0.48641304 0.46195652\n",
      " 0.72826087 0.45652174 0.51630435 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 547\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.6826087  0.6        0.35217391 0.46956522 0.71195652 0.33695652\n",
      " 0.60869565 0.54076087 0.6576087  0.63315217]\n",
      "----------------------------------------\n",
      "Trial 548\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57391304 0.28695652 0.51304348 0.59565217 0.79347826 0.43478261\n",
      " 0.48913043 0.55978261 0.51630435 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 549\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 184, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=184, random_state=100))])\n",
      "cv score: [0.73913043 0.36086957 0.4826087  0.56956522 0.55434783 0.54891304\n",
      " 0.51086957 0.43478261 0.7173913  0.60326087]\n",
      "----------------------------------------\n",
      "Trial 550\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 154, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, max_features='sqrt',\n",
      "                                            n_estimators=154, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.59565217 0.42608696 0.36956522 0.55217391 0.71195652 0.59782609\n",
      " 0.40217391 0.33152174 0.58152174 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 551\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52608696 0.32173913 0.50434783 0.59565217 0.83695652 0.375\n",
      " 0.48913043 0.47282609 0.56521739 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 552\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 63, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=63, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.81304348 0.43043478 0.47826087 0.56086957 0.61413043 0.58152174\n",
      " 0.48913043 0.65217391 0.57065217 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 553\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 196, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=196,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.68695652 0.34347826 0.46086957 0.58695652 0.77717391 0.61413043\n",
      " 0.46195652 0.32608696 0.67391304 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 554\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 148, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            n_estimators=148, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.69565217 0.42173913 0.47826087 0.61304348 0.65217391 0.56521739\n",
      " 0.63043478 0.29347826 0.70652174 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 555\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 24, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=24,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58695652 0.44347826 0.44347826 0.5826087  0.71195652 0.41847826\n",
      " 0.45108696 0.4673913  0.65217391 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 556\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 61, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=61, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.7        0.40869565 0.45652174 0.5173913  0.69565217 0.55978261\n",
      " 0.4673913  0.41304348 0.625      0.61956522]\n",
      "----------------------------------------\n",
      "Trial 557\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 15, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=15,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73695652 0.44565217 0.3826087  0.52608696 0.625      0.49456522\n",
      " 0.58152174 0.58423913 0.5326087  0.60326087]\n",
      "----------------------------------------\n",
      "Trial 558\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 86, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=86, random_state=100))])\n",
      "cv score: [0.62173913 0.4826087  0.39130435 0.55217391 0.52717391 0.72826087\n",
      " 0.44565217 0.21195652 0.58152174 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 559\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 195, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=195,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76086957 0.3826087  0.47826087 0.64782609 0.35869565 0.61956522\n",
      " 0.75543478 0.39673913 0.66032609 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 560\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 160, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=160, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.51304348 0.50652174 0.55434783 0.66086957 0.63043478 0.55978261\n",
      " 0.42934783 0.54891304 0.50815217 0.42391304]\n",
      "----------------------------------------\n",
      "Trial 561\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.7326087  0.45434783 0.57826087 0.57173913 0.7201087  0.57065217\n",
      " 0.70380435 0.39130435 0.48913043 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 562\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.69130435 0.33478261 0.42173913 0.53913043 0.73369565 0.63043478\n",
      " 0.44565217 0.375      0.67391304 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 563\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 167, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=167,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53478261 0.28695652 0.57391304 0.54347826 0.80978261 0.42934783\n",
      " 0.48913043 0.50543478 0.50543478 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 564\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.45652174 0.2826087  0.6173913  0.53478261 0.77173913 0.5326087\n",
      " 0.52717391 0.50543478 0.58695652 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 565\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 14, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=14, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.27826087 0.4826087  0.49130435 0.39565217 0.66847826 0.61413043\n",
      " 0.58152174 0.39673913 0.58152174 0.39130435]\n",
      "----------------------------------------\n",
      "Trial 566\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 199, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=199,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45217391 0.28695652 0.43043478 0.58695652 0.7826087  0.47282609\n",
      " 0.42934783 0.66304348 0.43478261 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 567\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=108,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73695652 0.49782609 0.52173913 0.58478261 0.58152174 0.50815217\n",
      " 0.55434783 0.70652174 0.57336957 0.72282609]\n",
      "----------------------------------------\n",
      "Trial 568\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 163, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=163, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.76086957 0.44782609 0.4826087  0.56956522 0.7173913  0.57065217\n",
      " 0.49456522 0.65217391 0.59782609 0.69021739]\n",
      "----------------------------------------\n",
      "Trial 569\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 198, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            n_estimators=198, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.63478261 0.34782609 0.4826087  0.46086957 0.75       0.51630435\n",
      " 0.46195652 0.29347826 0.71195652 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 570\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 175, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=175,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67826087 0.35652174 0.5826087  0.43913043 0.51902174 0.47554348\n",
      " 0.71195652 0.41304348 0.51086957 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 571\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 47, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=47,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64347826 0.3        0.53913043 0.57391304 0.74456522 0.56521739\n",
      " 0.48913043 0.5        0.54891304 0.47282609]\n",
      "----------------------------------------\n",
      "Trial 572\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 106, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=106, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.75217391 0.44347826 0.43043478 0.63478261 0.71195652 0.60869565\n",
      " 0.46195652 0.375      0.66304348 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 573\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 42, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=42,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67826087 0.46086957 0.57608696 0.44347826 0.72282609 0.50815217\n",
      " 0.68478261 0.44021739 0.5326087  0.54076087]\n",
      "----------------------------------------\n",
      "Trial 574\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 33, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=33, random_state=100))])\n",
      "cv score: [0.52608696 0.46086957 0.44782609 0.49130435 0.43478261 0.67663043\n",
      " 0.41032609 0.28804348 0.61413043 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 575\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 198, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=198,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.59130435 0.35652174 0.46956522 0.50434783 0.72282609 0.58152174\n",
      " 0.40217391 0.32608696 0.64130435 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 576\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 60, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=60,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36086957 0.31304348 0.59130435 0.60434783 0.5923913  0.47282609\n",
      " 0.49456522 0.64673913 0.49456522 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 577\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 19, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            n_estimators=19, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.55652174 0.4673913  0.43913043 0.57391304 0.66576087 0.48913043\n",
      " 0.39130435 0.25543478 0.70923913 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 578\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 104, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=104,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61304348 0.41304348 0.5826087  0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 579\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 74, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=74,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57173913 0.44130435 0.60434783 0.43478261 0.61684783 0.49184783\n",
      " 0.64130435 0.47826087 0.58423913 0.5951087 ]\n",
      "----------------------------------------\n",
      "Trial 580\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=108, random_state=100))])\n",
      "cv score: [0.61304348 0.39565217 0.47391304 0.5        0.64673913 0.51630435\n",
      " 0.47282609 0.32608696 0.72826087 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 581\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 91, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=91,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60217391 0.41304348 0.57826087 0.50869565 0.45652174 0.36956522\n",
      " 0.60326087 0.36956522 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 582\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=174, random_state=100))])\n",
      "cv score: [0.67826087 0.46521739 0.44347826 0.4826087  0.74456522 0.69565217\n",
      " 0.4673913  0.34782609 0.5923913  0.57065217]\n",
      "----------------------------------------\n",
      "Trial 583\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 20, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=20,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63043478 0.45217391 0.55652174 0.43913043 0.59782609 0.48913043\n",
      " 0.64402174 0.2201087  0.48913043 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 584\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 61, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=61, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57391304 0.53913043 0.42173913 0.6        0.79347826 0.44565217\n",
      " 0.47282609 0.50543478 0.2826087  0.5       ]\n",
      "----------------------------------------\n",
      "Trial 585\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=183,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66086957 0.38913043 0.57608696 0.73043478 0.45108696 0.57608696\n",
      " 0.47282609 0.30706522 0.57608696 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 586\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=101, random_state=100))])\n",
      "cv score: [0.75652174 0.47391304 0.50434783 0.53913043 0.63043478 0.63586957\n",
      " 0.54347826 0.58695652 0.48913043 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 587\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 86, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=86,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53913043 0.28695652 0.54782609 0.46956522 0.83695652 0.60326087\n",
      " 0.54347826 0.44021739 0.63586957 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 588\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 97, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=97,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4826087  0.33478261 0.56086957 0.54782609 0.75       0.40217391\n",
      " 0.48913043 0.70652174 0.5326087  0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 589\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 146, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=146, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.72608696 0.44347826 0.4        0.54347826 0.70108696 0.4673913\n",
      " 0.42391304 0.45108696 0.53804348 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 590\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 48, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=48, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.73478261 0.43043478 0.39130435 0.49565217 0.72826087 0.5\n",
      " 0.42934783 0.46195652 0.61413043 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 591\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 49, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=49, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.54347826 0.39565217 0.47391304 0.54782609 0.74456522 0.61956522\n",
      " 0.49456522 0.35869565 0.60869565 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 592\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 43, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=43, random_state=100))])\n",
      "cv score: [0.63043478 0.39130435 0.49565217 0.6        0.60869565 0.6576087\n",
      " 0.36141304 0.41304348 0.64130435 0.4048913 ]\n",
      "----------------------------------------\n",
      "Trial 593\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 49, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=49,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36086957 0.27826087 0.30869565 0.40869565 0.81521739 0.41304348\n",
      " 0.47282609 0.48913043 0.60326087 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 594\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.76956522 0.42608696 0.50434783 0.57826087 0.77173913 0.50543478\n",
      " 0.49456522 0.53804348 0.65217391 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 595\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 50, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=50, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.73478261 0.44782609 0.5173913  0.6173913  0.77717391 0.67934783\n",
      " 0.51086957 0.4076087  0.5326087  0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 596\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 46, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=46,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57826087 0.38043478 0.59130435 0.7173913  0.42934783 0.44565217\n",
      " 0.60597826 0.38043478 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 597\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=51,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60869565 0.42173913 0.59565217 0.5673913  0.39673913 0.57336957\n",
      " 0.63315217 0.34782609 0.61413043 0.5298913 ]\n",
      "----------------------------------------\n",
      "Trial 598\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 124, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=124, random_state=100))])\n",
      "cv score: [0.63913043 0.4173913  0.4173913  0.54347826 0.60869565 0.73913043\n",
      " 0.46195652 0.3423913  0.63586957 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 599\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 53, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=53,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70434783 0.30869565 0.4826087  0.54782609 0.77717391 0.66847826\n",
      " 0.44565217 0.35326087 0.61413043 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 600\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 147, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=147,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60434783 0.41304348 0.57826087 0.5173913  0.45652174 0.36956522\n",
      " 0.60326087 0.40217391 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 601\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 195, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=195, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.73043478 0.39130435 0.4173913  0.4173913  0.76630435 0.5\n",
      " 0.43478261 0.39130435 0.625      0.60326087]\n",
      "----------------------------------------\n",
      "Trial 602\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 87, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=87,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75217391 0.46521739 0.52173913 0.56086957 0.70652174 0.56521739\n",
      " 0.49456522 0.5        0.70108696 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 603\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 186, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=186, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.5826087  0.42173913 0.35652174 0.59130435 0.73369565 0.63586957\n",
      " 0.4673913  0.29347826 0.60326087 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 604\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 185, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=185, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.55652174 0.65217391 0.36521739 0.46521739 0.79347826 0.57608696\n",
      " 0.51630435 0.67934783 0.45108696 0.72826087]\n",
      "----------------------------------------\n",
      "Trial 605\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 44, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=44, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.67826087 0.42608696 0.47826087 0.59565217 0.66304348 0.54347826\n",
      " 0.49456522 0.5326087  0.57065217 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 606\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.47391304 0.30434783 0.56086957 0.5        0.69565217 0.58695652\n",
      " 0.52173913 0.39130435 0.59782609 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 607\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 62, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=62,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67173913 0.38913043 0.5326087  0.45652174 0.51902174 0.45108696\n",
      " 0.77445652 0.29076087 0.47826087 0.57336957]\n",
      "----------------------------------------\n",
      "Trial 608\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 89, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=89,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54347826 0.29130435 0.57391304 0.51304348 0.82608696 0.56521739\n",
      " 0.53804348 0.42391304 0.52173913 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 609\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 25, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=25,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60869565 0.41521739 0.56086957 0.42608696 0.5625     0.4673913\n",
      " 0.48913043 0.45652174 0.58423913 0.60597826]\n",
      "----------------------------------------\n",
      "Trial 610\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 28, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=28,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63043478 0.51956522 0.47826087 0.42173913 0.55434783 0.47554348\n",
      " 0.66304348 0.36141304 0.60869565 0.55163043]\n",
      "----------------------------------------\n",
      "Trial 611\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 160, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=160, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.73043478 0.45652174 0.51304348 0.53043478 0.71195652 0.55434783\n",
      " 0.51086957 0.5923913  0.53804348 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 612\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=70,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65217391 0.28695652 0.5        0.53043478 0.80978261 0.70108696\n",
      " 0.43206522 0.27717391 0.65217391 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 613\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43913043 0.23043478 0.50869565 0.53913043 0.80434783 0.50543478\n",
      " 0.51086957 0.60869565 0.60869565 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 614\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 137, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=137, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.70434783 0.42173913 0.46521739 0.4173913  0.75       0.61413043\n",
      " 0.47826087 0.45652174 0.61956522 0.66304348]\n",
      "----------------------------------------\n",
      "Trial 615\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=14, random_state=100))])\n",
      "cv score: [0.88695652 0.3173913  0.5826087  0.57826087 0.625      0.51630435\n",
      " 0.46195652 0.35869565 0.77717391 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 616\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 58, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=58,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51304348 0.35217391 0.5173913  0.56521739 0.66304348 0.43478261\n",
      " 0.31521739 0.61413043 0.54347826 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 617\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=121, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.63478261 0.43913043 0.39130435 0.5826087  0.76086957 0.66304348\n",
      " 0.4076087  0.36413043 0.58695652 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 618\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52608696 0.29565217 0.60869565 0.49565217 0.75       0.47282609\n",
      " 0.54891304 0.38586957 0.61956522 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 619\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            n_estimators=105,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.6326087  0.56521739 0.5826087  0.71304348 0.75       0.45380435\n",
      " 0.51086957 0.29891304 0.70108696 0.69293478]\n",
      "----------------------------------------\n",
      "Trial 620\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.56956522 0.33913043 0.49565217 0.58695652 0.68478261 0.50543478\n",
      " 0.50543478 0.23369565 0.72282609 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 621\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 133, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            n_estimators=133, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.56521739 0.36956522 0.52173913 0.4826087  0.73913043 0.46195652\n",
      " 0.4076087  0.30434783 0.73913043 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 622\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 143, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            n_estimators=143,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.63043478 0.4173913  0.49565217 0.6173913  0.58967391 0.49728261\n",
      " 0.65217391 0.30978261 0.70652174 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 623\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 135, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=135, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.54782609 0.35652174 0.44347826 0.55217391 0.79891304 0.60869565\n",
      " 0.40217391 0.51630435 0.61413043 0.32608696]\n",
      "----------------------------------------\n",
      "Trial 624\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 21, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=21, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.6173913  0.32608696 0.54347826 0.56956522 0.61956522 0.67391304\n",
      " 0.4076087  0.39673913 0.60869565 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 625\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 158, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=158,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43043478 0.3        0.56086957 0.53043478 0.70108696 0.47282609\n",
      " 0.52717391 0.47826087 0.53804348 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 626\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 195, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=195, random_state=100))])\n",
      "cv score: [0.52608696 0.36086957 0.49782609 0.43043478 0.6576087  0.44021739\n",
      " 0.46467391 0.35326087 0.7201087  0.60326087]\n",
      "----------------------------------------\n",
      "Trial 627\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 51, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            n_estimators=51, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.69130435 0.40869565 0.44782609 0.57391304 0.53804348 0.55434783\n",
      " 0.54891304 0.29347826 0.66847826 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 628\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 137, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=137,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66086957 0.37173913 0.5826087  0.42173913 0.56793478 0.46467391\n",
      " 0.77717391 0.38858696 0.51086957 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 629\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 154, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=154,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48695652 0.32608696 0.46086957 0.46521739 0.70652174 0.51630435\n",
      " 0.51086957 0.57065217 0.54891304 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 630\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 57, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=8, max_features='sqrt',\n",
      "                                            n_estimators=57, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.66086957 0.49130435 0.36956522 0.62608696 0.68478261 0.63043478\n",
      " 0.45652174 0.4076087  0.51086957 0.47282609]\n",
      "----------------------------------------\n",
      "Trial 631\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 177, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=177, random_state=100))])\n",
      "cv score: [0.75217391 0.43913043 0.54347826 0.50434783 0.67391304 0.55434783\n",
      " 0.57065217 0.55434783 0.50543478 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 632\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 103, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=103,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4        0.33043478 0.52608696 0.5173913  0.77173913 0.51630435\n",
      " 0.47826087 0.45108696 0.58152174 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 633\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 152, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=152, random_state=100))])\n",
      "cv score: [0.48478261 0.35       0.48913043 0.4173913  0.67934783 0.45108696\n",
      " 0.46467391 0.32336957 0.70652174 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 634\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            n_estimators=168, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.72608696 0.4        0.44347826 0.62608696 0.64673913 0.56521739\n",
      " 0.51630435 0.27717391 0.69565217 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 635\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 148, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=148, random_state=100))])\n",
      "cv score: [0.64782609 0.4173913  0.41304348 0.54347826 0.67934783 0.73369565\n",
      " 0.44565217 0.40217391 0.61413043 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 636\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 187, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=187, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62608696 0.44782609 0.38695652 0.55217391 0.73913043 0.74456522\n",
      " 0.45652174 0.3423913  0.59782609 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 637\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 130, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=130,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40434783 0.32173913 0.51304348 0.44347826 0.75543478 0.49456522\n",
      " 0.46195652 0.58695652 0.375      0.56521739]\n",
      "----------------------------------------\n",
      "Trial 638\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59565217 0.26521739 0.58695652 0.5173913  0.77173913 0.4076087\n",
      " 0.51630435 0.48369565 0.60869565 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 639\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63043478 0.44347826 0.55217391 0.48695652 0.5326087  0.45108696\n",
      " 0.75543478 0.43478261 0.50543478 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 640\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=95, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.55217391 0.43478261 0.42173913 0.6826087  0.7173913  0.69021739\n",
      " 0.44565217 0.32065217 0.61413043 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 641\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 114, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=114, random_state=100))])\n",
      "cv score: [0.62608696 0.38043478 0.41304348 0.54347826 0.64130435 0.72282609\n",
      " 0.45652174 0.35869565 0.63858696 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 642\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 34, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=34,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4173913  0.35652174 0.26956522 0.4826087  0.69565217 0.38586957\n",
      " 0.51630435 0.64130435 0.64673913 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 643\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 149, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=149, random_state=100))])\n",
      "cv score: [0.59130435 0.38695652 0.47391304 0.49130435 0.6576087  0.51630435\n",
      " 0.47826087 0.35326087 0.69565217 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 644\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62173913 0.34347826 0.61304348 0.42608696 0.78804348 0.57608696\n",
      " 0.36956522 0.53804348 0.57608696 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 645\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 176, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=176, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.72173913 0.4173913  0.37391304 0.53043478 0.70652174 0.63043478\n",
      " 0.47282609 0.44565217 0.6576087  0.56521739]\n",
      "----------------------------------------\n",
      "Trial 646\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 16, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=12,\n",
      "                                            n_estimators=16, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.53043478 0.3826087  0.47391304 0.69130435 0.54347826 0.63586957\n",
      " 0.45652174 0.25       0.41847826 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 647\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 76, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=76, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.76086957 0.41304348 0.49565217 0.57391304 0.63043478 0.4673913\n",
      " 0.5        0.61413043 0.60326087 0.64673913]\n",
      "----------------------------------------\n",
      "Trial 648\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 158, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=158,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65652174 0.2826087  0.43478261 0.50434783 0.79891304 0.64673913\n",
      " 0.45108696 0.3423913  0.67391304 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 649\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 118, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=118,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6826087  0.44347826 0.58695652 0.45869565 0.66847826 0.46467391\n",
      " 0.72554348 0.57065217 0.52173913 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 650\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 17, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, max_features='log2',\n",
      "                                            n_estimators=17, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.6173913  0.36086957 0.55652174 0.63043478 0.84782609 0.54347826\n",
      " 0.51630435 0.29347826 0.5923913  0.41304348]\n",
      "----------------------------------------\n",
      "Trial 651\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 35, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=35, random_state=100))])\n",
      "cv score: [0.65652174 0.42608696 0.46521739 0.55217391 0.64130435 0.6548913\n",
      " 0.37228261 0.45108696 0.62228261 0.39402174]\n",
      "----------------------------------------\n",
      "Trial 652\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 113, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=113, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.66956522 0.46956522 0.43043478 0.55652174 0.71195652 0.66304348\n",
      " 0.50543478 0.35869565 0.65217391 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 653\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 148, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=148, random_state=100))])\n",
      "cv score: [0.48478261 0.34130435 0.48478261 0.44130435 0.65217391 0.45652174\n",
      " 0.4701087  0.33152174 0.71195652 0.58967391]\n",
      "----------------------------------------\n",
      "Trial 654\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51304348 0.33913043 0.53478261 0.53913043 0.75543478 0.47826087\n",
      " 0.54891304 0.44565217 0.49456522 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 655\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62173913 0.29130435 0.57391304 0.52608696 0.71195652 0.5923913\n",
      " 0.47826087 0.57065217 0.57608696 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 656\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 56, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=56,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.7173913  0.29565217 0.54782609 0.43478261 0.77173913 0.47826087\n",
      " 0.42934783 0.58695652 0.5        0.55434783]\n",
      "----------------------------------------\n",
      "Trial 657\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=51,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57826087 0.38043478 0.58695652 0.7173913  0.42934783 0.44565217\n",
      " 0.60597826 0.38043478 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 658\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 24, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=24,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6173913  0.41304348 0.58695652 0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 659\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 117, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=117,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37391304 0.43478261 0.38695652 0.43913043 0.7173913  0.47282609\n",
      " 0.49456522 0.54347826 0.58152174 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 660\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 63, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=63, random_state=100))])\n",
      "cv score: [0.74782609 0.49130435 0.46956522 0.54347826 0.65217391 0.66847826\n",
      " 0.54347826 0.58152174 0.49456522 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 661\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 22, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=22,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63695652 0.52608696 0.5826087  0.42608696 0.57608696 0.47282609\n",
      " 0.66032609 0.36413043 0.52173913 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 662\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 176, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=176, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.69130435 0.44782609 0.42173913 0.54347826 0.76630435 0.59782609\n",
      " 0.4673913  0.25543478 0.56521739 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 663\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 112, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            n_estimators=112, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.34782609 0.49130435 0.52173913 0.53913043 0.63043478 0.53804348\n",
      " 0.6576087  0.54347826 0.70108696 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 664\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 33, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=33,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67391304 0.42608696 0.56956522 0.44782609 0.7173913  0.4673913\n",
      " 0.6875     0.38315217 0.58967391 0.57336957]\n",
      "----------------------------------------\n",
      "Trial 665\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=171,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58695652 0.42826087 0.48695652 0.55217391 0.41847826 0.57880435\n",
      " 0.54347826 0.42663043 0.7173913  0.49456522]\n",
      "----------------------------------------\n",
      "Trial 666\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 32, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=32, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.65652174 0.29130435 0.43478261 0.62608696 0.66304348 0.58152174\n",
      " 0.54891304 0.39130435 0.52717391 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 667\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.7826087  0.46086957 0.50869565 0.53913043 0.68478261 0.51630435\n",
      " 0.51086957 0.63043478 0.66304348 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 668\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 86, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=86,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.74782609 0.46521739 0.50434783 0.56521739 0.70108696 0.57065217\n",
      " 0.48913043 0.5        0.70108696 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 669\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 88, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            n_estimators=88, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.64347826 0.33043478 0.46956522 0.59565217 0.6576087  0.54891304\n",
      " 0.47282609 0.27717391 0.66304348 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 670\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 139, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=139,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6        0.31304348 0.57391304 0.4826087  0.78804348 0.6576087\n",
      " 0.51086957 0.54347826 0.58695652 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 671\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 13, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=13, random_state=100))])\n",
      "cv score: [0.62826087 0.32173913 0.41304348 0.48913043 0.4076087  0.50543478\n",
      " 0.58423913 0.50271739 0.57880435 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 672\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 72, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=72,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49565217 0.30434783 0.46956522 0.54782609 0.78804348 0.45652174\n",
      " 0.55978261 0.47282609 0.53804348 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 673\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 55, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=55, random_state=100))])\n",
      "cv score: [0.66086957 0.39565217 0.43478261 0.57391304 0.63586957 0.51086957\n",
      " 0.44021739 0.50543478 0.625      0.61956522]\n",
      "----------------------------------------\n",
      "Trial 674\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 144, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=144,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56521739 0.2826087  0.52608696 0.53913043 0.70108696 0.56521739\n",
      " 0.51630435 0.47826087 0.61413043 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 675\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70434783 0.41304348 0.62391304 0.49130435 0.73913043 0.52717391\n",
      " 0.6576087  0.5326087  0.48097826 0.5625    ]\n",
      "----------------------------------------\n",
      "Trial 676\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 173, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=173,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76521739 0.36956522 0.46521739 0.54347826 0.7173913  0.625\n",
      " 0.46195652 0.38586957 0.67391304 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 677\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56086957 0.23913043 0.4826087  0.56086957 0.7173913  0.44565217\n",
      " 0.52173913 0.57065217 0.49456522 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 678\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 79, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=79, random_state=100))])\n",
      "cv score: [0.72173913 0.42608696 0.49130435 0.58695652 0.69565217 0.66304348\n",
      " 0.38586957 0.28804348 0.69021739 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 679\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=68, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.6826087  0.56086957 0.41304348 0.53478261 0.68478261 0.55434783\n",
      " 0.47282609 0.44021739 0.43478261 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 680\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 73, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=73,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54782609 0.21304348 0.4826087  0.5826087  0.73369565 0.38586957\n",
      " 0.41847826 0.56521739 0.39673913 0.38586957]\n",
      "----------------------------------------\n",
      "Trial 681\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.75217391 0.38043478 0.49347826 0.43478261 0.625      0.44021739\n",
      " 0.73369565 0.51086957 0.54347826 0.5298913 ]\n",
      "----------------------------------------\n",
      "Trial 682\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 135, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=135,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61304348 0.3        0.43913043 0.43043478 0.75543478 0.55978261\n",
      " 0.41304348 0.73369565 0.45108696 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 683\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 182, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=182,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.67391304 0.34347826 0.45217391 0.57391304 0.78804348 0.61413043\n",
      " 0.46195652 0.33152174 0.67934783 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 684\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 142, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=142, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.79130435 0.46521739 0.44347826 0.57826087 0.7173913  0.51086957\n",
      " 0.51630435 0.55978261 0.57608696 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 685\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 94, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=94,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60434783 0.29565217 0.57826087 0.53043478 0.78804348 0.61413043\n",
      " 0.39673913 0.5923913  0.58695652 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 686\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            random_state=100, subsample=0.7))])\n",
      "cv score: [0.52173913 0.36086957 0.47391304 0.46956522 0.6576087  0.5\n",
      " 0.40217391 0.38043478 0.68478261 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 687\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 146, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            n_estimators=146, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.64347826 0.34782609 0.47826087 0.35652174 0.73913043 0.52173913\n",
      " 0.45108696 0.31521739 0.73369565 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 688\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62826087 0.45869565 0.48043478 0.42173913 0.48369565 0.48369565\n",
      " 0.75271739 0.48369565 0.58152174 0.60054348]\n",
      "----------------------------------------\n",
      "Trial 689\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 89, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=89,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55652174 0.36086957 0.5826087  0.53043478 0.77173913 0.48913043\n",
      " 0.52173913 0.43478261 0.59782609 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 690\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 146, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=146, random_state=100))])\n",
      "cv score: [0.69130435 0.41304348 0.45652174 0.43043478 0.72282609 0.625\n",
      " 0.47826087 0.4673913  0.61956522 0.64673913]\n",
      "----------------------------------------\n",
      "Trial 691\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 166, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=166,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76521739 0.41304348 0.47826087 0.62608696 0.73369565 0.59782609\n",
      " 0.46195652 0.31521739 0.65217391 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 692\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 176, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=176,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.72608696 0.38913043 0.59130435 0.48913043 0.72282609 0.52173913\n",
      " 0.63586957 0.42391304 0.58695652 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 693\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 194, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, n_estimators=194,\n",
      "                                            random_state=100, subsample=0.8))])\n",
      "cv score: [0.54347826 0.4        0.46956522 0.43478261 0.77173913 0.45108696\n",
      " 0.47826087 0.375      0.76630435 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 694\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 31, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=31,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60869565 0.42173913 0.59565217 0.5673913  0.39673913 0.57336957\n",
      " 0.63315217 0.34782609 0.61413043 0.5298913 ]\n",
      "----------------------------------------\n",
      "Trial 695\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 86, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=86,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.7826087  0.43913043 0.52173913 0.59130435 0.66847826 0.50271739\n",
      " 0.51086957 0.52173913 0.64130435 0.66847826]\n",
      "----------------------------------------\n",
      "Trial 696\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 113, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=113, random_state=100))])\n",
      "cv score: [0.59565217 0.37608696 0.42173913 0.49347826 0.60326087 0.69021739\n",
      " 0.43206522 0.375      0.67391304 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 697\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 169, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=169, random_state=100))])\n",
      "cv score: [0.75217391 0.44347826 0.53913043 0.50869565 0.68478261 0.55434783\n",
      " 0.56521739 0.55434783 0.51086957 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 698\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 103, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=103, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.64782609 0.38695652 0.43913043 0.56956522 0.73913043 0.64130435\n",
      " 0.43478261 0.29891304 0.57065217 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 699\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 162, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            n_estimators=162, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.61304348 0.34347826 0.46521739 0.55652174 0.63586957 0.5\n",
      " 0.47826087 0.32065217 0.66847826 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 700\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47826087 0.27826087 0.51304348 0.61304348 0.82608696 0.47282609\n",
      " 0.49456522 0.52173913 0.48913043 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 701\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 147, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=147,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66086957 0.38913043 0.57608696 0.73043478 0.45108696 0.57608696\n",
      " 0.47282609 0.30706522 0.57608696 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 702\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 60, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=60, random_state=100))])\n",
      "cv score: [0.7173913  0.46521739 0.5        0.54782609 0.69565217 0.52717391\n",
      " 0.44565217 0.58152174 0.47282609 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 703\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=115,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.66521739 0.35652174 0.3826087  0.57826087 0.84782609 0.61413043\n",
      " 0.38586957 0.29347826 0.60869565 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 704\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 195, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, n_estimators=195,\n",
      "                                            random_state=100, subsample=0.7))])\n",
      "cv score: [0.53478261 0.47826087 0.42173913 0.50434783 0.74456522 0.44565217\n",
      " 0.35869565 0.6576087  0.52717391 0.46195652]\n",
      "----------------------------------------\n",
      "Trial 705\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 22, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=22,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.74782609 0.39347826 0.6173913  0.4826087  0.72282609 0.51086957\n",
      " 0.63043478 0.51630435 0.61956522 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 706\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 136, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=136, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.57826087 0.64347826 0.52173913 0.52608696 0.64130435 0.75543478\n",
      " 0.47282609 0.8423913  0.625      0.38586957]\n",
      "----------------------------------------\n",
      "Trial 707\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 26, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=26, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.6173913  0.44782609 0.25217391 0.72608696 0.61413043 0.625\n",
      " 0.55978261 0.41304348 0.61413043 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 708\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 77, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=77, random_state=100))])\n",
      "cv score: [0.6826087  0.36086957 0.5173913  0.53043478 0.66847826 0.64130435\n",
      " 0.45108696 0.31521739 0.65217391 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 709\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 140, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=140,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75652174 0.43478261 0.5173913  0.57391304 0.63586957 0.53804348\n",
      " 0.50543478 0.47826087 0.65217391 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 710\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.74782609 0.45652174 0.47173913 0.56956522 0.4673913  0.55163043\n",
      " 0.64673913 0.50543478 0.58152174 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 711\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 177, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=177, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.79130435 0.42608696 0.50434783 0.52173913 0.77173913 0.63586957\n",
      " 0.46195652 0.57065217 0.6576087  0.61413043]\n",
      "----------------------------------------\n",
      "Trial 712\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 150, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=150,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62173913 0.47173913 0.56956522 0.43043478 0.61141304 0.56521739\n",
      " 0.70652174 0.63858696 0.55434783 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 713\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 18, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=18, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.75217391 0.39565217 0.30869565 0.64347826 0.60326087 0.55706522\n",
      " 0.625      0.41847826 0.48641304 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 714\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 141, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=141,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5        0.23913043 0.4        0.54347826 0.79347826 0.47282609\n",
      " 0.51630435 0.57608696 0.52173913 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 715\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 23, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=23, random_state=100))])\n",
      "cv score: [0.56086957 0.43043478 0.55652174 0.62391304 0.5326087  0.48369565\n",
      " 0.49184783 0.31521739 0.67934783 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 716\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.6173913  0.44782609 0.55652174 0.53043478 0.81521739 0.5\n",
      " 0.35326087 0.65217391 0.60326087 0.66847826]\n",
      "----------------------------------------\n",
      "Trial 717\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 85, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=85, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.56956522 0.40869565 0.43043478 0.63913043 0.51086957 0.77173913\n",
      " 0.61956522 0.5923913  0.54891304 0.45652174]\n",
      "----------------------------------------\n",
      "Trial 718\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 61, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=61, random_state=100))])\n",
      "cv score: [0.49565217 0.34782609 0.50869565 0.50434783 0.60326087 0.4701087\n",
      " 0.5        0.32880435 0.73913043 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 719\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 126, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=126,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52173913 0.28695652 0.60434783 0.5826087  0.81521739 0.57065217\n",
      " 0.49456522 0.5        0.55434783 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 720\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 51, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=51,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.60869565 0.46521739 0.44782609 0.57391304 0.80434783 0.64130435\n",
      " 0.47282609 0.3423913  0.65217391 0.71195652]\n",
      "----------------------------------------\n",
      "Trial 721\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=10,\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.52173913 0.46521739 0.53913043 0.47826087 0.5326087  0.41304348\n",
      " 0.48369565 0.33152174 0.74456522 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 722\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 184, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=184,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75652174 0.36956522 0.46521739 0.55217391 0.71195652 0.63043478\n",
      " 0.46195652 0.375      0.67391304 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 723\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 65, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            n_estimators=65, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.76521739 0.41304348 0.46086957 0.5826087  0.55434783 0.5923913\n",
      " 0.53804348 0.32065217 0.66304348 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 724\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 68, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=68, random_state=100))])\n",
      "cv score: [0.64347826 0.4        0.46956522 0.52608696 0.61956522 0.5326087\n",
      " 0.45652174 0.29891304 0.71195652 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 725\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 124, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=124, random_state=100))])\n",
      "cv score: [0.59130435 0.38695652 0.46956522 0.46956522 0.63586957 0.51086957\n",
      " 0.47826087 0.33152174 0.7173913  0.60326087]\n",
      "----------------------------------------\n",
      "Trial 726\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.32608696 0.7        0.70652174 0.73478261 0.80978261 0.55434783\n",
      " 0.66032609 0.47826087 0.3423913  0.76902174]\n",
      "----------------------------------------\n",
      "Trial 727\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 32, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=32, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.71304348 0.38695652 0.46086957 0.54782609 0.73369565 0.46467391\n",
      " 0.48369565 0.56521739 0.60326087 0.64673913]\n",
      "----------------------------------------\n",
      "Trial 728\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 84, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=84, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.57391304 0.6        0.39130435 0.59130435 0.64130435 0.53804348\n",
      " 0.39130435 0.34782609 0.55978261 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 729\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 16, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=16,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60652174 0.49347826 0.6        0.42173913 0.58967391 0.45108696\n",
      " 0.60054348 0.45652174 0.5        0.47826087]\n",
      "----------------------------------------\n",
      "Trial 730\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 144, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=144, random_state=100))])\n",
      "cv score: [0.50869565 0.33913043 0.48695652 0.43913043 0.63586957 0.4673913\n",
      " 0.45652174 0.32608696 0.71195652 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 731\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 46, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=46,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62391304 0.22826087 0.55       0.77826087 0.4673913  0.32608696\n",
      " 0.61684783 0.55434783 0.60326087 0.50271739]\n",
      "----------------------------------------\n",
      "Trial 732\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 170, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=170,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54347826 0.2826087  0.62608696 0.48695652 0.73369565 0.51630435\n",
      " 0.5326087  0.39130435 0.53804348 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 733\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 161, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, n_estimators=161,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.48695652 0.37391304 0.46521739 0.42608696 0.63586957 0.47282609\n",
      " 0.41847826 0.32608696 0.72826087 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 734\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 61, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=61, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.65652174 0.37826087 0.4        0.46086957 0.84782609 0.47554348\n",
      " 0.38586957 0.55978261 0.5        0.61413043]\n",
      "----------------------------------------\n",
      "Trial 735\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 94, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            n_estimators=94, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.73043478 0.44782609 0.53043478 0.5673913  0.5298913  0.55434783\n",
      " 0.77717391 0.51630435 0.64130435 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 736\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 66, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=66,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75652174 0.4826087  0.46521739 0.54782609 0.69565217 0.56521739\n",
      " 0.47282609 0.51086957 0.69021739 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 737\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 81, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=81,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72608696 0.37391304 0.47826087 0.63478261 0.69021739 0.64673913\n",
      " 0.47826087 0.27173913 0.66304348 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 738\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 166, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=166,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61304348 0.41304348 0.5826087  0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 739\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.65652174 0.46086957 0.5173913  0.5173913  0.76086957 0.42391304\n",
      " 0.48369565 0.51086957 0.5        0.54891304]\n",
      "----------------------------------------\n",
      "Trial 740\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 65, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=65,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61304348 0.20869565 0.53913043 0.53043478 0.77717391 0.64673913\n",
      " 0.41304348 0.54347826 0.58695652 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 741\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 81, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=81,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67173913 0.44130435 0.57391304 0.43043478 0.76630435 0.53804348\n",
      " 0.70380435 0.3451087  0.52173913 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 742\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 173, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=173,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.58695652 0.54782609 0.42608696 0.63043478 0.73913043 0.69021739\n",
      " 0.47282609 0.57065217 0.56521739 0.45652174]\n",
      "----------------------------------------\n",
      "Trial 743\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 117, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=117, random_state=100))])\n",
      "cv score: [0.69565217 0.32608696 0.47826087 0.56086957 0.73913043 0.6576087\n",
      " 0.42391304 0.35326087 0.63586957 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 744\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 136, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            n_estimators=136, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.75217391 0.32608696 0.46956522 0.53043478 0.60869565 0.57608696\n",
      " 0.47826087 0.33695652 0.73369565 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 745\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 25, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=25, random_state=100))])\n",
      "cv score: [0.75217391 0.43478261 0.52173913 0.50869565 0.68478261 0.45108696\n",
      " 0.42391304 0.39673913 0.70923913 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 746\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 45, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=45,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6326087  0.35869565 0.5826087  0.7326087  0.40217391 0.42119565\n",
      " 0.60597826 0.41032609 0.50815217 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 747\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.57391304 0.53043478 0.46956522 0.78695652 0.48913043 0.61956522\n",
      " 0.61956522 0.44021739 0.5326087  0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 748\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 11, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=11,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62608696 0.45434783 0.56956522 0.48695652 0.72826087 0.65217391\n",
      " 0.47282609 0.52173913 0.55434783 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 749\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 56, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=56, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.72173913 0.36521739 0.44347826 0.60434783 0.69021739 0.68478261\n",
      " 0.34782609 0.28804348 0.5923913  0.63586957]\n",
      "----------------------------------------\n",
      "Trial 750\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 45, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            n_estimators=45, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.5173913  0.45217391 0.40217391 0.57173913 0.57608696 0.69293478\n",
      " 0.32608696 0.53804348 0.44565217 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 751\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 119, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=119,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.46521739 0.26521739 0.54347826 0.51304348 0.71195652 0.50543478\n",
      " 0.47282609 0.61956522 0.49456522 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 752\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 122, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=122, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.7173913  0.63043478 0.6        0.47826087 0.73913043 0.58152174\n",
      " 0.61413043 0.46467391 0.5        0.55434783]\n",
      "----------------------------------------\n",
      "Trial 753\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 105, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=105,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45217391 0.29565217 0.5826087  0.46086957 0.79347826 0.53804348\n",
      " 0.53804348 0.41304348 0.59782609 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 754\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 104, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=104, random_state=100))])\n",
      "cv score: [0.55217391 0.37391304 0.5        0.46086957 0.60326087 0.4673913\n",
      " 0.4673913  0.3423913  0.77717391 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 755\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 134, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=134,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.7326087  0.49347826 0.48695652 0.58478261 0.60869565 0.49728261\n",
      " 0.55434783 0.65217391 0.57336957 0.72826087]\n",
      "----------------------------------------\n",
      "Trial 756\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=52, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.73913043 0.3826087  0.47391304 0.53913043 0.79891304 0.61956522\n",
      " 0.47282609 0.5        0.56521739 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 757\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 48, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=48, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.61304348 0.36086957 0.33478261 0.35652174 0.66847826 0.61956522\n",
      " 0.4673913  0.38586957 0.53804348 0.49456522]\n",
      "----------------------------------------\n",
      "Trial 758\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 89, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=89, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.57826087 0.30434783 0.4173913  0.60869565 0.60869565 0.66304348\n",
      " 0.36413043 0.40217391 0.64673913 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 759\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 144, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=144,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.75217391 0.38695652 0.60434783 0.5173913  0.67391304 0.5\n",
      " 0.55978261 0.55434783 0.53804348 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 760\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50434783 0.2173913  0.33043478 0.59130435 0.59782609 0.45652174\n",
      " 0.44021739 0.5923913  0.52173913 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 761\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            n_estimators=121, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.6        0.64782609 0.3173913  0.47608696 0.64673913 0.53804348\n",
      " 0.25543478 0.66304348 0.36413043 0.72282609]\n",
      "----------------------------------------\n",
      "Trial 762\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 155, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=155,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66086957 0.4173913  0.51304348 0.56521739 0.58152174 0.58695652\n",
      " 0.55978261 0.57065217 0.54347826 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 763\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 78, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=78,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.74347826 0.49130435 0.50869565 0.56956522 0.67391304 0.49456522\n",
      " 0.51630435 0.40217391 0.66304348 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 764\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 145, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=145,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6326087  0.35869565 0.5826087  0.7326087  0.40217391 0.42119565\n",
      " 0.60597826 0.41032609 0.50815217 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 765\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 77, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=77,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.46086957 0.37391304 0.64347826 0.49565217 0.81521739 0.5326087\n",
      " 0.5326087  0.42934783 0.57608696 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 766\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74782609 0.40217391 0.54347826 0.47173913 0.51358696 0.42119565\n",
      " 0.72554348 0.25543478 0.58695652 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 767\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 92, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=92,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.65217391 0.5        0.44782609 0.58695652 0.61413043 0.58152174\n",
      " 0.47826087 0.39673913 0.55434783 0.66304348]\n",
      "----------------------------------------\n",
      "Trial 768\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 13, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=13,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65217391 0.41521739 0.67391304 0.41304348 0.52445652 0.46195652\n",
      " 0.66304348 0.50815217 0.58695652 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 769\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 134, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=134,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62826087 0.29347826 0.58043478 0.77826087 0.39945652 0.39673913\n",
      " 0.64130435 0.61956522 0.48369565 0.47554348]\n",
      "----------------------------------------\n",
      "Trial 770\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 119, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=119, random_state=100))])\n",
      "cv score: [0.63478261 0.39347826 0.41304348 0.53913043 0.625      0.72826087\n",
      " 0.45108696 0.3423913  0.64402174 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 771\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 34, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=34,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60869565 0.41304348 0.63695652 0.42608696 0.67391304 0.47826087\n",
      " 0.64945652 0.36413043 0.57065217 0.60054348]\n",
      "----------------------------------------\n",
      "Trial 772\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 126, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            n_estimators=126,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.53043478 0.28695652 0.47826087 0.55217391 0.63043478 0.42391304\n",
      " 0.44021739 0.48913043 0.50543478 0.67391304]\n",
      "----------------------------------------\n",
      "Trial 773\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 57, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=57,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64565217 0.4326087  0.53043478 0.46086957 0.75       0.63043478\n",
      " 0.66847826 0.42391304 0.72826087 0.54076087]\n",
      "----------------------------------------\n",
      "Trial 774\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 188, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=188,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61304348 0.27826087 0.61304348 0.5173913  0.77173913 0.55434783\n",
      " 0.5        0.54347826 0.53804348 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 775\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 116, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=116, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.66086957 0.3826087  0.40869565 0.45217391 0.77173913 0.68478261\n",
      " 0.42934783 0.36413043 0.60869565 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 776\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 35, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=35,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61304348 0.33913043 0.52173913 0.47826087 0.73369565 0.46195652\n",
      " 0.57608696 0.30434783 0.54347826 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 777\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 100, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5173913  0.3        0.5173913  0.56521739 0.79347826 0.4076087\n",
      " 0.52173913 0.44021739 0.57065217 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 778\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 67, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=67, random_state=100))])\n",
      "cv score: [0.64782609 0.39565217 0.46956522 0.53043478 0.63586957 0.52717391\n",
      " 0.45652174 0.2826087  0.71195652 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 779\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=174, random_state=100))])\n",
      "cv score: [0.7173913  0.47391304 0.51304348 0.54347826 0.54347826 0.50271739\n",
      " 0.67391304 0.51630435 0.57608696 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 780\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 184, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=184,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66956522 0.33478261 0.44782609 0.57391304 0.79347826 0.61413043\n",
      " 0.45652174 0.32608696 0.67934783 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 781\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 152, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=152, random_state=100))])\n",
      "cv score: [0.6826087  0.46521739 0.45652174 0.47391304 0.72282609 0.70652174\n",
      " 0.45108696 0.33152174 0.59782609 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 782\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 100, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62608696 0.44347826 0.56956522 0.43043478 0.72282609 0.47282609\n",
      " 0.70380435 0.51358696 0.51902174 0.67119565]\n",
      "----------------------------------------\n",
      "Trial 783\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 31, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=31,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62173913 0.35217391 0.59565217 0.56956522 0.66847826 0.52173913\n",
      " 0.55978261 0.4076087  0.67934783 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 784\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 177, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            n_estimators=177, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.8173913  0.4        0.50434783 0.55652174 0.60869565 0.52173913\n",
      " 0.57065217 0.52173913 0.61956522 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 785\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 23, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=23, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.80869565 0.44347826 0.4826087  0.46086957 0.90217391 0.625\n",
      " 0.47826087 0.60869565 0.5        0.16847826]\n",
      "----------------------------------------\n",
      "Trial 786\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 156, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, max_features='sqrt',\n",
      "                                            n_estimators=156, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.63478261 0.5        0.42608696 0.63478261 0.72282609 0.58152174\n",
      " 0.44565217 0.39673913 0.55434783 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 787\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 184, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=184, random_state=100))])\n",
      "cv score: [0.7826087  0.45652174 0.45652174 0.56956522 0.64673913 0.56521739\n",
      " 0.57608696 0.61413043 0.54891304 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 788\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 41, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=41,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60217391 0.41304348 0.57826087 0.50869565 0.45652174 0.36956522\n",
      " 0.60326087 0.36956522 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 789\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=70,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60869565 0.4        0.44782609 0.62608696 0.76086957 0.63043478\n",
      " 0.48369565 0.38586957 0.72282609 0.67391304]\n",
      "----------------------------------------\n",
      "Trial 790\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 19, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=19,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62608696 0.30434783 0.56086957 0.40869565 0.8423913  0.42391304\n",
      " 0.64130435 0.44565217 0.66847826 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 791\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 62, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=62, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.6826087  0.4        0.42608696 0.56956522 0.70108696 0.625\n",
      " 0.42391304 0.3423913  0.66304348 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 792\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 63, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=63,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6826087  0.41304348 0.4826087  0.52608696 0.67934783 0.5326087\n",
      " 0.42391304 0.375      0.66847826 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 793\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 138, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=138, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.79565217 0.43478261 0.45217391 0.5173913  0.67391304 0.53804348\n",
      " 0.50543478 0.61956522 0.58695652 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 794\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 89, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, max_features='sqrt',\n",
      "                                            n_estimators=89, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.82608696 0.48695652 0.61304348 0.69130435 0.82065217 0.39130435\n",
      " 0.5326087  0.52173913 0.50543478 0.48913043]\n",
      "----------------------------------------\n",
      "Trial 795\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 95, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=95,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72608696 0.43913043 0.57391304 0.51304348 0.66847826 0.63858696\n",
      " 0.64673913 0.5        0.52173913 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 796\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 65, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=65,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.54347826 0.41304348 0.53913043 0.50869565 0.77173913 0.63586957\n",
      " 0.39130435 0.26630435 0.5923913  0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 797\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=159,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58695652 0.38695652 0.43913043 0.63478261 0.77717391 0.60326087\n",
      " 0.4673913  0.38043478 0.70652174 0.64673913]\n",
      "----------------------------------------\n",
      "Trial 798\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 126, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=126, random_state=100))])\n",
      "cv score: [0.7173913  0.40869565 0.45652174 0.5173913  0.52173913 0.49456522\n",
      " 0.625      0.54891304 0.6576087  0.625     ]\n",
      "----------------------------------------\n",
      "Trial 799\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 15, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=15,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61956522 0.49347826 0.63913043 0.42173913 0.58967391 0.45108696\n",
      " 0.60054348 0.45652174 0.5        0.47826087]\n",
      "----------------------------------------\n",
      "Trial 800\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 189, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=7, max_features='sqrt',\n",
      "                                            n_estimators=189, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.59130435 0.37826087 0.36086957 0.6        0.73369565 0.51086957\n",
      " 0.43478261 0.50543478 0.52173913 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 801\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 150, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=150,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.45217391 0.25217391 0.52173913 0.55652174 0.67391304 0.54347826\n",
      " 0.48913043 0.66847826 0.4673913  0.50543478]\n",
      "----------------------------------------\n",
      "Trial 802\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 101, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=101,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70869565 0.48478261 0.57608696 0.35217391 0.72826087 0.46195652\n",
      " 0.70652174 0.57065217 0.49184783 0.53804348]\n",
      "----------------------------------------\n",
      "Trial 803\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 128, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=128, random_state=100))])\n",
      "cv score: [0.67826087 0.4        0.45217391 0.5826087  0.67391304 0.58695652\n",
      " 0.4673913  0.52173913 0.65217391 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 804\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 105, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=105,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66521739 0.32608696 0.56956522 0.5173913  0.67934783 0.4673913\n",
      " 0.51086957 0.4076087  0.68478261 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 805\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 53, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=53, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.70652174 0.46304348 0.51304348 0.5826087  0.5923913  0.58152174\n",
      " 0.52173913 0.57065217 0.61684783 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 806\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 186, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=186,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76086957 0.4173913  0.47391304 0.6173913  0.74456522 0.60869565\n",
      " 0.46195652 0.33695652 0.6576087  0.625     ]\n",
      "----------------------------------------\n",
      "Trial 807\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 72, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=72, random_state=100))])\n",
      "cv score: [0.75652174 0.38695652 0.4826087  0.53043478 0.5923913  0.625\n",
      " 0.4076087  0.30978261 0.59782609 0.41576087]\n",
      "----------------------------------------\n",
      "Trial 808\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 66, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=66, random_state=100))])\n",
      "cv score: [0.7173913  0.39130435 0.44782609 0.54347826 0.60326087 0.63043478\n",
      " 0.38586957 0.32880435 0.60054348 0.42391304]\n",
      "----------------------------------------\n",
      "Trial 809\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 22, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=22, random_state=100))])\n",
      "cv score: [0.53043478 0.44130435 0.49347826 0.55217391 0.49184783 0.44565217\n",
      " 0.46195652 0.36141304 0.69836957 0.69021739]\n",
      "----------------------------------------\n",
      "Trial 810\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 135, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=135, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.64782609 0.37826087 0.36086957 0.50869565 0.75       0.66304348\n",
      " 0.4673913  0.35326087 0.7173913  0.63586957]\n",
      "----------------------------------------\n",
      "Trial 811\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67391304 0.50217391 0.59130435 0.47608696 0.73369565 0.52717391\n",
      " 0.67934783 0.34782609 0.53804348 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 812\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 77, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=77,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65434783 0.47173913 0.59782609 0.50869565 0.68206522 0.45652174\n",
      " 0.71467391 0.28804348 0.50271739 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 813\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 96, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=96, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.70434783 0.43478261 0.41304348 0.5826087  0.67934783 0.74456522\n",
      " 0.49456522 0.32608696 0.66847826 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 814\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=16,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72173913 0.46521739 0.47391304 0.61304348 0.5326087  0.54891304\n",
      " 0.52173913 0.19021739 0.60869565 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 815\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 106, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=106,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68695652 0.35652174 0.55434783 0.53478261 0.67391304 0.52173913\n",
      " 0.65217391 0.42934783 0.53804348 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 816\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 105, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=105,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47826087 0.29565217 0.57391304 0.5826087  0.83695652 0.4673913\n",
      " 0.50543478 0.54347826 0.51086957 0.45652174]\n",
      "----------------------------------------\n",
      "Trial 817\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 66, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=66,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77173913 0.44347826 0.49130435 0.6        0.67934783 0.48641304\n",
      " 0.51086957 0.51630435 0.54891304 0.66847826]\n",
      "----------------------------------------\n",
      "Trial 818\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 73, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=73,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54782609 0.2826087  0.46086957 0.5826087  0.79347826 0.44021739\n",
      " 0.51086957 0.64130435 0.52717391 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 819\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66086957 0.36956522 0.50434783 0.45869565 0.75543478 0.64673913\n",
      " 0.68478261 0.36956522 0.70652174 0.5625    ]\n",
      "----------------------------------------\n",
      "Trial 820\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.74782609 0.4673913  0.5673913  0.59565217 0.52717391 0.48641304\n",
      " 0.7173913  0.52717391 0.59782609 0.60054348]\n",
      "----------------------------------------\n",
      "Trial 821\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 50, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=50, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.73043478 0.44782609 0.34782609 0.7        0.84782609 0.63043478\n",
      " 0.4076087  0.78804348 0.27173913 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 822\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 172, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=172, random_state=100))])\n",
      "cv score: [0.6826087  0.42173913 0.4173913  0.55652174 0.72826087 0.7173913\n",
      " 0.45652174 0.39130435 0.64673913 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 823\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 165, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            n_estimators=165, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.56956522 0.36956522 0.46956522 0.63478261 0.75       0.52717391\n",
      " 0.48913043 0.25       0.69021739 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 824\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 33, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=33,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56956522 0.32173913 0.66956522 0.4173913  0.83152174 0.56521739\n",
      " 0.55978261 0.65217391 0.52717391 0.40217391]\n",
      "----------------------------------------\n",
      "Trial 825\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50869565 0.27391304 0.62173913 0.5826087  0.75543478 0.44565217\n",
      " 0.48369565 0.50543478 0.58695652 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 826\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, max_features='sqrt',\n",
      "                                            random_state=100))])\n",
      "cv score: [0.6173913  0.43913043 0.5        0.66521739 0.74456522 0.63586957\n",
      " 0.36956522 0.30434783 0.55434783 0.50543478]\n",
      "----------------------------------------\n",
      "Trial 827\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=7, max_features='log2',\n",
      "                                            n_estimators=145,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.55217391 0.4826087  0.43478261 0.67391304 0.81521739 0.55978261\n",
      " 0.40217391 0.33152174 0.5        0.61956522]\n",
      "----------------------------------------\n",
      "Trial 828\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 97, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=97,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48695652 0.27826087 0.59130435 0.52173913 0.76086957 0.45652174\n",
      " 0.5        0.44021739 0.54891304 0.48369565]\n",
      "----------------------------------------\n",
      "Trial 829\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 154, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=154, random_state=100))])\n",
      "cv score: [0.67826087 0.46521739 0.46086957 0.48695652 0.72282609 0.70108696\n",
      " 0.4673913  0.32065217 0.59782609 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 830\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 107, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=107, random_state=100))])\n",
      "cv score: [0.50652174 0.34130435 0.52826087 0.46521739 0.5923913  0.47554348\n",
      " 0.48913043 0.33423913 0.75       0.63043478]\n",
      "----------------------------------------\n",
      "Trial 831\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 22, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            n_estimators=22, random_state=100,\n",
      "                                            subsample=0.75))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.46521739 0.41304348 0.35652174 0.57391304 0.5923913  0.43478261\n",
      " 0.2173913  0.48369565 0.64673913 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 832\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67391304 0.34782609 0.55869565 0.46086957 0.5        0.44836957\n",
      " 0.73097826 0.28532609 0.4673913  0.56521739]\n",
      "----------------------------------------\n",
      "Trial 833\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 169, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=169, random_state=100))])\n",
      "cv score: [0.6        0.40869565 0.37826087 0.51956522 0.7173913  0.69021739\n",
      " 0.44293478 0.41847826 0.62771739 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 834\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 191, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=191, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.63478261 0.46956522 0.34347826 0.5        0.75       0.51086957\n",
      " 0.44565217 0.65217391 0.625      0.69565217]\n",
      "----------------------------------------\n",
      "Trial 835\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 158, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=158,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54347826 0.3        0.57826087 0.55217391 0.74456522 0.51630435\n",
      " 0.40217391 0.73913043 0.53804348 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 836\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 90, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=90,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60434783 0.41304348 0.57826087 0.5173913  0.45652174 0.36956522\n",
      " 0.60869565 0.40217391 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 837\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 189, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=9,\n",
      "                                            n_estimators=189, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.60869565 0.37826087 0.45652174 0.4826087  0.66304348 0.5326087\n",
      " 0.47826087 0.25       0.70652174 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 838\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 45, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=45, random_state=100))])\n",
      "cv score: [0.73913043 0.47826087 0.49130435 0.55652174 0.71195652 0.53804348\n",
      " 0.42934783 0.58152174 0.51086957 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 839\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 144, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=144,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69130435 0.38478261 0.5826087  0.51304348 0.7173913  0.57336957\n",
      " 0.6576087  0.46195652 0.52717391 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 840\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 55, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=55,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43043478 0.33478261 0.59130435 0.59130435 0.79347826 0.47282609\n",
      " 0.47826087 0.375      0.43478261 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 841\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 44, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, n_estimators=44,\n",
      "                                            random_state=100, subsample=0.9))])\n",
      "cv score: [0.57391304 0.3        0.50434783 0.54347826 0.67391304 0.5326087\n",
      " 0.57065217 0.32065217 0.60869565 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 842\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 106, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            n_estimators=106,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.49347826 0.40434783 0.57826087 0.62391304 0.38858696 0.29347826\n",
      " 0.48097826 0.36684783 0.51358696 0.49184783]\n",
      "----------------------------------------\n",
      "Trial 843\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=115, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.64782609 0.43913043 0.36956522 0.60434783 0.82608696 0.57608696\n",
      " 0.47826087 0.36413043 0.625      0.54347826]\n",
      "----------------------------------------\n",
      "Trial 844\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.85217391 0.40869565 0.40869565 0.56956522 0.72282609 0.58695652\n",
      " 0.47282609 0.5326087  0.5923913  0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 845\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 29, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=29,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65217391 0.45217391 0.51304348 0.56086957 0.6576087  0.55978261\n",
      " 0.50543478 0.58695652 0.70652174 0.68478261]\n",
      "----------------------------------------\n",
      "Trial 846\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=91, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.64782609 0.40434783 0.36521739 0.60869565 0.81521739 0.57065217\n",
      " 0.47282609 0.41847826 0.58695652 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 847\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=171,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60217391 0.45869565 0.59130435 0.45869565 0.38315217 0.52717391\n",
      " 0.66304348 0.48913043 0.58152174 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 848\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54782609 0.23913043 0.6        0.47826087 0.75543478 0.44021739\n",
      " 0.49456522 0.52717391 0.58152174 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 849\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 179, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=179,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51304348 0.2826087  0.44347826 0.46956522 0.63043478 0.68478261\n",
      " 0.5326087  0.83152174 0.33695652 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 850\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 35, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=35,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.56956522 0.42173913 0.45217391 0.6173913  0.80978261 0.625\n",
      " 0.43478261 0.27445652 0.62771739 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 851\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 187, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=187,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.50869565 0.3        0.6173913  0.48695652 0.81521739 0.52173913\n",
      " 0.54891304 0.48369565 0.63586957 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 852\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 18, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=18, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.43478261 0.29130435 0.3826087  0.70434783 0.55978261 0.625\n",
      " 0.43478261 0.30978261 0.64673913 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 853\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 10, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=10,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66521739 0.44347826 0.62826087 0.42173913 0.45652174 0.44021739\n",
      " 0.66304348 0.73913043 0.58695652 0.4673913 ]\n",
      "----------------------------------------\n",
      "Trial 854\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            n_estimators=115, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.76086957 0.39565217 0.43043478 0.62173913 0.44565217 0.59782609\n",
      " 0.58152174 0.31521739 0.70652174 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 855\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 160, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=160,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36956522 0.30434783 0.55652174 0.4826087  0.86956522 0.61413043\n",
      " 0.46195652 0.7173913  0.57608696 0.52717391]\n",
      "----------------------------------------\n",
      "Trial 856\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 51, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=51,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4173913  0.24782609 0.65652174 0.51304348 0.74456522 0.45652174\n",
      " 0.5326087  0.5923913  0.59782609 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 857\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 144, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            n_estimators=144, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.5826087  0.43913043 0.45217391 0.46086957 0.6576087  0.36956522\n",
      " 0.5326087  0.30978261 0.75543478 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 858\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50869565 0.28695652 0.49565217 0.53478261 0.73913043 0.47282609\n",
      " 0.51630435 0.58695652 0.55978261 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 859\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 65, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=65, random_state=100))])\n",
      "cv score: [0.64347826 0.37826087 0.5        0.43913043 0.72826087 0.60869565\n",
      " 0.46195652 0.42934783 0.65217391 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 860\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 91, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=91, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66956522 0.39130435 0.49130435 0.42608696 0.73369565 0.66304348\n",
      " 0.45652174 0.42934783 0.64130435 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 861\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 76, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=76,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50434783 0.43913043 0.5173913  0.56521739 0.63586957 0.54347826\n",
      " 0.25       0.625      0.52173913 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 862\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 127, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=127,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5826087  0.37826087 0.43913043 0.61304348 0.74456522 0.63586957\n",
      " 0.4673913  0.38043478 0.68478261 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 863\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 119, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=119,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47391304 0.3173913  0.59565217 0.53478261 0.80434783 0.47282609\n",
      " 0.52717391 0.42391304 0.55434783 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 864\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 166, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=166,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57826087 0.38043478 0.58695652 0.7173913  0.42934783 0.44565217\n",
      " 0.60054348 0.38043478 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 865\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 20, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=20, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.76521739 0.47391304 0.47826087 0.66956522 0.77717391 0.70923913\n",
      " 0.50543478 0.47282609 0.50543478 0.69021739]\n",
      "----------------------------------------\n",
      "Trial 866\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 167, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=167,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69565217 0.42826087 0.63913043 0.49130435 0.76630435 0.53804348\n",
      " 0.66847826 0.48641304 0.51630435 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 867\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 24, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=24, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.70434783 0.42173913 0.4        0.46086957 0.72826087 0.64130435\n",
      " 0.4076087  0.2173913  0.59782609 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 868\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 116, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            n_estimators=116, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.67391304 0.44347826 0.48695652 0.62173913 0.64673913 0.60326087\n",
      " 0.52717391 0.24456522 0.72826087 0.61956522]\n",
      "----------------------------------------\n",
      "Trial 869\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 171, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=171,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.47391304 0.26956522 0.54782609 0.44347826 0.63043478 0.5326087\n",
      " 0.32065217 0.64130435 0.54347826 0.45108696]\n",
      "----------------------------------------\n",
      "Trial 870\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 93, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=93,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4        0.30869565 0.59565217 0.55217391 0.82065217 0.41304348\n",
      " 0.51086957 0.48369565 0.55434783 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 871\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74347826 0.39347826 0.56956522 0.46956522 0.55434783 0.48369565\n",
      " 0.56521739 0.45652174 0.52717391 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 872\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 130, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=130,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53913043 0.26521739 0.53913043 0.53913043 0.79891304 0.42934783\n",
      " 0.5        0.42934783 0.57065217 0.47826087]\n",
      "----------------------------------------\n",
      "Trial 873\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 118, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=118,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57391304 0.2826087  0.51304348 0.54347826 0.70652174 0.50543478\n",
      " 0.44565217 0.5        0.51086957 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 874\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 84, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=84, random_state=100))])\n",
      "cv score: [0.60869565 0.40869565 0.46086957 0.5173913  0.625      0.51086957\n",
      " 0.46195652 0.27717391 0.72282609 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 875\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=101,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.74782609 0.46521739 0.50434783 0.55652174 0.70108696 0.57608696\n",
      " 0.49456522 0.5        0.70652174 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 876\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 141, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=141,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6        0.30434783 0.56956522 0.5826087  0.72826087 0.54347826\n",
      " 0.52173913 0.47826087 0.65217391 0.55434783]\n",
      "----------------------------------------\n",
      "Trial 877\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=183, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.64782609 0.44347826 0.40434783 0.5173913  0.7173913  0.69565217\n",
      " 0.44021739 0.41847826 0.5923913  0.52717391]\n",
      "----------------------------------------\n",
      "Trial 878\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 34, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            n_estimators=34, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.80434783 0.37826087 0.46956522 0.59565217 0.57065217 0.60869565\n",
      " 0.55978261 0.26086957 0.61956522 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 879\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 54, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=54,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60869565 0.42173913 0.59565217 0.5673913  0.39673913 0.57336957\n",
      " 0.63315217 0.34782609 0.61413043 0.5298913 ]\n",
      "----------------------------------------\n",
      "Trial 880\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=197,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61304348 0.41304348 0.5826087  0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Trial 881\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 138, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=138, random_state=100))])\n",
      "cv score: [0.69565217 0.40869565 0.45217391 0.56521739 0.66304348 0.58152174\n",
      " 0.4673913  0.52173913 0.6576087  0.63043478]\n",
      "----------------------------------------\n",
      "Trial 882\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 47, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=47, random_state=100))])\n",
      "cv score: [0.75652174 0.41304348 0.55217391 0.59130435 0.66304348 0.76630435\n",
      " 0.48369565 0.625      0.52717391 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 883\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 87, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=87, random_state=100))])\n",
      "cv score: [0.66086957 0.33695652 0.43478261 0.54347826 0.57608696 0.6576087\n",
      " 0.48097826 0.35869565 0.61413043 0.48097826]\n",
      "----------------------------------------\n",
      "Trial 884\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 45, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=45,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64130435 0.48478261 0.58695652 0.42608696 0.66032609 0.45652174\n",
      " 0.64130435 0.33152174 0.51630435 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 885\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 149, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, n_estimators=149,\n",
      "                                            random_state=100, subsample=0.6))])\n",
      "cv score: [0.50434783 0.46086957 0.5        0.50434783 0.48913043 0.38315217\n",
      " 0.77173913 0.65217391 0.31793478 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 886\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 64, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=64,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63695652 0.44347826 0.5326087  0.43478261 0.57608696 0.46467391\n",
      " 0.75543478 0.53804348 0.51630435 0.62228261]\n",
      "----------------------------------------\n",
      "Trial 887\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 94, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=94, random_state=100))])\n",
      "cv score: [0.6826087  0.32173913 0.49565217 0.56521739 0.7173913  0.61956522\n",
      " 0.45108696 0.33152174 0.63043478 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 888\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 50, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=50, random_state=100))])\n",
      "cv score: [0.54782609 0.37826087 0.4826087  0.47826087 0.7826087  0.60869565\n",
      " 0.50543478 0.40217391 0.60326087 0.64130435]\n",
      "----------------------------------------\n",
      "Trial 889\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 29, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=29,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63913043 0.52826087 0.31956522 0.60434783 0.67391304 0.42119565\n",
      " 0.50271739 0.75       0.54891304 0.73913043]\n",
      "----------------------------------------\n",
      "Trial 890\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 90, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=90, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65652174 0.34782609 0.46521739 0.53913043 0.625      0.50543478\n",
      " 0.48369565 0.35326087 0.75       0.59782609]\n",
      "----------------------------------------\n",
      "Trial 891\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 152, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=152,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76086957 0.42608696 0.4826087  0.64347826 0.73913043 0.61413043\n",
      " 0.46195652 0.32608696 0.67391304 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 892\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 181, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=181,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67826087 0.43043478 0.6173913  0.50869565 0.73369565 0.625\n",
      " 0.65217391 0.44021739 0.50271739 0.56793478]\n",
      "----------------------------------------\n",
      "Trial 893\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 146, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=146,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75217391 0.37826087 0.46956522 0.53913043 0.73369565 0.64130435\n",
      " 0.4673913  0.41847826 0.67934783 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 894\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 185, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='sqrt',\n",
      "                                            n_estimators=185,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.65652174 0.43043478 0.43478261 0.4826087  0.77173913 0.55978261\n",
      " 0.44565217 0.63586957 0.66847826 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 895\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47391304 0.29130435 0.52173913 0.53478261 0.77717391 0.40217391\n",
      " 0.4673913  0.70652174 0.5        0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 896\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 98, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=98,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64347826 0.34347826 0.57391304 0.54782609 0.78804348 0.52173913\n",
      " 0.55434783 0.46195652 0.63586957 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 897\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63478261 0.1826087  0.60434783 0.40869565 0.72826087 0.42391304\n",
      " 0.34782609 0.48369565 0.57608696 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 898\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 42, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=42,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49130435 0.30434783 0.68695652 0.49565217 0.77173913 0.50543478\n",
      " 0.57608696 0.49456522 0.66847826 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 899\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 197, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=197, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.69130435 0.36521739 0.43478261 0.6        0.75543478 0.60869565\n",
      " 0.4673913  0.36956522 0.63043478 0.56521739]\n",
      "----------------------------------------\n",
      "Trial 900\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 61, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=61, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.79130435 0.48695652 0.54347826 0.58695652 0.64130435 0.57065217\n",
      " 0.4673913  0.5326087  0.5298913  0.57608696]\n",
      "----------------------------------------\n",
      "Trial 901\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 153, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=153, random_state=100))])\n",
      "cv score: [0.48043478 0.35       0.48913043 0.4173913  0.67391304 0.45108696\n",
      " 0.46467391 0.32336957 0.70652174 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 902\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50434783 0.29130435 0.56086957 0.54782609 0.72826087 0.47282609\n",
      " 0.54347826 0.51086957 0.58152174 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 903\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 99, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=99, random_state=100))])\n",
      "cv score: [0.66956522 0.39565217 0.4826087  0.40869565 0.73369565 0.625\n",
      " 0.45652174 0.42934783 0.625      0.63043478]\n",
      "----------------------------------------\n",
      "Trial 904\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 32, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=32,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74347826 0.45217391 0.6173913  0.42608696 0.66032609 0.55978261\n",
      " 0.67391304 0.3451087  0.51630435 0.58967391]\n",
      "----------------------------------------\n",
      "Trial 905\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 154, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=154,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47391304 0.29130435 0.49130435 0.5826087  0.77173913 0.48913043\n",
      " 0.39130435 0.6576087  0.39130435 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 906\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 192, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=192, random_state=100))])\n",
      "cv score: [0.65217391 0.43043478 0.44347826 0.42173913 0.72826087 0.625\n",
      " 0.46195652 0.44565217 0.625      0.66304348]\n",
      "----------------------------------------\n",
      "Trial 907\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=178,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60652174 0.41304348 0.57826087 0.4826087  0.43478261 0.33695652\n",
      " 0.5923913  0.33695652 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 908\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 59, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=59, random_state=100))])\n",
      "cv score: [0.57391304 0.53478261 0.4        0.54782609 0.5        0.67934783\n",
      " 0.4076087  0.22826087 0.61413043 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 909\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            n_estimators=52, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43695652 0.53043478 0.22826087 0.54347826 0.63043478 0.57065217\n",
      " 0.52445652 0.4673913  0.47282609 0.86413043]\n",
      "----------------------------------------\n",
      "Trial 910\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=8, max_features='log2',\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.62173913 0.5826087  0.4        0.66956522 0.67934783 0.66304348\n",
      " 0.44021739 0.42391304 0.625      0.58695652]\n",
      "----------------------------------------\n",
      "Trial 911\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=115,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76521739 0.45217391 0.51304348 0.59565217 0.64130435 0.49184783\n",
      " 0.50543478 0.55434783 0.60869565 0.66304348]\n",
      "----------------------------------------\n",
      "Trial 912\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 147, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=147,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.7173913  0.44347826 0.5826087  0.40652174 0.70108696 0.48913043\n",
      " 0.69021739 0.625      0.48641304 0.54619565]\n",
      "----------------------------------------\n",
      "Trial 913\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 112, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=112, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.72608696 0.46956522 0.5        0.56956522 0.6576087  0.50271739\n",
      " 0.51630435 0.52717391 0.59782609 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 914\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 181, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=181, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.56086957 0.41304348 0.53913043 0.44782609 0.72282609 0.58152174\n",
      " 0.60326087 0.59782609 0.3423913  0.57065217]\n",
      "----------------------------------------\n",
      "Trial 915\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 142, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            n_estimators=142, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.54782609 0.36086957 0.4826087  0.4826087  0.76086957 0.375\n",
      " 0.43478261 0.2826087  0.75       0.54347826]\n",
      "----------------------------------------\n",
      "Trial 916\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56521739 0.3        0.57826087 0.41304348 0.77173913 0.58152174\n",
      " 0.54347826 0.51086957 0.51086957 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 917\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 140, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, n_estimators=140,\n",
      "                                            random_state=100, subsample=0.6))])\n",
      "cv score: [0.6        0.27391304 0.39565217 0.59565217 0.6576087  0.39130435\n",
      " 0.47282609 0.3423913  0.52173913 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 918\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 183, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=183,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70217391 0.35217391 0.57173913 0.46086957 0.625      0.5\n",
      " 0.7173913  0.4673913  0.55434783 0.5625    ]\n",
      "----------------------------------------\n",
      "Trial 919\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=91, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57391304 0.5826087  0.54782609 0.64347826 0.57608696 0.7173913\n",
      " 0.31521739 0.2826087  0.49456522 0.66304348]\n",
      "----------------------------------------\n",
      "Trial 920\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 129, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=129, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.55652174 0.53043478 0.42608696 0.59565217 0.83695652 0.68478261\n",
      " 0.39673913 0.52717391 0.54347826 0.60869565]\n",
      "----------------------------------------\n",
      "Trial 921\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65       0.37608696 0.5673913  0.57608696 0.47282609 0.5298913\n",
      " 0.62771739 0.51358696 0.57065217 0.60054348]\n",
      "----------------------------------------\n",
      "Trial 922\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 14, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=14, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.68695652 0.4        0.42608696 0.56086957 0.80978261 0.60326087\n",
      " 0.47282609 0.5        0.55978261 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 923\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 73, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=73,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67826087 0.41956522 0.56956522 0.49130435 0.69836957 0.44565217\n",
      " 0.7173913  0.4076087  0.5326087  0.48369565]\n",
      "----------------------------------------\n",
      "Trial 924\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 60, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            n_estimators=60, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.53913043 0.30434783 0.51304348 0.52173913 0.77173913 0.39130435\n",
      " 0.47282609 0.41304348 0.61956522 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 925\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=16,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64347826 0.32608696 0.53043478 0.58478261 0.67663043 0.52445652\n",
      " 0.44021739 0.39673913 0.70380435 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 926\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 60, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=60, random_state=100))])\n",
      "cv score: [0.50434783 0.3826087  0.50869565 0.45217391 0.60869565 0.42391304\n",
      " 0.49456522 0.32065217 0.73641304 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 927\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 71, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=12,\n",
      "                                            n_estimators=71, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.57391304 0.43043478 0.29565217 0.46086957 0.56521739 0.53804348\n",
      " 0.23369565 0.2173913  0.60326087 0.66847826]\n",
      "----------------------------------------\n",
      "Trial 928\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 64, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=64,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.67391304 0.41304348 0.47826087 0.52608696 0.67391304 0.53804348\n",
      " 0.42391304 0.375      0.66847826 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 929\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 179, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=179,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65652174 0.5        0.58478261 0.50434783 0.74456522 0.54347826\n",
      " 0.78804348 0.48641304 0.51358696 0.5298913 ]\n",
      "----------------------------------------\n",
      "Trial 930\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 104, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=104, random_state=100))])\n",
      "cv score: [0.86521739 0.42608696 0.50434783 0.55652174 0.66304348 0.63586957\n",
      " 0.53804348 0.55978261 0.625      0.57065217]\n",
      "----------------------------------------\n",
      "Trial 931\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 31, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=31, random_state=100))])\n",
      "cv score: [0.67826087 0.4        0.52173913 0.49130435 0.67934783 0.51086957\n",
      " 0.4673913  0.3423913  0.64402174 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 932\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 44, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=44, random_state=100))])\n",
      "cv score: [0.53043478 0.36521739 0.50434783 0.51304348 0.60869565 0.4673913\n",
      " 0.5        0.32608696 0.70652174 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 933\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 188, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=188,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45217391 0.27826087 0.55217391 0.49130435 0.67391304 0.41847826\n",
      " 0.45652174 0.4673913  0.5        0.54347826]\n",
      "----------------------------------------\n",
      "Trial 934\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 171, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=171, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.54347826 0.52173913 0.43043478 0.54782609 0.69565217 0.60326087\n",
      " 0.41304348 0.33152174 0.64130435 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 935\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 39, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=39, random_state=100))])\n",
      "cv score: [0.49565217 0.42173913 0.4326087  0.53913043 0.5        0.69021739\n",
      " 0.41576087 0.25543478 0.59782609 0.58695652]\n",
      "----------------------------------------\n",
      "Trial 936\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72826087 0.43695652 0.61086957 0.46086957 0.73097826 0.63586957\n",
      " 0.6548913  0.51358696 0.49456522 0.5625    ]\n",
      "----------------------------------------\n",
      "Trial 937\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 194, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=194,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63695652 0.43695652 0.54130435 0.42608696 0.61141304 0.49456522\n",
      " 0.76086957 0.51630435 0.60326087 0.66847826]\n",
      "----------------------------------------\n",
      "Trial 938\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 85, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=85, random_state=100))])\n",
      "cv score: [0.70869565 0.41304348 0.53478261 0.45652174 0.7173913  0.5\n",
      " 0.45108696 0.48913043 0.625      0.60326087]\n",
      "----------------------------------------\n",
      "Trial 939\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 55, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=55,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.52608696 0.2826087  0.52173913 0.5        0.76630435 0.51630435\n",
      " 0.56521739 0.4673913  0.58695652 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 940\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 112, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=112,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47391304 0.3173913  0.56086957 0.49130435 0.72282609 0.57065217\n",
      " 0.52173913 0.47826087 0.53804348 0.58152174]\n",
      "----------------------------------------\n",
      "Trial 941\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 129, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=129, random_state=100))])\n",
      "cv score: [0.67826087 0.40434783 0.44782609 0.5826087  0.67934783 0.58152174\n",
      " 0.4673913  0.52173913 0.65217391 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 942\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 187, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            n_estimators=187, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.60434783 0.36956522 0.47826087 0.46521739 0.66304348 0.57065217\n",
      " 0.45108696 0.23913043 0.70108696 0.52173913]\n",
      "----------------------------------------\n",
      "Trial 943\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 114, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=114,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5173913  0.33913043 0.56521739 0.3826087  0.77717391 0.67391304\n",
      " 0.3423913  0.6576087  0.54347826 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 944\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 96, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=4,\n",
      "                                            n_estimators=96, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.8        0.42608696 0.53478261 0.64347826 0.47282609 0.5625\n",
      " 0.64130435 0.44021739 0.70652174 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 945\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 151, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=151,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73478261 0.36521739 0.60434783 0.46956522 0.73369565 0.55978261\n",
      " 0.63043478 0.43478261 0.56521739 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 946\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 193, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=193,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66086957 0.38913043 0.57608696 0.73043478 0.45108696 0.57608696\n",
      " 0.47282609 0.30706522 0.57608696 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 947\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 41, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=41,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54347826 0.34782609 0.66086957 0.40434783 0.78804348 0.5923913\n",
      " 0.49456522 0.5        0.6576087  0.48913043]\n",
      "----------------------------------------\n",
      "Trial 948\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 135, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=135,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.7173913  0.47391304 0.58913043 0.5173913  0.73369565 0.46195652\n",
      " 0.61413043 0.6576087  0.50543478 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 949\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54782609 0.23478261 0.59565217 0.5173913  0.75       0.48913043\n",
      " 0.48369565 0.57065217 0.55434783 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 950\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 49, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=49,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.7        0.33043478 0.55       0.49130435 0.69021739 0.45652174\n",
      " 0.60869565 0.32065217 0.77173913 0.5326087 ]\n",
      "----------------------------------------\n",
      "Trial 951\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 32, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=32,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71304348 0.40434783 0.5826087  0.60869565 0.66847826 0.56793478\n",
      " 0.52717391 0.47282609 0.64673913 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 952\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 62, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=62, random_state=100))])\n",
      "cv score: [0.59565217 0.37826087 0.50869565 0.52173913 0.57608696 0.51086957\n",
      " 0.47826087 0.34782609 0.75       0.54347826]\n",
      "----------------------------------------\n",
      "Trial 953\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 28, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=28,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64347826 0.30869565 0.59130435 0.45434783 0.77173913 0.45652174\n",
      " 0.51630435 0.5        0.59782609 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 954\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 34, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=34, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.67391304 0.4        0.52608696 0.55217391 0.76086957 0.46195652\n",
      " 0.41304348 0.35326087 0.64673913 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 955\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 85, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=85,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67391304 0.33043478 0.53043478 0.54347826 0.67934783 0.51630435\n",
      " 0.53804348 0.43478261 0.68478261 0.51086957]\n",
      "----------------------------------------\n",
      "Trial 956\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 155, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=155, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57826087 0.4        0.49565217 0.4173913  0.64673913 0.46195652\n",
      " 0.46195652 0.34782609 0.73369565 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 957\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 106, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=106, random_state=100))])\n",
      "cv score: [0.86086957 0.4173913  0.50434783 0.55652174 0.66304348 0.64673913\n",
      " 0.53804348 0.55978261 0.625      0.58152174]\n",
      "----------------------------------------\n",
      "Trial 958\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 127, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=127,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64782609 0.39565217 0.43043478 0.58695652 0.73369565 0.66847826\n",
      " 0.46195652 0.34782609 0.63586957 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 959\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 188, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=188,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5173913  0.2173913  0.51304348 0.55217391 0.61956522 0.4673913\n",
      " 0.47826087 0.47826087 0.46195652 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 960\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 75, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=75,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52608696 0.28695652 0.52173913 0.52608696 0.82608696 0.48369565\n",
      " 0.42391304 0.42391304 0.38043478 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 961\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 172, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=172,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6826087  0.43913043 0.57826087 0.45       0.58695652 0.5326087\n",
      " 0.73641304 0.54891304 0.50815217 0.49184783]\n",
      "----------------------------------------\n",
      "Trial 962\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=14,\n",
      "                                            n_estimators=68, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.52608696 0.36521739 0.56956522 0.39130435 0.69021739 0.51086957\n",
      " 0.375      0.27173913 0.77173913 0.73369565]\n",
      "----------------------------------------\n",
      "Trial 963\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61304348 0.51086957 0.64130435 0.42608696 0.66576087 0.46195652\n",
      " 0.75543478 0.5625     0.57880435 0.54619565]\n",
      "----------------------------------------\n",
      "Trial 964\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 114, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=114, random_state=100))])\n",
      "cv score: [0.61304348 0.49565217 0.39130435 0.53913043 0.5326087  0.73369565\n",
      " 0.44021739 0.27173913 0.59782609 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 965\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 134, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=134, random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.72173913 0.44347826 0.50869565 0.62173913 0.64673913 0.49456522\n",
      " 0.54347826 0.56521739 0.63586957 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 966\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 161, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=161, random_state=100))])\n",
      "cv score: [0.59565217 0.39565217 0.49130435 0.41304348 0.64673913 0.47826087\n",
      " 0.45652174 0.3423913  0.72282609 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 967\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 138, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            n_estimators=138, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.72608696 0.4826087  0.54782609 0.70434783 0.54891304 0.57065217\n",
      " 0.61956522 0.38586957 0.69021739 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 968\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 181, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=181, random_state=100))])\n",
      "cv score: [0.58695652 0.4173913  0.39130435 0.53913043 0.73369565 0.67391304\n",
      " 0.43206522 0.43206522 0.625      0.54891304]\n",
      "----------------------------------------\n",
      "Trial 969\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 128, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=128, random_state=100))])\n",
      "cv score: [0.69130435 0.33043478 0.47826087 0.55652174 0.76630435 0.65217391\n",
      " 0.43478261 0.33695652 0.60869565 0.5923913 ]\n",
      "----------------------------------------\n",
      "Trial 970\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 131, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=131,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60652174 0.41304348 0.57826087 0.4826087  0.43478261 0.33695652\n",
      " 0.5923913  0.33695652 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 971\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 146, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, max_features='log2',\n",
      "                                            n_estimators=146, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.6173913  0.43478261 0.37391304 0.6826087  0.83695652 0.64130435\n",
      " 0.48369565 0.52717391 0.47826087 0.55978261]\n",
      "----------------------------------------\n",
      "Trial 972\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 52, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=52,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62826087 0.40869565 0.56521739 0.59782609 0.48097826 0.50271739\n",
      " 0.62228261 0.54891304 0.57608696 0.60597826]\n",
      "----------------------------------------\n",
      "Trial 973\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 194, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=194,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66521739 0.30869565 0.59130435 0.50434783 0.72826087 0.61956522\n",
      " 0.50543478 0.52173913 0.55434783 0.57608696]\n",
      "----------------------------------------\n",
      "Trial 974\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72173913 0.35217391 0.56086957 0.54347826 0.70652174 0.5\n",
      " 0.55434783 0.42391304 0.61413043 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 975\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 40, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=40, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.69565217 0.40434783 0.5173913  0.55652174 0.64130435 0.57608696\n",
      " 0.45108696 0.42934783 0.58152174 0.59782609]\n",
      "----------------------------------------\n",
      "Trial 976\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 38, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=38,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60869565 0.47608696 0.5173913  0.5173913  0.67663043 0.49728261\n",
      " 0.68206522 0.51630435 0.51358696 0.47282609]\n",
      "----------------------------------------\n",
      "Trial 977\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 48, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=48,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.46086957 0.26086957 0.66956522 0.50434783 0.77173913 0.58695652\n",
      " 0.50543478 0.51086957 0.58695652 0.46195652]\n",
      "----------------------------------------\n",
      "Trial 978\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 67, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=67,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49130435 0.30434783 0.54782609 0.6173913  0.70652174 0.57065217\n",
      " 0.5326087  0.42391304 0.55978261 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 979\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 171, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=171,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53478261 0.22173913 0.59565217 0.41304348 0.73369565 0.45652174\n",
      " 0.39130435 0.67391304 0.51086957 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 980\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 49, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=49,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60652174 0.41304348 0.57826087 0.4826087  0.43478261 0.33695652\n",
      " 0.5923913  0.33695652 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 981\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 85, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=85,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6326087  0.29347826 0.58043478 0.77826087 0.39945652 0.39673913\n",
      " 0.64130435 0.61956522 0.48369565 0.47554348]\n",
      "----------------------------------------\n",
      "Trial 982\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 190, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=190, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.6        0.12173913 0.40434783 0.6826087  0.5326087  0.49456522\n",
      " 0.36956522 0.45108696 0.48913043 0.54347826]\n",
      "----------------------------------------\n",
      "Trial 983\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 143, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=143,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53478261 0.27826087 0.58695652 0.5173913  0.77717391 0.5326087\n",
      " 0.50543478 0.59782609 0.57608696 0.51630435]\n",
      "----------------------------------------\n",
      "Trial 984\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.40869565 0.28695652 0.51304348 0.51304348 0.73369565 0.5\n",
      " 0.52173913 0.4673913  0.47826087 0.47282609]\n",
      "----------------------------------------\n",
      "Trial 985\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 140, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=140, random_state=100))])\n",
      "cv score: [0.74782609 0.43478261 0.5173913  0.4826087  0.73913043 0.54891304\n",
      " 0.45652174 0.4673913  0.63586957 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 986\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 128, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=128, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.70869565 0.43478261 0.50869565 0.60869565 0.63043478 0.5\n",
      " 0.54891304 0.56521739 0.61413043 0.63043478]\n",
      "----------------------------------------\n",
      "Trial 987\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 87, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=87, random_state=100))])\n",
      "cv score: [0.74782609 0.42173913 0.4826087  0.50869565 0.60326087 0.66847826\n",
      " 0.42934783 0.32065217 0.60869565 0.44293478]\n",
      "----------------------------------------\n",
      "Trial 988\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 122, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=122,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56956522 0.32608696 0.56521739 0.54347826 0.7826087  0.60869565\n",
      " 0.5        0.55434783 0.5923913  0.55978261]\n",
      "----------------------------------------\n",
      "Trial 989\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 80, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=80,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71086957 0.44130435 0.58913043 0.53478261 0.73369565 0.58152174\n",
      " 0.63858696 0.5326087  0.50271739 0.54076087]\n",
      "----------------------------------------\n",
      "Trial 990\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 199, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=199, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.39565217 0.45652174 0.61521739 0.54782609 0.54619565 0.41847826\n",
      " 0.44836957 0.41304348 0.64673913 0.33423913]\n",
      "----------------------------------------\n",
      "Trial 991\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 149, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=149,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76086957 0.44347826 0.49130435 0.6        0.61956522 0.49456522\n",
      " 0.51630435 0.57608696 0.65217391 0.6576087 ]\n",
      "----------------------------------------\n",
      "Trial 992\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            n_estimators=183,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.59130435 0.41304348 0.57826087 0.59130435 0.45652174 0.36956522\n",
      " 0.61413043 0.23913043 0.54619565 0.54891304]\n",
      "----------------------------------------\n",
      "Trial 993\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 180, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=180, random_state=100))])\n",
      "cv score: [0.60434783 0.39565217 0.4826087  0.49565217 0.64673913 0.5326087\n",
      " 0.48913043 0.34782609 0.71195652 0.57065217]\n",
      "----------------------------------------\n",
      "Trial 994\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 43, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=43, random_state=100))])\n",
      "cv score: [0.82173913 0.42608696 0.40434783 0.48695652 0.57608696 0.49456522\n",
      " 0.49456522 0.45652174 0.58152174 0.60326087]\n",
      "----------------------------------------\n",
      "Trial 995\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 33, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=33,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66956522 0.32608696 0.56521739 0.56956522 0.72826087 0.58695652\n",
      " 0.36956522 0.51086957 0.60326087 0.46195652]\n",
      "----------------------------------------\n",
      "Trial 996\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54347826 0.24782609 0.6        0.67826087 0.74456522 0.4076087\n",
      " 0.53804348 0.61413043 0.45652174 0.61413043]\n",
      "----------------------------------------\n",
      "Trial 997\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 175, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=175,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34782609 0.24347826 0.48695652 0.44347826 0.8423913  0.48913043\n",
      " 0.35869565 0.63586957 0.47282609 0.63586957]\n",
      "----------------------------------------\n",
      "Trial 998\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 167, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=167,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75217391 0.45217391 0.48695652 0.59565217 0.63043478 0.48913043\n",
      " 0.51630435 0.58152174 0.64130435 0.65217391]\n",
      "----------------------------------------\n",
      "Trial 999\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 196, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=196,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61304348 0.41304348 0.5826087  0.69565217 0.42663043 0.33695652\n",
      " 0.62228261 0.39402174 0.50543478 0.52445652]\n",
      "----------------------------------------\n",
      "Selecting and refitting best classifier\n",
      "----------------------------------------\n",
      "best score: 0.6081521739130434\n",
      "best pipe: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            n_estimators=183,\n",
      "                                            random_state=100))])\n"
     ]
    }
   ],
   "source": [
    "# do the search\n",
    "_,_, best_estimator_rec = mmh.randomized_search_cv(X_rec_rest, y_rec_rest, \n",
    "                                                   search_space, \n",
    "                                                   cv=cv_10,\n",
    "                                                   refit=True,\n",
    "                                                   n_iter=5000, \n",
    "                                                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e2559d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the test set\n",
      "Classification accuracy: 0.9078947368421053\n",
      "AUROC: 0.5\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "Log-loss: 3.181203089004932\n"
     ]
    }
   ],
   "source": [
    "mmh.get_test_scores(X_rec_rest, y_rec_rest, X_rec_test, y_rec_test, best_estimator_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bd00ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_rec_test = confusion_matrix(y_rec_test, best_estimator_rec.predict(X_rec_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_rec_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92eb509",
   "metadata": {},
   "source": [
    "---\n",
    "## Predicting $T$ (drain) from controls $X, W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f79390fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_drain_full = csdh_doc['drain']\n",
    "X_drain_full = csdh_doc.drop(['drain', 'recurrence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a42a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation set and rest\n",
    "X_drain_rest, X_drain_val, y_drain_rest, y_drain_val = train_test_split(X_drain_full, y_drain_full, \n",
    "                                                                        test_size=0.20,\n",
    "                                                                        random_state=random_state,\n",
    "                                                                        stratify=y_drain_full)\n",
    "\n",
    "# Split rest into train and test set\n",
    "X_drain_train, X_drain_test, y_drain_train, y_drain_test = train_test_split(X_drain_rest, y_drain_rest, \n",
    "                                                                            test_size=0.20,\n",
    "                                                                            random_state=random_state,\n",
    "                                                                            stratify=y_drain_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61a30f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:56:12] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "drain_training_scores, drain_val_scores = mmh.train_and_validate_classifiers(X_drain_train, \n",
    "                                                                             y_drain_train,\n",
    "                                                                             X_drain_val,\n",
    "                                                                             y_drain_val,\n",
    "                                                                             names,\n",
    "                                                                             classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c9fdb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set: \n",
      "\n",
      "             ----------------Validation-----------------   -----------------Training------------------\n",
      "Method         Acc   AUROC  Recall      F1      LL     Acc   AUROC  Recall      F1      LL\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dummy         0.844    0.500    1.000    0.916   5.373    0.839    0.500    1.000    0.912    5.568\n",
      "LR            0.844    0.500    1.000    0.916   5.373    0.846    0.522    1.000    0.916    5.326\n",
      "Linear SVM    0.844    0.500    1.000    0.916   5.373    0.839    0.500    1.000    0.912    5.568\n",
      "RBF SVM       0.844    0.500    1.000    0.916   5.373    0.839    0.500    1.000    0.912    5.568\n",
      "GB            0.800    0.503    0.934    0.888   6.908    0.956    0.874    0.994    0.974    1.533\n",
      "RF            0.844    0.500    1.000    0.916   5.373    1.000    1.000    1.000    1.000    0.000\n",
      "XGB           0.767    0.512    0.882    0.865   8.059    1.000    1.000    1.000    1.000    0.000\n"
     ]
    }
   ],
   "source": [
    "mmh.print_metrics_table(drain_training_scores, drain_val_scores, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9724ce35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_drain_test = confusion_matrix(y_drain_test, classifiers[5].predict(X_drain_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_drain_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5016b273",
   "metadata": {},
   "source": [
    "## `model_t` K-Fold cross validation for hyperparameter tuning and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c247fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv strategy StratifiedKFold(n_splits=10, random_state=100, shuffle=True)\n",
      "----------------------------------------\n",
      "Trial 0\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 41, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=41, random_state=100))])\n",
      "cv score: [0.88081395 0.75436047 0.65843023 0.66666667 0.75892857 0.5922619\n",
      " 0.79017857 0.80952381 0.60714286 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 1\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 23, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=23,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90988372 0.83430233 0.70639535 0.82539683 0.89880952 0.91964286\n",
      " 0.82142857 0.88690476 0.79464286 0.7172619 ]\n",
      "----------------------------------------\n",
      "Trial 2\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 69, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=69, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.75872093 0.75581395 0.51744186 0.61904762 0.64285714 0.88392857\n",
      " 0.61904762 0.70833333 0.7202381  0.53571429]\n",
      "----------------------------------------\n",
      "Trial 3\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 28, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=28,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.75872093 0.77325581 0.62209302 0.6031746  0.79761905 0.77083333\n",
      " 0.73214286 0.78571429 0.80654762 0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 4\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 177, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=9,\n",
      "                                            n_estimators=177, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.81686047 0.70930233 0.64244186 0.8015873  0.69047619 0.8125\n",
      " 0.73511905 0.625      0.83035714 0.52678571]\n",
      "----------------------------------------\n",
      "Trial 5\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 123, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=123,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.81686047 0.74127907 0.76984127 0.91369048 0.9047619\n",
      " 0.77380952 0.85416667 0.7797619  0.66071429]\n",
      "----------------------------------------\n",
      "Trial 6\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 20, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=20,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84302326 0.70348837 0.64825581 0.76322751 0.8139881  0.88095238\n",
      " 0.71279762 0.79910714 0.71130952 0.66220238]\n",
      "----------------------------------------\n",
      "Trial 7\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 46, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=46, random_state=100))])\n",
      "cv score: [0.93604651 0.76744186 0.73255814 0.84920635 0.88095238 0.92559524\n",
      " 0.8125     0.85119048 0.83630952 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 8\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 17, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=17,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90116279 0.75581395 0.75581395 0.72486772 0.86011905 0.9375\n",
      " 0.63988095 0.85416667 0.73214286 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 9\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93604651 0.8255814  0.75290698 0.78571429 0.9047619  0.91369048\n",
      " 0.83333333 0.86607143 0.84821429 0.72619048]\n",
      "----------------------------------------\n",
      "Trial 10\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 41, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=41, random_state=100))])\n",
      "cv score: [0.91860465 0.77906977 0.68313953 0.78571429 0.82440476 0.79761905\n",
      " 0.76190476 0.79166667 0.80059524 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 11\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 156, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=156, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.90116279 0.75       0.74709302 0.63227513 0.91964286 0.8422619\n",
      " 0.78869048 0.6547619  0.77678571 0.55059524]\n",
      "----------------------------------------\n",
      "Trial 12\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 70, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=70,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.92732558 0.77616279 0.74709302 0.76190476 0.87202381 0.86904762\n",
      " 0.79761905 0.83928571 0.79761905 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 13\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 93, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=93, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.91860465 0.77906977 0.65116279 0.76984127 0.82142857 0.79166667\n",
      " 0.75892857 0.83630952 0.75       0.51785714]\n",
      "----------------------------------------\n",
      "Trial 14\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 35, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=35,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.84011628 0.68459302 0.75661376 0.89583333 0.91369048\n",
      " 0.83928571 0.88690476 0.82440476 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 15\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.92151163 0.78488372 0.68604651 0.6984127  0.89880952 0.80952381\n",
      " 0.82440476 0.78571429 0.75297619 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 16\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 180, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=180, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.88081395 0.80523256 0.74418605 0.7037037  0.91369048 0.83035714\n",
      " 0.83333333 0.72619048 0.74404762 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 17\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 155, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=155,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.81104651 0.71656977 0.85449735 0.88988095 0.9077381\n",
      " 0.8110119  0.85863095 0.79761905 0.70684524]\n",
      "----------------------------------------\n",
      "Trial 18\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 136, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=136, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.875      0.7994186  0.75872093 0.6984127  0.9047619  0.79761905\n",
      " 0.76488095 0.63988095 0.70238095 0.5327381 ]\n",
      "----------------------------------------\n",
      "Trial 19\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 100, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.9244186  0.77906977 0.72383721 0.83597884 0.87202381 0.9047619\n",
      " 0.81845238 0.875      0.79761905 0.7172619 ]\n",
      "----------------------------------------\n",
      "Trial 20\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 74, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=74,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.85755814 0.74418605 0.68895349 0.71428571 0.85714286 0.81547619\n",
      " 0.79761905 0.83035714 0.75595238 0.58630952]\n",
      "----------------------------------------\n",
      "Trial 21\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 44, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=44,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.85901163 0.74709302 0.63517442 0.71957672 0.79166667 0.72619048\n",
      " 0.75       0.81547619 0.78571429 0.58928571]\n",
      "----------------------------------------\n",
      "Trial 22\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 52, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=52,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94186047 0.81395349 0.70494186 0.76984127 0.875      0.85416667\n",
      " 0.83333333 0.88988095 0.77380952 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 23\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 88, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, n_estimators=88,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.91860465 0.80813953 0.7877907  0.68518519 0.81547619 0.88392857\n",
      " 0.67261905 0.77083333 0.79464286 0.52380952]\n",
      "----------------------------------------\n",
      "Trial 24\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 52, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=52,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.89244186 0.81104651 0.71802326 0.75132275 0.89583333 0.93452381\n",
      " 0.78869048 0.84821429 0.75595238 0.7172619 ]\n",
      "----------------------------------------\n",
      "Trial 25\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 131, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=131,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.77616279 0.68168605 0.78835979 0.9047619  0.94642857\n",
      " 0.79910714 0.91071429 0.79166667 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 26\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 16, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=16,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88953488 0.79505814 0.6497093  0.6984127  0.84970238 0.63988095\n",
      " 0.8125     0.77380952 0.59821429 0.63541667]\n",
      "----------------------------------------\n",
      "Trial 27\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 99, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=99,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.83430233 0.76453488 0.72383721 0.80687831 0.89583333 0.91666667\n",
      " 0.74107143 0.82738095 0.76190476 0.64285714]\n",
      "----------------------------------------\n",
      "Trial 28\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 161, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=161, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.87790698 0.80523256 0.65406977 0.73280423 0.85416667 0.89583333\n",
      " 0.85714286 0.81547619 0.7797619  0.625     ]\n",
      "----------------------------------------\n",
      "Trial 29\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 113, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=113, random_state=100))])\n",
      "cv score: [0.86046512 0.74418605 0.64534884 0.73809524 0.85714286 0.86904762\n",
      " 0.86309524 0.79464286 0.78869048 0.63690476]\n",
      "----------------------------------------\n",
      "Trial 30\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 103, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            n_estimators=103, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.91569767 0.75       0.7994186  0.79100529 0.89880952 0.91071429\n",
      " 0.77678571 0.8452381  0.79166667 0.68154762]\n",
      "----------------------------------------\n",
      "Trial 31\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.86627907 0.77906977 0.68895349 0.70899471 0.91071429 0.9047619\n",
      " 0.76190476 0.82440476 0.7827381  0.48214286]\n",
      "----------------------------------------\n",
      "Trial 32\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 75, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=75,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.875      0.72383721 0.72383721 0.6984127  0.88541667 0.87202381\n",
      " 0.88690476 0.82142857 0.78571429 0.57738095]\n",
      "----------------------------------------\n",
      "Trial 33\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 112, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=112, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.81104651 0.77906977 0.77906977 0.67460317 0.93154762 0.85416667\n",
      " 0.67261905 0.61309524 0.7797619  0.59821429]\n",
      "----------------------------------------\n",
      "Trial 34\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 60, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=60,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.79360465 0.69186047 0.8015873  0.88988095 0.91369048\n",
      " 0.82738095 0.89285714 0.80654762 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 35\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 126, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=126,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90697674 0.83139535 0.72093023 0.71693122 0.91071429 0.89583333\n",
      " 0.75       0.7827381  0.75       0.61904762]\n",
      "----------------------------------------\n",
      "Trial 36\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=183,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77616279 0.72674419 0.6119186  0.71031746 0.75595238 0.60119048\n",
      " 0.75892857 0.70684524 0.68452381 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 37\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 20, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=20,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.87209302 0.72819767 0.71947674 0.66402116 0.93005952 0.92559524\n",
      " 0.75595238 0.83035714 0.79761905 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 38\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.81976744 0.81976744 0.74418605 0.75661376 0.92559524 0.83333333\n",
      " 0.67559524 0.79166667 0.68452381 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 39\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 180, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=180,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84447674 0.72383721 0.64534884 0.8042328  0.81547619 0.84375\n",
      " 0.72321429 0.78571429 0.73363095 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 40\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 44, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=44, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.86918605 0.74418605 0.65116279 0.7037037  0.88095238 0.86607143\n",
      " 0.80654762 0.86309524 0.79761905 0.6547619 ]\n",
      "----------------------------------------\n",
      "Trial 41\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 54, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=54,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81686047 0.74127907 0.82539683 0.90178571 0.90178571\n",
      " 0.85119048 0.89583333 0.80357143 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 42\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 92, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=92, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.89825581 0.74418605 0.69476744 0.74603175 0.85119048 0.80654762\n",
      " 0.79464286 0.79166667 0.75297619 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 43\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 139, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=139,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94186047 0.84011628 0.74127907 0.77513228 0.89583333 0.89583333\n",
      " 0.85714286 0.88095238 0.81845238 0.70833333]\n",
      "----------------------------------------\n",
      "Trial 44\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=170, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.90988372 0.79360465 0.73546512 0.69312169 0.88392857 0.86011905\n",
      " 0.85416667 0.76488095 0.77678571 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 45\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 59, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=59, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.70639535 0.5755814  0.50436047 0.54232804 0.46428571 0.53571429\n",
      " 0.73511905 0.56547619 0.52380952 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 46\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 130, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=130,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.81395349 0.73255814 0.78835979 0.89880952 0.92261905\n",
      " 0.83630952 0.9077381  0.79761905 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 47\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 144, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=144, random_state=100))])\n",
      "cv score: [0.84883721 0.75290698 0.63081395 0.72486772 0.87797619 0.8422619\n",
      " 0.85714286 0.79166667 0.75892857 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 48\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 170, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=170,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.94186047 0.7877907  0.75290698 0.75132275 0.9077381  0.91666667\n",
      " 0.77678571 0.85416667 0.78869048 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 49\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 25, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=25,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94040698 0.7877907  0.71656977 0.76190476 0.86458333 0.90178571\n",
      " 0.77380952 0.89285714 0.83482143 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 50\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=91, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.93023256 0.72965116 0.76162791 0.73544974 0.85714286 0.88392857\n",
      " 0.7797619  0.74404762 0.78869048 0.57738095]\n",
      "----------------------------------------\n",
      "Trial 51\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 33, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=33,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91860465 0.81686047 0.6627907  0.7962963  0.88690476 0.89880952\n",
      " 0.85416667 0.9077381  0.80952381 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 52\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 189, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=189, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.72965116 0.58430233 0.65988372 0.64814815 0.7797619  0.73511905\n",
      " 0.89583333 0.58333333 0.64285714 0.51190476]\n",
      "----------------------------------------\n",
      "Trial 53\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 26, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=26,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84302326 0.71802326 0.60465116 0.78835979 0.75744048 0.84672619\n",
      " 0.69494048 0.69196429 0.68303571 0.75297619]\n",
      "----------------------------------------\n",
      "Trial 54\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=70,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6744186  0.69186047 0.49273256 0.55820106 0.68154762 0.48809524\n",
      " 0.52678571 0.60267857 0.51785714 0.44047619]\n",
      "----------------------------------------\n",
      "Trial 55\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 140, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=140, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.91569767 0.77906977 0.72965116 0.65079365 0.92559524 0.83035714\n",
      " 0.80952381 0.74107143 0.77678571 0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 56\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 15, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, max_features='log2',\n",
      "                                            n_estimators=15, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.72674419 0.6744186  0.70348837 0.71693122 0.83035714 0.87797619\n",
      " 0.80952381 0.64285714 0.73214286 0.74702381]\n",
      "----------------------------------------\n",
      "Trial 57\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 13, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            n_estimators=13, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.88226744 0.70784884 0.79505814 0.81613757 0.83928571 0.86458333\n",
      " 0.75       0.83928571 0.83035714 0.77827381]\n",
      "----------------------------------------\n",
      "Trial 58\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 67, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=67,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.92732558 0.80523256 0.69767442 0.81746032 0.88690476 0.91666667\n",
      " 0.81547619 0.86607143 0.83630952 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 59\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 19, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=19,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.88662791 0.72965116 0.65116279 0.74867725 0.89285714 0.875\n",
      " 0.87202381 0.82738095 0.7797619  0.52380952]\n",
      "----------------------------------------\n",
      "Trial 60\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 79, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=79, random_state=100))])\n",
      "cv score: [0.91569767 0.77616279 0.72674419 0.82539683 0.87202381 0.90178571\n",
      " 0.82440476 0.86607143 0.80654762 0.71428571]\n",
      "----------------------------------------\n",
      "Trial 61\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 91, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=91, random_state=100))])\n",
      "cv score: [0.90116279 0.77761628 0.62209302 0.74867725 0.88392857 0.88392857\n",
      " 0.84821429 0.80208333 0.8125     0.64880952]\n",
      "----------------------------------------\n",
      "Trial 62\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 84, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=84, random_state=100))])\n",
      "cv score: [0.90406977 0.77906977 0.63953488 0.75132275 0.86011905 0.88690476\n",
      " 0.8452381  0.78869048 0.79464286 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 63\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=70,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81686047 0.56686047 0.64244186 0.75793651 0.78571429 0.76636905\n",
      " 0.61309524 0.70833333 0.65922619 0.58035714]\n",
      "----------------------------------------\n",
      "Trial 64\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 57, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=57, random_state=100))])\n",
      "cv score: [0.83866279 0.76453488 0.68168605 0.71693122 0.82440476 0.64880952\n",
      " 0.69047619 0.8452381  0.66964286 0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 65\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 140, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=140,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.89244186 0.80523256 0.68313953 0.75925926 0.875      0.76488095\n",
      " 0.7797619  0.83630952 0.78571429 0.55059524]\n",
      "----------------------------------------\n",
      "Trial 66\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 38, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=38,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.80813953 0.72965116 0.80952381 0.89285714 0.89285714\n",
      " 0.86011905 0.91071429 0.7797619  0.70833333]\n",
      "----------------------------------------\n",
      "Trial 67\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.82267442 0.75872093 0.78042328 0.91369048 0.91369048\n",
      " 0.83630952 0.86309524 0.83035714 0.73511905]\n",
      "----------------------------------------\n",
      "Trial 68\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 41, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            n_estimators=41, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.90116279 0.76162791 0.79069767 0.77248677 0.89583333 0.875\n",
      " 0.80654762 0.85714286 0.83035714 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 69\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 80, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=80,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.84156977 0.73837209 0.67877907 0.7989418  0.85565476 0.85565476\n",
      " 0.6875     0.70833333 0.72172619 0.73809524]\n",
      "----------------------------------------\n",
      "Trial 70\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 118, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=118,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.80232558 0.75290698 0.78042328 0.9077381  0.92559524\n",
      " 0.8125     0.86309524 0.76785714 0.71428571]\n",
      "----------------------------------------\n",
      "Trial 71\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 113, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=113,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.80813953 0.72093023 0.77513228 0.88690476 0.91071429\n",
      " 0.72619048 0.81547619 0.79464286 0.63690476]\n",
      "----------------------------------------\n",
      "Trial 72\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 94, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=94,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.87790698 0.75290698 0.73255814 0.71560847 0.90029762 0.89880952\n",
      " 0.85119048 0.82142857 0.7827381  0.56845238]\n",
      "----------------------------------------\n",
      "Trial 73\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 109, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=109,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.82267442 0.72965116 0.78835979 0.89583333 0.92559524\n",
      " 0.83630952 0.9077381  0.78869048 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 74\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=174, random_state=100))])\n",
      "cv score: [0.87790698 0.7747093  0.66860465 0.74338624 0.88988095 0.875\n",
      " 0.85119048 0.79464286 0.8125     0.63988095]\n",
      "----------------------------------------\n",
      "Trial 75\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 0.95, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, max_features='sqrt',\n",
      "                                            n_estimators=170, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.88081395 0.74418605 0.71802326 0.67460317 0.9047619  0.85119048\n",
      " 0.78571429 0.72916667 0.76488095 0.54464286]\n",
      "----------------------------------------\n",
      "Trial 76\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 56, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=56,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.80232558 0.70639535 0.76190476 0.88988095 0.91666667\n",
      " 0.76488095 0.86904762 0.77083333 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 77\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 24, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=7, max_features='sqrt',\n",
      "                                            n_estimators=24, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.90697674 0.70348837 0.69186047 0.65873016 0.87202381 0.80654762\n",
      " 0.78571429 0.6547619  0.80357143 0.64880952]\n",
      "----------------------------------------\n",
      "Trial 78\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 114, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=114, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.89825581 0.75581395 0.69476744 0.72222222 0.875      0.88095238\n",
      " 0.82738095 0.82738095 0.77380952 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 79\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 155, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=155,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.81686047 0.71075581 0.76455026 0.89583333 0.91071429\n",
      " 0.8452381  0.87202381 0.83035714 0.69494048]\n",
      "----------------------------------------\n",
      "Trial 80\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 153, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=153, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.79651163 0.7122093  0.7005814  0.65873016 0.89583333 0.85416667\n",
      " 0.82440476 0.69345238 0.69047619 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 81\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 64, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=64,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.90261628 0.74709302 0.6744186  0.75396825 0.86309524 0.78571429\n",
      " 0.84821429 0.7827381  0.78869048 0.6547619 ]\n",
      "----------------------------------------\n",
      "Trial 82\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 71, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, n_estimators=71,\n",
      "                                            random_state=100, subsample=0.7))])\n",
      "cv score: [0.86918605 0.7994186  0.73837209 0.77777778 0.91071429 0.92559524\n",
      " 0.77083333 0.78571429 0.80357143 0.64583333]\n",
      "----------------------------------------\n",
      "Trial 83\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 120, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=120,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84156977 0.73837209 0.67877907 0.7989418  0.85565476 0.84375\n",
      " 0.6875     0.70833333 0.72172619 0.73809524]\n",
      "----------------------------------------\n",
      "Trial 84\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 111, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=111, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.89825581 0.76162791 0.69476744 0.68253968 0.87797619 0.87202381\n",
      " 0.80357143 0.80952381 0.75297619 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 85\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 88, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=88, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.90697674 0.77616279 0.64534884 0.76984127 0.8452381  0.77678571\n",
      " 0.7797619  0.83333333 0.71428571 0.64583333]\n",
      "----------------------------------------\n",
      "Trial 86\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 50, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=50,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.8255814  0.72674419 0.7962963  0.9047619  0.93154762\n",
      " 0.82738095 0.88095238 0.81547619 0.69791667]\n",
      "----------------------------------------\n",
      "Trial 87\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 190, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=190, random_state=100))])\n",
      "cv score: [0.86337209 0.75872093 0.65988372 0.76455026 0.86904762 0.87797619\n",
      " 0.85119048 0.80654762 0.79761905 0.64880952]\n",
      "----------------------------------------\n",
      "Trial 88\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 196, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=196, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.84593023 0.70639535 0.71511628 0.64021164 0.9077381  0.87797619\n",
      " 0.76785714 0.69642857 0.72916667 0.58630952]\n",
      "----------------------------------------\n",
      "Trial 89\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 107, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=107, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.92732558 0.80232558 0.67732558 0.7010582  0.9047619  0.88095238\n",
      " 0.83928571 0.76488095 0.74404762 0.68154762]\n",
      "----------------------------------------\n",
      "Trial 90\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 43, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=43,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.8255814  0.69040698 0.77248677 0.88988095 0.91369048\n",
      " 0.82440476 0.88392857 0.81547619 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 91\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 161, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            n_estimators=161,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.84302326 0.73546512 0.62645349 0.83333333 0.78422619 0.85863095\n",
      " 0.73660714 0.72619048 0.48214286 0.64434524]\n",
      "----------------------------------------\n",
      "Trial 92\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 86, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=86, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.8372093  0.74418605 0.77906977 0.68518519 0.9047619  0.82738095\n",
      " 0.69047619 0.66964286 0.81547619 0.4672619 ]\n",
      "----------------------------------------\n",
      "Trial 93\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 22, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=22,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88953488 0.83139535 0.70348837 0.71693122 0.9047619  0.9077381\n",
      " 0.75297619 0.77380952 0.79166667 0.66071429]\n",
      "----------------------------------------\n",
      "Trial 94\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 163, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            n_estimators=163, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.90406977 0.79651163 0.75872093 0.79100529 0.86607143 0.91369048\n",
      " 0.84821429 0.85416667 0.7827381  0.71130952]\n",
      "----------------------------------------\n",
      "Trial 95\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 114, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=114, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.875      0.79069767 0.73546512 0.6984127  0.86309524 0.8452381\n",
      " 0.86607143 0.74702381 0.76488095 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 96\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 158, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=158,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90116279 0.81686047 0.72093023 0.73544974 0.89285714 0.91369048\n",
      " 0.72916667 0.85714286 0.79761905 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 97\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 190, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=190, random_state=100))])\n",
      "cv score: [0.91569767 0.77325581 0.71511628 0.81481481 0.86607143 0.89285714\n",
      " 0.81547619 0.87797619 0.79464286 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 98\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 15, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=15,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.80959302 0.69331395 0.56395349 0.7962963  0.73660714 0.8422619\n",
      " 0.66369048 0.70238095 0.58035714 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 99\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 198, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=198,\n",
      "                                            random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.84011628 0.75872093 0.65116279 0.6984127  0.9077381  0.88392857\n",
      " 0.82440476 0.7797619  0.74107143 0.58630952]\n",
      "----------------------------------------\n",
      "Trial 100\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 42, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=42, random_state=100))])\n",
      "cv score: [0.9375     0.7877907  0.69186047 0.74338624 0.86309524 0.83333333\n",
      " 0.80505952 0.83035714 0.8110119  0.63690476]\n",
      "----------------------------------------\n",
      "Trial 101\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94186047 0.84011628 0.69186047 0.81216931 0.86309524 0.89583333\n",
      " 0.88095238 0.88392857 0.82738095 0.7172619 ]\n",
      "----------------------------------------\n",
      "Trial 102\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88081395 0.77906977 0.75872093 0.71428571 0.90178571 0.89583333\n",
      " 0.73511905 0.82440476 0.75595238 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 103\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 86, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=86,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.84593023 0.77616279 0.76719577 0.91964286 0.94940476\n",
      " 0.8125     0.86011905 0.79464286 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 104\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 182, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            n_estimators=182,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.90697674 0.67151163 0.77180233 0.82539683 0.82589286 0.84970238\n",
      " 0.71875    0.86755952 0.70535714 0.64732143]\n",
      "----------------------------------------\n",
      "Trial 105\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.91860465 0.75290698 0.69186047 0.78571429 0.82738095 0.73214286\n",
      " 0.76785714 0.81845238 0.74107143 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 106\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 84, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=84,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88081395 0.80813953 0.76162791 0.7010582  0.93154762 0.88988095\n",
      " 0.79464286 0.82440476 0.73511905 0.55059524]\n",
      "----------------------------------------\n",
      "Trial 107\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 156, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=156, random_state=100))])\n",
      "cv score: [0.85755814 0.75872093 0.64244186 0.74338624 0.8125     0.70833333\n",
      " 0.76785714 0.80357143 0.72619048 0.61011905]\n",
      "----------------------------------------\n",
      "Trial 108\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 106, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=106, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.87209302 0.77906977 0.64244186 0.72486772 0.86011905 0.81845238\n",
      " 0.79761905 0.78869048 0.73809524 0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 109\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 140, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=140,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.81976744 0.69186047 0.81746032 0.89583333 0.92261905\n",
      " 0.85714286 0.875      0.79761905 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 110\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 193, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=193,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.84011628 0.75290698 0.76984127 0.90178571 0.91369048\n",
      " 0.80952381 0.88095238 0.77083333 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 111\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 184, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=184,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.90988372 0.77034884 0.72093023 0.67460317 0.91071429 0.88095238\n",
      " 0.85714286 0.76190476 0.78571429 0.58630952]\n",
      "----------------------------------------\n",
      "Trial 112\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 56, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, max_features='sqrt',\n",
      "                                            n_estimators=56, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.79069767 0.77616279 0.72965116 0.73809524 0.95535714 0.8422619\n",
      " 0.85714286 0.77678571 0.77380952 0.55952381]\n",
      "----------------------------------------\n",
      "Trial 113\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=58,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86046512 0.75       0.67732558 0.71428571 0.8452381  0.81845238\n",
      " 0.79166667 0.81547619 0.76190476 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 114\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 123, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=123, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.90988372 0.74418605 0.70348837 0.69047619 0.88392857 0.875\n",
      " 0.85714286 0.79464286 0.75       0.69642857]\n",
      "----------------------------------------\n",
      "Trial 115\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 36, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=36,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.80232558 0.69040698 0.56540698 0.81216931 0.73363095 0.84375\n",
      " 0.65922619 0.69494048 0.54910714 0.56845238]\n",
      "----------------------------------------\n",
      "Trial 116\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.77616279 0.72674419 0.74709302 0.74867725 0.79166667 0.8452381\n",
      " 0.70535714 0.78869048 0.59821429 0.50595238]\n",
      "----------------------------------------\n",
      "Trial 117\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 10, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            n_estimators=10, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.8997093  0.76744186 0.70494186 0.7010582  0.91517857 0.8422619\n",
      " 0.75595238 0.79017857 0.81547619 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 118\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 39, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=39,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.88081395 0.76162791 0.64534884 0.76455026 0.88392857 0.87202381\n",
      " 0.80654762 0.81547619 0.76190476 0.63690476]\n",
      "----------------------------------------\n",
      "Trial 119\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93313953 0.80813953 0.74127907 0.76455026 0.91964286 0.93452381\n",
      " 0.80059524 0.86904762 0.75595238 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 120\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 173, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=173, random_state=100))])\n",
      "cv score: [0.88662791 0.78488372 0.64244186 0.71957672 0.88095238 0.86011905\n",
      " 0.85416667 0.82440476 0.77380952 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 121\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 26, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=26, random_state=100))])\n",
      "cv score: [0.88081395 0.76017442 0.69331395 0.69312169 0.82142857 0.60714286\n",
      " 0.70238095 0.77529762 0.6889881  0.63541667]\n",
      "----------------------------------------\n",
      "Trial 122\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 84, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=84,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.85174419 0.73110465 0.81481481 0.9047619  0.94642857\n",
      " 0.83035714 0.88690476 0.78869048 0.72321429]\n",
      "----------------------------------------\n",
      "Trial 123\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 93, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=93,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.80523256 0.74709302 0.6744186  0.73809524 0.88392857 0.88988095\n",
      " 0.80952381 0.73511905 0.75595238 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 124\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 148, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=148, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.81686047 0.79651163 0.63662791 0.74867725 0.76785714 0.5952381\n",
      " 0.75       0.77083333 0.69642857 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 125\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 33, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=33,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.89534884 0.77325581 0.72674419 0.69444444 0.89880952 0.89732143\n",
      " 0.82142857 0.81696429 0.75595238 0.67708333]\n",
      "----------------------------------------\n",
      "Trial 126\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 167, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=167, random_state=100))])\n",
      "cv score: [0.89244186 0.78197674 0.64244186 0.73015873 0.8422619  0.75595238\n",
      " 0.78571429 0.79761905 0.69047619 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 127\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 143, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=143, random_state=100))])\n",
      "cv score: [0.86918605 0.74127907 0.64825581 0.74603175 0.85119048 0.86309524\n",
      " 0.85119048 0.82142857 0.7827381  0.63392857]\n",
      "----------------------------------------\n",
      "Trial 128\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 100, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.82848837 0.76453488 0.75396825 0.90178571 0.9047619\n",
      " 0.78571429 0.86309524 0.81547619 0.71428571]\n",
      "----------------------------------------\n",
      "Trial 129\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 196, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            n_estimators=196, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.93313953 0.79360465 0.76744186 0.76190476 0.9047619  0.89583333\n",
      " 0.7797619  0.79761905 0.7797619  0.60119048]\n",
      "----------------------------------------\n",
      "Trial 130\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 143, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=143,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.9127907  0.81395349 0.69186047 0.72222222 0.93154762 0.9077381\n",
      " 0.7827381  0.79761905 0.69940476 0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 131\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            n_estimators=101, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.91569767 0.75       0.73255814 0.82010582 0.80654762 0.9047619\n",
      " 0.82440476 0.8452381  0.75       0.75595238]\n",
      "----------------------------------------\n",
      "Trial 132\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94186047 0.75581395 0.68895349 0.61111111 0.87202381 0.83630952\n",
      " 0.69345238 0.83630952 0.7202381  0.64583333]\n",
      "----------------------------------------\n",
      "Trial 133\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.83139535 0.7005814  0.77777778 0.90178571 0.91964286\n",
      " 0.875      0.88988095 0.81547619 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 134\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 65, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=65, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.9244186  0.73546512 0.67732558 0.72222222 0.86309524 0.86607143\n",
      " 0.87202381 0.82738095 0.77083333 0.70535714]\n",
      "----------------------------------------\n",
      "Trial 135\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.84302326 0.78488372 0.68895349 0.7037037  0.9077381  0.83928571\n",
      " 0.77083333 0.80952381 0.75       0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 136\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 45, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=45, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.71802326 0.63953488 0.59883721 0.56613757 0.83035714 0.85714286\n",
      " 0.7797619  0.71130952 0.57440476 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 137\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 98, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=98, random_state=100))])\n",
      "cv score: [0.93604651 0.79360465 0.72674419 0.81481481 0.88988095 0.89285714\n",
      " 0.80357143 0.875      0.82440476 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 138\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 147, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=147, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.87790698 0.6627907  0.79651163 0.71428571 0.77380952 0.78869048\n",
      " 0.74702381 0.46130952 0.83928571 0.41071429]\n",
      "----------------------------------------\n",
      "Trial 139\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 87, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=87, random_state=100))])\n",
      "cv score: [0.92732558 0.77325581 0.71511628 0.82936508 0.87202381 0.9047619\n",
      " 0.84970238 0.87202381 0.78869048 0.72470238]\n",
      "----------------------------------------\n",
      "Trial 140\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 13, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=7, max_features='sqrt',\n",
      "                                            n_estimators=13, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.74418605 0.73837209 0.57994186 0.64285714 0.75       0.84821429\n",
      " 0.70238095 0.71428571 0.8452381  0.60714286]\n",
      "----------------------------------------\n",
      "Trial 141\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 36, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=36,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93023256 0.81104651 0.68459302 0.75132275 0.90327381 0.75\n",
      " 0.83779762 0.88392857 0.76785714 0.67113095]\n",
      "----------------------------------------\n",
      "Trial 142\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 71, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=71, random_state=100))])\n",
      "cv score: [0.90116279 0.7630814  0.63953488 0.72222222 0.85714286 0.86607143\n",
      " 0.83630952 0.80357143 0.78571429 0.65178571]\n",
      "----------------------------------------\n",
      "Trial 143\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 154, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=154,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91860465 0.82267442 0.76453488 0.78571429 0.91071429 0.94047619\n",
      " 0.7797619  0.87797619 0.77083333 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 144\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 127, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, max_features='sqrt',\n",
      "                                            n_estimators=127, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.78197674 0.70930233 0.64534884 0.75396825 0.88095238 0.80952381\n",
      " 0.8422619  0.78571429 0.70238095 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 145\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 157, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=9,\n",
      "                                            n_estimators=157, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.91860465 0.73546512 0.81686047 0.8042328  0.8422619  0.88392857\n",
      " 0.7827381  0.77678571 0.77083333 0.75892857]\n",
      "----------------------------------------\n",
      "Trial 146\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 128, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=128,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.79360465 0.77034884 0.67732558 0.68783069 0.78422619 0.66071429\n",
      " 0.79315476 0.79017857 0.70089286 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 147\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 76, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=76,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6744186  0.69186047 0.49273256 0.55820106 0.68154762 0.48809524\n",
      " 0.52678571 0.60267857 0.51785714 0.44047619]\n",
      "----------------------------------------\n",
      "Trial 148\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 191, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=191, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.83430233 0.71511628 0.57848837 0.70634921 0.82738095 0.38095238\n",
      " 0.7827381  0.63690476 0.48809524 0.36309524]\n",
      "----------------------------------------\n",
      "Trial 149\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 53, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=53,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.90988372 0.76453488 0.72383721 0.71428571 0.89285714 0.85714286\n",
      " 0.82738095 0.85119048 0.7827381  0.61607143]\n",
      "----------------------------------------\n",
      "Trial 150\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 120, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            n_estimators=120,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.90988372 0.67877907 0.83139535 0.79761905 0.84672619 0.86458333\n",
      " 0.74404762 0.7202381  0.69940476 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 151\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 118, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=118,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.92151163 0.7994186  0.76744186 0.85449735 0.9047619  0.9077381\n",
      " 0.80654762 0.86904762 0.75892857 0.70833333]\n",
      "----------------------------------------\n",
      "Trial 152\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 189, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=189, random_state=100))])\n",
      "cv score: [0.9244186  0.78488372 0.72383721 0.80687831 0.85714286 0.9047619\n",
      " 0.85416667 0.86011905 0.77380952 0.70386905]\n",
      "----------------------------------------\n",
      "Trial 153\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 181, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=181,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90406977 0.7994186  0.6744186  0.75925926 0.89880952 0.89285714\n",
      " 0.80059524 0.83928571 0.78571429 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 154\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 111, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=111,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.8372093  0.74127907 0.69186047 0.70899471 0.90178571 0.89880952\n",
      " 0.8422619  0.77678571 0.75892857 0.55059524]\n",
      "----------------------------------------\n",
      "Trial 155\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 187, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=187, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.88081395 0.75581395 0.68313953 0.6031746  0.89880952 0.86607143\n",
      " 0.69940476 0.66964286 0.74404762 0.52083333]\n",
      "----------------------------------------\n",
      "Trial 156\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 112, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            n_estimators=112, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.93313953 0.73837209 0.73546512 0.79365079 0.83928571 0.9047619\n",
      " 0.75892857 0.80059524 0.75892857 0.76041667]\n",
      "----------------------------------------\n",
      "Trial 157\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 153, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=153, random_state=100))])\n",
      "cv score: [0.875      0.7877907  0.65116279 0.78042328 0.85714286 0.86011905\n",
      " 0.83630952 0.79761905 0.73809524 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 158\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 44, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=44, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.70348837 0.70639535 0.62209302 0.57407407 0.83333333 0.83333333\n",
      " 0.76190476 0.62202381 0.70535714 0.49702381]\n",
      "----------------------------------------\n",
      "Trial 159\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=197, random_state=100))])\n",
      "cv score: [0.86627907 0.74709302 0.65406977 0.74338624 0.81547619 0.69047619\n",
      " 0.77083333 0.80654762 0.70535714 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 160\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 103, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=103,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.84302326 0.74418605 0.81746032 0.9077381  0.93154762\n",
      " 0.82738095 0.88690476 0.80059524 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 161\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 117, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=117,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93604651 0.81395349 0.72093023 0.80952381 0.89583333 0.92261905\n",
      " 0.85416667 0.89285714 0.80952381 0.67559524]\n",
      "----------------------------------------\n",
      "Trial 162\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 84, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=84, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.88226744 0.74418605 0.625      0.74867725 0.75892857 0.62797619\n",
      " 0.72916667 0.78869048 0.67559524 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 163\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=159, random_state=100))])\n",
      "cv score: [0.86627907 0.76453488 0.65988372 0.75396825 0.86309524 0.82440476\n",
      " 0.83035714 0.82738095 0.72619048 0.57738095]\n",
      "----------------------------------------\n",
      "Trial 164\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 186, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=186,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88662791 0.73110465 0.75290698 0.69444444 0.89285714 0.89285714\n",
      " 0.87202381 0.81994048 0.75297619 0.5625    ]\n",
      "----------------------------------------\n",
      "Trial 165\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 113, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=113, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.51453488 0.64825581 0.42732558 0.62169312 0.74404762 0.83035714\n",
      " 0.67857143 0.65178571 0.71428571 0.47619048]\n",
      "----------------------------------------\n",
      "Trial 166\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 49, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=49,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.78197674 0.69912791 0.73544974 0.89583333 0.92857143\n",
      " 0.78720238 0.86011905 0.80505952 0.67708333]\n",
      "----------------------------------------\n",
      "Trial 167\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=198,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.80523256 0.72383721 0.625      0.72486772 0.80059524 0.67857143\n",
      " 0.76785714 0.80654762 0.73511905 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 168\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 35, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=35,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88662791 0.70930233 0.72965116 0.70238095 0.89285714 0.89583333\n",
      " 0.83928571 0.8125     0.73809524 0.54464286]\n",
      "----------------------------------------\n",
      "Trial 169\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.7994186  0.66860465 0.66931217 0.88392857 0.875\n",
      " 0.76190476 0.83928571 0.73809524 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 170\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 121, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=121,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81976744 0.66860465 0.78488372 0.83597884 0.80357143 0.84970238\n",
      " 0.70238095 0.84375    0.71279762 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 171\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 123, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=123,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93895349 0.81395349 0.76744186 0.78835979 0.89285714 0.88095238\n",
      " 0.79166667 0.8452381  0.77380952 0.67857143]\n",
      "----------------------------------------\n",
      "Trial 172\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 96, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=96, random_state=100))])\n",
      "cv score: [0.87790698 0.75290698 0.64825581 0.74074074 0.86011905 0.88095238\n",
      " 0.85714286 0.78571429 0.77083333 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 173\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 127, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=127, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.79360465 0.79069767 0.6380814  0.7037037  0.7797619  0.63392857\n",
      " 0.73214286 0.7797619  0.7202381  0.63690476]\n",
      "----------------------------------------\n",
      "Trial 174\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 156, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=156,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86918605 0.74127907 0.71511628 0.7037037  0.87797619 0.875\n",
      " 0.80654762 0.78869048 0.75892857 0.6547619 ]\n",
      "----------------------------------------\n",
      "Trial 175\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 128, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=128,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.82703488 0.77616279 0.6744186  0.71693122 0.86904762 0.80952381\n",
      " 0.80654762 0.84821429 0.74107143 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 176\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 62, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=62,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.8372093  0.83430233 0.67151163 0.81746032 0.8452381  0.86607143\n",
      " 0.70833333 0.7827381  0.69940476 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 177\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 113, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=113,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86337209 0.70930233 0.72965116 0.6957672  0.88392857 0.86904762\n",
      " 0.8125     0.82738095 0.75297619 0.55059524]\n",
      "----------------------------------------\n",
      "Trial 178\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 75, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=75,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.81104651 0.69331395 0.75396825 0.89285714 0.92261905\n",
      " 0.8422619  0.88690476 0.80357143 0.69791667]\n",
      "----------------------------------------\n",
      "Trial 179\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 199, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=199,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.80813953 0.74709302 0.60465116 0.76190476 0.79761905 0.875\n",
      " 0.77083333 0.71428571 0.77678571 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 180\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.78197674 0.77034884 0.66860465 0.58201058 0.8452381  0.85714286\n",
      " 0.76785714 0.68154762 0.67261905 0.52678571]\n",
      "----------------------------------------\n",
      "Trial 181\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 38, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=38,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.92877907 0.75581395 0.68168605 0.73677249 0.875      0.90922619\n",
      " 0.81845238 0.8764881  0.7797619  0.65029762]\n",
      "----------------------------------------\n",
      "Trial 182\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 50, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=50,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.84883721 0.80523256 0.71511628 0.7010582  0.89880952 0.8422619\n",
      " 0.6547619  0.81547619 0.72916667 0.51488095]\n",
      "----------------------------------------\n",
      "Trial 183\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 31, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=31,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91569767 0.79069767 0.72093023 0.81481481 0.87797619 0.85714286\n",
      " 0.86011905 0.80654762 0.77083333 0.76190476]\n",
      "----------------------------------------\n",
      "Trial 184\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.87209302 0.80232558 0.65697674 0.72751323 0.88392857 0.84821429\n",
      " 0.81547619 0.79761905 0.72321429 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 185\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 154, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(n_estimators=154, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.88372093 0.77325581 0.74418605 0.77513228 0.9077381  0.88690476\n",
      " 0.72916667 0.82142857 0.77678571 0.66964286]\n",
      "----------------------------------------\n",
      "Trial 186\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 21, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=21,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90697674 0.79360465 0.72383721 0.78042328 0.85416667 0.92559524\n",
      " 0.7797619  0.81547619 0.75297619 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 187\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 162, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            n_estimators=162, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.84883721 0.78488372 0.64534884 0.72751323 0.80952381 0.8452381\n",
      " 0.86904762 0.72619048 0.79761905 0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 188\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 42, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=42,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.80232558 0.69040698 0.56540698 0.7989418  0.73363095 0.8422619\n",
      " 0.66220238 0.70238095 0.58035714 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 189\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 155, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=155,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.84593023 0.81104651 0.60755814 0.62433862 0.88392857 0.9047619\n",
      " 0.81547619 0.69642857 0.80654762 0.49404762]\n",
      "----------------------------------------\n",
      "Trial 190\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 85, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=85,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.77180233 0.71947674 0.62063953 0.71428571 0.74702381 0.58928571\n",
      " 0.76041667 0.72172619 0.66815476 0.58928571]\n",
      "----------------------------------------\n",
      "Trial 191\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 176, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=176,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.86627907 0.77034884 0.66860465 0.80687831 0.89880952 0.86011905\n",
      " 0.7202381  0.79464286 0.6875     0.71428571]\n",
      "----------------------------------------\n",
      "Trial 192\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 160, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=160, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.65697674 0.33284884 0.62063953 0.48015873 0.50595238 0.41815476\n",
      " 0.48511905 0.56547619 0.58928571 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 193\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 183, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=183,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.82848837 0.78488372 0.73015873 0.92857143 0.91964286\n",
      " 0.80059524 0.8452381  0.77380952 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 194\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 165, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=165, random_state=100))])\n",
      "cv score: [0.875      0.7877907  0.66569767 0.74867725 0.89285714 0.88095238\n",
      " 0.86011905 0.80505952 0.80952381 0.64434524]\n",
      "----------------------------------------\n",
      "Trial 195\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=133,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.83139535 0.72093023 0.54505814 0.7962963  0.76934524 0.82440476\n",
      " 0.71130952 0.69345238 0.66666667 0.65327381]\n",
      "----------------------------------------\n",
      "Trial 196\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 181, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=181,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88372093 0.72965116 0.68604651 0.6984127  0.85416667 0.83928571\n",
      " 0.80059524 0.8422619  0.75892857 0.61011905]\n",
      "----------------------------------------\n",
      "Trial 197\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 99, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=99,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9127907  0.80523256 0.70348837 0.73809524 0.93452381 0.89880952\n",
      " 0.75297619 0.85416667 0.73511905 0.58928571]\n",
      "----------------------------------------\n",
      "Trial 198\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 26, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=26,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.8255814  0.74709302 0.85449735 0.89285714 0.91964286\n",
      " 0.83035714 0.88988095 0.80059524 0.70833333]\n",
      "----------------------------------------\n",
      "Trial 199\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 54, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=54,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.87790698 0.71802326 0.72674419 0.66931217 0.89880952 0.88095238\n",
      " 0.80357143 0.83333333 0.7827381  0.625     ]\n",
      "----------------------------------------\n",
      "Trial 200\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 167, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=167,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.8372093  0.76453488 0.78571429 0.9077381  0.88988095\n",
      " 0.81845238 0.86309524 0.80654762 0.72916667]\n",
      "----------------------------------------\n",
      "Trial 201\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 35, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=35,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94186047 0.84011628 0.73255814 0.81216931 0.875      0.88392857\n",
      " 0.84821429 0.88095238 0.80059524 0.66071429]\n",
      "----------------------------------------\n",
      "Trial 202\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 107, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=107,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84883721 0.74418605 0.6744186  0.70899471 0.9047619  0.89285714\n",
      " 0.83630952 0.77380952 0.75892857 0.56547619]\n",
      "----------------------------------------\n",
      "Trial 203\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 18, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=18,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.73837209 0.73255814 0.71428571 0.87202381 0.83928571\n",
      " 0.72321429 0.80059524 0.76785714 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 204\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 101, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=101,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.7994186  0.69186047 0.76455026 0.86309524 0.86011905\n",
      " 0.8452381  0.87202381 0.76785714 0.68303571]\n",
      "----------------------------------------\n",
      "Trial 205\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 171, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=171,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.79651163 0.69476744 0.74603175 0.89285714 0.91666667\n",
      " 0.7797619  0.83035714 0.72619048 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 206\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 175, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=5,\n",
      "                                            n_estimators=175, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.90697674 0.79069767 0.79069767 0.74867725 0.94345238 0.9077381\n",
      " 0.79166667 0.85119048 0.81547619 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 207\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 60, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=60,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.88081395 0.75872093 0.68023256 0.7037037  0.86309524 0.83035714\n",
      " 0.75892857 0.86904762 0.76190476 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 208\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 184, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=184,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84302326 0.70639535 0.64825581 0.77910053 0.8139881  0.88392857\n",
      " 0.71279762 0.79910714 0.71130952 0.66220238]\n",
      "----------------------------------------\n",
      "Trial 209\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 159, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=159,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.82848837 0.70348837 0.77513228 0.89880952 0.89583333\n",
      " 0.82738095 0.87202381 0.81547619 0.67708333]\n",
      "----------------------------------------\n",
      "Trial 210\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 20, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=20, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.90697674 0.74418605 0.59593023 0.64285714 0.80357143 0.89583333\n",
      " 0.79761905 0.75297619 0.85416667 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 211\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.84302326 0.8255814  0.67151163 0.81746032 0.79166667 0.8452381\n",
      " 0.7172619  0.76785714 0.74702381 0.55654762]\n",
      "----------------------------------------\n",
      "Trial 212\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 180, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=180, random_state=100))])\n",
      "cv score: [0.85174419 0.75872093 0.62790698 0.74867725 0.875      0.83928571\n",
      " 0.85416667 0.80059524 0.76785714 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 213\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 174, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            n_estimators=174, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.9244186  0.7994186  0.72965116 0.81746032 0.86011905 0.88392857\n",
      " 0.8452381  0.85714286 0.79464286 0.71428571]\n",
      "----------------------------------------\n",
      "Trial 214\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 76, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=76,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.81686047 0.72238372 0.8042328  0.9077381  0.93154762\n",
      " 0.83928571 0.89285714 0.79761905 0.70982143]\n",
      "----------------------------------------\n",
      "Trial 215\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 159, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=159, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.88953488 0.72965116 0.63372093 0.74603175 0.86011905 0.77380952\n",
      " 0.77380952 0.83035714 0.76190476 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 216\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 43, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=43, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.77616279 0.5755814  0.43023256 0.83862434 0.80357143 0.68154762\n",
      " 0.73809524 0.75297619 0.74702381 0.50892857]\n",
      "----------------------------------------\n",
      "Trial 217\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 21, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=21, random_state=100))])\n",
      "cv score: [0.88662791 0.75581395 0.57267442 0.6957672  0.85714286 0.82738095\n",
      " 0.86011905 0.82440476 0.83928571 0.55357143]\n",
      "----------------------------------------\n",
      "Trial 218\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.9127907  0.77906977 0.68313953 0.70634921 0.88392857 0.81845238\n",
      " 0.82142857 0.81845238 0.78571429 0.67559524]\n",
      "----------------------------------------\n",
      "Trial 219\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 146, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=146, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.89825581 0.75290698 0.76162791 0.65873016 0.91964286 0.86309524\n",
      " 0.82142857 0.72321429 0.77083333 0.52380952]\n",
      "----------------------------------------\n",
      "Trial 220\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 110, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=110,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.82848837 0.77325581 0.76984127 0.89880952 0.92857143\n",
      " 0.80059524 0.85714286 0.79464286 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 221\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94040698 0.78197674 0.69476744 0.78042328 0.89880952 0.875\n",
      " 0.84821429 0.90922619 0.80059524 0.67708333]\n",
      "----------------------------------------\n",
      "Trial 222\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.88372093 0.72383721 0.70930233 0.73809524 0.86607143 0.82738095\n",
      " 0.81845238 0.8452381  0.72916667 0.58630952]\n",
      "----------------------------------------\n",
      "Trial 223\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 180, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=180,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.83139535 0.72093023 0.54505814 0.7962963  0.76636905 0.82440476\n",
      " 0.71130952 0.69345238 0.68154762 0.65327381]\n",
      "----------------------------------------\n",
      "Trial 224\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 11, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=11, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.72674419 0.7005814  0.45639535 0.53174603 0.41369048 0.5922619\n",
      " 0.5297619  0.66369048 0.66071429 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 225\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.90988372 0.73546512 0.77616279 0.68253968 0.87797619 0.83333333\n",
      " 0.7797619  0.70833333 0.76785714 0.4702381 ]\n",
      "----------------------------------------\n",
      "Trial 226\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 112, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=112,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90406977 0.79651163 0.69767442 0.75396825 0.87202381 0.86904762\n",
      " 0.83035714 0.86011905 0.7827381  0.6860119 ]\n",
      "----------------------------------------\n",
      "Trial 227\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 69, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=69,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.86627907 0.71511628 0.75       0.68253968 0.88095238 0.875\n",
      " 0.83333333 0.75595238 0.79464286 0.57440476]\n",
      "----------------------------------------\n",
      "Trial 228\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 35, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=35,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.88081395 0.85465116 0.60755814 0.77248677 0.87797619 0.92857143\n",
      " 0.78869048 0.83035714 0.76488095 0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 229\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 64, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=64, random_state=100))])\n",
      "cv score: [0.93023256 0.76453488 0.7005814  0.84126984 0.88095238 0.90178571\n",
      " 0.8125     0.86607143 0.83035714 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 230\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 24, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=24, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.86046512 0.69186047 0.68313953 0.68518519 0.89285714 0.78571429\n",
      " 0.82142857 0.76488095 0.78571429 0.55654762]\n",
      "----------------------------------------\n",
      "Trial 231\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 111, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            n_estimators=111,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.8502907  0.73255814 0.49273256 0.86507937 0.76488095 0.86011905\n",
      " 0.77232143 0.73511905 0.6547619  0.54910714]\n",
      "----------------------------------------\n",
      "Trial 232\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=51, random_state=100))])\n",
      "cv score: [0.93313953 0.76162791 0.63081395 0.75132275 0.86011905 0.82738095\n",
      " 0.78571429 0.6577381  0.8452381  0.58779762]\n",
      "----------------------------------------\n",
      "Trial 233\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 79, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=79, random_state=100))])\n",
      "cv score: [0.81976744 0.75872093 0.67296512 0.70634921 0.78571429 0.66071429\n",
      " 0.68154762 0.82738095 0.68452381 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 234\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 191, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=191, random_state=100))])\n",
      "cv score: [0.89244186 0.71802326 0.65406977 0.75396825 0.85119048 0.83035714\n",
      " 0.79166667 0.80654762 0.77083333 0.64285714]\n",
      "----------------------------------------\n",
      "Trial 235\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 23, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=23,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84156977 0.73837209 0.67296512 0.7962963  0.85565476 0.85565476\n",
      " 0.6875     0.70535714 0.72172619 0.73809524]\n",
      "----------------------------------------\n",
      "Trial 236\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 48, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=48,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.90116279 0.75290698 0.71802326 0.66402116 0.86309524 0.88988095\n",
      " 0.84821429 0.80059524 0.72321429 0.67559524]\n",
      "----------------------------------------\n",
      "Trial 237\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 177, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=177, random_state=100))])\n",
      "cv score: [0.85465116 0.76162791 0.62790698 0.74074074 0.875      0.8422619\n",
      " 0.85416667 0.79761905 0.76785714 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 238\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 143, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=143,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.81686047 0.72674419 0.79365079 0.89285714 0.9077381\n",
      " 0.85416667 0.88095238 0.82738095 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 239\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 49, 'gb__subsample': 0.85, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, max_features='log2',\n",
      "                                            n_estimators=49, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.87209302 0.76453488 0.74127907 0.63756614 0.93452381 0.8452381\n",
      " 0.85119048 0.69345238 0.75892857 0.55357143]\n",
      "----------------------------------------\n",
      "Trial 240\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 150, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, max_features='sqrt',\n",
      "                                            n_estimators=150, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.90406977 0.75       0.69186047 0.69047619 0.9047619  0.8422619\n",
      " 0.8422619  0.71130952 0.75297619 0.59821429]\n",
      "----------------------------------------\n",
      "Trial 241\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93313953 0.8255814  0.73401163 0.80952381 0.9077381  0.92857143\n",
      " 0.84821429 0.88988095 0.79464286 0.73065476]\n",
      "----------------------------------------\n",
      "Trial 242\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 57, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=57,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.87209302 0.85465116 0.76162791 0.75396825 0.89880952 0.88988095\n",
      " 0.73511905 0.76785714 0.7827381  0.57440476]\n",
      "----------------------------------------\n",
      "Trial 243\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=168, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.91569767 0.77616279 0.65988372 0.6984127  0.86309524 0.83035714\n",
      " 0.82142857 0.80357143 0.79166667 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 244\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 89, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=89,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84302326 0.71802326 0.60755814 0.7989418  0.76041667 0.84672619\n",
      " 0.6889881  0.69494048 0.68303571 0.75297619]\n",
      "----------------------------------------\n",
      "Trial 245\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 129, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=129, random_state=100))])\n",
      "cv score: [0.89534884 0.80813953 0.63372093 0.74867725 0.86011905 0.88095238\n",
      " 0.8452381  0.82440476 0.79761905 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 246\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.74127907 0.80523256 0.5872093  0.64550265 0.61011905 0.77083333\n",
      " 0.59821429 0.73809524 0.76785714 0.50892857]\n",
      "----------------------------------------\n",
      "Trial 247\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91860465 0.84302326 0.72674419 0.74338624 0.92559524 0.86607143\n",
      " 0.75595238 0.81845238 0.7172619  0.61904762]\n",
      "----------------------------------------\n",
      "Trial 248\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 163, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=163,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81395349 0.68895349 0.56540698 0.8042328  0.72321429 0.83779762\n",
      " 0.65625    0.70089286 0.61011905 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 249\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 66, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=66,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84302326 0.70348837 0.64825581 0.77910053 0.8139881  0.88095238\n",
      " 0.71279762 0.79910714 0.71130952 0.66220238]\n",
      "----------------------------------------\n",
      "Trial 250\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 79, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=79, random_state=100))])\n",
      "cv score: [0.875      0.76453488 0.66569767 0.74603175 0.77083333 0.75\n",
      " 0.77678571 0.85416667 0.77083333 0.59821429]\n",
      "----------------------------------------\n",
      "Trial 251\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 189, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=189,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88662791 0.8372093  0.69767442 0.73544974 0.9077381  0.94047619\n",
      " 0.79166667 0.77083333 0.71130952 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 252\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=16,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.92005814 0.75290698 0.71511628 0.7037037  0.82440476 0.86904762\n",
      " 0.78869048 0.80357143 0.72916667 0.66071429]\n",
      "----------------------------------------\n",
      "Trial 253\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 164, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=164, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.88372093 0.71802326 0.75290698 0.71164021 0.91666667 0.88392857\n",
      " 0.7827381  0.7172619  0.73214286 0.55059524]\n",
      "----------------------------------------\n",
      "Trial 254\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 145, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=145,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.83139535 0.72093023 0.54505814 0.7962963  0.76934524 0.82440476\n",
      " 0.71130952 0.69345238 0.66666667 0.65327381]\n",
      "----------------------------------------\n",
      "Trial 255\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 122, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=122,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.78488372 0.68459302 0.72222222 0.88988095 0.88095238\n",
      " 0.82738095 0.8452381  0.77232143 0.6860119 ]\n",
      "----------------------------------------\n",
      "Trial 256\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 122, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=122,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90406977 0.80232558 0.75581395 0.77513228 0.92857143 0.91964286\n",
      " 0.79464286 0.88988095 0.7797619  0.68452381]\n",
      "----------------------------------------\n",
      "Trial 257\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 93, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=93,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.77034884 0.72674419 0.74867725 0.89880952 0.9047619\n",
      " 0.75297619 0.78869048 0.75595238 0.54761905]\n",
      "----------------------------------------\n",
      "Trial 258\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 11, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=11,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94331395 0.84593023 0.72238372 0.82671958 0.88095238 0.89285714\n",
      " 0.84970238 0.90029762 0.76785714 0.66071429]\n",
      "----------------------------------------\n",
      "Trial 259\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=197, random_state=100))])\n",
      "cv score: [0.89534884 0.77906977 0.63953488 0.73544974 0.83333333 0.74107143\n",
      " 0.80357143 0.83333333 0.69345238 0.65178571]\n",
      "----------------------------------------\n",
      "Trial 260\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.81976744 0.71802326 0.76984127 0.89583333 0.91369048\n",
      " 0.82738095 0.89285714 0.78571429 0.68303571]\n",
      "----------------------------------------\n",
      "Trial 261\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=108,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.83139535 0.72093023 0.54505814 0.7962963  0.76934524 0.82440476\n",
      " 0.71130952 0.69345238 0.68154762 0.65327381]\n",
      "----------------------------------------\n",
      "Trial 262\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88372093 0.77034884 0.71802326 0.73280423 0.94642857 0.91666667\n",
      " 0.74107143 0.8422619  0.7797619  0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 263\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 147, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=147, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.88662791 0.77906977 0.7877907  0.67195767 0.92261905 0.82738095\n",
      " 0.78571429 0.72321429 0.77380952 0.56845238]\n",
      "----------------------------------------\n",
      "Trial 264\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 44, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=44,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81395349 0.68895349 0.56540698 0.8015873  0.7202381  0.83482143\n",
      " 0.65922619 0.69494048 0.61011905 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 265\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 144, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=144, random_state=100))])\n",
      "cv score: [0.9244186  0.75290698 0.72093023 0.82539683 0.88690476 0.88988095\n",
      " 0.82142857 0.86904762 0.8125     0.71130952]\n",
      "----------------------------------------\n",
      "Trial 266\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 139, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=4,\n",
      "                                            n_estimators=139, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.93604651 0.77616279 0.71511628 0.76719577 0.88839286 0.92261905\n",
      " 0.78720238 0.85416667 0.80654762 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 267\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 178, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=178, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.88662791 0.74127907 0.6744186  0.71693122 0.86904762 0.78571429\n",
      " 0.82142857 0.80357143 0.77678571 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 268\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 159, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=159,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.81395349 0.69912791 0.76455026 0.89285714 0.88988095\n",
      " 0.8452381  0.875      0.8125     0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 269\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 72, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=72,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.89825581 0.75581395 0.70639535 0.6984127  0.875      0.88988095\n",
      " 0.80357143 0.80654762 0.74404762 0.66666667]\n",
      "----------------------------------------\n",
      "Trial 270\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 155, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=155,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.8372093  0.79651163 0.7005814  0.6984127  0.89880952 0.88988095\n",
      " 0.82440476 0.79464286 0.75595238 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 271\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 167, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=167, random_state=100))])\n",
      "cv score: [0.89244186 0.78197674 0.64244186 0.73015873 0.8422619  0.75595238\n",
      " 0.78571429 0.79761905 0.69047619 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 272\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 143, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=143, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.89825581 0.74127907 0.73546512 0.64285714 0.9047619  0.89285714\n",
      " 0.86607143 0.79464286 0.79166667 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 273\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 33, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=33,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.8255814  0.71075581 0.80952381 0.89880952 0.95535714\n",
      " 0.82142857 0.88839286 0.8125     0.70238095]\n",
      "----------------------------------------\n",
      "Trial 274\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 69, 'gb__subsample': 0.85, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='sqrt',\n",
      "                                            n_estimators=69, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.90406977 0.80813953 0.72093023 0.8042328  0.79464286 0.84821429\n",
      " 0.75595238 0.8125     0.8125     0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 275\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=51,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.875      0.75436047 0.75290698 0.71560847 0.88690476 0.875\n",
      " 0.8125     0.81547619 0.77380952 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 276\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 138, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=138, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.89534884 0.79069767 0.71802326 0.64814815 0.93452381 0.87202381\n",
      " 0.8452381  0.72916667 0.75892857 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 277\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=74,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.79651163 0.7877907  0.66860465 0.6957672  0.91666667 0.875\n",
      " 0.77380952 0.69047619 0.74702381 0.64880952]\n",
      "----------------------------------------\n",
      "Trial 278\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 168, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=168,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81976744 0.74273256 0.85714286 0.89583333 0.9047619\n",
      " 0.82440476 0.86904762 0.80059524 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 279\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 144, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=144, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.90988372 0.79360465 0.77906977 0.72751323 0.89285714 0.83333333\n",
      " 0.76488095 0.75297619 0.78869048 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 280\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 187, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=187,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.84302326 0.76453488 0.75396825 0.91666667 0.91369048\n",
      " 0.82738095 0.88392857 0.82142857 0.73809524]\n",
      "----------------------------------------\n",
      "Trial 281\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 41, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=41, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.84011628 0.72093023 0.68895349 0.66931217 0.86607143 0.8452381\n",
      " 0.86011905 0.66369048 0.8125     0.61011905]\n",
      "----------------------------------------\n",
      "Trial 282\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 159, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=159, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93604651 0.77906977 0.69767442 0.78835979 0.83333333 0.81845238\n",
      " 0.74404762 0.8452381  0.78571429 0.5327381 ]\n",
      "----------------------------------------\n",
      "Trial 283\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 107, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=107,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.82848837 0.76162791 0.78042328 0.92559524 0.91666667\n",
      " 0.80952381 0.86309524 0.81547619 0.74404762]\n",
      "----------------------------------------\n",
      "Trial 284\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 25, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=25, random_state=100))])\n",
      "cv score: [0.92732558 0.71511628 0.65261628 0.75132275 0.83928571 0.78571429\n",
      " 0.72916667 0.7202381  0.80357143 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 285\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 144, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=144, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.92151163 0.78488372 0.73255814 0.72751323 0.9077381  0.86309524\n",
      " 0.80952381 0.66964286 0.74702381 0.55059524]\n",
      "----------------------------------------\n",
      "Trial 286\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=197,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.87209302 0.72965116 0.71511628 0.6957672  0.87797619 0.86011905\n",
      " 0.81547619 0.79464286 0.76190476 0.65178571]\n",
      "----------------------------------------\n",
      "Trial 287\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.87209302 0.8372093  0.73255814 0.74338624 0.96428571 0.86011905\n",
      " 0.71130952 0.83928571 0.73511905 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 288\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=58,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84447674 0.72383721 0.64534884 0.78306878 0.84375    0.84672619\n",
      " 0.72321429 0.78571429 0.73363095 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 289\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 190, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            n_estimators=190,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.9244186  0.79360465 0.73837209 0.72486772 0.90178571 0.92857143\n",
      " 0.78571429 0.83333333 0.7797619  0.66964286]\n",
      "----------------------------------------\n",
      "Trial 290\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 19, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=19,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.83139535 0.72674419 0.54505814 0.78306878 0.77083333 0.82738095\n",
      " 0.71130952 0.69642857 0.66666667 0.65327381]\n",
      "----------------------------------------\n",
      "Trial 291\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 71, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=71,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88662791 0.7005814  0.74709302 0.68518519 0.89285714 0.88988095\n",
      " 0.83035714 0.83035714 0.77678571 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 292\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 164, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=164, random_state=100))])\n",
      "cv score: [0.81976744 0.75872093 0.68023256 0.71164021 0.7827381  0.61904762\n",
      " 0.74404762 0.81547619 0.68154762 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 293\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.91569767 0.8255814  0.72965116 0.81481481 0.89880952 0.92261905\n",
      " 0.82738095 0.88392857 0.80654762 0.69494048]\n",
      "----------------------------------------\n",
      "Trial 294\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 67, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=67,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.89825581 0.77906977 0.74709302 0.73280423 0.9077381  0.87202381\n",
      " 0.82440476 0.74702381 0.76785714 0.57738095]\n",
      "----------------------------------------\n",
      "Trial 295\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 32, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=32,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.84302326 0.72093023 0.80952381 0.83928571 0.89583333\n",
      " 0.88392857 0.89285714 0.77380952 0.70833333]\n",
      "----------------------------------------\n",
      "Trial 296\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 117, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=117,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84447674 0.72383721 0.64534884 0.7989418  0.8139881  0.84672619\n",
      " 0.72321429 0.7827381  0.73363095 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 297\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 96, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, max_features='sqrt',\n",
      "                                            n_estimators=96, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.88662791 0.74127907 0.61918605 0.67460317 0.93452381 0.8422619\n",
      " 0.80357143 0.73511905 0.7202381  0.53869048]\n",
      "----------------------------------------\n",
      "Trial 298\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 103, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=103,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.84011628 0.75581395 0.82010582 0.89880952 0.92261905\n",
      " 0.81547619 0.86011905 0.81547619 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 299\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.79360465 0.72093023 0.80687831 0.9047619  0.91666667\n",
      " 0.82440476 0.89285714 0.8452381  0.69940476]\n",
      "----------------------------------------\n",
      "Trial 300\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.74127907 0.77034884 0.63953488 0.76190476 0.85416667 0.76785714\n",
      " 0.7797619  0.8125     0.75595238 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 301\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 184, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=184,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.81686047 0.71802326 0.78571429 0.88988095 0.9047619\n",
      " 0.85119048 0.89285714 0.79166667 0.70089286]\n",
      "----------------------------------------\n",
      "Trial 302\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 187, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=187, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.91860465 0.78197674 0.66860465 0.67195767 0.91071429 0.84821429\n",
      " 0.86011905 0.77678571 0.78571429 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 303\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 39, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            n_estimators=39,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.9244186  0.77616279 0.84593023 0.75661376 0.91071429 0.87797619\n",
      " 0.76488095 0.83630952 0.77083333 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 304\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 99, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=99, random_state=100))])\n",
      "cv score: [0.87790698 0.68313953 0.68313953 0.74867725 0.85714286 0.81547619\n",
      " 0.78571429 0.81547619 0.75       0.66071429]\n",
      "----------------------------------------\n",
      "Trial 305\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 193, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=193, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.5755814  0.81540698 0.54505814 0.53703704 0.58184524 0.75595238\n",
      " 0.77678571 0.52529762 0.44940476 0.46577381]\n",
      "----------------------------------------\n",
      "Trial 306\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 32, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=32, random_state=100))])\n",
      "cv score: [0.89825581 0.76598837 0.63662791 0.68518519 0.84077381 0.84672619\n",
      " 0.84077381 0.78720238 0.79315476 0.52083333]\n",
      "----------------------------------------\n",
      "Trial 307\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 43, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, n_estimators=43,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.90406977 0.72674419 0.76453488 0.69179894 0.86755952 0.87202381\n",
      " 0.82738095 0.84672619 0.78869048 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 308\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 141, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=141,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81686047 0.56686047 0.64244186 0.75793651 0.78571429 0.76636905\n",
      " 0.61309524 0.70833333 0.65922619 0.58035714]\n",
      "----------------------------------------\n",
      "Trial 309\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 169, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=169,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.80523256 0.80232558 0.62790698 0.68518519 0.88690476 0.88690476\n",
      " 0.81547619 0.81547619 0.7202381  0.63988095]\n",
      "----------------------------------------\n",
      "Trial 310\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=178, random_state=100))])\n",
      "cv score: [0.94186047 0.79069767 0.68313953 0.73809524 0.88392857 0.83333333\n",
      " 0.80357143 0.82440476 0.7797619  0.62202381]\n",
      "----------------------------------------\n",
      "Trial 311\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 199, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=199,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88953488 0.71802326 0.73837209 0.67724868 0.89285714 0.88988095\n",
      " 0.85714286 0.83035714 0.74404762 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 312\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 165, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=165,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88372093 0.73546512 0.69767442 0.6957672  0.87797619 0.88095238\n",
      " 0.83928571 0.81845238 0.74702381 0.66071429]\n",
      "----------------------------------------\n",
      "Trial 313\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 179, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=179,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.89244186 0.71802326 0.75290698 0.66931217 0.88392857 0.9077381\n",
      " 0.85416667 0.83333333 0.74404762 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 314\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 11, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=11,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84447674 0.72383721 0.64244186 0.76719577 0.78720238 0.84375\n",
      " 0.73214286 0.7827381  0.73363095 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 315\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 141, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=141,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.9244186  0.83139535 0.78197674 0.77513228 0.93452381 0.93452381\n",
      " 0.80654762 0.85416667 0.80059524 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 316\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.8255814  0.72674419 0.73280423 0.92559524 0.91369048\n",
      " 0.7797619  0.85416667 0.73809524 0.66071429]\n",
      "----------------------------------------\n",
      "Trial 317\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 15, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=15,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88081395 0.7369186  0.7005814  0.65343915 0.91815476 0.91071429\n",
      " 0.79464286 0.8139881  0.82738095 0.71279762]\n",
      "----------------------------------------\n",
      "Trial 318\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 119, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=119,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.89534884 0.80523256 0.77325581 0.73280423 0.91666667 0.89583333\n",
      " 0.72916667 0.83630952 0.73511905 0.67857143]\n",
      "----------------------------------------\n",
      "Trial 319\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 142, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=142, random_state=100))])\n",
      "cv score: [0.92151163 0.77325581 0.71802326 0.81481481 0.86904762 0.9077381\n",
      " 0.82142857 0.86904762 0.79464286 0.71428571]\n",
      "----------------------------------------\n",
      "Trial 320\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 131, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=131,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77034884 0.69186047 0.60901163 0.71428571 0.74702381 0.625\n",
      " 0.75744048 0.71577381 0.67857143 0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 321\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 104, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=104,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.89244186 0.7747093  0.65697674 0.72486772 0.79166667 0.79761905\n",
      " 0.82440476 0.87202381 0.73511905 0.68005952]\n",
      "----------------------------------------\n",
      "Trial 322\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 90, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=90, random_state=100))])\n",
      "cv score: [0.87209302 0.76453488 0.66569767 0.74867725 0.77083333 0.73214286\n",
      " 0.76190476 0.8422619  0.77380952 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 323\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 192, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=192,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.81976744 0.74709302 0.74867725 0.91666667 0.91666667\n",
      " 0.7797619  0.88095238 0.76190476 0.68154762]\n",
      "----------------------------------------\n",
      "Trial 324\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 27, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=27, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.51162791 0.5494186  0.63662791 0.56084656 0.59821429 0.80357143\n",
      " 0.65178571 0.48214286 0.58035714 0.43452381]\n",
      "----------------------------------------\n",
      "Trial 325\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 180, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=180, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.90988372 0.78197674 0.69476744 0.67460317 0.90178571 0.8422619\n",
      " 0.85119048 0.75       0.77678571 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 326\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 103, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=103,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.81976744 0.7122093  0.78042328 0.86607143 0.86607143\n",
      " 0.8422619  0.9047619  0.77380952 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 327\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 191, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=191, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.83430233 0.73837209 0.68313953 0.80952381 0.77678571 0.80059524\n",
      " 0.69940476 0.76488095 0.80952381 0.50892857]\n",
      "----------------------------------------\n",
      "Trial 328\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 63, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=63, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.82848837 0.70348837 0.69476744 0.71693122 0.87797619 0.875\n",
      " 0.76785714 0.62202381 0.69940476 0.45833333]\n",
      "----------------------------------------\n",
      "Trial 329\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 34, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=34,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.7630814  0.78343023 0.59011628 0.68783069 0.77232143 0.58630952\n",
      " 0.74702381 0.70982143 0.63839286 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 330\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 14, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            n_estimators=14, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.90988372 0.81395349 0.69476744 0.72222222 0.83630952 0.85416667\n",
      " 0.80059524 0.82440476 0.66964286 0.5625    ]\n",
      "----------------------------------------\n",
      "Trial 331\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.89534884 0.75581395 0.72674419 0.67724868 0.88690476 0.85714286\n",
      " 0.78571429 0.72916667 0.76488095 0.57440476]\n",
      "----------------------------------------\n",
      "Trial 332\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 89, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=89,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.81395349 0.77616279 0.76719577 0.87797619 0.91666667\n",
      " 0.7797619  0.84821429 0.79166667 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 333\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 140, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            n_estimators=140, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.90697674 0.75872093 0.74418605 0.8015873  0.8452381  0.91369048\n",
      " 0.82142857 0.82738095 0.76190476 0.75      ]\n",
      "----------------------------------------\n",
      "Trial 334\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 109, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=109,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.90697674 0.82267442 0.75290698 0.77777778 0.93452381 0.88690476\n",
      " 0.77678571 0.83630952 0.79166667 0.66964286]\n",
      "----------------------------------------\n",
      "Trial 335\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 87, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=87,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.80813953 0.72674419 0.78571429 0.89583333 0.90178571\n",
      " 0.80952381 0.85714286 0.8125     0.67261905]\n",
      "----------------------------------------\n",
      "Trial 336\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 156, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=156, random_state=100))])\n",
      "cv score: [0.86046512 0.79069767 0.66569767 0.73544974 0.89880952 0.87202381\n",
      " 0.85416667 0.79910714 0.80357143 0.63244048]\n",
      "----------------------------------------\n",
      "Trial 337\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 71, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=71, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.39534884 0.64244186 0.49418605 0.44708995 0.5297619  0.49107143\n",
      " 0.55952381 0.52380952 0.5952381  0.44345238]\n",
      "----------------------------------------\n",
      "Trial 338\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88081395 0.77034884 0.70348837 0.75661376 0.92559524 0.89285714\n",
      " 0.74702381 0.86309524 0.77083333 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 339\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 131, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=131,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88372093 0.70639535 0.77325581 0.67724868 0.89583333 0.9047619\n",
      " 0.8452381  0.83333333 0.75297619 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 340\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 72, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=72, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.90116279 0.72965116 0.67151163 0.74074074 0.875      0.86904762\n",
      " 0.83035714 0.79761905 0.75892857 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 341\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 179, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=179,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.81395349 0.7122093  0.65261628 0.64417989 0.79315476 0.58779762\n",
      " 0.76636905 0.72172619 0.6264881  0.65625   ]\n",
      "----------------------------------------\n",
      "Trial 342\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 136, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=136, random_state=100))])\n",
      "cv score: [0.90552326 0.76453488 0.68168605 0.66137566 0.79315476 0.60714286\n",
      " 0.77827381 0.77380952 0.63095238 0.6264881 ]\n",
      "----------------------------------------\n",
      "Trial 343\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=102, random_state=100))])\n",
      "cv score: [0.88372093 0.79069767 0.65406977 0.71164021 0.82738095 0.74404762\n",
      " 0.75595238 0.82142857 0.66666667 0.57142857]\n",
      "----------------------------------------\n",
      "Trial 344\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 188, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=188,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81976744 0.66860465 0.78488372 0.83597884 0.80357143 0.84970238\n",
      " 0.70238095 0.84672619 0.71279762 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 345\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 191, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=191,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93313953 0.77325581 0.69040698 0.78571429 0.89880952 0.9375\n",
      " 0.82142857 0.89880952 0.79464286 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 346\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 194, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=194, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.76744186 0.76162791 0.63372093 0.68783069 0.91369048 0.8422619\n",
      " 0.80654762 0.72619048 0.69940476 0.53571429]\n",
      "----------------------------------------\n",
      "Trial 347\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 97, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=97,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92587209 0.75145349 0.69186047 0.71957672 0.85416667 0.85119048\n",
      " 0.82291667 0.8452381  0.76339286 0.63541667]\n",
      "----------------------------------------\n",
      "Trial 348\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 33, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=33,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.81686047 0.69912791 0.75925926 0.90178571 0.92559524\n",
      " 0.83333333 0.89583333 0.78571429 0.72619048]\n",
      "----------------------------------------\n",
      "Trial 349\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 37, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=37,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86627907 0.77034884 0.67877907 0.73809524 0.80952381 0.78869048\n",
      " 0.81547619 0.81845238 0.69642857 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 350\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 145, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=145, random_state=100))])\n",
      "cv score: [0.85755814 0.77034884 0.64244186 0.73544974 0.8125     0.69642857\n",
      " 0.76190476 0.81547619 0.73214286 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 351\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 79, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=79,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90406977 0.79069767 0.71802326 0.8015873  0.90178571 0.91071429\n",
      " 0.83333333 0.88690476 0.75595238 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 352\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 10, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=10, random_state=100))])\n",
      "cv score: [0.91715116 0.76889535 0.7005814  0.70767196 0.81547619 0.90327381\n",
      " 0.65625    0.8110119  0.78422619 0.7485119 ]\n",
      "----------------------------------------\n",
      "Trial 353\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 155, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=155, random_state=100))])\n",
      "cv score: [0.88081395 0.77616279 0.66860465 0.74074074 0.88095238 0.87202381\n",
      " 0.85416667 0.78571429 0.8125     0.64285714]\n",
      "----------------------------------------\n",
      "Trial 354\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 158, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=5,\n",
      "                                            n_estimators=158, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.9244186  0.76744186 0.76162791 0.72751323 0.90178571 0.91666667\n",
      " 0.80357143 0.8452381  0.77380952 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 355\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 111, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=111,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.91860465 0.80523256 0.7005814  0.76719577 0.88095238 0.87797619\n",
      " 0.76785714 0.83630952 0.77678571 0.66071429]\n",
      "----------------------------------------\n",
      "Trial 356\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=102, random_state=100))])\n",
      "cv score: [0.89534884 0.81104651 0.62209302 0.73544974 0.86607143 0.89880952\n",
      " 0.8452381  0.80952381 0.78869048 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 357\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 72, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=72,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.80523256 0.71366279 0.77777778 0.90178571 0.92559524\n",
      " 0.83035714 0.88392857 0.78571429 0.70535714]\n",
      "----------------------------------------\n",
      "Trial 358\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.81976744 0.75       0.78306878 0.91666667 0.93154762\n",
      " 0.82142857 0.86607143 0.79464286 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 359\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 133, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=133,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.84011628 0.75581395 0.7122093  0.74603175 0.88690476 0.92261905\n",
      " 0.77678571 0.7797619  0.75595238 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 360\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 43, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=43,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.83139535 0.72093023 0.54796512 0.78835979 0.76636905 0.83035714\n",
      " 0.69940476 0.69047619 0.68154762 0.65327381]\n",
      "----------------------------------------\n",
      "Trial 361\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 81, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=81,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.84302326 0.79651163 0.72383721 0.83068783 0.9047619  0.89285714\n",
      " 0.77678571 0.85119048 0.72321429 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 362\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 69, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=69, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.90697674 0.77034884 0.66569767 0.72751323 0.88988095 0.86607143\n",
      " 0.85416667 0.82440476 0.73809524 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 363\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 169, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            n_estimators=169,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.86627907 0.80523256 0.75872093 0.74074074 0.79464286 0.86309524\n",
      " 0.71428571 0.80952381 0.77083333 0.50595238]\n",
      "----------------------------------------\n",
      "Trial 364\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=108, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.89825581 0.81104651 0.63662791 0.74074074 0.86607143 0.88392857\n",
      " 0.8422619  0.82440476 0.78571429 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 365\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 164, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=164,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88372093 0.78197674 0.72093023 0.69312169 0.91666667 0.8422619\n",
      " 0.7797619  0.83630952 0.73511905 0.63690476]\n",
      "----------------------------------------\n",
      "Trial 366\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 33, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=33,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90406977 0.80232558 0.74854651 0.8478836  0.88839286 0.89880952\n",
      " 0.82291667 0.87053571 0.78869048 0.71279762]\n",
      "----------------------------------------\n",
      "Trial 367\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 176, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=176,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.86337209 0.84011628 0.7122093  0.7037037  0.92559524 0.86607143\n",
      " 0.66369048 0.80357143 0.80357143 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 368\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 36, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=36, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.72674419 0.80232558 0.7877907  0.57407407 0.71428571 0.83630952\n",
      " 0.625      0.66369048 0.74107143 0.52678571]\n",
      "----------------------------------------\n",
      "Trial 369\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 10, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=10,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.85465116 0.65406977 0.85449735 0.88244048 0.93154762\n",
      " 0.83035714 0.86309524 0.79910714 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 370\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.83430233 0.77034884 0.66860465 0.67989418 0.875      0.85119048\n",
      " 0.85416667 0.75892857 0.77678571 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 371\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 113, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=113,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.80232558 0.75290698 0.78571429 0.91369048 0.89285714\n",
      " 0.80357143 0.8422619  0.75595238 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 372\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93313953 0.7994186  0.74709302 0.7962963  0.89880952 0.88392857\n",
      " 0.8452381  0.81547619 0.76190476 0.72916667]\n",
      "----------------------------------------\n",
      "Trial 373\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 199, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=199,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81976744 0.76162791 0.75925926 0.9047619  0.94047619\n",
      " 0.80357143 0.86309524 0.76785714 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 374\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 92, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=92,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84302326 0.71802326 0.60755814 0.7989418  0.76041667 0.84672619\n",
      " 0.6889881  0.69642857 0.68303571 0.75297619]\n",
      "----------------------------------------\n",
      "Trial 375\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 192, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=192,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88372093 0.72674419 0.70348837 0.68253968 0.875      0.88392857\n",
      " 0.83630952 0.8125     0.74702381 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 376\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 113, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=113, random_state=100))])\n",
      "cv score: [0.85755814 0.76744186 0.6627907  0.74338624 0.7827381  0.7202381\n",
      " 0.74404762 0.80952381 0.76190476 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 377\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=115, random_state=100))])\n",
      "cv score: [0.85755814 0.76162791 0.65406977 0.74074074 0.77678571 0.7202381\n",
      " 0.73511905 0.80654762 0.76488095 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 378\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 68, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=68,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.81104651 0.71511628 0.80952381 0.90178571 0.9077381\n",
      " 0.77380952 0.87202381 0.83333333 0.70535714]\n",
      "----------------------------------------\n",
      "Trial 379\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 94, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=94,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88953488 0.80813953 0.73546512 0.76719577 0.87797619 0.89880952\n",
      " 0.79166667 0.87202381 0.80654762 0.64880952]\n",
      "----------------------------------------\n",
      "Trial 380\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07,\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.88081395 0.79651163 0.76453488 0.77513228 0.86607143 0.86607143\n",
      " 0.79166667 0.8422619  0.78571429 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 381\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 143, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=143,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.83139535 0.77034884 0.67732558 0.82804233 0.875      0.84821429\n",
      " 0.64880952 0.72619048 0.66666667 0.57886905]\n",
      "----------------------------------------\n",
      "Trial 382\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 47, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=47,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.7994186  0.69040698 0.56540698 0.81349206 0.73214286 0.84375\n",
      " 0.6577381  0.69494048 0.54910714 0.56845238]\n",
      "----------------------------------------\n",
      "Trial 383\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91860465 0.85755814 0.67151163 0.68783069 0.89285714 0.93154762\n",
      " 0.8125     0.80357143 0.75892857 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 384\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 11, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=11,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.89244186 0.82267442 0.70494186 0.83597884 0.88392857 0.9077381\n",
      " 0.85416667 0.87946429 0.75297619 0.68154762]\n",
      "----------------------------------------\n",
      "Trial 385\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 97, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt', n_estimators=97,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.87209302 0.72965116 0.73255814 0.7037037  0.88690476 0.87797619\n",
      " 0.87797619 0.81845238 0.77678571 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 386\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 188, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=188, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.89244186 0.74127907 0.69476744 0.72486772 0.86309524 0.86309524\n",
      " 0.86011905 0.80357143 0.7797619  0.63095238]\n",
      "----------------------------------------\n",
      "Trial 387\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 60, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, n_estimators=60,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.92151163 0.80813953 0.72674419 0.77513228 0.89285714 0.84821429\n",
      " 0.8125     0.8422619  0.79761905 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 388\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 73, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=73, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.88372093 0.74709302 0.65988372 0.66137566 0.88392857 0.84821429\n",
      " 0.87797619 0.76785714 0.7797619  0.64583333]\n",
      "----------------------------------------\n",
      "Trial 389\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 161, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=161, random_state=100))])\n",
      "cv score: [0.86627907 0.76453488 0.6627907  0.75132275 0.86309524 0.82440476\n",
      " 0.83035714 0.82440476 0.72619048 0.57738095]\n",
      "----------------------------------------\n",
      "Trial 390\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 20, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, n_estimators=20,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.91860465 0.83139535 0.76017442 0.73412698 0.85119048 0.84970238\n",
      " 0.8139881  0.81547619 0.80505952 0.67113095]\n",
      "----------------------------------------\n",
      "Trial 391\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 11, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            n_estimators=11, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.87645349 0.67732558 0.71075581 0.82804233 0.82440476 0.93452381\n",
      " 0.79613095 0.83333333 0.82440476 0.78720238]\n",
      "----------------------------------------\n",
      "Trial 392\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 135, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=135, random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.85174419 0.72093023 0.625      0.65343915 0.79166667 0.74404762\n",
      " 0.86607143 0.71428571 0.6577381  0.56547619]\n",
      "----------------------------------------\n",
      "Trial 393\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 94, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=94,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92296512 0.77906977 0.71947674 0.76851852 0.90178571 0.95238095\n",
      " 0.81994048 0.8452381  0.77380952 0.6860119 ]\n",
      "----------------------------------------\n",
      "Trial 394\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 105, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=105,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91569767 0.84302326 0.74709302 0.83862434 0.9047619  0.91666667\n",
      " 0.81547619 0.87202381 0.7827381  0.69047619]\n",
      "----------------------------------------\n",
      "Trial 395\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 14, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=14, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.75436047 0.67732558 0.59011628 0.6957672  0.61458333 0.79761905\n",
      " 0.63392857 0.71428571 0.69345238 0.52678571]\n",
      "----------------------------------------\n",
      "Trial 396\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 178, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=178,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.81104651 0.72674419 0.8042328  0.89285714 0.91369048\n",
      " 0.85714286 0.89285714 0.81845238 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 397\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 54, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=54,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.80232558 0.69040698 0.56540698 0.8042328  0.73214286 0.8422619\n",
      " 0.65922619 0.70684524 0.57589286 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 398\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 137, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=137,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88081395 0.75       0.66569767 0.71428571 0.87797619 0.81547619\n",
      " 0.7797619  0.82440476 0.73809524 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 399\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.85174419 0.7877907  0.77034884 0.70899471 0.91369048 0.91369048\n",
      " 0.69345238 0.83928571 0.72321429 0.55654762]\n",
      "----------------------------------------\n",
      "Trial 400\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 77, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=77, random_state=100))])\n",
      "cv score: [0.87209302 0.76744186 0.66860465 0.74603175 0.77083333 0.72916667\n",
      " 0.7797619  0.85416667 0.77380952 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 401\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 26, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            n_estimators=26, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.7877907  0.7877907  0.59738372 0.65608466 0.86607143 0.61309524\n",
      " 0.78720238 0.71875    0.6577381  0.58184524]\n",
      "----------------------------------------\n",
      "Trial 402\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 94, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=94, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.90988372 0.74709302 0.73546512 0.79100529 0.88392857 0.82738095\n",
      " 0.75       0.73511905 0.76488095 0.58035714]\n",
      "----------------------------------------\n",
      "Trial 403\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 49, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=49, random_state=100))])\n",
      "cv score: [0.9127907  0.80087209 0.62790698 0.69312169 0.83630952 0.87202381\n",
      " 0.82886905 0.75744048 0.8422619  0.63839286]\n",
      "----------------------------------------\n",
      "Trial 404\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 123, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=123, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.89825581 0.81104651 0.67151163 0.75132275 0.85119048 0.84821429\n",
      " 0.82738095 0.83928571 0.77678571 0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 405\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 184, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=184,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.79069767 0.85755814 0.68023256 0.76190476 0.86011905 0.79464286\n",
      " 0.74107143 0.76785714 0.66964286 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 406\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 59, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=59,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.80523256 0.78488372 0.68168605 0.71957672 0.81547619 0.79761905\n",
      " 0.78869048 0.82142857 0.67261905 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 407\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 13, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=13, random_state=100))])\n",
      "cv score: [0.93895349 0.82267442 0.62790698 0.70899471 0.79464286 0.85416667\n",
      " 0.75595238 0.6875     0.80357143 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 408\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 170, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=170, random_state=100))])\n",
      "cv score: [0.88372093 0.7005814  0.6627907  0.75396825 0.85119048 0.81845238\n",
      " 0.80059524 0.82440476 0.77083333 0.64285714]\n",
      "----------------------------------------\n",
      "Trial 409\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 76, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=76, random_state=100))])\n",
      "cv score: [0.9244186  0.77325581 0.7252907  0.82539683 0.86607143 0.91071429\n",
      " 0.84821429 0.86904762 0.79166667 0.71428571]\n",
      "----------------------------------------\n",
      "Trial 410\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 105, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=105, random_state=100))])\n",
      "cv score: [0.89244186 0.7994186  0.625      0.7037037  0.88392857 0.86904762\n",
      " 0.85119048 0.82440476 0.77678571 0.6547619 ]\n",
      "----------------------------------------\n",
      "Trial 411\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 60, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=60,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90988372 0.81686047 0.71075581 0.83730159 0.88392857 0.90178571\n",
      " 0.80803571 0.87053571 0.7827381  0.71428571]\n",
      "----------------------------------------\n",
      "Trial 412\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=108,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.89534884 0.72093023 0.70639535 0.7037037  0.86904762 0.89880952\n",
      " 0.81547619 0.79166667 0.73214286 0.64880952]\n",
      "----------------------------------------\n",
      "Trial 413\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 149, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=149,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86627907 0.77034884 0.6627907  0.71428571 0.87797619 0.81845238\n",
      " 0.80059524 0.85119048 0.74702381 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 414\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 46, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=46, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.90116279 0.77325581 0.66860465 0.74867725 0.85119048 0.83928571\n",
      " 0.78571429 0.70535714 0.79761905 0.57440476]\n",
      "----------------------------------------\n",
      "Trial 415\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.81686047 0.70930233 0.7962963  0.9047619  0.91964286\n",
      " 0.83333333 0.86904762 0.81845238 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 416\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 186, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=186,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.89244186 0.65261628 0.73982558 0.77777778 0.88690476 0.80505952\n",
      " 0.67708333 0.76934524 0.6547619  0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 417\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 48, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=48,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88372093 0.77034884 0.67151163 0.68783069 0.86904762 0.8422619\n",
      " 0.76190476 0.87797619 0.77083333 0.64880952]\n",
      "----------------------------------------\n",
      "Trial 418\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 125, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=125, random_state=100))])\n",
      "cv score: [0.93023256 0.76162791 0.72383721 0.83333333 0.89583333 0.90178571\n",
      " 0.80952381 0.88988095 0.8125     0.7202381 ]\n",
      "----------------------------------------\n",
      "Trial 419\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 49, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, max_features='log2',\n",
      "                                            n_estimators=49,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.88953488 0.68313953 0.74709302 0.64285714 0.91369048 0.875\n",
      " 0.82440476 0.83333333 0.70535714 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 420\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 192, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=192,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.80813953 0.68895349 0.56540698 0.80687831 0.72321429 0.83184524\n",
      " 0.65625    0.70089286 0.60714286 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 421\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 159, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=159, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.85174419 0.73546512 0.78488372 0.69312169 0.89583333 0.86309524\n",
      " 0.80952381 0.72321429 0.79761905 0.55952381]\n",
      "----------------------------------------\n",
      "Trial 422\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 142, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=142, random_state=100))])\n",
      "cv score: [0.90988372 0.77616279 0.63953488 0.73809524 0.875      0.85416667\n",
      " 0.85416667 0.77380952 0.79464286 0.58035714]\n",
      "----------------------------------------\n",
      "Trial 423\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 181, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=181,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81976744 0.66860465 0.78488372 0.83597884 0.80357143 0.84970238\n",
      " 0.70238095 0.84672619 0.71279762 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 424\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 83, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=83,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.85465116 0.75290698 0.66860465 0.72751323 0.85416667 0.80952381\n",
      " 0.7797619  0.84821429 0.74107143 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 425\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 57, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            n_estimators=57, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.9244186  0.66569767 0.72383721 0.74206349 0.91071429 0.88839286\n",
      " 0.79166667 0.80654762 0.79613095 0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 426\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 154, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=154,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93895349 0.82848837 0.77034884 0.76190476 0.91964286 0.91964286\n",
      " 0.78571429 0.85416667 0.79166667 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 427\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 122, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=122, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.85465116 0.78197674 0.61627907 0.76984127 0.8422619  0.74107143\n",
      " 0.79166667 0.83928571 0.74702381 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 428\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 60, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=60,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9127907  0.82267442 0.75872093 0.7010582  0.88988095 0.9077381\n",
      " 0.7202381  0.86904762 0.75       0.5297619 ]\n",
      "----------------------------------------\n",
      "Trial 429\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 15, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=15,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86918605 0.74127907 0.69476744 0.72751323 0.8422619  0.77380952\n",
      " 0.75297619 0.82142857 0.75892857 0.67261905]\n",
      "----------------------------------------\n",
      "Trial 430\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.81686047 0.75872093 0.74603175 0.9077381  0.91369048\n",
      " 0.80059524 0.86607143 0.78869048 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 431\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 98, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=98,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.82122093 0.77616279 0.6744186  0.74603175 0.86904762 0.81547619\n",
      " 0.80059524 0.83928571 0.71130952 0.64583333]\n",
      "----------------------------------------\n",
      "Trial 432\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 180, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            n_estimators=180, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.93023256 0.73546512 0.8372093  0.8015873  0.87797619 0.88392857\n",
      " 0.80654762 0.80952381 0.79166667 0.68154762]\n",
      "----------------------------------------\n",
      "Trial 433\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 18, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=18, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.8255814  0.67151163 0.56395349 0.61375661 0.88690476 0.80059524\n",
      " 0.80952381 0.66071429 0.72619048 0.58630952]\n",
      "----------------------------------------\n",
      "Trial 434\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 98, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=98,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.7994186  0.69040698 0.56540698 0.81481481 0.73809524 0.84375\n",
      " 0.65922619 0.70684524 0.55059524 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 435\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 51, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=51, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.86046512 0.67732558 0.68604651 0.74603175 0.91071429 0.88690476\n",
      " 0.87202381 0.75595238 0.73511905 0.55059524]\n",
      "----------------------------------------\n",
      "Trial 436\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 39, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=39, random_state=100))])\n",
      "cv score: [0.90697674 0.76453488 0.68459302 0.71428571 0.85714286 0.73214286\n",
      " 0.73809524 0.82738095 0.73511905 0.58928571]\n",
      "----------------------------------------\n",
      "Trial 437\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=14,\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.94186047 0.72383721 0.7005814  0.62433862 0.80654762 0.875\n",
      " 0.76488095 0.75297619 0.75297619 0.47619048]\n",
      "----------------------------------------\n",
      "Trial 438\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 162, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=162,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.84883721 0.74418605 0.82804233 0.9077381  0.93154762\n",
      " 0.8422619  0.89583333 0.81845238 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 439\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.82267442 0.77325581 0.72751323 0.92857143 0.9375\n",
      " 0.80059524 0.85119048 0.7827381  0.69642857]\n",
      "----------------------------------------\n",
      "Trial 440\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 40, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=40,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.85755814 0.79651163 0.67877907 0.74867725 0.80059524 0.81845238\n",
      " 0.80059524 0.81547619 0.70238095 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 441\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 22, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=22, random_state=100))])\n",
      "cv score: [0.89244186 0.77034884 0.60319767 0.62962963 0.82142857 0.7827381\n",
      " 0.75892857 0.70535714 0.82142857 0.46428571]\n",
      "----------------------------------------\n",
      "Trial 442\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 57, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            n_estimators=57, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.9244186  0.77616279 0.73546512 0.83068783 0.86011905 0.9077381\n",
      " 0.83035714 0.86011905 0.79761905 0.70833333]\n",
      "----------------------------------------\n",
      "Trial 443\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91569767 0.81976744 0.68313953 0.76455026 0.88095238 0.89285714\n",
      " 0.86011905 0.87202381 0.79761905 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 444\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 93, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=93,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.8255814  0.7252907  0.81216931 0.89285714 0.9375\n",
      " 0.83333333 0.87202381 0.80654762 0.71428571]\n",
      "----------------------------------------\n",
      "Trial 445\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 25, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=25,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.90988372 0.82848837 0.7252907  0.78306878 0.9077381  0.94642857\n",
      " 0.82738095 0.87797619 0.80059524 0.6860119 ]\n",
      "----------------------------------------\n",
      "Trial 446\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 138, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=138, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.87790698 0.76453488 0.68313953 0.71428571 0.86904762 0.82738095\n",
      " 0.8422619  0.80059524 0.7797619  0.59821429]\n",
      "----------------------------------------\n",
      "Trial 447\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=58,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77180233 0.71656977 0.61482558 0.6957672  0.75297619 0.57440476\n",
      " 0.76636905 0.72767857 0.66517857 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 448\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.92732558 0.71802326 0.70930233 0.72751323 0.91964286 0.87797619\n",
      " 0.82738095 0.78571429 0.74702381 0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 449\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 68, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=68,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.7877907  0.77616279 0.6875     0.73280423 0.8125     0.79761905\n",
      " 0.80059524 0.81845238 0.63988095 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 450\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 180, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=180,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.8255814  0.75       0.79365079 0.90178571 0.92261905\n",
      " 0.81547619 0.86904762 0.79761905 0.72321429]\n",
      "----------------------------------------\n",
      "Trial 451\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 49, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=12,\n",
      "                                            n_estimators=49, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.88081395 0.68895349 0.74418605 0.7037037  0.88392857 0.88690476\n",
      " 0.73511905 0.71130952 0.7827381  0.56845238]\n",
      "----------------------------------------\n",
      "Trial 452\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81395349 0.80232558 0.73015873 0.91071429 0.88988095\n",
      " 0.7202381  0.78869048 0.74107143 0.7202381 ]\n",
      "----------------------------------------\n",
      "Trial 453\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 190, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=190,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.8255814  0.76744186 0.76984127 0.89880952 0.91964286\n",
      " 0.8125     0.86011905 0.79464286 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 454\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 194, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=194,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93023256 0.82267442 0.77906977 0.78042328 0.9077381  0.89285714\n",
      " 0.81547619 0.88392857 0.82440476 0.68154762]\n",
      "----------------------------------------\n",
      "Trial 455\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 41, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=41,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.79069767 0.71511628 0.82275132 0.86904762 0.92559524\n",
      " 0.85416667 0.86011905 0.80952381 0.66964286]\n",
      "----------------------------------------\n",
      "Trial 456\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.86337209 0.78197674 0.72674419 0.73809524 0.87797619 0.85714286\n",
      " 0.77083333 0.88690476 0.75892857 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 457\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 43, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=43, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.75872093 0.75581395 0.61337209 0.7989418  0.9375     0.88392857\n",
      " 0.8422619  0.78869048 0.75892857 0.50297619]\n",
      "----------------------------------------\n",
      "Trial 458\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 131, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=131,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81976744 0.77325581 0.67732558 0.71957672 0.86309524 0.80952381\n",
      " 0.80357143 0.84821429 0.73809524 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 459\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=171, random_state=100))])\n",
      "cv score: [0.875      0.77906977 0.6744186  0.75661376 0.89285714 0.88095238\n",
      " 0.85714286 0.80208333 0.8125     0.625     ]\n",
      "----------------------------------------\n",
      "Trial 460\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 119, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=119,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.79651163 0.72093023 0.79365079 0.9047619  0.93154762\n",
      " 0.81696429 0.88244048 0.80654762 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 461\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 73, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=73,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90988372 0.8372093  0.7369186  0.78968254 0.88988095 0.91964286\n",
      " 0.82440476 0.86309524 0.79166667 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 462\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 128, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=128, random_state=100))])\n",
      "cv score: [0.87790698 0.79651163 0.63081395 0.78571429 0.85714286 0.85416667\n",
      " 0.82142857 0.7797619  0.73214286 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 463\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.92732558 0.84883721 0.73837209 0.75132275 0.91964286 0.91964286\n",
      " 0.82142857 0.83630952 0.75892857 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 464\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 40, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=40,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90697674 0.76453488 0.73546512 0.71164021 0.86011905 0.87202381\n",
      " 0.75892857 0.85714286 0.75595238 0.50892857]\n",
      "----------------------------------------\n",
      "Trial 465\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.95, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, max_features='sqrt',\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.88662791 0.77906977 0.74709302 0.65608466 0.92261905 0.83333333\n",
      " 0.80952381 0.76785714 0.77380952 0.51488095]\n",
      "----------------------------------------\n",
      "Trial 466\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 80, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=80,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.78488372 0.72819767 0.77513228 0.88095238 0.92857143\n",
      " 0.80357143 0.88690476 0.77827381 0.66220238]\n",
      "----------------------------------------\n",
      "Trial 467\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 31, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=31,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.90843023 0.78488372 0.69040698 0.71957672 0.88690476 0.85119048\n",
      " 0.80654762 0.85416667 0.79315476 0.67857143]\n",
      "----------------------------------------\n",
      "Trial 468\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 124, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=124,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76453488 0.69767442 0.60610465 0.71428571 0.74702381 0.62202381\n",
      " 0.7514881  0.73363095 0.67857143 0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 469\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 75, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=75,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.90988372 0.70639535 0.72965116 0.64550265 0.92559524 0.89285714\n",
      " 0.85714286 0.81845238 0.75595238 0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 470\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=171, random_state=100))])\n",
      "cv score: [0.85755814 0.75581395 0.63372093 0.73809524 0.875      0.84821429\n",
      " 0.85714286 0.79761905 0.77083333 0.58928571]\n",
      "----------------------------------------\n",
      "Trial 471\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 139, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=139,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.87209302 0.72093023 0.74418605 0.68518519 0.88988095 0.875\n",
      " 0.83630952 0.83035714 0.74107143 0.56845238]\n",
      "----------------------------------------\n",
      "Trial 472\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.87790698 0.74127907 0.74709302 0.68253968 0.91071429 0.83333333\n",
      " 0.80952381 0.75       0.7797619  0.59821429]\n",
      "----------------------------------------\n",
      "Trial 473\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 29, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=29, random_state=100))])\n",
      "cv score: [0.93313953 0.76889535 0.72093023 0.79365079 0.87797619 0.91369048\n",
      " 0.8452381  0.83184524 0.8125     0.69047619]\n",
      "----------------------------------------\n",
      "Trial 474\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 149, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=149,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.77906977 0.7877907  0.64825581 0.7010582  0.89583333 0.86904762\n",
      " 0.85714286 0.69345238 0.74404762 0.58928571]\n",
      "----------------------------------------\n",
      "Trial 475\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=9,\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.89534884 0.73546512 0.77325581 0.77645503 0.88392857 0.91071429\n",
      " 0.77083333 0.83630952 0.78869048 0.71577381]\n",
      "----------------------------------------\n",
      "Trial 476\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.80813953 0.7122093  0.72486772 0.91071429 0.9047619\n",
      " 0.7797619  0.83333333 0.73511905 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 477\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 12, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=12,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93168605 0.68604651 0.71511628 0.6984127  0.88690476 0.89136905\n",
      " 0.83184524 0.8764881  0.78869048 0.67857143]\n",
      "----------------------------------------\n",
      "Trial 478\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81104651 0.70639535 0.83333333 0.85714286 0.91964286\n",
      " 0.83035714 0.87797619 0.84821429 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 479\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 33, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=33, random_state=100))])\n",
      "cv score: [0.90988372 0.76162791 0.62354651 0.68386243 0.83035714 0.83184524\n",
      " 0.83482143 0.79761905 0.78720238 0.52678571]\n",
      "----------------------------------------\n",
      "Trial 480\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.78488372 0.76744186 0.58139535 0.7010582  0.88988095 0.82738095\n",
      " 0.83630952 0.66369048 0.66666667 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 481\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 109, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=109,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.82267442 0.74127907 0.81746032 0.90178571 0.9047619\n",
      " 0.8452381  0.9047619  0.8125     0.69047619]\n",
      "----------------------------------------\n",
      "Trial 482\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 93, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=93,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.81686047 0.71075581 0.77513228 0.88988095 0.89285714\n",
      " 0.83035714 0.88392857 0.78869048 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 483\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=178, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.89534884 0.77906977 0.63953488 0.73544974 0.83630952 0.75\n",
      " 0.79761905 0.80654762 0.71428571 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 484\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 144, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=144, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.90697674 0.74709302 0.67732558 0.75925926 0.84821429 0.75297619\n",
      " 0.79166667 0.83630952 0.75       0.63392857]\n",
      "----------------------------------------\n",
      "Trial 485\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 121, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=121,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9505814  0.81686047 0.7005814  0.78571429 0.90029762 0.89880952\n",
      " 0.82738095 0.85714286 0.83630952 0.69196429]\n",
      "----------------------------------------\n",
      "Trial 486\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 79, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=79,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.82848837 0.75290698 0.79365079 0.9047619  0.91071429\n",
      " 0.83035714 0.89583333 0.79761905 0.70535714]\n",
      "----------------------------------------\n",
      "Trial 487\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 195, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=195, random_state=100))])\n",
      "cv score: [0.89534884 0.80813953 0.65116279 0.77248677 0.85714286 0.89583333\n",
      " 0.86607143 0.78571429 0.77380952 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 488\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 47, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=47,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.85174419 0.75872093 0.70639535 0.72486772 0.89285714 0.86904762\n",
      " 0.80654762 0.8452381  0.75       0.61309524]\n",
      "----------------------------------------\n",
      "Trial 489\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 132, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=132, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.90697674 0.76744186 0.71802326 0.72486772 0.86904762 0.85416667\n",
      " 0.84821429 0.82440476 0.77678571 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 490\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 119, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=119,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81686047 0.71075581 0.86507937 0.89880952 0.91369048\n",
      " 0.85119048 0.875      0.8125     0.74107143]\n",
      "----------------------------------------\n",
      "Trial 491\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 52, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=52, random_state=100))])\n",
      "cv score: [0.90116279 0.72674419 0.64825581 0.75132275 0.85119048 0.80059524\n",
      " 0.80654762 0.73511905 0.76785714 0.56547619]\n",
      "----------------------------------------\n",
      "Trial 492\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 49, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=49, random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.88226744 0.77034884 0.64825581 0.73809524 0.86309524 0.77083333\n",
      " 0.81547619 0.77083333 0.74107143 0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 493\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 159, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=159,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.81976744 0.72093023 0.78306878 0.91666667 0.9077381\n",
      " 0.8422619  0.875      0.7797619  0.66369048]\n",
      "----------------------------------------\n",
      "Trial 494\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 132, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=132, random_state=100))])\n",
      "cv score: [0.92732558 0.7877907  0.73255814 0.8015873  0.84672619 0.89583333\n",
      " 0.85119048 0.86011905 0.7797619  0.70535714]\n",
      "----------------------------------------\n",
      "Trial 495\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 142, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=142, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.82848837 0.72674419 0.74127907 0.72751323 0.80357143 0.81845238\n",
      " 0.6577381  0.68452381 0.70238095 0.4702381 ]\n",
      "----------------------------------------\n",
      "Trial 496\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 122, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=122, random_state=100))])\n",
      "cv score: [0.86337209 0.74127907 0.63662791 0.74603175 0.85119048 0.85416667\n",
      " 0.85714286 0.79761905 0.79166667 0.64285714]\n",
      "----------------------------------------\n",
      "Trial 497\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 27, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=27, random_state=100))])\n",
      "cv score: [0.94186047 0.72093023 0.69186047 0.72751323 0.88095238 0.86309524\n",
      " 0.72916667 0.69940476 0.87202381 0.54017857]\n",
      "----------------------------------------\n",
      "Trial 498\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 165, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=165,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.90116279 0.7994186  0.81395349 0.64285714 0.94642857 0.86904762\n",
      " 0.80059524 0.71428571 0.76488095 0.53571429]\n",
      "----------------------------------------\n",
      "Trial 499\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 24, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            n_estimators=24, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.77616279 0.51453488 0.45348837 0.6005291  0.70535714 0.60714286\n",
      " 0.63988095 0.63392857 0.4702381  0.57738095]\n",
      "----------------------------------------\n",
      "Trial 500\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 12, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=12, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.83866279 0.67732558 0.67296512 0.77248677 0.71875    0.70238095\n",
      " 0.69196429 0.70684524 0.78869048 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 501\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 117, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=117,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.875      0.72965116 0.70639535 0.71957672 0.87202381 0.875\n",
      " 0.80952381 0.78571429 0.75595238 0.66071429]\n",
      "----------------------------------------\n",
      "Trial 502\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 20, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            n_estimators=20, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.90988372 0.74273256 0.74854651 0.80026455 0.8764881  0.88839286\n",
      " 0.77678571 0.88095238 0.79166667 0.66815476]\n",
      "----------------------------------------\n",
      "Trial 503\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 83, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=83, random_state=100))])\n",
      "cv score: [0.94040698 0.77906977 0.7252907  0.80291005 0.87797619 0.89732143\n",
      " 0.8452381  0.86607143 0.79166667 0.71428571]\n",
      "----------------------------------------\n",
      "Trial 504\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 130, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=130, random_state=100))])\n",
      "cv score: [0.875      0.75872093 0.65988372 0.75661376 0.85416667 0.80357143\n",
      " 0.80059524 0.82142857 0.73511905 0.58035714]\n",
      "----------------------------------------\n",
      "Trial 505\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 92, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=92,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.9127907  0.82848837 0.74127907 0.85449735 0.89880952 0.91369048\n",
      " 0.82440476 0.875      0.77083333 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 506\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 95, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=95,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81395349 0.68895349 0.56540698 0.8042328  0.72619048 0.83779762\n",
      " 0.65625    0.70089286 0.61011905 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 507\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 106, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=106, random_state=100))])\n",
      "cv score: [0.92732558 0.77906977 0.65988372 0.75661376 0.85714286 0.83630952\n",
      " 0.83333333 0.75595238 0.80357143 0.54761905]\n",
      "----------------------------------------\n",
      "Trial 508\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 24, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=24,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.85174419 0.78197674 0.65697674 0.6984127  0.93452381 0.91369048\n",
      " 0.72619048 0.82738095 0.7827381  0.57738095]\n",
      "----------------------------------------\n",
      "Trial 509\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 138, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=138,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.83139535 0.74127907 0.6957672  0.89285714 0.90178571\n",
      " 0.77083333 0.81845238 0.74404762 0.58928571]\n",
      "----------------------------------------\n",
      "Trial 510\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 190, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=190,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.80523256 0.76162791 0.75132275 0.875      0.88392857\n",
      " 0.72321429 0.86309524 0.82738095 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 511\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=68, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.88081395 0.72965116 0.73837209 0.64550265 0.9047619  0.86904762\n",
      " 0.81547619 0.73809524 0.72321429 0.5625    ]\n",
      "----------------------------------------\n",
      "Trial 512\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.81104651 0.75       0.61627907 0.63888889 0.77529762 0.60714286\n",
      " 0.75744048 0.7514881  0.625      0.67113095]\n",
      "----------------------------------------\n",
      "Trial 513\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 10, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=10,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.89244186 0.79651163 0.73401163 0.83730159 0.89880952 0.91369048\n",
      " 0.81696429 0.86755952 0.73363095 0.71875   ]\n",
      "----------------------------------------\n",
      "Trial 514\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 133, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=133, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.90406977 0.74127907 0.73546512 0.67460317 0.91071429 0.86607143\n",
      " 0.79464286 0.70535714 0.75892857 0.61011905]\n",
      "----------------------------------------\n",
      "Trial 515\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 185, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=185,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.89825581 0.76744186 0.75       0.72222222 0.88392857 0.88988095\n",
      " 0.73511905 0.81845238 0.74107143 0.63690476]\n",
      "----------------------------------------\n",
      "Trial 516\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 165, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=165, random_state=100))])\n",
      "cv score: [0.89534884 0.78488372 0.64244186 0.73280423 0.83928571 0.75\n",
      " 0.7797619  0.80059524 0.68154762 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 517\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 172, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=13,\n",
      "                                            n_estimators=172, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.85755814 0.75       0.6627907  0.67460317 0.80654762 0.85714286\n",
      " 0.80654762 0.66071429 0.80059524 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 518\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 111, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=111,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.85465116 0.72093023 0.56104651 0.8015873  0.71577381 0.8452381\n",
      " 0.66071429 0.70386905 0.64732143 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 519\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 135, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=135,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.80232558 0.69040698 0.56540698 0.80687831 0.73511905 0.8422619\n",
      " 0.65922619 0.70089286 0.57589286 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 520\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91715116 0.77034884 0.70203488 0.73809524 0.89880952 0.91666667\n",
      " 0.80505952 0.84821429 0.7827381  0.68154762]\n",
      "----------------------------------------\n",
      "Trial 521\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 52, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=52,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86918605 0.75       0.68604651 0.73544974 0.84821429 0.82440476\n",
      " 0.79761905 0.81845238 0.75       0.60416667]\n",
      "----------------------------------------\n",
      "Trial 522\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 156, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=156,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.84011628 0.77325581 0.78042328 0.89285714 0.9047619\n",
      " 0.8422619  0.87797619 0.82440476 0.73809524]\n",
      "----------------------------------------\n",
      "Trial 523\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 184, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=184, random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.88953488 0.77034884 0.73255814 0.67724868 0.9077381  0.87797619\n",
      " 0.8452381  0.76785714 0.76190476 0.57440476]\n",
      "----------------------------------------\n",
      "Trial 524\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 50, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=50,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.8619186  0.73546512 0.63226744 0.71693122 0.79761905 0.69940476\n",
      " 0.75297619 0.80357143 0.77083333 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 525\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 30, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=30, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.86337209 0.68313953 0.69767442 0.66666667 0.92261905 0.84821429\n",
      " 0.83333333 0.77083333 0.76785714 0.66071429]\n",
      "----------------------------------------\n",
      "Trial 526\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.9127907  0.79069767 0.69186047 0.6984127  0.88392857 0.87202381\n",
      " 0.86309524 0.83333333 0.74107143 0.58928571]\n",
      "----------------------------------------\n",
      "Trial 527\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 184, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=184,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88662791 0.77325581 0.75581395 0.74603175 0.88988095 0.9047619\n",
      " 0.75297619 0.82738095 0.75297619 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 528\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 104, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=104,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88081395 0.7994186  0.75290698 0.76719577 0.91369048 0.90178571\n",
      " 0.76190476 0.81845238 0.75       0.66964286]\n",
      "----------------------------------------\n",
      "Trial 529\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 107, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            n_estimators=107, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.7877907  0.61046512 0.61337209 0.72222222 0.69345238 0.65178571\n",
      " 0.69047619 0.76785714 0.65178571 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 530\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 148, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=148, random_state=100))])\n",
      "cv score: [0.88372093 0.80813953 0.65406977 0.73015873 0.85416667 0.88690476\n",
      " 0.83928571 0.81547619 0.79464286 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 531\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 162, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=162,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.84302326 0.75290698 0.78306878 0.90178571 0.91071429\n",
      " 0.82440476 0.89880952 0.80654762 0.66964286]\n",
      "----------------------------------------\n",
      "Trial 532\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 104, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=104, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.8372093  0.72674419 0.67732558 0.58994709 0.91369048 0.78869048\n",
      " 0.73214286 0.6875     0.79761905 0.48214286]\n",
      "----------------------------------------\n",
      "Trial 533\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=95,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.77325581 0.69767442 0.6119186  0.71693122 0.76934524 0.61011905\n",
      " 0.76041667 0.78720238 0.69345238 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 534\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 107, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=107,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.9244186  0.83139535 0.73546512 0.75661376 0.92559524 0.9047619\n",
      " 0.75595238 0.86607143 0.78571429 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 535\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.92732558 0.80232558 0.72674419 0.66137566 0.93154762 0.8452381\n",
      " 0.81547619 0.69047619 0.72619048 0.56845238]\n",
      "----------------------------------------\n",
      "Trial 536\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 112, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=7,\n",
      "                                            n_estimators=112, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.88081395 0.79069767 0.72383721 0.66666667 0.8125     0.875\n",
      " 0.82738095 0.77083333 0.80357143 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 537\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 155, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=155,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90116279 0.79796512 0.69040698 0.82275132 0.86458333 0.91666667\n",
      " 0.79166667 0.83333333 0.73214286 0.64136905]\n",
      "----------------------------------------\n",
      "Trial 538\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 103, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=103,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.82267442 0.75       0.75132275 0.88690476 0.92559524\n",
      " 0.77678571 0.85416667 0.74107143 0.67857143]\n",
      "----------------------------------------\n",
      "Trial 539\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 62, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=62,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.83139535 0.72093023 0.54796512 0.79365079 0.76934524 0.82440476\n",
      " 0.69940476 0.69345238 0.66666667 0.65327381]\n",
      "----------------------------------------\n",
      "Trial 540\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 83, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=83, random_state=100))])\n",
      "cv score: [0.89534884 0.77761628 0.62790698 0.72751323 0.86309524 0.86011905\n",
      " 0.84821429 0.82142857 0.78571429 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 541\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 49, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=49,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.81686047 0.73110465 0.84920635 0.89880952 0.89583333\n",
      " 0.81547619 0.87797619 0.79166667 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 542\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=4,\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.94040698 0.76453488 0.71656977 0.77777778 0.89434524 0.92261905\n",
      " 0.78422619 0.86458333 0.81845238 0.70684524]\n",
      "----------------------------------------\n",
      "Trial 543\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 192, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=192, random_state=100))])\n",
      "cv score: [0.86627907 0.75       0.65406977 0.74338624 0.81547619 0.69047619\n",
      " 0.77678571 0.81547619 0.70833333 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 544\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 17, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=17,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.86337209 0.81395349 0.65697674 0.71164021 0.84821429 0.85714286\n",
      " 0.79166667 0.75       0.70535714 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 545\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 176, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            n_estimators=176, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.90697674 0.75581395 0.73546512 0.82010582 0.88988095 0.89880952\n",
      " 0.80952381 0.86011905 0.80654762 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 546\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 107, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=107, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.88662791 0.68895349 0.71511628 0.64550265 0.90178571 0.8422619\n",
      " 0.85416667 0.73809524 0.74702381 0.55654762]\n",
      "----------------------------------------\n",
      "Trial 547\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 39, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=39,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90697674 0.78488372 0.69331395 0.83465608 0.8452381  0.85416667\n",
      " 0.76190476 0.8139881  0.72767857 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 548\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 174, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=174, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.90116279 0.76453488 0.70930233 0.6957672  0.86607143 0.81547619\n",
      " 0.80654762 0.83928571 0.76488095 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 549\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 62, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=62,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.81104651 0.72965116 0.81746032 0.88690476 0.91964286\n",
      " 0.83333333 0.87202381 0.8125     0.67857143]\n",
      "----------------------------------------\n",
      "Trial 550\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 61, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=61,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91715116 0.80232558 0.69622093 0.76190476 0.89285714 0.83928571\n",
      " 0.83333333 0.88988095 0.80357143 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 551\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.91860465 0.77034884 0.73255814 0.83068783 0.87202381 0.91369048\n",
      " 0.80357143 0.85714286 0.8125     0.72321429]\n",
      "----------------------------------------\n",
      "Trial 552\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 29, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=29, random_state=100))])\n",
      "cv score: [0.92877907 0.76598837 0.71947674 0.76851852 0.86011905 0.91369048\n",
      " 0.83482143 0.84970238 0.82291667 0.7172619 ]\n",
      "----------------------------------------\n",
      "Trial 553\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.9244186  0.76162791 0.70494186 0.73544974 0.88690476 0.91964286\n",
      " 0.79910714 0.88541667 0.79464286 0.6889881 ]\n",
      "----------------------------------------\n",
      "Trial 554\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 61, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            n_estimators=61, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.91860465 0.74127907 0.74563953 0.76851852 0.80952381 0.9047619\n",
      " 0.77678571 0.81547619 0.79464286 0.7485119 ]\n",
      "----------------------------------------\n",
      "Trial 555\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 103, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=103,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.83139535 0.75       0.72093023 0.86507937 0.87797619 0.77678571\n",
      " 0.77380952 0.77083333 0.72619048 0.50595238]\n",
      "----------------------------------------\n",
      "Trial 556\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=14,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.87209302 0.73837209 0.68895349 0.74074074 0.81845238 0.77380952\n",
      " 0.75       0.80654762 0.73511905 0.67559524]\n",
      "----------------------------------------\n",
      "Trial 557\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 93, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            n_estimators=93, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.91860465 0.75872093 0.75872093 0.81216931 0.88095238 0.92857143\n",
      " 0.80654762 0.875      0.82142857 0.72619048]\n",
      "----------------------------------------\n",
      "Trial 558\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 68, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=68,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.89244186 0.65261628 0.73982558 0.77777778 0.88690476 0.80505952\n",
      " 0.67708333 0.76934524 0.6547619  0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 559\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.89534884 0.83430233 0.73401163 0.79365079 0.89285714 0.91369048\n",
      " 0.82142857 0.86607143 0.79166667 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 560\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=170, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.66860465 0.42732558 0.5494186  0.47883598 0.73958333 0.72321429\n",
      " 0.43452381 0.39880952 0.39583333 0.35565476]\n",
      "----------------------------------------\n",
      "Trial 561\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 91, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=91,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92587209 0.81686047 0.74563953 0.82936508 0.89285714 0.9077381\n",
      " 0.79613095 0.86160714 0.79910714 0.67261905]\n",
      "----------------------------------------\n",
      "Trial 562\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 180, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            n_estimators=180, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.90116279 0.82267442 0.72674419 0.67989418 0.9077381  0.88988095\n",
      " 0.81547619 0.7797619  0.82738095 0.64880952]\n",
      "----------------------------------------\n",
      "Trial 563\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 37, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=37,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.9127907  0.79069767 0.63662791 0.74603175 0.76488095 0.91964286\n",
      " 0.80654762 0.78869048 0.77678571 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 564\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 84, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=10,\n",
      "                                            n_estimators=84, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.93313953 0.83430233 0.66569767 0.72751323 0.9047619  0.87797619\n",
      " 0.83928571 0.8125     0.83928571 0.67857143]\n",
      "----------------------------------------\n",
      "Trial 565\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91569767 0.83430233 0.77906977 0.76719577 0.88690476 0.9077381\n",
      " 0.77380952 0.85119048 0.74702381 0.70535714]\n",
      "----------------------------------------\n",
      "Trial 566\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 70, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=70,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.84011628 0.81104651 0.72093023 0.7989418  0.80059524 0.83035714\n",
      " 0.59821429 0.86309524 0.78571429 0.55952381]\n",
      "----------------------------------------\n",
      "Trial 567\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 199, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=199,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94186047 0.82848837 0.71366279 0.7962963  0.90178571 0.92559524\n",
      " 0.83928571 0.88988095 0.81547619 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 568\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 53, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=53,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.83430233 0.71511628 0.78835979 0.88392857 0.90178571\n",
      " 0.84821429 0.9047619  0.79464286 0.70535714]\n",
      "----------------------------------------\n",
      "Trial 569\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 136, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=136, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.90697674 0.76453488 0.66860465 0.67460317 0.89285714 0.89285714\n",
      " 0.83630952 0.82440476 0.79166667 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 570\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81686047 0.72965116 0.78835979 0.87202381 0.89583333\n",
      " 0.80654762 0.86607143 0.7827381  0.70833333]\n",
      "----------------------------------------\n",
      "Trial 571\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.92151163 0.80813953 0.6744186  0.74603175 0.85119048 0.8422619\n",
      " 0.85119048 0.86904762 0.77678571 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 572\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 117, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=117, random_state=100))])\n",
      "cv score: [0.91860465 0.75872093 0.73255814 0.83862434 0.89583333 0.88988095\n",
      " 0.81845238 0.86011905 0.80952381 0.71428571]\n",
      "----------------------------------------\n",
      "Trial 573\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 132, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=132, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.91860465 0.76162791 0.70930233 0.64285714 0.90178571 0.83333333\n",
      " 0.86309524 0.76785714 0.7797619  0.55952381]\n",
      "----------------------------------------\n",
      "Trial 574\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 167, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=167, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.92151163 0.81686047 0.76453488 0.7037037  0.9077381  0.85714286\n",
      " 0.70833333 0.7797619  0.81845238 0.52083333]\n",
      "----------------------------------------\n",
      "Trial 575\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 68, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=68,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9375     0.83139535 0.75290698 0.8015873  0.89285714 0.91071429\n",
      " 0.83035714 0.87797619 0.81845238 0.72619048]\n",
      "----------------------------------------\n",
      "Trial 576\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 31, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=31, random_state=100))])\n",
      "cv score: [0.93023256 0.75290698 0.6627907  0.69179894 0.83928571 0.82142857\n",
      " 0.7827381  0.69047619 0.83333333 0.50297619]\n",
      "----------------------------------------\n",
      "Trial 577\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 137, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=137,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84593023 0.76744186 0.6744186  0.71957672 0.875      0.80952381\n",
      " 0.80654762 0.84821429 0.74404762 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 578\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 96, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=96,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.77906977 0.72383721 0.75925926 0.9047619  0.86309524\n",
      " 0.7827381  0.86607143 0.80357143 0.67857143]\n",
      "----------------------------------------\n",
      "Trial 579\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=91,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.88081395 0.69767442 0.72674419 0.7037037  0.89880952 0.875\n",
      " 0.81845238 0.82738095 0.76488095 0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 580\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=51,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.87790698 0.74709302 0.7005814  0.67195767 0.88392857 0.86904762\n",
      " 0.83333333 0.82291667 0.75297619 0.54464286]\n",
      "----------------------------------------\n",
      "Trial 581\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 179, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=8, max_features='log2',\n",
      "                                            n_estimators=179,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.90116279 0.79069767 0.74127907 0.64550265 0.92261905 0.875\n",
      " 0.77678571 0.67857143 0.77083333 0.55654762]\n",
      "----------------------------------------\n",
      "Trial 582\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93895349 0.81831395 0.75436047 0.77116402 0.88244048 0.91666667\n",
      " 0.82738095 0.86011905 0.79464286 0.70684524]\n",
      "----------------------------------------\n",
      "Trial 583\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 129, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=129, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.66860465 0.72093023 0.65406977 0.57936508 0.7202381  0.50892857\n",
      " 0.88988095 0.58630952 0.61607143 0.5625    ]\n",
      "----------------------------------------\n",
      "Trial 584\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 39, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=39,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.77180233 0.75726744 0.63372093 0.70899471 0.78869048 0.66815476\n",
      " 0.7797619  0.78571429 0.63095238 0.69196429]\n",
      "----------------------------------------\n",
      "Trial 585\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 175, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=175, random_state=100))])\n",
      "cv score: [0.9244186  0.75872093 0.72093023 0.83862434 0.88690476 0.88392857\n",
      " 0.81547619 0.875      0.81845238 0.70833333]\n",
      "----------------------------------------\n",
      "Trial 586\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 117, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=117, random_state=100))])\n",
      "cv score: [0.88662791 0.79651163 0.63662791 0.74867725 0.85714286 0.88988095\n",
      " 0.84821429 0.80952381 0.79761905 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 587\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.85465116 0.76744186 0.73837209 0.71428571 0.91666667 0.88095238\n",
      " 0.75297619 0.8422619  0.72321429 0.67559524]\n",
      "----------------------------------------\n",
      "Trial 588\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=14,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.92151163 0.77034884 0.65406977 0.71296296 0.88690476 0.82142857\n",
      " 0.7514881  0.82886905 0.80803571 0.65178571]\n",
      "----------------------------------------\n",
      "Trial 589\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 198, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=198,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90116279 0.78488372 0.69186047 0.73544974 0.9047619  0.88392857\n",
      " 0.77083333 0.8422619  0.6875     0.64583333]\n",
      "----------------------------------------\n",
      "Trial 590\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 136, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            n_estimators=136, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.89825581 0.77616279 0.74418605 0.7010582  0.91071429 0.89880952\n",
      " 0.74702381 0.75       0.8125     0.63690476]\n",
      "----------------------------------------\n",
      "Trial 591\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 147, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=147,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84302326 0.71802326 0.60755814 0.7989418  0.76041667 0.84672619\n",
      " 0.6889881  0.69494048 0.68303571 0.75297619]\n",
      "----------------------------------------\n",
      "Trial 592\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 106, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=106,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.89825581 0.72383721 0.7122093  0.70634921 0.86904762 0.89880952\n",
      " 0.81845238 0.7797619  0.72916667 0.64285714]\n",
      "----------------------------------------\n",
      "Trial 593\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 199, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=199,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.87790698 0.73546512 0.75290698 0.7010582  0.88988095 0.88690476\n",
      " 0.875      0.81845238 0.75892857 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 594\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 140, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=140,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.84302326 0.73546512 0.80952381 0.89880952 0.93452381\n",
      " 0.84821429 0.88988095 0.81845238 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 595\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 32, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=32,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.79069767 0.74709302 0.76984127 0.86011905 0.91666667\n",
      " 0.75297619 0.86607143 0.70238095 0.6547619 ]\n",
      "----------------------------------------\n",
      "Trial 596\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 77, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=77,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.81976744 0.72674419 0.79365079 0.88988095 0.92261905\n",
      " 0.85714286 0.9047619  0.80357143 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 597\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 140, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=140,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88372093 0.73837209 0.71511628 0.71428571 0.86904762 0.86607143\n",
      " 0.80357143 0.79166667 0.75892857 0.66071429]\n",
      "----------------------------------------\n",
      "Trial 598\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 55, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=55,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81104651 0.78488372 0.6875     0.72751323 0.80952381 0.80059524\n",
      " 0.79166667 0.82142857 0.66666667 0.64285714]\n",
      "----------------------------------------\n",
      "Trial 599\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 55, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=55,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.82267442 0.70494186 0.74074074 0.9047619  0.92261905\n",
      " 0.82440476 0.87202381 0.80952381 0.68303571]\n",
      "----------------------------------------\n",
      "Trial 600\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=197, random_state=100))])\n",
      "cv score: [0.89680233 0.76162791 0.6627907  0.67195767 0.78720238 0.61607143\n",
      " 0.79315476 0.77678571 0.63839286 0.64880952]\n",
      "----------------------------------------\n",
      "Trial 601\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=16,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84447674 0.72383721 0.64389535 0.77248677 0.8139881  0.84375\n",
      " 0.73214286 0.78422619 0.73363095 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 602\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=183, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.89534884 0.78488372 0.66860465 0.75132275 0.86904762 0.87797619\n",
      " 0.85714286 0.77678571 0.79464286 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 603\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 185, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=185,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91860465 0.81686047 0.69622093 0.75925926 0.89285714 0.88392857\n",
      " 0.84821429 0.87202381 0.80654762 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 604\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 133, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=133, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.89534884 0.79651163 0.75290698 0.77513228 0.88095238 0.81547619\n",
      " 0.74404762 0.79761905 0.76488095 0.57440476]\n",
      "----------------------------------------\n",
      "Trial 605\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 13, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=13, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.77034884 0.75290698 0.68604651 0.61375661 0.87797619 0.84821429\n",
      " 0.83035714 0.65178571 0.79761905 0.75892857]\n",
      "----------------------------------------\n",
      "Trial 606\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 81, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=81,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.81976744 0.79360465 0.78835979 0.88392857 0.89880952\n",
      " 0.83035714 0.86904762 0.79761905 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 607\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 59, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=59, random_state=100))])\n",
      "cv score: [0.90116279 0.78488372 0.65406977 0.72222222 0.83333333 0.7202381\n",
      " 0.73809524 0.83630952 0.70535714 0.54166667]\n",
      "----------------------------------------\n",
      "Trial 608\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 132, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, max_features='sqrt',\n",
      "                                            n_estimators=132,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.9127907  0.76453488 0.76162791 0.61111111 0.92857143 0.83928571\n",
      " 0.80059524 0.7172619  0.71428571 0.54166667]\n",
      "----------------------------------------\n",
      "Trial 609\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 166, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=166,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.89244186 0.77906977 0.68895349 0.71957672 0.9047619  0.88690476\n",
      " 0.71428571 0.83035714 0.76488095 0.55952381]\n",
      "----------------------------------------\n",
      "Trial 610\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 126, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=126, random_state=100))])\n",
      "cv score: [0.93313953 0.78633721 0.7122093  0.80820106 0.86011905 0.88988095\n",
      " 0.85714286 0.86011905 0.7827381  0.7172619 ]\n",
      "----------------------------------------\n",
      "Trial 611\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 61, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=61,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.85755814 0.72383721 0.69767442 0.66931217 0.88988095 0.86309524\n",
      " 0.80952381 0.82440476 0.76488095 0.52678571]\n",
      "----------------------------------------\n",
      "Trial 612\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 37, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=37, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.82848837 0.73255814 0.65697674 0.70634921 0.89880952 0.88095238\n",
      " 0.81547619 0.74107143 0.75892857 0.65178571]\n",
      "----------------------------------------\n",
      "Trial 613\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 150, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=4,\n",
      "                                            n_estimators=150, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.9375     0.74127907 0.7122093  0.78571429 0.89136905 0.91071429\n",
      " 0.79166667 0.86755952 0.82589286 0.68005952]\n",
      "----------------------------------------\n",
      "Trial 614\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            n_estimators=101, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.92732558 0.73837209 0.76453488 0.82407407 0.88690476 0.91666667\n",
      " 0.77678571 0.85565476 0.8125     0.73660714]\n",
      "----------------------------------------\n",
      "Trial 615\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 110, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=110, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.78197674 0.79651163 0.64825581 0.74338624 0.91071429 0.84821429\n",
      " 0.84821429 0.79464286 0.73214286 0.51488095]\n",
      "----------------------------------------\n",
      "Trial 616\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 126, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=126, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.84593023 0.76744186 0.62790698 0.84126984 0.74107143 0.77083333\n",
      " 0.73809524 0.77380952 0.80952381 0.54464286]\n",
      "----------------------------------------\n",
      "Trial 617\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 33, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=33, random_state=100))])\n",
      "cv score: [0.89244186 0.71366279 0.57267442 0.6521164  0.86011905 0.86755952\n",
      " 0.8139881  0.65327381 0.82291667 0.60267857]\n",
      "----------------------------------------\n",
      "Trial 618\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 77, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=77,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90116279 0.81104651 0.70930233 0.77777778 0.88988095 0.90178571\n",
      " 0.75595238 0.80357143 0.70535714 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 619\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 192, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=192,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.83139535 0.74709302 0.77513228 0.89880952 0.89583333\n",
      " 0.8422619  0.85416667 0.7827381  0.69345238]\n",
      "----------------------------------------\n",
      "Trial 620\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 181, 'gb__subsample': 0.85, 'gb__learning_rate': 0.1, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=7, max_features='sqrt',\n",
      "                                            n_estimators=181, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.88662791 0.75872093 0.74127907 0.64021164 0.9077381  0.86607143\n",
      " 0.71130952 0.63095238 0.76190476 0.51488095]\n",
      "----------------------------------------\n",
      "Trial 621\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=121,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.79651163 0.78488372 0.62790698 0.68783069 0.88988095 0.86011905\n",
      " 0.6875     0.74107143 0.79761905 0.64880952]\n",
      "----------------------------------------\n",
      "Trial 622\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 179, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=179,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88662791 0.72383721 0.71511628 0.67989418 0.86904762 0.9077381\n",
      " 0.82142857 0.7797619  0.75       0.65178571]\n",
      "----------------------------------------\n",
      "Trial 623\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=174, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.87790698 0.7747093  0.66860465 0.74338624 0.88988095 0.875\n",
      " 0.85119048 0.79464286 0.8125     0.63988095]\n",
      "----------------------------------------\n",
      "Trial 624\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 159, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=159,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81976744 0.71656977 0.82539683 0.90178571 0.93154762\n",
      " 0.82440476 0.87797619 0.80357143 0.70386905]\n",
      "----------------------------------------\n",
      "Trial 625\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 166, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=166,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.86627907 0.79360465 0.75581395 0.78306878 0.92857143 0.86011905\n",
      " 0.72321429 0.80357143 0.76785714 0.64285714]\n",
      "----------------------------------------\n",
      "Trial 626\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 142, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=142,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88081395 0.75       0.67732558 0.71164021 0.875      0.8125\n",
      " 0.79166667 0.82142857 0.74107143 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 627\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 104, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=104,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.875      0.8372093  0.71511628 0.73280423 0.93452381 0.88392857\n",
      " 0.67857143 0.83035714 0.79464286 0.66964286]\n",
      "----------------------------------------\n",
      "Trial 628\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90116279 0.83139535 0.66860465 0.89153439 0.87202381 0.92559524\n",
      " 0.86011905 0.88095238 0.7797619  0.58630952]\n",
      "----------------------------------------\n",
      "Trial 629\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 59, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            n_estimators=59, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.93023256 0.79360465 0.72965116 0.82010582 0.87202381 0.91369048\n",
      " 0.81845238 0.86309524 0.80357143 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 630\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 11, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            n_estimators=11, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.73546512 0.39098837 0.6627907  0.48412698 0.7202381  0.74107143\n",
      " 0.77083333 0.82738095 0.70833333 0.39880952]\n",
      "----------------------------------------\n",
      "Trial 631\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 149, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=149,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.89534884 0.81104651 0.68895349 0.73280423 0.88690476 0.91666667\n",
      " 0.76488095 0.81547619 0.74107143 0.5625    ]\n",
      "----------------------------------------\n",
      "Trial 632\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 190, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=190, random_state=100))])\n",
      "cv score: [0.86627907 0.75       0.65406977 0.74074074 0.8125     0.68452381\n",
      " 0.7797619  0.8125     0.70833333 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 633\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94912791 0.82848837 0.71656977 0.77248677 0.89285714 0.83035714\n",
      " 0.8452381  0.89583333 0.78869048 0.71577381]\n",
      "----------------------------------------\n",
      "Trial 634\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 12, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            n_estimators=12, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.7994186  0.72383721 0.7630814  0.73941799 0.88095238 0.91369048\n",
      " 0.7172619  0.83630952 0.69940476 0.75595238]\n",
      "----------------------------------------\n",
      "Trial 635\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=101, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.63081395 0.75581395 0.60465116 0.67460317 0.75892857 0.70535714\n",
      " 0.78571429 0.61904762 0.7202381  0.58630952]\n",
      "----------------------------------------\n",
      "Trial 636\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 18, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=18, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.87354651 0.67296512 0.59156977 0.78042328 0.79166667 0.68452381\n",
      " 0.75744048 0.69494048 0.75595238 0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 637\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 158, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=158, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.88372093 0.70639535 0.68313953 0.65873016 0.91071429 0.83333333\n",
      " 0.86011905 0.70238095 0.74702381 0.58630952]\n",
      "----------------------------------------\n",
      "Trial 638\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 80, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=80,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.84011628 0.74418605 0.83597884 0.89583333 0.92857143\n",
      " 0.82738095 0.88392857 0.78869048 0.66964286]\n",
      "----------------------------------------\n",
      "Trial 639\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 13, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=13,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88081395 0.75581395 0.72383721 0.73015873 0.88392857 0.84821429\n",
      " 0.81547619 0.83035714 0.7172619  0.4702381 ]\n",
      "----------------------------------------\n",
      "Trial 640\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 175, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=175,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.88372093 0.7994186  0.70930233 0.79100529 0.94047619 0.90178571\n",
      " 0.73214286 0.82142857 0.77380952 0.64285714]\n",
      "----------------------------------------\n",
      "Trial 641\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 166, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=166,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81686047 0.71366279 0.78306878 0.90178571 0.92261905\n",
      " 0.81547619 0.86904762 0.80952381 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 642\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 35, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=35, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.80813953 0.72674419 0.6497093  0.71164021 0.84821429 0.77083333\n",
      " 0.79464286 0.80357143 0.73214286 0.64880952]\n",
      "----------------------------------------\n",
      "Trial 643\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 101, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=101,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.8880814  0.78197674 0.65116279 0.73809524 0.83333333 0.72321429\n",
      " 0.80803571 0.8735119  0.7202381  0.68005952]\n",
      "----------------------------------------\n",
      "Trial 644\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 180, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=180, random_state=100))])\n",
      "cv score: [0.91569767 0.77616279 0.71802326 0.82539683 0.86904762 0.89880952\n",
      " 0.8422619  0.875      0.78571429 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 645\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 192, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=192,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.80523256 0.79651163 0.80687831 0.91666667 0.93452381\n",
      " 0.80654762 0.83333333 0.7202381  0.69345238]\n",
      "----------------------------------------\n",
      "Trial 646\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 131, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=131,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81976744 0.75290698 0.74074074 0.92559524 0.92559524\n",
      " 0.81547619 0.88392857 0.79166667 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 647\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='sqrt',\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.90406977 0.70930233 0.78488372 0.71957672 0.88095238 0.84821429\n",
      " 0.75892857 0.76785714 0.75595238 0.54166667]\n",
      "----------------------------------------\n",
      "Trial 648\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 136, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=136,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93313953 0.84302326 0.75       0.75396825 0.91964286 0.92261905\n",
      " 0.78571429 0.82738095 0.75297619 0.70535714]\n",
      "----------------------------------------\n",
      "Trial 649\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=183, random_state=100))])\n",
      "cv score: [0.91569767 0.77325581 0.71802326 0.82539683 0.86607143 0.89583333\n",
      " 0.83630952 0.875      0.78869048 0.70833333]\n",
      "----------------------------------------\n",
      "Trial 650\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 138, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=138,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91569767 0.7994186  0.72674419 0.64550265 0.91666667 0.9047619\n",
      " 0.75       0.81845238 0.75595238 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 651\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.84883721 0.76744186 0.79365079 0.91071429 0.91071429\n",
      " 0.83035714 0.89285714 0.82440476 0.72916667]\n",
      "----------------------------------------\n",
      "Trial 652\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 91, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=91, random_state=100))])\n",
      "cv score: [0.89534884 0.79069767 0.63662791 0.74603175 0.85714286 0.89583333\n",
      " 0.85416667 0.79761905 0.8125     0.60416667]\n",
      "----------------------------------------\n",
      "Trial 653\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9127907  0.81976744 0.76162791 0.74867725 0.91071429 0.92857143\n",
      " 0.77678571 0.87202381 0.75297619 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 654\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 105, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=105, random_state=100))])\n",
      "cv score: [0.89825581 0.81976744 0.64244186 0.73544974 0.86309524 0.88690476\n",
      " 0.8422619  0.80952381 0.79166667 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 655\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 20, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=20, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.85319767 0.70348837 0.75       0.7010582  0.89583333 0.76785714\n",
      " 0.75297619 0.78571429 0.69047619 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 656\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 165, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            n_estimators=165, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.90988372 0.72674419 0.66860465 0.57936508 0.68452381 0.69047619\n",
      " 0.72321429 0.6547619  0.75595238 0.5297619 ]\n",
      "----------------------------------------\n",
      "Trial 657\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 140, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=140,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6744186  0.69186047 0.49273256 0.55820106 0.68154762 0.48809524\n",
      " 0.52678571 0.60267857 0.51785714 0.44047619]\n",
      "----------------------------------------\n",
      "Trial 658\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 59, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=59,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.87209302 0.81686047 0.67732558 0.71957672 0.9047619  0.91666667\n",
      " 0.73511905 0.81547619 0.67261905 0.66666667]\n",
      "----------------------------------------\n",
      "Trial 659\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 31, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=9,\n",
      "                                            n_estimators=31, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.88517442 0.75       0.73110465 0.76851852 0.89583333 0.91071429\n",
      " 0.77380952 0.86607143 0.79761905 0.75446429]\n",
      "----------------------------------------\n",
      "Trial 660\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 188, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            n_estimators=188, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.93604651 0.81686047 0.72965116 0.75132275 0.9047619  0.875\n",
      " 0.82738095 0.86309524 0.80952381 0.70833333]\n",
      "----------------------------------------\n",
      "Trial 661\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 64, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=64,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81976744 0.66860465 0.78488372 0.84126984 0.80357143 0.84970238\n",
      " 0.70238095 0.84672619 0.71279762 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 662\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 42, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=42,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90406977 0.79360465 0.69767442 0.75396825 0.92857143 0.88988095\n",
      " 0.79761905 0.85119048 0.76785714 0.65178571]\n",
      "----------------------------------------\n",
      "Trial 663\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 180, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            n_estimators=180, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.91569767 0.73546512 0.80087209 0.81746032 0.88095238 0.90178571\n",
      " 0.7797619  0.85119048 0.82440476 0.72916667]\n",
      "----------------------------------------\n",
      "Trial 664\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 136, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=136, random_state=100))])\n",
      "cv score: [0.86337209 0.73837209 0.65116279 0.74867725 0.85714286 0.86011905\n",
      " 0.86011905 0.8125     0.78571429 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 665\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 103, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=103, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.88953488 0.73837209 0.69767442 0.73280423 0.89285714 0.87202381\n",
      " 0.81845238 0.83630952 0.75595238 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 666\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 176, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=12,\n",
      "                                            n_estimators=176,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.89244186 0.67151163 0.85174419 0.71825397 0.82886905 0.9047619\n",
      " 0.78571429 0.77678571 0.79761905 0.69791667]\n",
      "----------------------------------------\n",
      "Trial 667\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 185, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=185,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88662791 0.72674419 0.69767442 0.68518519 0.87202381 0.87797619\n",
      " 0.8422619  0.8125     0.75       0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 668\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 163, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=163, random_state=100))])\n",
      "cv score: [0.85755814 0.75290698 0.65697674 0.74074074 0.86309524 0.87202381\n",
      " 0.84821429 0.80952381 0.79464286 0.64583333]\n",
      "----------------------------------------\n",
      "Trial 669\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 189, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=189,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.89825581 0.73837209 0.71802326 0.7010582  0.89583333 0.84821429\n",
      " 0.82440476 0.85416667 0.78869048 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 670\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 67, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=67,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.91860465 0.8255814  0.71947674 0.78703704 0.90178571 0.91666667\n",
      " 0.81845238 0.875      0.79464286 0.68303571]\n",
      "----------------------------------------\n",
      "Trial 671\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 169, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=169,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.80377907 0.72238372 0.72486772 0.89583333 0.91666667\n",
      " 0.79613095 0.86011905 0.79910714 0.69494048]\n",
      "----------------------------------------\n",
      "Trial 672\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 29, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=29,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94767442 0.82267442 0.74709302 0.8015873  0.91071429 0.91071429\n",
      " 0.82142857 0.85714286 0.78571429 0.68154762]\n",
      "----------------------------------------\n",
      "Trial 673\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=14,\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.65406977 0.71511628 0.59011628 0.68783069 0.70535714 0.78571429\n",
      " 0.75595238 0.67261905 0.61904762 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 674\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 143, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=143, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.86918605 0.72965116 0.71511628 0.67724868 0.91071429 0.87797619\n",
      " 0.86011905 0.81547619 0.76190476 0.55654762]\n",
      "----------------------------------------\n",
      "Trial 675\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 12, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=12, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.72093023 0.71802326 0.76453488 0.7962963  0.9672619  0.88392857\n",
      " 0.83333333 0.69940476 0.71130952 0.54761905]\n",
      "----------------------------------------\n",
      "Trial 676\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 37, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=37, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.86627907 0.7877907  0.69476744 0.7037037  0.91666667 0.8422619\n",
      " 0.8452381  0.73511905 0.82440476 0.68154762]\n",
      "----------------------------------------\n",
      "Trial 677\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 74, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=74, random_state=100))])\n",
      "cv score: [0.88372093 0.77325581 0.67151163 0.75661376 0.79166667 0.73214286\n",
      " 0.7827381  0.83035714 0.75297619 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 678\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 20, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=20,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94912791 0.81686047 0.69476744 0.76322751 0.89285714 0.95535714\n",
      " 0.80952381 0.8735119  0.80654762 0.68005952]\n",
      "----------------------------------------\n",
      "Trial 679\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 42, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=42, random_state=100))])\n",
      "cv score: [0.91860465 0.75872093 0.65697674 0.74338624 0.85119048 0.84821429\n",
      " 0.77678571 0.69047619 0.80059524 0.56547619]\n",
      "----------------------------------------\n",
      "Trial 680\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 19, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=19,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.88081395 0.7369186  0.72965116 0.67592593 0.91964286 0.91369048\n",
      " 0.75595238 0.82440476 0.80059524 0.69791667]\n",
      "----------------------------------------\n",
      "Trial 681\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 135, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=135,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91569767 0.83430233 0.76744186 0.75661376 0.90178571 0.92261905\n",
      " 0.77678571 0.85714286 0.80952381 0.67559524]\n",
      "----------------------------------------\n",
      "Trial 682\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 43, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            n_estimators=43, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.86918605 0.87209302 0.66569767 0.81216931 0.86607143 0.85119048\n",
      " 0.79464286 0.81845238 0.83035714 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 683\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 60, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=60,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.89244186 0.75       0.69767442 0.71164021 0.88690476 0.88690476\n",
      " 0.82440476 0.75892857 0.8125     0.62202381]\n",
      "----------------------------------------\n",
      "Trial 684\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 77, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=77, random_state=100))])\n",
      "cv score: [0.9244186  0.76744186 0.71802326 0.84391534 0.88392857 0.91071429\n",
      " 0.80952381 0.88392857 0.83035714 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 685\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 110, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=110, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.81686047 0.81686047 0.71802326 0.67195767 0.91071429 0.84821429\n",
      " 0.6577381  0.63095238 0.77678571 0.44047619]\n",
      "----------------------------------------\n",
      "Trial 686\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.80232558 0.72383721 0.82804233 0.89880952 0.91071429\n",
      " 0.81845238 0.88392857 0.80654762 0.68154762]\n",
      "----------------------------------------\n",
      "Trial 687\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 52, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=52, random_state=100))])\n",
      "cv score: [0.89825581 0.79360465 0.65697674 0.71428571 0.86309524 0.86904762\n",
      " 0.79464286 0.73214286 0.81845238 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 688\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 173, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=173, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.38226744 0.80813953 0.52906977 0.54761905 0.61607143 0.7797619\n",
      " 0.51785714 0.61607143 0.56845238 0.54315476]\n",
      "----------------------------------------\n",
      "Trial 689\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=183, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.82267442 0.68313953 0.6627907  0.66402116 0.62946429 0.79761905\n",
      " 0.72619048 0.66369048 0.72321429 0.51785714]\n",
      "----------------------------------------\n",
      "Trial 690\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 26, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            n_estimators=26, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.9244186  0.77616279 0.77906977 0.8042328  0.90178571 0.90178571\n",
      " 0.82142857 0.83928571 0.79761905 0.74553571]\n",
      "----------------------------------------\n",
      "Trial 691\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 50, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=50, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.90406977 0.75290698 0.63662791 0.78835979 0.81547619 0.76190476\n",
      " 0.74702381 0.77678571 0.80357143 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 692\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 16, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=16,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94476744 0.83430233 0.57848837 0.69047619 0.86607143 0.89285714\n",
      " 0.78571429 0.7827381  0.77083333 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 693\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 111, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=111, random_state=100))])\n",
      "cv score: [0.93023256 0.76744186 0.67151163 0.74867725 0.86309524 0.8452381\n",
      " 0.84821429 0.75297619 0.79464286 0.56547619]\n",
      "----------------------------------------\n",
      "Trial 694\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 181, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=181,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.83430233 0.74127907 0.78571429 0.89583333 0.89583333\n",
      " 0.81547619 0.87202381 0.79761905 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 695\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.69767442 0.70639535 0.62209302 0.60846561 0.60714286 0.80952381\n",
      " 0.81547619 0.44642857 0.43154762 0.56845238]\n",
      "----------------------------------------\n",
      "Trial 696\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 35, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=35, random_state=100))])\n",
      "cv score: [0.91569767 0.74418605 0.67587209 0.77513228 0.83333333 0.79761905\n",
      " 0.73214286 0.80654762 0.77380952 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 697\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 36, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=36,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91715116 0.79360465 0.67877907 0.76190476 0.89880952 0.80952381\n",
      " 0.8452381  0.88095238 0.8125     0.68303571]\n",
      "----------------------------------------\n",
      "Trial 698\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 45, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=45, random_state=100))])\n",
      "cv score: [0.90406977 0.76744186 0.65988372 0.75132275 0.85416667 0.83928571\n",
      " 0.79166667 0.70535714 0.79761905 0.5625    ]\n",
      "----------------------------------------\n",
      "Trial 699\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 91, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=91, random_state=100))])\n",
      "cv score: [0.88662791 0.7994186  0.63372093 0.78042328 0.85714286 0.86309524\n",
      " 0.81845238 0.77380952 0.73809524 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 700\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 114, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=114,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90697674 0.7994186  0.69186047 0.75396825 0.86607143 0.85416667\n",
      " 0.8452381  0.85714286 0.77678571 0.68303571]\n",
      "----------------------------------------\n",
      "Trial 701\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 100, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt',\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.89244186 0.72965116 0.71511628 0.71164021 0.87202381 0.89880952\n",
      " 0.82738095 0.79761905 0.72916667 0.64583333]\n",
      "----------------------------------------\n",
      "Trial 702\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9505814  0.81395349 0.67587209 0.84656085 0.87202381 0.92261905\n",
      " 0.82142857 0.88988095 0.81845238 0.71279762]\n",
      "----------------------------------------\n",
      "Trial 703\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 189, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=189, random_state=100))])\n",
      "cv score: [0.91860465 0.78197674 0.71947674 0.8042328  0.85416667 0.89583333\n",
      " 0.84821429 0.86309524 0.7797619  0.70982143]\n",
      "----------------------------------------\n",
      "Trial 704\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 63, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=63, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.85465116 0.77906977 0.71511628 0.63227513 0.81547619 0.91964286\n",
      " 0.70833333 0.5952381  0.77083333 0.48511905]\n",
      "----------------------------------------\n",
      "Trial 705\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 73, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=73,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90406977 0.7877907  0.69331395 0.78306878 0.87797619 0.91369048\n",
      " 0.85416667 0.90178571 0.82738095 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 706\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 65, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=65,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86337209 0.72093023 0.7005814  0.67460317 0.88392857 0.86904762\n",
      " 0.8125     0.82142857 0.76190476 0.51785714]\n",
      "----------------------------------------\n",
      "Trial 707\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 32, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=32,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.91133721 0.79360465 0.69331395 0.72222222 0.88095238 0.85416667\n",
      " 0.80059524 0.86607143 0.79613095 0.67559524]\n",
      "----------------------------------------\n",
      "Trial 708\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 129, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=129,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.90116279 0.73837209 0.75581395 0.71164021 0.85714286 0.87202381\n",
      " 0.6547619  0.67261905 0.80059524 0.43452381]\n",
      "----------------------------------------\n",
      "Trial 709\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 147, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=147,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88081395 0.74854651 0.75581395 0.70634921 0.89583333 0.88988095\n",
      " 0.86607143 0.8139881  0.76488095 0.57142857]\n",
      "----------------------------------------\n",
      "Trial 710\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90988372 0.7994186  0.72674419 0.80687831 0.85119048 0.91369048\n",
      " 0.79166667 0.86309524 0.76488095 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 711\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 106, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=106, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93895349 0.78488372 0.70639535 0.74867725 0.89583333 0.8422619\n",
      " 0.79761905 0.86309524 0.80059524 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 712\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 80, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=80, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.84593023 0.75872093 0.6744186  0.69312169 0.93452381 0.85416667\n",
      " 0.85119048 0.82738095 0.76785714 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 713\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 190, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            n_estimators=190, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.92732558 0.7994186  0.78197674 0.74074074 0.91071429 0.89880952\n",
      " 0.79761905 0.8452381  0.80952381 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 714\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 175, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=175,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.83430233 0.73982558 0.84126984 0.88690476 0.9047619\n",
      " 0.82440476 0.85267857 0.80059524 0.70982143]\n",
      "----------------------------------------\n",
      "Trial 715\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 160, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=160, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.9127907  0.81104651 0.70348837 0.74074074 0.88690476 0.86309524\n",
      " 0.75595238 0.78869048 0.80059524 0.56845238]\n",
      "----------------------------------------\n",
      "Trial 716\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 81, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=81,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.875      0.77616279 0.77616279 0.72222222 0.91071429 0.88392857\n",
      " 0.64880952 0.875      0.73809524 0.54166667]\n",
      "----------------------------------------\n",
      "Trial 717\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 10, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=10, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.8255814  0.68604651 0.72093023 0.64550265 0.8452381  0.86904762\n",
      " 0.86309524 0.85119048 0.7797619  0.73809524]\n",
      "----------------------------------------\n",
      "Trial 718\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 65, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=65, random_state=100))])\n",
      "cv score: [0.94040698 0.78633721 0.71656977 0.79100529 0.86011905 0.91369048\n",
      " 0.83482143 0.86309524 0.80357143 0.71428571]\n",
      "----------------------------------------\n",
      "Trial 719\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 178, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=2, max_features='log2',\n",
      "                                            n_estimators=178, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.84593023 0.78197674 0.67732558 0.7962963  0.83928571 0.82142857\n",
      " 0.73214286 0.81845238 0.80357143 0.57738095]\n",
      "----------------------------------------\n",
      "Trial 720\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 125, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=125, random_state=100))])\n",
      "cv score: [0.93313953 0.79069767 0.72383721 0.8042328  0.89285714 0.88690476\n",
      " 0.8125     0.875      0.82738095 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 721\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 21, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=21, random_state=100))])\n",
      "cv score: [0.92732558 0.69186047 0.64244186 0.71693122 0.82142857 0.85863095\n",
      " 0.72619048 0.69345238 0.875      0.47470238]\n",
      "----------------------------------------\n",
      "Trial 722\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 24, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=24,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.90988372 0.86627907 0.72383721 0.74867725 0.93154762 0.88988095\n",
      " 0.75       0.83928571 0.80952381 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 723\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            n_estimators=170, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.93895349 0.74127907 0.75145349 0.80952381 0.85119048 0.88690476\n",
      " 0.79761905 0.80654762 0.78869048 0.76190476]\n",
      "----------------------------------------\n",
      "Trial 724\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 21, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            n_estimators=21, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.94186047 0.81976744 0.73546512 0.8042328  0.85119048 0.91666667\n",
      " 0.81845238 0.8452381  0.82738095 0.74404762]\n",
      "----------------------------------------\n",
      "Trial 725\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 156, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=156,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86918605 0.74127907 0.71511628 0.7037037  0.87797619 0.875\n",
      " 0.80654762 0.78869048 0.75892857 0.6547619 ]\n",
      "----------------------------------------\n",
      "Trial 726\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 173, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=173,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.8372093  0.73837209 0.74074074 0.91964286 0.91369048\n",
      " 0.80059524 0.86607143 0.7797619  0.70238095]\n",
      "----------------------------------------\n",
      "Trial 727\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 89, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=89,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84302326 0.71802326 0.60755814 0.7989418  0.76041667 0.84672619\n",
      " 0.6889881  0.69494048 0.68303571 0.75297619]\n",
      "----------------------------------------\n",
      "Trial 728\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 192, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=192,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88081395 0.72965116 0.71511628 0.68253968 0.87797619 0.89583333\n",
      " 0.82440476 0.79464286 0.75       0.64583333]\n",
      "----------------------------------------\n",
      "Trial 729\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 55, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=55,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90116279 0.7994186  0.67587209 0.74603175 0.87797619 0.86607143\n",
      " 0.84970238 0.85119048 0.78571429 0.67708333]\n",
      "----------------------------------------\n",
      "Trial 730\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=102,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86918605 0.72674419 0.72093023 0.70899471 0.88690476 0.87202381\n",
      " 0.81547619 0.80654762 0.75       0.54166667]\n",
      "----------------------------------------\n",
      "Trial 731\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 77, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=77,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77180233 0.71947674 0.62063953 0.6984127  0.74702381 0.58333333\n",
      " 0.76041667 0.72470238 0.65922619 0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 732\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.91860465 0.82848837 0.75290698 0.77248677 0.92559524 0.92559524\n",
      " 0.78571429 0.8422619  0.79166667 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 733\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 137, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=137,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84447674 0.72383721 0.64534884 0.8015873  0.8139881  0.84375\n",
      " 0.73214286 0.78571429 0.73363095 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 734\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 65, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=65,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.84011628 0.72674419 0.82804233 0.87202381 0.9047619\n",
      " 0.82142857 0.86607143 0.83035714 0.67261905]\n",
      "----------------------------------------\n",
      "Trial 735\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 172, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=172,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9127907  0.83430233 0.74709302 0.75132275 0.92857143 0.92261905\n",
      " 0.80059524 0.83928571 0.76190476 0.67857143]\n",
      "----------------------------------------\n",
      "Trial 736\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.84883721 0.72965116 0.71511628 0.72222222 0.88690476 0.86309524\n",
      " 0.79464286 0.7797619  0.78571429 0.58035714]\n",
      "----------------------------------------\n",
      "Trial 737\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 104, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            n_estimators=104,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.93168605 0.82412791 0.72674419 0.7037037  0.91666667 0.89285714\n",
      " 0.82886905 0.82142857 0.79464286 0.72916667]\n",
      "----------------------------------------\n",
      "Trial 738\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 56, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=56,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84447674 0.72383721 0.64534884 0.78306878 0.84375    0.84672619\n",
      " 0.73214286 0.78571429 0.73363095 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 739\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 189, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=189,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81686047 0.72674419 0.63372093 0.72751323 0.79761905 0.6875\n",
      " 0.77083333 0.80654762 0.73809524 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 740\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.9127907  0.72674419 0.64825581 0.71693122 0.86607143 0.89880952\n",
      " 0.85714286 0.78869048 0.74107143 0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 741\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 159, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=159,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.82848837 0.74127907 0.74074074 0.93452381 0.94642857\n",
      " 0.79464286 0.85416667 0.72916667 0.66071429]\n",
      "----------------------------------------\n",
      "Trial 742\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 17, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=17, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.81395349 0.77325581 0.63662791 0.73544974 0.77678571 0.77380952\n",
      " 0.74255952 0.75       0.76785714 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 743\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 193, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=193, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.86046512 0.76162791 0.63081395 0.73809524 0.875      0.85119048\n",
      " 0.8422619  0.80357143 0.76785714 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 744\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=171, random_state=100))])\n",
      "cv score: [0.85755814 0.75581395 0.63372093 0.73809524 0.875      0.84821429\n",
      " 0.85714286 0.79761905 0.77083333 0.58928571]\n",
      "----------------------------------------\n",
      "Trial 745\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 117, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=117,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.85174419 0.74127907 0.70348837 0.71164021 0.89880952 0.9077381\n",
      " 0.83928571 0.79166667 0.75595238 0.56845238]\n",
      "----------------------------------------\n",
      "Trial 746\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 59, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=59,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81686047 0.56686047 0.64244186 0.75793651 0.78571429 0.76636905\n",
      " 0.61309524 0.70833333 0.65922619 0.58035714]\n",
      "----------------------------------------\n",
      "Trial 747\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 181, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=181,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.80523256 0.69331395 0.83068783 0.89880952 0.91369048\n",
      " 0.80952381 0.88095238 0.79761905 0.69494048]\n",
      "----------------------------------------\n",
      "Trial 748\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 36, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=36, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.83430233 0.64244186 0.66569767 0.61375661 0.9047619  0.81845238\n",
      " 0.79464286 0.73511905 0.73214286 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 749\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 47, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=47,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.84883721 0.77325581 0.72383721 0.73280423 0.89285714 0.94940476\n",
      " 0.75       0.82440476 0.79166667 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 750\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91860465 0.8255814  0.73546512 0.76190476 0.92857143 0.89880952\n",
      " 0.79761905 0.84821429 0.80357143 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 751\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 86, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=86,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94476744 0.83139535 0.70494186 0.76455026 0.90178571 0.91666667\n",
      " 0.83333333 0.875      0.82440476 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 752\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 66, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=66, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.92151163 0.78488372 0.71075581 0.82539683 0.86607143 0.91071429\n",
      " 0.85565476 0.87202381 0.79166667 0.71577381]\n",
      "----------------------------------------\n",
      "Trial 753\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 143, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=143,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.7994186  0.72383721 0.82539683 0.90178571 0.92559524\n",
      " 0.83333333 0.89285714 0.81547619 0.67857143]\n",
      "----------------------------------------\n",
      "Trial 754\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 20, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=20,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.79069767 0.63517442 0.73015873 0.86904762 0.92708333\n",
      " 0.80505952 0.88541667 0.77232143 0.64136905]\n",
      "----------------------------------------\n",
      "Trial 755\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 19, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=19, random_state=100))])\n",
      "cv score: [0.94622093 0.74709302 0.70203488 0.74206349 0.85714286 0.63839286\n",
      " 0.79017857 0.80059524 0.8452381  0.6235119 ]\n",
      "----------------------------------------\n",
      "Trial 756\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 68, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=68, random_state=100))])\n",
      "cv score: [0.88953488 0.80523256 0.64534884 0.74338624 0.83333333 0.72916667\n",
      " 0.73511905 0.8422619  0.71130952 0.5297619 ]\n",
      "----------------------------------------\n",
      "Trial 757\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 55, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=55, random_state=100))])\n",
      "cv score: [0.88953488 0.79215116 0.63662791 0.70502646 0.86607143 0.88988095\n",
      " 0.83333333 0.76190476 0.80952381 0.59375   ]\n",
      "----------------------------------------\n",
      "Trial 758\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 56, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=56, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.82267442 0.65406977 0.70930233 0.72222222 0.90178571 0.88690476\n",
      " 0.8452381  0.7827381  0.78869048 0.56547619]\n",
      "----------------------------------------\n",
      "Trial 759\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 88, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=88,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86337209 0.71511628 0.68604651 0.73809524 0.87202381 0.85416667\n",
      " 0.79464286 0.77380952 0.75595238 0.66666667]\n",
      "----------------------------------------\n",
      "Trial 760\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 76, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=76,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.8255814  0.72965116 0.82010582 0.9077381  0.89880952\n",
      " 0.85714286 0.89583333 0.82440476 0.68154762]\n",
      "----------------------------------------\n",
      "Trial 761\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 189, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=189, random_state=100))])\n",
      "cv score: [0.88372093 0.7994186  0.66424419 0.75132275 0.88095238 0.875\n",
      " 0.85416667 0.80357143 0.80952381 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 762\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 158, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=158,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93023256 0.81686047 0.77034884 0.77513228 0.90178571 0.91666667\n",
      " 0.79166667 0.87797619 0.76488095 0.72916667]\n",
      "----------------------------------------\n",
      "Trial 763\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 162, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=162, random_state=100))])\n",
      "cv score: [0.86627907 0.76744186 0.65406977 0.75132275 0.86309524 0.82440476\n",
      " 0.82440476 0.82738095 0.72619048 0.58928571]\n",
      "----------------------------------------\n",
      "Trial 764\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.92151163 0.68895349 0.73982558 0.71296296 0.90029762 0.88244048\n",
      " 0.79910714 0.82886905 0.80654762 0.61458333]\n",
      "----------------------------------------\n",
      "Trial 765\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 196, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=196,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90697674 0.77616279 0.75290698 0.7010582  0.89583333 0.77380952\n",
      " 0.63690476 0.76785714 0.75       0.67559524]\n",
      "----------------------------------------\n",
      "Trial 766\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 57, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=57,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81976744 0.66860465 0.78488372 0.84126984 0.80357143 0.84970238\n",
      " 0.70238095 0.84375    0.71279762 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 767\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 167, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=167,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88081395 0.73837209 0.69767442 0.6957672  0.87797619 0.875\n",
      " 0.8452381  0.81547619 0.74702381 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 768\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 36, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=36,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94476744 0.8255814  0.69767442 0.80952381 0.89880952 0.90178571\n",
      " 0.875      0.9047619  0.8125     0.67261905]\n",
      "----------------------------------------\n",
      "Trial 769\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 46, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            n_estimators=46, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.90406977 0.73546512 0.78197674 0.78306878 0.86309524 0.89880952\n",
      " 0.8125     0.85416667 0.7827381  0.70833333]\n",
      "----------------------------------------\n",
      "Trial 770\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 184, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=184, random_state=100))])\n",
      "cv score: [0.90406977 0.79069767 0.6627907  0.75925926 0.87202381 0.86904762\n",
      " 0.86309524 0.77380952 0.78869048 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 771\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=58,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.87209302 0.75436047 0.73546512 0.72089947 0.91071429 0.88839286\n",
      " 0.83630952 0.82142857 0.7797619  0.61755952]\n",
      "----------------------------------------\n",
      "Trial 772\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 47, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=47, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.88662791 0.73255814 0.63953488 0.70899471 0.88690476 0.86309524\n",
      " 0.82738095 0.75892857 0.72916667 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 773\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 168, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=168, random_state=100))])\n",
      "cv score: [0.89534884 0.77906977 0.66860465 0.76190476 0.88392857 0.87797619\n",
      " 0.85416667 0.7827381  0.80357143 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 774\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 153, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=153,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.87209302 0.80523256 0.72965116 0.80687831 0.9375     0.89583333\n",
      " 0.74107143 0.82738095 0.73809524 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 775\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 87, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=87, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.83139535 0.81976744 0.75       0.73809524 0.91071429 0.81547619\n",
      " 0.77083333 0.78869048 0.7202381  0.54166667]\n",
      "----------------------------------------\n",
      "Trial 776\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 154, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            n_estimators=154,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.84883721 0.72965116 0.68459302 0.77513228 0.7797619  0.87053571\n",
      " 0.73065476 0.74255952 0.61904762 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 777\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=159, random_state=100))])\n",
      "cv score: [0.88372093 0.76744186 0.65697674 0.7010582  0.87202381 0.86011905\n",
      " 0.85119048 0.83630952 0.7797619  0.61309524]\n",
      "----------------------------------------\n",
      "Trial 778\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 173, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=173, random_state=100))])\n",
      "cv score: [0.8997093  0.76162791 0.6627907  0.66666667 0.80208333 0.61309524\n",
      " 0.78422619 0.76785714 0.63392857 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 779\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 21, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=21,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88953488 0.82848837 0.7005814  0.64021164 0.91666667 0.82738095\n",
      " 0.8422619  0.70238095 0.74702381 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 780\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 114, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=114,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91860465 0.81976744 0.74418605 0.72751323 0.92559524 0.92857143\n",
      " 0.7827381  0.86011905 0.78869048 0.70535714]\n",
      "----------------------------------------\n",
      "Trial 781\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 84, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=84, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.90988372 0.75581395 0.68895349 0.75661376 0.83630952 0.73511905\n",
      " 0.77678571 0.79464286 0.75       0.57440476]\n",
      "----------------------------------------\n",
      "Trial 782\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 30, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, n_estimators=30,\n",
      "                                            random_state=100, subsample=0.8))])\n",
      "cv score: [0.93023256 0.81976744 0.76744186 0.73544974 0.92559524 0.85119048\n",
      " 0.80059524 0.79464286 0.80357143 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 783\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 79, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=79, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.89244186 0.75581395 0.65697674 0.82010582 0.8125     0.74702381\n",
      " 0.6875     0.82440476 0.75892857 0.58928571]\n",
      "----------------------------------------\n",
      "Trial 784\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 43, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=43, random_state=100))])\n",
      "cv score: [0.9127907  0.76453488 0.66569767 0.76719577 0.85416667 0.85714286\n",
      " 0.7797619  0.69047619 0.80059524 0.56845238]\n",
      "----------------------------------------\n",
      "Trial 785\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 18, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=18,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.78052326 0.64534884 0.77248677 0.88839286 0.91815476\n",
      " 0.81547619 0.89434524 0.77232143 0.68303571]\n",
      "----------------------------------------\n",
      "Trial 786\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 168, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=168,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.9127907  0.8255814  0.70639535 0.73809524 0.88392857 0.92857143\n",
      " 0.74702381 0.8452381  0.7797619  0.57738095]\n",
      "----------------------------------------\n",
      "Trial 787\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 148, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=148, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.90406977 0.74709302 0.74709302 0.62433862 0.9077381  0.85714286\n",
      " 0.7797619  0.70833333 0.76488095 0.54464286]\n",
      "----------------------------------------\n",
      "Trial 788\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 55, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=55, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.88081395 0.66860465 0.78488372 0.64021164 0.88392857 0.85416667\n",
      " 0.79464286 0.54166667 0.82440476 0.57142857]\n",
      "----------------------------------------\n",
      "Trial 789\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 82, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=82,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6744186  0.69186047 0.49273256 0.55820106 0.68154762 0.48809524\n",
      " 0.52678571 0.60267857 0.51785714 0.44047619]\n",
      "----------------------------------------\n",
      "Trial 790\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 15, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=15,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88081395 0.7369186  0.7005814  0.65343915 0.91815476 0.91071429\n",
      " 0.79464286 0.8139881  0.82738095 0.71279762]\n",
      "----------------------------------------\n",
      "Trial 791\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 41, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=41,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.76017442 0.73982558 0.69912791 0.67592593 0.75       0.6577381\n",
      " 0.71428571 0.74553571 0.63095238 0.60565476]\n",
      "----------------------------------------\n",
      "Trial 792\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 30, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=30,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.81540698 0.6627907  0.8015873  0.9047619  0.78571429\n",
      " 0.8452381  0.91369048 0.7827381  0.70238095]\n",
      "----------------------------------------\n",
      "Trial 793\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 27, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=27,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.92587209 0.7877907  0.69622093 0.6957672  0.89583333 0.86607143\n",
      " 0.80357143 0.84821429 0.80505952 0.67559524]\n",
      "----------------------------------------\n",
      "Trial 794\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 36, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=36, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.75290698 0.83139535 0.61337209 0.71164021 0.83928571 0.77380952\n",
      " 0.83035714 0.55059524 0.67261905 0.49702381]\n",
      "----------------------------------------\n",
      "Trial 795\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 185, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            n_estimators=185, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.7122093  0.72965116 0.68604651 0.63492063 0.80059524 0.72619048\n",
      " 0.77083333 0.76785714 0.74404762 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 796\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 79, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=79, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.88081395 0.75872093 0.63081395 0.74338624 0.83928571 0.69940476\n",
      " 0.75595238 0.82142857 0.73809524 0.58630952]\n",
      "----------------------------------------\n",
      "Trial 797\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.90406977 0.73837209 0.75581395 0.82010582 0.87202381 0.90178571\n",
      " 0.82738095 0.82738095 0.76190476 0.74404762]\n",
      "----------------------------------------\n",
      "Trial 798\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 46, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            n_estimators=46, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.91860465 0.79651163 0.72093023 0.75396825 0.88392857 0.88392857\n",
      " 0.80654762 0.86011905 0.84821429 0.7202381 ]\n",
      "----------------------------------------\n",
      "Trial 799\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 104, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=104,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.82267442 0.71366279 0.77910053 0.9047619  0.92261905\n",
      " 0.80654762 0.87797619 0.80952381 0.69196429]\n",
      "----------------------------------------\n",
      "Trial 800\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=16, random_state=100))])\n",
      "cv score: [0.93604651 0.76889535 0.49709302 0.67857143 0.80357143 0.80208333\n",
      " 0.82738095 0.73363095 0.8139881  0.45982143]\n",
      "----------------------------------------\n",
      "Trial 801\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 90, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=90, random_state=100))])\n",
      "cv score: [0.87209302 0.76453488 0.66569767 0.74867725 0.77083333 0.73214286\n",
      " 0.76190476 0.8422619  0.77380952 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 802\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 156, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=156,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.80523256 0.70639535 0.78835979 0.90178571 0.9077381\n",
      " 0.7797619  0.83035714 0.80952381 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 803\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 36, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=7,\n",
      "                                            n_estimators=36, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.9127907  0.76162791 0.68604651 0.71164021 0.94047619 0.91666667\n",
      " 0.77083333 0.7797619  0.67559524 0.54464286]\n",
      "----------------------------------------\n",
      "Trial 804\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81395349 0.73837209 0.79100529 0.90178571 0.88095238\n",
      " 0.76785714 0.8452381  0.79761905 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 805\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 173, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=173,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94476744 0.84302326 0.77034884 0.78306878 0.89583333 0.88988095\n",
      " 0.78869048 0.875      0.82738095 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 806\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93313953 0.79651163 0.7122093  0.78835979 0.9047619  0.92559524\n",
      " 0.81696429 0.87797619 0.80952381 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 807\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 82, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=82,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94767442 0.81104651 0.70784884 0.76719577 0.9047619  0.9077381\n",
      " 0.83630952 0.88690476 0.82142857 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 808\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 99, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=99, random_state=100))])\n",
      "cv score: [0.84011628 0.73837209 0.62790698 0.74074074 0.87797619 0.8452381\n",
      " 0.84821429 0.82142857 0.75892857 0.57142857]\n",
      "----------------------------------------\n",
      "Trial 809\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9127907  0.81976744 0.71656977 0.8042328  0.89583333 0.9077381\n",
      " 0.80952381 0.87202381 0.80059524 0.70386905]\n",
      "----------------------------------------\n",
      "Trial 810\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 143, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=143,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.81395349 0.7122093  0.63953488 0.58994709 0.85119048 0.88392857\n",
      " 0.78571429 0.76488095 0.76785714 0.57738095]\n",
      "----------------------------------------\n",
      "Trial 811\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 96, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=96,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81976744 0.66860465 0.78488372 0.83597884 0.80357143 0.84970238\n",
      " 0.70238095 0.84375    0.71279762 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 812\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 84, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            n_estimators=84, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.90697674 0.73837209 0.76453488 0.8015873  0.86904762 0.89285714\n",
      " 0.81845238 0.8452381  0.77678571 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 813\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 114, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=114,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.85174419 0.75872093 0.74418605 0.65873016 0.88392857 0.88690476\n",
      " 0.89285714 0.8125     0.80059524 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 814\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.91569767 0.74709302 0.7630814  0.80026455 0.88095238 0.92559524\n",
      " 0.75       0.85416667 0.77380952 0.7485119 ]\n",
      "----------------------------------------\n",
      "Trial 815\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 124, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=124, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.79651163 0.79069767 0.6380814  0.7037037  0.7827381  0.63392857\n",
      " 0.73214286 0.77678571 0.7172619  0.63690476]\n",
      "----------------------------------------\n",
      "Trial 816\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 189, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=189,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.86627907 0.74709302 0.67151163 0.70899471 0.88392857 0.8125\n",
      " 0.80059524 0.82440476 0.76190476 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 817\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 145, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=145,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.79651163 0.66569767 0.73015873 0.8452381  0.83630952\n",
      " 0.72321429 0.68154762 0.7202381  0.68452381]\n",
      "----------------------------------------\n",
      "Trial 818\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 35, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=35,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9127907  0.8372093  0.7122093  0.82804233 0.88988095 0.92261905\n",
      " 0.81547619 0.8422619  0.8422619  0.70535714]\n",
      "----------------------------------------\n",
      "Trial 819\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 122, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=122,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90697674 0.80232558 0.68604651 0.75132275 0.86607143 0.86309524\n",
      " 0.8452381  0.85714286 0.77678571 0.6860119 ]\n",
      "----------------------------------------\n",
      "Trial 820\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 22, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=22,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.83139535 0.76453488 0.81746032 0.87797619 0.92857143\n",
      " 0.72916667 0.86904762 0.82142857 0.72321429]\n",
      "----------------------------------------\n",
      "Trial 821\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 19, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=19,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88081395 0.7369186  0.72965116 0.67592593 0.91964286 0.91369048\n",
      " 0.75595238 0.82440476 0.80059524 0.69791667]\n",
      "----------------------------------------\n",
      "Trial 822\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            random_state=100, subsample=0.7))])\n",
      "cv score: [0.90116279 0.78488372 0.67151163 0.70634921 0.88690476 0.8422619\n",
      " 0.82440476 0.73214286 0.7797619  0.59821429]\n",
      "----------------------------------------\n",
      "Trial 823\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 121, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=121, random_state=100))])\n",
      "cv score: [0.93023256 0.76453488 0.65406977 0.74867725 0.86607143 0.8422619\n",
      " 0.85119048 0.75       0.8125     0.56845238]\n",
      "----------------------------------------\n",
      "Trial 824\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 70, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=70,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.89825581 0.74709302 0.68895349 0.6957672  0.89583333 0.83630952\n",
      " 0.82440476 0.82142857 0.79464286 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 825\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 50, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=50, random_state=100,\n",
      "                                            subsample=0.65))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.87209302 0.72383721 0.75872093 0.74867725 0.87202381 0.85416667\n",
      " 0.75892857 0.67261905 0.61011905 0.58035714]\n",
      "----------------------------------------\n",
      "Trial 826\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 53, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=53,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.77616279 0.68604651 0.79100529 0.9047619  0.9375\n",
      " 0.79910714 0.88392857 0.76934524 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 827\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=183, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.5872093  0.56540698 0.60755814 0.66931217 0.62053571 0.55059524\n",
      " 0.65029762 0.67559524 0.60416667 0.5297619 ]\n",
      "----------------------------------------\n",
      "Trial 828\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 37, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=37,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.77906977 0.68895349 0.78306878 0.83630952 0.89583333\n",
      " 0.78869048 0.85119048 0.78869048 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 829\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=101, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.63953488 0.57267442 0.56686047 0.71693122 0.8452381  0.77380952\n",
      " 0.78869048 0.64880952 0.7172619  0.57440476]\n",
      "----------------------------------------\n",
      "Trial 830\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 76, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=76,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.80523256 0.70784884 0.80952381 0.9047619  0.92857143\n",
      " 0.78869048 0.86309524 0.80357143 0.68005952]\n",
      "----------------------------------------\n",
      "Trial 831\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 67, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=67,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.88372093 0.79360465 0.76453488 0.77248677 0.91071429 0.88988095\n",
      " 0.79166667 0.80357143 0.75297619 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 832\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 180, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=180, random_state=100))])\n",
      "cv score: [0.88662791 0.77616279 0.65988372 0.76190476 0.85714286 0.86607143\n",
      " 0.85119048 0.81547619 0.75       0.625     ]\n",
      "----------------------------------------\n",
      "Trial 833\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 165, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='sqrt',\n",
      "                                            n_estimators=165, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.89244186 0.76453488 0.75290698 0.76984127 0.88690476 0.83928571\n",
      " 0.74404762 0.78571429 0.77678571 0.51190476]\n",
      "----------------------------------------\n",
      "Trial 834\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 12, 'gb__subsample': 0.85, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, max_features='sqrt',\n",
      "                                            n_estimators=12, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.89825581 0.74127907 0.66860465 0.64285714 0.86309524 0.81547619\n",
      " 0.72916667 0.67261905 0.74404762 0.50297619]\n",
      "----------------------------------------\n",
      "Trial 835\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 16, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=16, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.80523256 0.73837209 0.77034884 0.73544974 0.86904762 0.83333333\n",
      " 0.80654762 0.76785714 0.82738095 0.54761905]\n",
      "----------------------------------------\n",
      "Trial 836\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 176, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=176,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90697674 0.76162791 0.70930233 0.71428571 0.91369048 0.88988095\n",
      " 0.74107143 0.85416667 0.74404762 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 837\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 72, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=72,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77180233 0.72819767 0.6380814  0.7010582  0.75595238 0.5952381\n",
      " 0.76636905 0.73065476 0.65625    0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 838\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=81,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.82267442 0.70348837 0.62936047 0.73809524 0.82440476 0.63392857\n",
      " 0.80952381 0.80059524 0.72619048 0.63690476]\n",
      "----------------------------------------\n",
      "Trial 839\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 56, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=56, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.88081395 0.74127907 0.6744186  0.73015873 0.84821429 0.86904762\n",
      " 0.86904762 0.82738095 0.74404762 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 840\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.76744186 0.73255814 0.62790698 0.46825397 0.89583333 0.81547619\n",
      " 0.8452381  0.65178571 0.76190476 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 841\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=102,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84593023 0.75290698 0.66860465 0.71428571 0.86309524 0.79761905\n",
      " 0.79761905 0.8422619  0.73809524 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 842\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 156, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, n_estimators=156,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.93313953 0.77616279 0.76744186 0.72751323 0.83630952 0.87797619\n",
      " 0.82142857 0.79166667 0.80952381 0.65178571]\n",
      "----------------------------------------\n",
      "Trial 843\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.81395349 0.69622093 0.73015873 0.88988095 0.91071429\n",
      " 0.83333333 0.88095238 0.81547619 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 844\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 117, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=117, random_state=100))])\n",
      "cv score: [0.87209302 0.80232558 0.625      0.78306878 0.86011905 0.86011905\n",
      " 0.83035714 0.77380952 0.73809524 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 845\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.87790698 0.7994186  0.68604651 0.73809524 0.93154762 0.87202381\n",
      " 0.77678571 0.82440476 0.76190476 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 846\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 77, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=77,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86627907 0.74418605 0.69476744 0.71164021 0.85416667 0.82142857\n",
      " 0.79166667 0.83333333 0.75892857 0.5922619 ]\n",
      "----------------------------------------\n",
      "Trial 847\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 89, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            n_estimators=89,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.79796512 0.71802326 0.56831395 0.81878307 0.73511905 0.83928571\n",
      " 0.69940476 0.70684524 0.54761905 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 848\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91569767 0.83139535 0.70494186 0.76455026 0.88988095 0.91666667\n",
      " 0.83035714 0.88095238 0.82440476 0.67113095]\n",
      "----------------------------------------\n",
      "Trial 849\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 142, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=142, random_state=100))])\n",
      "cv score: [0.84593023 0.74127907 0.63372093 0.72222222 0.875      0.83630952\n",
      " 0.85714286 0.79464286 0.75       0.58035714]\n",
      "----------------------------------------\n",
      "Trial 850\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 88, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=88,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.84011628 0.73255814 0.64244186 0.7010582  0.89880952 0.875\n",
      " 0.7827381  0.7172619  0.76785714 0.55059524]\n",
      "----------------------------------------\n",
      "Trial 851\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 177, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=177,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86337209 0.76744186 0.6627907  0.71428571 0.87797619 0.80952381\n",
      " 0.80654762 0.8452381  0.75       0.62202381]\n",
      "----------------------------------------\n",
      "Trial 852\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 173, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=173, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.90988372 0.75290698 0.7122093  0.71693122 0.87797619 0.85119048\n",
      " 0.8452381  0.81547619 0.76488095 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 853\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 21, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=21,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84302326 0.71802326 0.60465116 0.78835979 0.76041667 0.84672619\n",
      " 0.69494048 0.69196429 0.67708333 0.75297619]\n",
      "----------------------------------------\n",
      "Trial 854\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 121, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=121,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.80668605 0.72674419 0.67296512 0.66137566 0.78571429 0.65327381\n",
      " 0.79464286 0.77678571 0.65327381 0.70535714]\n",
      "----------------------------------------\n",
      "Trial 855\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 179, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=179,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84447674 0.72383721 0.64534884 0.8042328  0.81696429 0.84375\n",
      " 0.72321429 0.78571429 0.73363095 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 856\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 172, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=172, random_state=100))])\n",
      "cv score: [0.93604651 0.78488372 0.70639535 0.75661376 0.90178571 0.86011905\n",
      " 0.80059524 0.85119048 0.80059524 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 857\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 198, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            n_estimators=198, random_state=100,\n",
      "                                            subsample=0.75))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.78488372 0.77034884 0.61046512 0.73809524 0.81845238 0.8452381\n",
      " 0.80952381 0.8125     0.80357143 0.58035714]\n",
      "----------------------------------------\n",
      "Trial 858\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 170, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=170,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.89534884 0.78197674 0.68895349 0.74338624 0.91071429 0.89583333\n",
      " 0.76785714 0.78869048 0.76190476 0.65178571]\n",
      "----------------------------------------\n",
      "Trial 859\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 25, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=25,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.90988372 0.80523256 0.68604651 0.64021164 0.90178571 0.81845238\n",
      " 0.83630952 0.70833333 0.75892857 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 860\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 47, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=11,\n",
      "                                            n_estimators=47, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.95639535 0.58430233 0.67151163 0.7037037  0.57738095 0.73214286\n",
      " 0.62797619 0.5297619  0.85714286 0.38392857]\n",
      "----------------------------------------\n",
      "Trial 861\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 71, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=71,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.84156977 0.73837209 0.67877907 0.8015873  0.85565476 0.85565476\n",
      " 0.6875     0.70833333 0.72172619 0.73809524]\n",
      "----------------------------------------\n",
      "Trial 862\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 150, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=150,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81686047 0.78488372 0.78042328 0.9375     0.92261905\n",
      " 0.80357143 0.85416667 0.76488095 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 863\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.86627907 0.75290698 0.73546512 0.74603175 0.87202381 0.87797619\n",
      " 0.75892857 0.81845238 0.72321429 0.54166667]\n",
      "----------------------------------------\n",
      "Trial 864\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 56, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=56,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.87790698 0.7122093  0.69476744 0.68253968 0.86904762 0.83928571\n",
      " 0.77678571 0.76785714 0.75892857 0.68154762]\n",
      "----------------------------------------\n",
      "Trial 865\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 111, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=111,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91860465 0.8372093  0.73110465 0.82804233 0.89583333 0.9077381\n",
      " 0.80654762 0.88690476 0.79761905 0.69196429]\n",
      "----------------------------------------\n",
      "Trial 866\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 47, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, n_estimators=47,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.92732558 0.80523256 0.73546512 0.74338624 0.88988095 0.85119048\n",
      " 0.80654762 0.85119048 0.79166667 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 867\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 193, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=193, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.91860465 0.78488372 0.72674419 0.75132275 0.87797619 0.81547619\n",
      " 0.77678571 0.79166667 0.78571429 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 868\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=115, random_state=100))])\n",
      "cv score: [0.9244186  0.76744186 0.65406977 0.74603175 0.86309524 0.8452381\n",
      " 0.8422619  0.75       0.80059524 0.56547619]\n",
      "----------------------------------------\n",
      "Trial 869\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.83139535 0.74127907 0.74074074 0.91071429 0.91964286\n",
      " 0.76190476 0.85714286 0.78571429 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 870\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 181, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=181,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86337209 0.77034884 0.6627907  0.71428571 0.875      0.80952381\n",
      " 0.80357143 0.8422619  0.75       0.62202381]\n",
      "----------------------------------------\n",
      "Trial 871\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 80, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, n_estimators=80,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.84011628 0.77325581 0.69476744 0.74867725 0.83035714 0.85714286\n",
      " 0.56547619 0.75892857 0.62202381 0.55059524]\n",
      "----------------------------------------\n",
      "Trial 872\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 33, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=33,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.81686047 0.75581395 0.81481481 0.89285714 0.92261905\n",
      " 0.78571429 0.86904762 0.75595238 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 873\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.95348837 0.83139535 0.64534884 0.65343915 0.85714286 0.89880952\n",
      " 0.75       0.88095238 0.80952381 0.55357143]\n",
      "----------------------------------------\n",
      "Trial 874\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 86, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=86, random_state=100))])\n",
      "cv score: [0.93895349 0.79069767 0.69767442 0.74338624 0.89583333 0.8452381\n",
      " 0.79761905 0.86011905 0.80654762 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 875\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 151, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=151,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90697674 0.79069767 0.65988372 0.73015873 0.85416667 0.92857143\n",
      " 0.75595238 0.79761905 0.79166667 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 876\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 136, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=136,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.9127907  0.80813953 0.72383721 0.76719577 0.94345238 0.92857143\n",
      " 0.75595238 0.7827381  0.7202381  0.63988095]\n",
      "----------------------------------------\n",
      "Trial 877\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 84, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=84,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74273256 0.73837209 0.69912791 0.62566138 0.7827381  0.61309524\n",
      " 0.73660714 0.73065476 0.66815476 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 878\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 43, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=43,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.89534884 0.74709302 0.69767442 0.71428571 0.9047619  0.89285714\n",
      " 0.86607143 0.80059524 0.77380952 0.52678571]\n",
      "----------------------------------------\n",
      "Trial 879\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 12, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=12, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.83430233 0.71802326 0.61046512 0.50793651 0.80654762 0.83630952\n",
      " 0.83928571 0.61607143 0.78869048 0.70833333]\n",
      "----------------------------------------\n",
      "Trial 880\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 167, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            n_estimators=167, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.91569767 0.77034884 0.64825581 0.79100529 0.8452381  0.91369048\n",
      " 0.70535714 0.68154762 0.80654762 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 881\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 126, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=126,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.81104651 0.74127907 0.75396825 0.9077381  0.92857143\n",
      " 0.8125     0.8452381  0.79464286 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 882\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94476744 0.85174419 0.73837209 0.78571429 0.9047619  0.92559524\n",
      " 0.82440476 0.89583333 0.8125     0.72916667]\n",
      "----------------------------------------\n",
      "Trial 883\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=51, random_state=100))])\n",
      "cv score: [0.89825581 0.6744186  0.68023256 0.77513228 0.8452381  0.83333333\n",
      " 0.79166667 0.83333333 0.79761905 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 884\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 89, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=89, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.87209302 0.74709302 0.65697674 0.74338624 0.875      0.80654762\n",
      " 0.7827381  0.8125     0.69940476 0.58630952]\n",
      "----------------------------------------\n",
      "Trial 885\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, n_estimators=105,\n",
      "                                            random_state=100, subsample=0.9))])\n",
      "cv score: [0.90988372 0.7877907  0.81686047 0.73809524 0.87202381 0.87797619\n",
      " 0.70833333 0.80654762 0.80357143 0.54166667]\n",
      "----------------------------------------\n",
      "Trial 886\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 33, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=33,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93168605 0.81395349 0.70203488 0.76719577 0.88392857 0.85714286\n",
      " 0.8422619  0.90178571 0.7797619  0.6860119 ]\n",
      "----------------------------------------\n",
      "Trial 887\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 17, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            n_estimators=17, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.82848837 0.77034884 0.7369186  0.78835979 0.85416667 0.89583333\n",
      " 0.81994048 0.81547619 0.81845238 0.74404762]\n",
      "----------------------------------------\n",
      "Trial 888\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=159,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.87209302 0.75       0.6744186  0.71428571 0.88095238 0.80952381\n",
      " 0.80059524 0.83035714 0.75892857 0.61011905]\n",
      "----------------------------------------\n",
      "Trial 889\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 191, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=191,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91569767 0.84011628 0.72093023 0.84920635 0.89880952 0.91964286\n",
      " 0.85119048 0.87202381 0.80059524 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 890\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 99, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=99,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.77325581 0.69331395 0.61482558 0.70634921 0.74702381 0.57738095\n",
      " 0.7514881  0.71875    0.66964286 0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 891\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 180, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=2, max_features='sqrt',\n",
      "                                            n_estimators=180, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.9244186  0.83139535 0.67732558 0.79365079 0.82738095 0.80059524\n",
      " 0.74107143 0.82738095 0.79761905 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 892\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 105, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=105, random_state=100))])\n",
      "cv score: [0.87209302 0.75581395 0.63372093 0.74074074 0.86904762 0.87202381\n",
      " 0.85416667 0.79464286 0.78571429 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 893\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 140, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=140,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88953488 0.73837209 0.75290698 0.6984127  0.89136905 0.89583333\n",
      " 0.86309524 0.81547619 0.77678571 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 894\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92151163 0.81686047 0.70494186 0.81216931 0.88988095 0.91964286\n",
      " 0.80952381 0.88095238 0.80059524 0.70535714]\n",
      "----------------------------------------\n",
      "Trial 895\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 44, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=44, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.86918605 0.79069767 0.63081395 0.62962963 0.875      0.86309524\n",
      " 0.76488095 0.64880952 0.80357143 0.55357143]\n",
      "----------------------------------------\n",
      "Trial 896\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 87, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=87,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93895349 0.80523256 0.75581395 0.76719577 0.89285714 0.91071429\n",
      " 0.75       0.9047619  0.80654762 0.6547619 ]\n",
      "----------------------------------------\n",
      "Trial 897\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 119, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=119,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.87209302 0.72965116 0.70639535 0.71428571 0.86904762 0.87797619\n",
      " 0.80654762 0.78571429 0.75297619 0.66964286]\n",
      "----------------------------------------\n",
      "Trial 898\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 110, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            n_estimators=110, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.9127907  0.77906977 0.77325581 0.78571429 0.83630952 0.89880952\n",
      " 0.82142857 0.83928571 0.77678571 0.74702381]\n",
      "----------------------------------------\n",
      "Trial 899\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=171, random_state=100))])\n",
      "cv score: [0.875      0.77906977 0.6744186  0.75661376 0.89285714 0.88095238\n",
      " 0.85714286 0.80208333 0.8125     0.625     ]\n",
      "----------------------------------------\n",
      "Trial 900\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 178, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=178,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.93023256 0.77906977 0.74127907 0.72751323 0.88392857 0.8422619\n",
      " 0.82142857 0.80059524 0.79761905 0.6547619 ]\n",
      "----------------------------------------\n",
      "Trial 901\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 39, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=39,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.78343023 0.77180233 0.59883721 0.68783069 0.77380952 0.5952381\n",
      " 0.76190476 0.73958333 0.65029762 0.625     ]\n",
      "----------------------------------------\n",
      "Trial 902\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 127, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=127, random_state=100))])\n",
      "cv score: [0.88081395 0.7994186  0.63081395 0.78835979 0.86011905 0.85416667\n",
      " 0.82142857 0.77380952 0.73511905 0.61011905]\n",
      "----------------------------------------\n",
      "Trial 903\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 103, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=103,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.88372093 0.75872093 0.76162791 0.70899471 0.91369048 0.8422619\n",
      " 0.8422619  0.82440476 0.7797619  0.6547619 ]\n",
      "----------------------------------------\n",
      "Trial 904\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.82267442 0.76453488 0.75132275 0.9047619  0.92857143\n",
      " 0.78571429 0.86309524 0.77083333 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 905\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 59, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=9,\n",
      "                                            n_estimators=59, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.91860465 0.78488372 0.70639535 0.80687831 0.875      0.9047619\n",
      " 0.82738095 0.83630952 0.79761905 0.73809524]\n",
      "----------------------------------------\n",
      "Trial 906\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 104, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=104,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90697674 0.82848837 0.70930233 0.72222222 0.92559524 0.9077381\n",
      " 0.79166667 0.80059524 0.74107143 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 907\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 160, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=160, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.7994186  0.67732558 0.55523256 0.48015873 0.70238095 0.91964286\n",
      " 0.30952381 0.60416667 0.67857143 0.48511905]\n",
      "----------------------------------------\n",
      "Trial 908\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 33, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=33, random_state=100))])\n",
      "cv score: [0.87645349 0.7630814  0.73982558 0.6957672  0.82440476 0.61011905\n",
      " 0.73214286 0.78125    0.67410714 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 909\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=14, random_state=100))])\n",
      "cv score: [0.86337209 0.78197674 0.60174419 0.6957672  0.83630952 0.79166667\n",
      " 0.83035714 0.82440476 0.85119048 0.57440476]\n",
      "----------------------------------------\n",
      "Trial 910\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 159, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=159,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.80523256 0.72383721 0.74867725 0.91071429 0.91369048\n",
      " 0.80059524 0.86011905 0.77083333 0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 911\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 105, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=105,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.79360465 0.71656977 0.82010582 0.90178571 0.94345238\n",
      " 0.80654762 0.88392857 0.77083333 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 912\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 133, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=133, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.93313953 0.7877907  0.69767442 0.79365079 0.83630952 0.81845238\n",
      " 0.75595238 0.8422619  0.78869048 0.55952381]\n",
      "----------------------------------------\n",
      "Trial 913\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 187, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=187,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.81686047 0.7252907  0.81216931 0.90178571 0.93452381\n",
      " 0.83630952 0.9047619  0.79166667 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 914\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 157, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=157, random_state=100))])\n",
      "cv score: [0.86918605 0.76744186 0.65988372 0.74867725 0.85714286 0.82738095\n",
      " 0.82440476 0.81845238 0.72916667 0.58035714]\n",
      "----------------------------------------\n",
      "Trial 915\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 22, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=22, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.625      0.70348837 0.53633721 0.72751323 0.80952381 0.79464286\n",
      " 0.72321429 0.71428571 0.77380952 0.45535714]\n",
      "----------------------------------------\n",
      "Trial 916\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 42, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=42,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.83139535 0.72093023 0.54796512 0.78835979 0.76934524 0.83035714\n",
      " 0.69940476 0.69047619 0.68154762 0.65327381]\n",
      "----------------------------------------\n",
      "Trial 917\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 70, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=70, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.9127907  0.77034884 0.71802326 0.63227513 0.9047619  0.89880952\n",
      " 0.72321429 0.68154762 0.75892857 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 918\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=91,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.8372093  0.68895349 0.63081395 0.73544974 0.82440476 0.63392857\n",
      " 0.81845238 0.83333333 0.70238095 0.63690476]\n",
      "----------------------------------------\n",
      "Trial 919\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 32, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=32,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94476744 0.82848837 0.72093023 0.80687831 0.875      0.91071429\n",
      " 0.85714286 0.86904762 0.8125     0.69642857]\n",
      "----------------------------------------\n",
      "Trial 920\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 103, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=103,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6744186  0.69186047 0.49273256 0.55820106 0.68154762 0.48809524\n",
      " 0.52678571 0.60267857 0.51785714 0.44047619]\n",
      "----------------------------------------\n",
      "Trial 921\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 46, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=46,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.80813953 0.73837209 0.81746032 0.9047619  0.92261905\n",
      " 0.83333333 0.88988095 0.78869048 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 922\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 171, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=171,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.875      0.82267442 0.73837209 0.71693122 0.89285714 0.90178571\n",
      " 0.74702381 0.80654762 0.72916667 0.65178571]\n",
      "----------------------------------------\n",
      "Trial 923\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.80523256 0.76162791 0.83597884 0.90178571 0.93154762\n",
      " 0.81547619 0.89583333 0.76190476 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 924\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 60, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=60, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.90116279 0.76744186 0.64244186 0.65608466 0.91666667 0.86607143\n",
      " 0.86011905 0.8125     0.77083333 0.62797619]\n",
      "----------------------------------------\n",
      "Trial 925\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=168,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.89534884 0.73546512 0.75290698 0.67460317 0.9047619  0.87202381\n",
      " 0.86607143 0.7827381  0.76190476 0.56547619]\n",
      "----------------------------------------\n",
      "Trial 926\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 150, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=150,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.92732558 0.8255814  0.76453488 0.76984127 0.91964286 0.91666667\n",
      " 0.77678571 0.85714286 0.80059524 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 927\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.95, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, n_estimators=105,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.93313953 0.79360465 0.76453488 0.75396825 0.86904762 0.89880952\n",
      " 0.8452381  0.8452381  0.79464286 0.73214286]\n",
      "----------------------------------------\n",
      "Trial 928\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 75, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=75,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.86918605 0.74127907 0.53343023 0.71164021 0.83779762 0.81547619\n",
      " 0.78571429 0.8110119  0.79464286 0.54315476]\n",
      "----------------------------------------\n",
      "Trial 929\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 59, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=59,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.84593023 0.72674419 0.72486772 0.88988095 0.89583333\n",
      " 0.77380952 0.83779762 0.8422619  0.67857143]\n",
      "----------------------------------------\n",
      "Trial 930\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 107, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            n_estimators=107, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.85174419 0.77325581 0.68604651 0.63492063 0.88392857 0.9047619\n",
      " 0.76190476 0.68452381 0.77083333 0.5327381 ]\n",
      "----------------------------------------\n",
      "Trial 931\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 176, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=176,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86627907 0.72965116 0.70930233 0.6957672  0.88392857 0.86904762\n",
      " 0.80952381 0.8125     0.76488095 0.66369048]\n",
      "----------------------------------------\n",
      "Trial 932\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 24, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=24, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.8255814  0.74709302 0.63372093 0.69047619 0.83333333 0.83333333\n",
      " 0.81845238 0.66071429 0.80952381 0.6547619 ]\n",
      "----------------------------------------\n",
      "Trial 933\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 65, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=65, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.88081395 0.76453488 0.67151163 0.72222222 0.89583333 0.85416667\n",
      " 0.79166667 0.86904762 0.80059524 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 934\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 155, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=155,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73401163 0.80377907 0.63662791 0.62433862 0.76934524 0.60565476\n",
      " 0.82738095 0.80208333 0.65178571 0.6889881 ]\n",
      "----------------------------------------\n",
      "Trial 935\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 28, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=28,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93895349 0.75290698 0.7005814  0.74867725 0.86904762 0.88988095\n",
      " 0.75595238 0.83333333 0.76190476 0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 936\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 190, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=190,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9622093  0.79360465 0.7005814  0.52645503 0.92559524 0.90178571\n",
      " 0.64583333 0.8452381  0.74107143 0.53869048]\n",
      "----------------------------------------\n",
      "Trial 937\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 46, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=46,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.72674419 0.69186047 0.7962963  0.79761905 0.875\n",
      " 0.70535714 0.83928571 0.6875     0.69940476]\n",
      "----------------------------------------\n",
      "Trial 938\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 63, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=63, random_state=100))])\n",
      "cv score: [0.83139535 0.75872093 0.67005814 0.71957672 0.81845238 0.68154762\n",
      " 0.69047619 0.83333333 0.67559524 0.60416667]\n",
      "----------------------------------------\n",
      "Trial 939\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 65, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=65,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.90406977 0.81976744 0.74563953 0.84391534 0.88690476 0.89583333\n",
      " 0.82589286 0.87053571 0.7827381  0.70386905]\n",
      "----------------------------------------\n",
      "Trial 940\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.82267442 0.70494186 0.75925926 0.88988095 0.92559524\n",
      " 0.83928571 0.89880952 0.81547619 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 941\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 144, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=144, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.79651163 0.74127907 0.72093023 0.64814815 0.7202381  0.78869048\n",
      " 0.70535714 0.625      0.67559524 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 942\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 67, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=67, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.77906977 0.73546512 0.64244186 0.8968254  0.70238095 0.92261905\n",
      " 0.63988095 0.83928571 0.75297619 0.52678571]\n",
      "----------------------------------------\n",
      "Trial 943\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 23, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=23, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.84156977 0.77906977 0.73546512 0.7010582  0.90178571 0.77678571\n",
      " 0.73809524 0.77083333 0.69642857 0.63392857]\n",
      "----------------------------------------\n",
      "Trial 944\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 19, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=19,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88226744 0.7877907  0.6497093  0.73015873 0.78869048 0.80059524\n",
      " 0.75892857 0.74404762 0.71428571 0.63690476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Trial 945\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 145, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=145,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.83139535 0.75       0.67151163 0.75396825 0.91369048 0.86607143\n",
      " 0.76488095 0.83928571 0.74404762 0.57142857]\n",
      "----------------------------------------\n",
      "Trial 946\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 19, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=19,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.81395349 0.75581395 0.68895349 0.74603175 0.80952381 0.85119048\n",
      " 0.76190476 0.7172619  0.73511905 0.37202381]\n",
      "----------------------------------------\n",
      "Trial 947\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 182, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            n_estimators=182, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.9127907  0.75581395 0.80523256 0.79100529 0.89285714 0.91071429\n",
      " 0.82440476 0.84821429 0.79166667 0.69047619]\n",
      "----------------------------------------\n",
      "Trial 948\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 95, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=95,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.92732558 0.80813953 0.71511628 0.82010582 0.87797619 0.91071429\n",
      " 0.85119048 0.91666667 0.78869048 0.68452381]\n",
      "----------------------------------------\n",
      "Trial 949\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=51, random_state=100))])\n",
      "cv score: [0.90697674 0.7877907  0.63372093 0.71164021 0.83630952 0.72321429\n",
      " 0.73809524 0.82440476 0.71130952 0.5952381 ]\n",
      "----------------------------------------\n",
      "Trial 950\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 184, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=184,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.94767442 0.79069767 0.69767442 0.64021164 0.91369048 0.89285714\n",
      " 0.67261905 0.8422619  0.72619048 0.52380952]\n",
      "----------------------------------------\n",
      "Trial 951\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 83, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=83, random_state=100))])\n",
      "cv score: [0.93313953 0.79360465 0.72383721 0.79365079 0.88690476 0.87202381\n",
      " 0.80357143 0.87797619 0.83630952 0.69345238]\n",
      "----------------------------------------\n",
      "Trial 952\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 26, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=26, random_state=100))])\n",
      "cv score: [0.92732558 0.73546512 0.71656977 0.76455026 0.85119048 0.91666667\n",
      " 0.83333333 0.8422619  0.81994048 0.71279762]\n",
      "----------------------------------------\n",
      "Trial 953\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 148, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=148,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91860465 0.7877907  0.75581395 0.77248677 0.87797619 0.88988095\n",
      " 0.79761905 0.83928571 0.80357143 0.64583333]\n",
      "----------------------------------------\n",
      "Trial 954\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 139, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=139, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.88953488 0.80813953 0.64534884 0.73544974 0.85714286 0.88988095\n",
      " 0.8422619  0.8125     0.79464286 0.62202381]\n",
      "----------------------------------------\n",
      "Trial 955\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 100, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88953488 0.80813953 0.63953488 0.73809524 0.85714286 0.89285714\n",
      " 0.8452381  0.80059524 0.7827381  0.63095238]\n",
      "----------------------------------------\n",
      "Trial 956\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 177, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=177, random_state=100))])\n",
      "cv score: [0.92587209 0.7877907  0.71802326 0.81481481 0.85714286 0.90178571\n",
      " 0.85714286 0.86011905 0.7797619  0.70982143]\n",
      "----------------------------------------\n",
      "Trial 957\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 73, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=73,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9375     0.80813953 0.65261628 0.78042328 0.88392857 0.9077381\n",
      " 0.79166667 0.8735119  0.80654762 0.69642857]\n",
      "----------------------------------------\n",
      "Trial 958\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 18, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=18, random_state=100))])\n",
      "cv score: [0.94476744 0.76453488 0.5377907  0.68650794 0.78869048 0.79910714\n",
      " 0.8125     0.77380952 0.82291667 0.47172619]\n",
      "----------------------------------------\n",
      "Trial 959\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.9244186  0.81976744 0.69912791 0.75925926 0.89880952 0.91071429\n",
      " 0.84821429 0.875      0.8125     0.6875    ]\n",
      "----------------------------------------\n",
      "Trial 960\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 33, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=33,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.91569767 0.72383721 0.75290698 0.66666667 0.86755952 0.89583333\n",
      " 0.8422619  0.80357143 0.72619048 0.67857143]\n",
      "----------------------------------------\n",
      "Trial 961\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 127, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=127, random_state=100))])\n",
      "cv score: [0.88953488 0.78197674 0.63662791 0.70634921 0.88095238 0.86011905\n",
      " 0.85119048 0.8422619  0.7827381  0.61607143]\n",
      "----------------------------------------\n",
      "Trial 962\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 197, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, max_features='log2',\n",
      "                                            n_estimators=197,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.87209302 0.75581395 0.70348837 0.66402116 0.91964286 0.88392857\n",
      " 0.80654762 0.78869048 0.76488095 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 963\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 143, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt', n_estimators=143,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.89534884 0.75581395 0.75581395 0.6984127  0.88541667 0.89285714\n",
      " 0.86309524 0.81547619 0.7797619  0.62797619]\n",
      "----------------------------------------\n",
      "Trial 964\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, max_features='log2',\n",
      "                                            n_estimators=90,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.88953488 0.73837209 0.73546512 0.67724868 0.92261905 0.88095238\n",
      " 0.79761905 0.77380952 0.67559524 0.55654762]\n",
      "----------------------------------------\n",
      "Trial 965\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 68, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=68, random_state=100))])\n",
      "cv score: [0.90406977 0.76598837 0.63662791 0.73015873 0.86011905 0.86904762\n",
      " 0.83928571 0.79910714 0.7797619  0.63095238]\n",
      "----------------------------------------\n",
      "Trial 966\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 174, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=6,\n",
      "                                            n_estimators=174, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93604651 0.80523256 0.80232558 0.73544974 0.91666667 0.9077381\n",
      " 0.83928571 0.81547619 0.80952381 0.70238095]\n",
      "----------------------------------------\n",
      "Trial 967\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 52, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=52,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68895349 0.78343023 0.65406977 0.68518519 0.76785714 0.625\n",
      " 0.75297619 0.77827381 0.61755952 0.67261905]\n",
      "----------------------------------------\n",
      "Trial 968\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 198, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=198,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93023256 0.83139535 0.73255814 0.83068783 0.91071429 0.92261905\n",
      " 0.83333333 0.86607143 0.81547619 0.69940476]\n",
      "----------------------------------------\n",
      "Trial 969\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=105,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.92732558 0.78488372 0.77616279 0.67724868 0.91964286 0.8422619\n",
      " 0.80357143 0.75595238 0.81547619 0.64583333]\n",
      "----------------------------------------\n",
      "Trial 970\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 173, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=173,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93895349 0.80232558 0.72965116 0.74338624 0.91071429 0.9077381\n",
      " 0.77678571 0.81547619 0.79166667 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 971\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 111, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=9,\n",
      "                                            n_estimators=111, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.92151163 0.76744186 0.71511628 0.84126984 0.86607143 0.91071429\n",
      " 0.8452381  0.8452381  0.78869048 0.70833333]\n",
      "----------------------------------------\n",
      "Trial 972\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 185, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=185, random_state=100))])\n",
      "cv score: [0.86046512 0.77325581 0.65116279 0.75661376 0.86011905 0.8125\n",
      " 0.82440476 0.83630952 0.72916667 0.60119048]\n",
      "----------------------------------------\n",
      "Trial 973\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 149, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=149,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93604651 0.8255814  0.76162791 0.76719577 0.92261905 0.91369048\n",
      " 0.80952381 0.88690476 0.75892857 0.65178571]\n",
      "----------------------------------------\n",
      "Trial 974\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=14,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.89244186 0.76889535 0.69331395 0.69179894 0.88988095 0.88988095\n",
      " 0.8110119  0.81547619 0.73809524 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 975\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=174,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.84302326 0.70639535 0.64825581 0.77910053 0.8139881  0.88392857\n",
      " 0.71279762 0.79910714 0.71130952 0.66220238]\n",
      "----------------------------------------\n",
      "Trial 976\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 188, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=188,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.85901163 0.72383721 0.6380814  0.74603175 0.80357143 0.66666667\n",
      " 0.75892857 0.79761905 0.73511905 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 977\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 37, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=4,\n",
      "                                            n_estimators=37, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.91860465 0.73255814 0.68023256 0.75925926 0.88095238 0.86607143\n",
      " 0.75595238 0.80654762 0.73809524 0.67857143]\n",
      "----------------------------------------\n",
      "Trial 978\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 86, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            n_estimators=86, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.92732558 0.77034884 0.74127907 0.82275132 0.88392857 0.91369048\n",
      " 0.85416667 0.85119048 0.78571429 0.71130952]\n",
      "----------------------------------------\n",
      "Trial 979\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 80, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=10,\n",
      "                                            n_estimators=80, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.89534884 0.72674419 0.77616279 0.82407407 0.85119048 0.9077381\n",
      " 0.74702381 0.82142857 0.76488095 0.73363095]\n",
      "----------------------------------------\n",
      "Trial 980\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 85, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=85, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.9127907  0.76744186 0.64244186 0.76984127 0.79761905 0.79464286\n",
      " 0.75297619 0.83630952 0.73511905 0.52380952]\n",
      "----------------------------------------\n",
      "Trial 981\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 147, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=147, random_state=100))])\n",
      "cv score: [0.85755814 0.76744186 0.64244186 0.73544974 0.81547619 0.69345238\n",
      " 0.76190476 0.81547619 0.73214286 0.61904762]\n",
      "----------------------------------------\n",
      "Trial 982\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 27, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=27, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.74709302 0.68895349 0.67151163 0.69047619 0.87797619 0.81845238\n",
      " 0.75       0.75       0.69642857 0.70535714]\n",
      "----------------------------------------\n",
      "Trial 983\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 144, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=144,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88662791 0.73255814 0.71511628 0.71428571 0.875      0.86607143\n",
      " 0.80654762 0.79166667 0.75892857 0.6577381 ]\n",
      "----------------------------------------\n",
      "Trial 984\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 147, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=147,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.875      0.75       0.68023256 0.70634921 0.87797619 0.80654762\n",
      " 0.78571429 0.82440476 0.75297619 0.61607143]\n",
      "----------------------------------------\n",
      "Trial 985\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 177, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=177, random_state=100))])\n",
      "cv score: [0.88372093 0.7877907  0.64825581 0.73280423 0.88095238 0.86011905\n",
      " 0.85416667 0.8125     0.76785714 0.63988095]\n",
      "----------------------------------------\n",
      "Trial 986\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=58, random_state=100))])\n",
      "cv score: [0.93459302 0.78924419 0.72383721 0.78042328 0.86755952 0.91071429\n",
      " 0.83928571 0.86458333 0.80952381 0.72321429]\n",
      "----------------------------------------\n",
      "Trial 987\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 158, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=158,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.86337209 0.77034884 0.6627907  0.71164021 0.88095238 0.80952381\n",
      " 0.80357143 0.8452381  0.74702381 0.63095238]\n",
      "----------------------------------------\n",
      "Trial 988\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 181, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=181, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.83139535 0.71511628 0.56976744 0.7037037  0.83035714 0.38095238\n",
      " 0.77678571 0.64583333 0.48809524 0.36309524]\n",
      "----------------------------------------\n",
      "Trial 989\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 179, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=179,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.93604651 0.77906977 0.75872093 0.74867725 0.87202381 0.88095238\n",
      " 0.74107143 0.83630952 0.83035714 0.61309524]\n",
      "----------------------------------------\n",
      "Trial 990\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 10, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=10, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.79069767 0.74418605 0.57848837 0.67195767 0.8452381  0.86607143\n",
      " 0.71130952 0.74107143 0.81845238 0.52678571]\n",
      "----------------------------------------\n",
      "Trial 991\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 133, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=133,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.91569767 0.80523256 0.72383721 0.77777778 0.9077381  0.93154762\n",
      " 0.79166667 0.80654762 0.78571429 0.67261905]\n",
      "----------------------------------------\n",
      "Trial 992\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 180, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=180,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.93313953 0.81395349 0.75       0.78835979 0.91369048 0.88690476\n",
      " 0.83928571 0.86011905 0.7797619  0.67261905]\n",
      "----------------------------------------\n",
      "Trial 993\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 155, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=155,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.89825581 0.81395349 0.79360465 0.72751323 0.9047619  0.92559524\n",
      " 0.77083333 0.80357143 0.80952381 0.70833333]\n",
      "----------------------------------------\n",
      "Trial 994\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=168, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.9127907  0.77616279 0.69767442 0.73015873 0.92261905 0.82142857\n",
      " 0.86607143 0.75595238 0.72916667 0.57142857]\n",
      "----------------------------------------\n",
      "Trial 995\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 174, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=174, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.90988372 0.73546512 0.80232558 0.61111111 0.88690476 0.8422619\n",
      " 0.79761905 0.68154762 0.77678571 0.60714286]\n",
      "----------------------------------------\n",
      "Trial 996\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 182, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=182,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.88372093 0.72965116 0.75290698 0.6957672  0.89285714 0.89583333\n",
      " 0.87202381 0.81696429 0.75892857 0.55654762]\n",
      "----------------------------------------\n",
      "Trial 997\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 45, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=45, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.75581395 0.38372093 0.79651163 0.57936508 0.85119048 0.88690476\n",
      " 0.65178571 0.61904762 0.7797619  0.52083333]\n",
      "----------------------------------------\n",
      "Trial 998\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 158, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, max_features='log2',\n",
      "                                            n_estimators=158, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.90116279 0.74418605 0.72965116 0.72486772 0.90178571 0.79761905\n",
      " 0.69642857 0.69047619 0.78869048 0.50297619]\n",
      "----------------------------------------\n",
      "Trial 999\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 113, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=113, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.86046512 0.72965116 0.73546512 0.6984127  0.8125     0.8422619\n",
      " 0.70238095 0.67261905 0.69345238 0.46428571]\n",
      "----------------------------------------\n",
      "Selecting and refitting best classifier\n",
      "----------------------------------------\n",
      "[16:09:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best score: 0.8443490833025716\n",
      "best pipe: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.7,\n",
      "                               max_delta_step=0, max_depth=12,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=155,\n",
      "                               n_jobs=16, num_parallel_tree=1, random_state=100,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               subsample=1.0, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    }
   ],
   "source": [
    "# do the search\n",
    "_,_, best_estimator_drain = mmh.randomized_search_cv(X_drain_rest, y_drain_rest, \n",
    "                                                     search_space, \n",
    "                                                     cv=cv_10,\n",
    "                                                     refit=True,\n",
    "                                                     score='roc_auc',\n",
    "                                                     n_iter=5000, \n",
    "                                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47717588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Performance on the test set\n",
      "Classification accuracy: 1.0\n",
      "AUROC: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Log-loss: 9.992007221626415e-16\n"
     ]
    }
   ],
   "source": [
    "mmh.get_test_scores(X_drain_rest, y_drain_rest, X_drain_test, y_drain_test, best_estimator_drain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdde54bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_drain_test = confusion_matrix(y_drain_test, best_estimator_drain.predict(X_drain_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_drain_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee7c2ee",
   "metadata": {},
   "source": [
    "# _Doubly Robust Learning_: include `drain` as a feature into `model_y`.\n",
    "- In doubly robust estimators of ATEs and CATES, the treatment variable is included in `model_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fddf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full = csdh_doc['recurrence']\n",
    "X_full = csdh_doc.drop(['recurrence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a2e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation set and rest\n",
    "X_rest, X_val, y_rest, y_val = train_test_split(X_full, y_full, \n",
    "                                                test_size=0.20,\n",
    "                                                random_state=random_state,\n",
    "                                                stratify=y_full)\n",
    "\n",
    "# Split rest into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rest, y_rest, \n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=y_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eadd57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores, val_scores = mmh.train_and_validate_classifiers(X_train, \n",
    "                                                                 y_train,\n",
    "                                                                 X_val,\n",
    "                                                                 y_val,\n",
    "                                                                 names,\n",
    "                                                                 classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.print_metrics_table(training_scores, val_scores, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c10c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test, classifiers[5].predict(X_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ab1d9",
   "metadata": {},
   "source": [
    "## `model_y` K-Fold cross validation for hyperparameter tuning and model selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d0e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the search\n",
    "_,_, best_estimator = mmh.randomized_search_cv(X_rest, y_rest, \n",
    "                                               search_space, \n",
    "                                               cv=cv_10,\n",
    "                                               refit=True,\n",
    "                                               score='roc_auc',\n",
    "                                               n_iter=5000, \n",
    "                                               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0595f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.get_test_scores(X_rest, y_rest, X_test, y_test, best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test, best_estimator.predict(X_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_test, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65d987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
