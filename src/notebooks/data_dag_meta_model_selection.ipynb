{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f86429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports to get us started\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Utilities\n",
    "import os \n",
    "import sys\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "random_state = 100 # Ensure reproducible results\n",
    "\n",
    "# DoWhy\n",
    "import pygraphviz\n",
    "from IPython.display import Image, display\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import econml\n",
    "\n",
    "# Generic ML imports\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB\n",
    "from sklearn.linear_model import LassoCV, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, recall_score, f1_score, roc_auc_score, confusion_matrix, plot_roc_curve\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Import custom dowhy helper functions module\n",
    "cwd = Path().resolve()\n",
    "PARENT_DIR = os.path.dirname(cwd)\n",
    "SCRIPT_DIR = os.path.join(PARENT_DIR, 'helpers')\n",
    "sys.path.append(SCRIPT_DIR)\n",
    "import meta_model_helpers as mmh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5436079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O Stuff\n",
    "DATA_FILENAME = \"csdh_final.csv\"\n",
    "DATA_FILEPATH = \"/Users/callum/Uni/GitHubRepos/surviving-the-icu/datasets/drain_data/\" + DATA_FILENAME\n",
    "csdh = pd.read_csv(DATA_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc283df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA DAG features\n",
    "data_features = ['age', 'stroke', 'ihd', 'thickness_sum', 'hospital', 'platelet',\n",
    "                 'antiplatelet', 'metalvalve', 'drain', 'inr', 'recurrence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf00eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical type conversion\n",
    "categorical_features = ['stroke', 'antiplatelet', 'ihd', 'metalvalve', 'membranes', 'optype', 'recurrence',\n",
    "                        'drain', 'hospital', 'bedrest', 'warfarin', 'density', 'membranes', 'burrhole_num',\n",
    "                        'bedrest']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    col = pd.Categorical(csdh[feature])\n",
    "    csdh[feature] = col.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9500a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reduced datasets\n",
    "csdh_data = csdh[data_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c790aedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_model = CausalModel(data=csdh, \n",
    "                         treatment='drain', \n",
    "                         outcome='recurrence', \n",
    "                         graph='../causal_graphs/small_data_dag.dot'.replace(\"\\n\", \" \"))\n",
    "data_model.view_model()\n",
    "display(Image(filename=\"causal_model.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e6227",
   "metadata": {},
   "source": [
    "---\n",
    "## Define set of classifiers to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a12f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Dummy', 'LR', 'Linear SVM', 'RBF SVM', 'GB', 'RF', 'XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e45c9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes exluded due to mixture of variable types\n",
    "classifiers = [\n",
    "    DummyClassifier(strategy='most_frequent'),\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    SVC(kernel=\"linear\", probability=True, random_state=random_state),\n",
    "    SVC(kernel='rbf', probability=True, random_state=random_state),\n",
    "    GradientBoostingClassifier(random_state=random_state),\n",
    "    RandomForestClassifier(random_state=random_state),\n",
    "    XGBClassifier(random_state=random_state),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59332f",
   "metadata": {},
   "source": [
    "# _Double Machine Learning:_ finding `model_y` and `model_t`.\n",
    "- `model_y` models $\\mathbb{E}[Y \\mid X,W]$ where the treatment variable $T$ is omitted from the covariates\n",
    "- `model_t` is the propensity model and involves estimating $P[T=1\\mid X,W]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce793b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rec_full = csdh_data['recurrence']\n",
    "X_rec_full = csdh_data.drop(['drain', 'recurrence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72ab0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation set and rest\n",
    "X_rec_rest, X_rec_val, y_rec_rest, y_rec_val = train_test_split(X_rec_full, y_rec_full, \n",
    "                                                                test_size=0.20,\n",
    "                                                                random_state=random_state,\n",
    "                                                                stratify=y_rec_full)\n",
    "\n",
    "# Split rest into train and test set\n",
    "X_rec_train, X_rec_test, y_rec_train, y_rec_test = train_test_split(X_rec_rest, y_rec_rest, \n",
    "                                                                    test_size=0.20,\n",
    "                                                                    random_state=random_state,\n",
    "                                                                    stratify=y_rec_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f93fb198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:23:04] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "rec_training_scores, rec_val_scores = mmh.train_and_validate_classifiers(X_rec_train, \n",
    "                                                                         y_rec_train,\n",
    "                                                                         X_rec_val,\n",
    "                                                                         y_rec_val,\n",
    "                                                                         names,\n",
    "                                                                         classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebac9be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set: \n",
      "\n",
      "             ----------------Validation-----------------   -----------------Training------------------\n",
      "Method         Acc   AUROC  Recall      F1      LL     Acc   AUROC  Recall      F1      LL\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dummy         0.906    0.500    0.000    0.000   3.245    0.908    0.500    0.000    0.000    3.193\n",
      "LR            0.906    0.500    0.000    0.000   3.245    0.908    0.500    0.000    0.000    3.193\n",
      "Linear SVM    0.906    0.500    0.000    0.000   3.245    0.908    0.500    0.000    0.000    3.193\n",
      "RBF SVM       0.906    0.500    0.000    0.000   3.245    0.908    0.500    0.000    0.000    3.193\n",
      "GB            0.879    0.485    0.000    0.000   4.172    0.960    0.784    0.568    0.725    1.379\n",
      "RF            0.893    0.493    0.000    0.000   3.709    1.000    1.000    1.000    1.000    0.000\n",
      "XGB           0.886    0.521    0.071    0.105   3.941    1.000    1.000    1.000    1.000    0.000\n"
     ]
    }
   ],
   "source": [
    "mmh.print_metrics_table(rec_training_scores, rec_val_scores, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45345753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_rec_test = confusion_matrix(y_rec_test, classifiers[4].predict(X_rec_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_rec_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568f4a69",
   "metadata": {},
   "source": [
    "## `model_y` K-Fold cross validation for hyperparameter tuning and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f51e8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross-validation structure\n",
    "cv_5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "cv_10 = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b578f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classifiers and hyperparameters to search over\n",
    "rf = RandomForestClassifier()\n",
    "params_rf = {\n",
    "    # randomly sample numbers from 10 to 200 estimators\n",
    "    'rf__n_estimators':randint(10, 200),\n",
    "    \n",
    "    ### DONT TUNE THESE DUE TO DATASET SIZE ###\n",
    "    # minimum number of samples required to split an internal node\n",
    "    #'rf__min_samples_split':randint(1, 12),\n",
    "    # minimum number of samples required to split a leaf\n",
    "    #'rf__min_samples_leaf':randint(1, 50),\n",
    "    # The maximum depth of the individual regression estimators.\n",
    "    \n",
    "    'rf__max_depth':randint(2, 15),\n",
    "    # The number of features to consider when looking for the best split\n",
    "    'rf__max_features':['sqrt', 'log2', None],\n",
    "    # random seed\n",
    "    'rf__random_state':[random_state],\n",
    "    # Whether bootstrap samples are used when building trees\n",
    "    'rf__bootstrap':[True, False]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "params_gb = {\n",
    "    # randomly sample numbers from 10 to 200 estimators\n",
    "    'gb__n_estimators':randint(10, 200),\n",
    "    # fraction of samples to be used for fitting individual base learners\n",
    "    'gb__subsample':[0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1],\n",
    "    # learning rate\n",
    "    'gb__learning_rate':[0.001, 0.003, 0.01, 0.03, 0.07, 0.1, 0.3, 0.7, 1.0],\n",
    "        \n",
    "    ### DONT TUNE THESE DUE TO DATASET SIZE ###\n",
    "    # minimum number of samples required to split an internal node\n",
    "    #'gb__min_samples_split':randint(1, 12),\n",
    "    # minimum number of samples required to split a leaf\n",
    "    #'gb__min_samples_leaf':randint(1, 50),\n",
    "    # The maximum depth of the individual regression estimators\n",
    "    \n",
    "    'gb__max_depth':randint(2, 15),\n",
    "    # The number of features to consider when looking for the best split\n",
    "    'gb__max_features':['sqrt', 'log2', None],\n",
    "    # random seed\n",
    "    'gb__random_state':[random_state]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "params_xgb = {\n",
    "    # randomly sample numbers from 10 to 200 estimators\n",
    "    'xgb__n_estimators':randint(10, 200),\n",
    "    # fraction of samples to be used for fitting individual base learners\n",
    "    'xgb__subsample':[0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1],\n",
    "    # learning rate\n",
    "    'xgb__learning_rate':[0.001, 0.003, 0.01, 0.03, 0.07, 0.1, 0.3, 0.7, 1],\n",
    "    # min_split_loss\n",
    "    'xgb__gamma':[0.001, 0.003, 0.01, 0.03, 0.07, 0.1, 0.3],\n",
    " \n",
    "    ### DONT TUNE THESE DUE TO DATASET SIZE ###\n",
    "    # minimum number of samples required to split an internal node\n",
    "    #'gb__min_samples_split':randint(1, 12),\n",
    "    # minimum number of samples required to split a leaf\n",
    "    #'gb__min_samples_leaf':randint(1, 50),\n",
    "    # The maximum depth of the individual regression estimators\n",
    "    \n",
    "    'xgb__max_depth':randint(2, 15),\n",
    "    # analagous to max_features in rf and gb\n",
    "    'xgb__colsample_bytree':[0.6, 0.7, 0.8, 0.9, 1],\n",
    "    # random seed\n",
    "    'xgb__random_state':[random_state],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "536c5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search spaces for random search tuning\n",
    "search_space = [('rf', rf, params_rf), ('gb', gb, params_gb), ('xgb', xgb, params_xgb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6e66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv strategy StratifiedKFold(n_splits=10, random_state=100, shuffle=True)\n",
      "----------------------------------------\n",
      "Trial 0\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 136, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=136,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60727273 0.41666667 0.51234568 0.69444444 0.32716049 0.55246914\n",
      " 0.31481481 0.66296296 0.5037037  0.41481481]\n",
      "----------------------------------------\n",
      "Trial 1\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 160, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=160, random_state=100))])\n",
      "cv score: [0.67272727 0.42283951 0.61111111 0.83950617 0.65740741 0.58333333\n",
      " 0.28888889 0.40740741 0.52592593 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 2\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 61, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, n_estimators=61,\n",
      "                                            random_state=100, subsample=0.6))])\n",
      "cv score: [0.62909091 0.41049383 0.65432099 0.62654321 0.66975309 0.5\n",
      " 0.34814815 0.34444444 0.55925926 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 3\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 135, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=135,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72       0.47839506 0.61728395 0.75925926 0.47839506 0.50308642\n",
      " 0.35925926 0.3962963  0.51851852 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 4\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.61454545 0.44135802 0.63888889 0.59259259 0.65123457 0.54320988\n",
      " 0.52222222 0.45185185 0.37037037 0.31851852]\n",
      "----------------------------------------\n",
      "Trial 5\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 177, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            n_estimators=177, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.62909091 0.58641975 0.66666667 0.78703704 0.62345679 0.58950617\n",
      " 0.38888889 0.45185185 0.37777778 0.38148148]\n",
      "----------------------------------------\n",
      "Trial 6\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 45, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=45, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.68727273 0.58796296 0.57253086 0.63425926 0.63425926 0.46141975\n",
      " 0.47592593 0.36851852 0.50925926 0.50555556]\n",
      "----------------------------------------\n",
      "Trial 7\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 138, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=138, random_state=100))])\n",
      "cv score: [0.62545455 0.40740741 0.64197531 0.80555556 0.68518519 0.55555556\n",
      " 0.36666667 0.44444444 0.49259259 0.54074074]\n",
      "----------------------------------------\n",
      "Trial 8\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 30, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=30,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62727273 0.54320988 0.53858025 0.62191358 0.51697531 0.52006173\n",
      " 0.62962963 0.25740741 0.48148148 0.51296296]\n",
      "----------------------------------------\n",
      "Trial 9\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 130, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=130,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.34567901 0.70679012 0.73148148 0.62654321 0.49074074\n",
      " 0.43333333 0.32962963 0.63333333 0.66296296]\n",
      "----------------------------------------\n",
      "Trial 10\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 86, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=86,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61818182 0.42592593 0.62345679 0.75617284 0.4382716  0.53395062\n",
      " 0.4        0.55925926 0.54074074 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 11\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 139, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            n_estimators=139, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.66545455 0.41049383 0.62191358 0.66666667 0.62654321 0.51234568\n",
      " 0.36296296 0.23518519 0.54814815 0.51666667]\n",
      "----------------------------------------\n",
      "Trial 12\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=171,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66727273 0.5787037  0.63888889 0.55709877 0.61111111 0.54475309\n",
      " 0.52222222 0.16666667 0.32592593 0.53518519]\n",
      "----------------------------------------\n",
      "Trial 13\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=70,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66545455 0.39197531 0.57407407 0.78703704 0.59567901 0.47839506\n",
      " 0.41481481 0.2962963  0.51481481 0.62962963]\n",
      "----------------------------------------\n",
      "Trial 14\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=68, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.61090909 0.2808642  0.57407407 0.7191358  0.65123457 0.47222222\n",
      " 0.44814815 0.46666667 0.48518519 0.3962963 ]\n",
      "----------------------------------------\n",
      "Trial 15\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 148, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=148,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62181818 0.29012346 0.5462963  0.63271605 0.58333333 0.47839506\n",
      " 0.25925926 0.35185185 0.54074074 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 16\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70181818 0.37037037 0.60802469 0.74074074 0.64197531 0.50617284\n",
      " 0.35925926 0.41851852 0.44814815 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 17\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 186, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=186, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.62909091 0.55246914 0.63888889 0.68518519 0.55864198 0.59876543\n",
      " 0.52222222 0.44814815 0.49259259 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 18\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 168, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=168, random_state=100))])\n",
      "cv score: [0.69454545 0.40432099 0.57407407 0.74382716 0.73148148 0.58024691\n",
      " 0.28888889 0.46296296 0.5037037  0.5       ]\n",
      "----------------------------------------\n",
      "Trial 19\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 21, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=8, max_features='sqrt',\n",
      "                                            n_estimators=21,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.63636364 0.44135802 0.74382716 0.56790123 0.62037037 0.44444444\n",
      " 0.38148148 0.41481481 0.53703704 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 20\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 59, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=59, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.32       0.51851852 0.7654321  0.77160494 0.38888889 0.46296296\n",
      " 0.46666667 0.48518519 0.4037037  0.67037037]\n",
      "----------------------------------------\n",
      "Trial 21\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 89, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=89,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60363636 0.5941358  0.49691358 0.68209877 0.45679012 0.54012346\n",
      " 0.58518519 0.37037037 0.63148148 0.63703704]\n",
      "----------------------------------------\n",
      "Trial 22\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 104, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=104, random_state=100))])\n",
      "cv score: [0.62545455 0.40432099 0.63271605 0.84876543 0.63888889 0.58950617\n",
      " 0.39259259 0.37777778 0.47777778 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 23\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 159, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=159,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59090909 0.60648148 0.51697531 0.64197531 0.54166667 0.60185185\n",
      " 0.58703704 0.30185185 0.54074074 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 24\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 52, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=52,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.68       0.55246914 0.5787037  0.61882716 0.55401235 0.52314815\n",
      " 0.49074074 0.32777778 0.57222222 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 25\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 176, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=176,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67272727 0.39506173 0.56481481 0.72839506 0.63888889 0.55864198\n",
      " 0.34074074 0.35185185 0.44814815 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 26\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 89, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=89,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.51851852 0.37962963 0.47222222 0.50925926 0.47685185\n",
      " 0.5        0.46296296 0.47222222 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 27\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 139, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=139,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.5308642  0.49074074 0.7808642  0.37654321 0.48148148\n",
      " 0.37037037 0.4962963  0.3962963  0.35925926]\n",
      "----------------------------------------\n",
      "Trial 28\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 135, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=135, random_state=100))])\n",
      "cv score: [0.67272727 0.43518519 0.59876543 0.82407407 0.67901235 0.55246914\n",
      " 0.38518519 0.35185185 0.58888889 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 29\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 184, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=184, random_state=100))])\n",
      "cv score: [0.67636364 0.37345679 0.63580247 0.86419753 0.71296296 0.57098765\n",
      " 0.41481481 0.41111111 0.5037037  0.48518519]\n",
      "----------------------------------------\n",
      "Trial 30\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 168, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=168,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62545455 0.36419753 0.47530864 0.67592593 0.61419753 0.4537037\n",
      " 0.23703704 0.31111111 0.51481481 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 31\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 196, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            n_estimators=196, random_state=100,\n",
      "                                            subsample=0.65))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.6        0.33024691 0.37962963 0.73148148 0.83641975 0.38580247\n",
      " 0.31851852 0.3037037  0.59259259 0.63703704]\n",
      "----------------------------------------\n",
      "Trial 32\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 128, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            n_estimators=128, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.73090909 0.44135802 0.62654321 0.69444444 0.44753086 0.25\n",
      " 0.26666667 0.2        0.74074074 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 33\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=95,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.67272727 0.41666667 0.7962963  0.7345679  0.78395062 0.38888889\n",
      " 0.48148148 0.51111111 0.5        0.51481481]\n",
      "----------------------------------------\n",
      "Trial 34\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 24, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=24, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.60727273 0.34259259 0.64506173 0.83333333 0.4691358  0.67592593\n",
      " 0.52962963 0.25925926 0.4037037  0.42592593]\n",
      "----------------------------------------\n",
      "Trial 35\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 182, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=182, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.69090909 0.41049383 0.61419753 0.74382716 0.58333333 0.5\n",
      " 0.2037037  0.36666667 0.56666667 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 36\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 156, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=156, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.77818182 0.35802469 0.66049383 0.69753086 0.55555556 0.47222222\n",
      " 0.31481481 0.41851852 0.51851852 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 37\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 28, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=28, random_state=100))])\n",
      "cv score: [0.67636364 0.41358025 0.71296296 0.92283951 0.69753086 0.48765432\n",
      " 0.22592593 0.38888889 0.51481481 0.6       ]\n",
      "----------------------------------------\n",
      "Trial 38\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70909091 0.36111111 0.64197531 0.70987654 0.55555556 0.60802469\n",
      " 0.28888889 0.42962963 0.46666667 0.31481481]\n",
      "----------------------------------------\n",
      "Trial 39\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61090909 0.49691358 0.48765432 0.69135802 0.62962963 0.41358025\n",
      " 0.30740741 0.40740741 0.44814815 0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 40\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 119, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=119,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.46604938 0.44753086 0.62962963 0.42592593 0.33024691\n",
      " 0.31481481 0.35185185 0.58888889 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 41\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 16, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=16, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.64727273 0.56481481 0.5462963  0.5617284  0.6712963  0.27160494\n",
      " 0.35       0.31481481 0.55       0.40740741]\n",
      "----------------------------------------\n",
      "Trial 42\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 126, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=126, random_state=100,\n",
      "                                            subsample=0.75))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.81090909 0.47222222 0.67283951 0.65740741 0.41049383 0.44753086\n",
      " 0.45925926 0.39259259 0.55185185 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 43\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 176, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=176,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70181818 0.33641975 0.49691358 0.69135802 0.66975309 0.48148148\n",
      " 0.31481481 0.34814815 0.51111111 0.57037037]\n",
      "----------------------------------------\n",
      "Trial 44\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.76363636 0.30246914 0.66666667 0.91049383 0.61419753 0.43518519\n",
      " 0.38888889 0.41111111 0.41481481 0.34444444]\n",
      "----------------------------------------\n",
      "Trial 45\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 33, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=33,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.2962963  0.75617284 0.52006173 0.7808642  0.55555556\n",
      " 0.45925926 0.38888889 0.51296296 0.54074074]\n",
      "----------------------------------------\n",
      "Trial 46\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 123, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=123, random_state=100))])\n",
      "cv score: [0.64727273 0.54320988 0.60802469 0.61728395 0.61728395 0.55246914\n",
      " 0.4        0.31111111 0.52962963 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 47\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 100, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61454545 0.52469136 0.47530864 0.67901235 0.53703704 0.49691358\n",
      " 0.35185185 0.45555556 0.48888889 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 48\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 60, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=60, random_state=100))])\n",
      "cv score: [0.67272727 0.4212963  0.63117284 0.87345679 0.6404321  0.57407407\n",
      " 0.34444444 0.40185185 0.49444444 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 49\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 43, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=43,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66181818 0.2962963  0.51697531 0.5462963  0.51080247 0.50308642\n",
      " 0.66666667 0.26851852 0.55925926 0.45740741]\n",
      "----------------------------------------\n",
      "Trial 50\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 76, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=76, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.57454545 0.36728395 0.65123457 0.67901235 0.64197531 0.35493827\n",
      " 0.31481481 0.35925926 0.58518519 0.64814815]\n",
      "----------------------------------------\n",
      "Trial 51\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 94, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=94, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.62181818 0.37037037 0.66666667 0.79012346 0.6882716  0.46296296\n",
      " 0.37037037 0.31111111 0.48888889 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 52\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 47, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=47, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62727273 0.44444444 0.64969136 0.84876543 0.64969136 0.52623457\n",
      " 0.35740741 0.40925926 0.5        0.56666667]\n",
      "----------------------------------------\n",
      "Trial 53\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 188, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=188, random_state=100))])\n",
      "cv score: [0.67636364 0.44444444 0.59259259 0.78395062 0.72222222 0.56481481\n",
      " 0.38518519 0.35185185 0.58148148 0.48518519]\n",
      "----------------------------------------\n",
      "Trial 54\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=101, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.66909091 0.40432099 0.82098765 0.64814815 0.5462963  0.34876543\n",
      " 0.41481481 0.45185185 0.57777778 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 55\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 167, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=167, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.68363636 0.43518519 0.6882716  0.87962963 0.74074074 0.39814815\n",
      " 0.43333333 0.42962963 0.58888889 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 56\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72       0.37345679 0.52160494 0.79320988 0.53703704 0.45987654\n",
      " 0.2962963  0.47777778 0.37407407 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 57\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.63272727 0.40740741 0.74382716 0.77160494 0.62037037 0.4845679\n",
      " 0.4962963  0.43333333 0.5037037  0.41481481]\n",
      "----------------------------------------\n",
      "Trial 58\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 146, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=146, random_state=100))])\n",
      "cv score: [0.67272727 0.40432099 0.64506173 0.83024691 0.66666667 0.50925926\n",
      " 0.41111111 0.41111111 0.53333333 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 59\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 79, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=79,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.61090909 0.36419753 0.67283951 0.79012346 0.7345679  0.41358025\n",
      " 0.43703704 0.47407407 0.56666667 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 60\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 37, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=37,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.52006173 0.50617284 0.69135802 0.58641975 0.52469136\n",
      " 0.57037037 0.31111111 0.54074074 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 61\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 59, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=59,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.68       0.32407407 0.60185185 0.76234568 0.54938272 0.49074074\n",
      " 0.44074074 0.34444444 0.54074074 0.62592593]\n",
      "----------------------------------------\n",
      "Trial 62\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 93, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=93, random_state=100))])\n",
      "cv score: [0.73454545 0.65740741 0.60802469 0.70679012 0.56481481 0.50925926\n",
      " 0.48518519 0.27777778 0.45185185 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 63\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.73090909 0.46296296 0.50925926 0.66975309 0.54938272 0.46296296\n",
      " 0.33333333 0.44444444 0.53333333 0.36296296]\n",
      "----------------------------------------\n",
      "Trial 64\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 103, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=103,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73090909 0.44135802 0.44135802 0.70061728 0.71604938 0.48765432\n",
      " 0.3962963  0.40740741 0.47777778 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 65\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 71, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=71, random_state=100))])\n",
      "cv score: [0.69818182 0.52469136 0.61728395 0.80864198 0.7191358  0.47530864\n",
      " 0.30740741 0.39259259 0.48888889 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 66\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 62, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=62, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.69454545 0.32716049 0.62037037 0.78703704 0.61419753 0.4691358\n",
      " 0.23703704 0.27037037 0.51111111 0.63333333]\n",
      "----------------------------------------\n",
      "Trial 67\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 149, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=149,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63636364 0.41049383 0.68518519 0.66975309 0.5154321  0.42592593\n",
      " 0.28148148 0.4        0.54074074 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 68\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 189, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=189,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.77454545 0.39506173 0.5308642  0.75617284 0.63580247 0.5154321\n",
      " 0.41111111 0.42222222 0.5037037  0.46296296]\n",
      "----------------------------------------\n",
      "Trial 69\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=101,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72       0.52469136 0.5308642  0.66820988 0.59722222 0.50154321\n",
      " 0.38148148 0.28333333 0.51666667 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 70\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 71, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=71,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.48148148 0.49074074 0.5        0.48148148 0.5462963\n",
      " 0.5        0.47222222 0.5        0.41481481]\n",
      "----------------------------------------\n",
      "Trial 71\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=52, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.78181818 0.37962963 0.67901235 0.7654321  0.6882716  0.53395062\n",
      " 0.44444444 0.35555556 0.51851852 0.64074074]\n",
      "----------------------------------------\n",
      "Trial 72\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='log2',\n",
      "                                            n_estimators=52, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.64727273 0.39814815 0.65123457 0.67283951 0.59259259 0.29320988\n",
      " 0.22592593 0.42962963 0.46666667 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 73\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 61, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            n_estimators=61, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66545455 0.33641975 0.69753086 0.77469136 0.67901235 0.51851852\n",
      " 0.37037037 0.26666667 0.54074074 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 74\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 69, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=69, random_state=100))])\n",
      "cv score: [0.70181818 0.51234568 0.62654321 0.78703704 0.70061728 0.44753086\n",
      " 0.30740741 0.3962963  0.46296296 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 75\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 170, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=170,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6        0.47530864 0.70833333 0.57407407 0.63734568 0.55246914\n",
      " 0.59814815 0.44814815 0.41481481 0.60740741]\n",
      "----------------------------------------\n",
      "Trial 76\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 139, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=139, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.56363636 0.29938272 0.7808642  0.66049383 0.50617284 0.61111111\n",
      " 0.42962963 0.52222222 0.45925926 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 77\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 12, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=12,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56       0.47222222 0.48148148 0.47222222 0.46296296 0.46296296\n",
      " 0.4537037  0.41666667 0.49074074 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 78\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 109, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=109, random_state=100))])\n",
      "cv score: [0.65818182 0.37654321 0.62037037 0.88271605 0.74691358 0.54012346\n",
      " 0.34444444 0.4037037  0.4962963  0.55555556]\n",
      "----------------------------------------\n",
      "Trial 79\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66909091 0.47839506 0.51851852 0.6882716  0.5617284  0.4382716\n",
      " 0.3037037  0.25185185 0.58888889 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 80\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=10,\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.61454545 0.39814815 0.64814815 0.8117284  0.74074074 0.52777778\n",
      " 0.41851852 0.44444444 0.48888889 0.48518519]\n",
      "----------------------------------------\n",
      "Trial 81\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 163, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=163, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.61454545 0.37654321 0.73148148 0.80864198 0.74382716 0.47530864\n",
      " 0.38518519 0.35555556 0.5        0.48518519]\n",
      "----------------------------------------\n",
      "Trial 82\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 166, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=166,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72909091 0.55709877 0.57407407 0.66203704 0.60185185 0.47376543\n",
      " 0.45925926 0.34074074 0.55185185 0.50185185]\n",
      "----------------------------------------\n",
      "Trial 83\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 47, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=47,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65454545 0.58179012 0.43364198 0.68055556 0.52314815 0.57098765\n",
      " 0.60740741 0.27592593 0.5037037  0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 84\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62181818 0.44444444 0.56790123 0.7037037  0.47530864 0.50617284\n",
      " 0.44444444 0.31851852 0.57777778 0.58148148]\n",
      "----------------------------------------\n",
      "Trial 85\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74909091 0.41358025 0.52777778 0.81481481 0.45679012 0.41666667\n",
      " 0.22962963 0.51481481 0.41481481 0.39259259]\n",
      "----------------------------------------\n",
      "Trial 86\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 72, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            n_estimators=72, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.70181818 0.52623457 0.53549383 0.66512346 0.59567901 0.53858025\n",
      " 0.49444444 0.3462963  0.49074074 0.44259259]\n",
      "----------------------------------------\n",
      "Trial 87\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 100, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2',\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61818182 0.32407407 0.65123457 0.65740741 0.63271605 0.52777778\n",
      " 0.38148148 0.31851852 0.57777778 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 88\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 156, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=156,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51636364 0.49537037 0.50308642 0.65277778 0.49228395 0.6882716\n",
      " 0.48333333 0.4        0.58518519 0.5537037 ]\n",
      "----------------------------------------\n",
      "Trial 89\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 126, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=126,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60363636 0.43518519 0.41666667 0.58024691 0.42283951 0.44444444\n",
      " 0.21851852 0.3        0.55185185 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 90\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 153, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=153,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62909091 0.42592593 0.64814815 0.65740741 0.61419753 0.51234568\n",
      " 0.29259259 0.3        0.54444444 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 91\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 10, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=10,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.71636364 0.41358025 0.46296296 0.56790123 0.60185185 0.34259259\n",
      " 0.38888889 0.36296296 0.61111111 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 92\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 147, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            n_estimators=147, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.71636364 0.44444444 0.64197531 0.73765432 0.70061728 0.60802469\n",
      " 0.38518519 0.16296296 0.58518519 0.6       ]\n",
      "----------------------------------------\n",
      "Trial 93\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 59, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=59,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54727273 0.54012346 0.50617284 0.62345679 0.46141975 0.53858025\n",
      " 0.56111111 0.3462963  0.63888889 0.66666667]\n",
      "----------------------------------------\n",
      "Trial 94\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 186, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=186,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.51851852 0.37962963 0.47222222 0.50925926 0.47685185\n",
      " 0.5        0.46296296 0.47222222 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 95\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 186, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=186, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.66545455 0.45987654 0.67901235 0.65123457 0.48148148 0.30555556\n",
      " 0.53703704 0.45925926 0.37777778 0.28518519]\n",
      "----------------------------------------\n",
      "Trial 96\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 150, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=150,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.47222222 0.5        0.48148148]\n",
      "----------------------------------------\n",
      "Trial 97\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=121, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.60727273 0.35493827 0.72530864 0.69753086 0.7191358  0.36419753\n",
      " 0.38888889 0.41851852 0.48888889 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 98\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 68, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=68,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66727273 0.5787037  0.63888889 0.55709877 0.61111111 0.54475309\n",
      " 0.52222222 0.16666667 0.32592593 0.53518519]\n",
      "----------------------------------------\n",
      "Trial 99\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 47, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=47, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.71636364 0.37654321 0.7654321  0.71296296 0.74382716 0.45679012\n",
      " 0.46296296 0.45185185 0.4962963  0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 100\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62       0.54783951 0.50771605 0.5308642  0.5308642  0.5787037\n",
      " 0.55       0.37037037 0.60925926 0.65740741]\n",
      "----------------------------------------\n",
      "Trial 101\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 199, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=199,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.72       0.46296296 0.55246914 0.79320988 0.5308642  0.46296296\n",
      " 0.27777778 0.4037037  0.45925926 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 102\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 47, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=47, random_state=100))])\n",
      "cv score: [0.58909091 0.52777778 0.57716049 0.67283951 0.57098765 0.4691358\n",
      " 0.4037037  0.35555556 0.51851852 0.61851852]\n",
      "----------------------------------------\n",
      "Trial 103\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 160, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=160,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65090909 0.41358025 0.54320988 0.80864198 0.44444444 0.5\n",
      " 0.47407407 0.45185185 0.57777778 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 104\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 163, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=163, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.64727273 0.39506173 0.70679012 0.72839506 0.69444444 0.45679012\n",
      " 0.31851852 0.32962963 0.54074074 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 105\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 175, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=175,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64727273 0.35802469 0.52469136 0.69444444 0.60493827 0.45061728\n",
      " 0.34074074 0.36666667 0.58148148 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 106\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 87, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=87, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.72727273 0.44135802 0.67283951 0.77160494 0.60493827 0.56790123\n",
      " 0.41481481 0.54814815 0.61111111 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 107\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 96, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=96, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.71272727 0.44135802 0.62345679 0.66049383 0.59876543 0.41975309\n",
      " 0.41481481 0.4962963  0.26666667 0.33703704]\n",
      "----------------------------------------\n",
      "Trial 108\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=171,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63272727 0.35185185 0.66975309 0.64814815 0.62654321 0.51851852\n",
      " 0.35925926 0.3037037  0.60740741 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 109\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=81, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.70909091 0.52777778 0.61419753 0.75617284 0.65740741 0.41358025\n",
      " 0.35925926 0.28518519 0.55925926 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 110\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 58, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=58, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.72       0.53395062 0.62345679 0.73765432 0.67592593 0.39197531\n",
      " 0.32222222 0.31481481 0.4962963  0.55185185]\n",
      "----------------------------------------\n",
      "Trial 111\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 139, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=139, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.54181818 0.45679012 0.60185185 0.85185185 0.64814815 0.52160494\n",
      " 0.4037037  0.45185185 0.34074074 0.28888889]\n",
      "----------------------------------------\n",
      "Trial 112\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 73, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=73, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.73454545 0.47530864 0.66975309 0.63580247 0.63580247 0.52777778\n",
      " 0.37037037 0.34814815 0.5        0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 113\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 32, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=32, random_state=100))])\n",
      "cv score: [0.77636364 0.70679012 0.45987654 0.63117284 0.47839506 0.54938272\n",
      " 0.49074074 0.31666667 0.32037037 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 114\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 107, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=107,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.64       0.47530864 0.60802469 0.75617284 0.67592593 0.50925926\n",
      " 0.5        0.28518519 0.53333333 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 115\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.68363636 0.36419753 0.66049383 0.76851852 0.61111111 0.50925926\n",
      " 0.36666667 0.31481481 0.58888889 0.60740741]\n",
      "----------------------------------------\n",
      "Trial 116\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 95, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=95,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58909091 0.40740741 0.54320988 0.72530864 0.50617284 0.5462963\n",
      " 0.42592593 0.33703704 0.58518519 0.60740741]\n",
      "----------------------------------------\n",
      "Trial 117\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 107, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=107,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63636364 0.35802469 0.52777778 0.67901235 0.60493827 0.53395062\n",
      " 0.37037037 0.3        0.52962963 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 118\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 58, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            n_estimators=58, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.63272727 0.5462963  0.75308642 0.7654321  0.64506173 0.50925926\n",
      " 0.35925926 0.28518519 0.59259259 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 119\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 113, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=113, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.59636364 0.35802469 0.70987654 0.85802469 0.70679012 0.47530864\n",
      " 0.45185185 0.44814815 0.37407407 0.32962963]\n",
      "----------------------------------------\n",
      "Trial 120\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 161, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=161,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64363636 0.35185185 0.66975309 0.69753086 0.62037037 0.5\n",
      " 0.45925926 0.33703704 0.62222222 0.67407407]\n",
      "----------------------------------------\n",
      "Trial 121\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 77, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=77,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68       0.4845679  0.45987654 0.7037037  0.37037037 0.50308642\n",
      " 0.34074074 0.32222222 0.46666667 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 122\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 169, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=169,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.64363636 0.36728395 0.57407407 0.67283951 0.59567901 0.5462963\n",
      " 0.4037037  0.27777778 0.58518519 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 123\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 114, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=114, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.50909091 0.49382716 0.58333333 0.55246914 0.64506173 0.34567901\n",
      " 0.63703704 0.35555556 0.47777778 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 124\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68727273 0.37345679 0.52777778 0.67283951 0.67592593 0.44135802\n",
      " 0.30740741 0.38888889 0.57407407 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 125\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 36, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=36,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.78545455 0.57098765 0.52314815 0.58950617 0.62808642 0.49691358\n",
      " 0.52222222 0.42222222 0.5537037  0.47962963]\n",
      "----------------------------------------\n",
      "Trial 126\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 180, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=180,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62181818 0.35185185 0.66975309 0.65123457 0.62345679 0.5308642\n",
      " 0.37037037 0.31111111 0.61481481 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 127\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 105, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=105, random_state=100))])\n",
      "cv score: [0.69454545 0.37962963 0.64814815 0.87037037 0.68209877 0.57716049\n",
      " 0.32222222 0.46296296 0.51481481 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 128\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 185, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=4,\n",
      "                                            n_estimators=185, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.65272727 0.54320988 0.52469136 0.55709877 0.58641975 0.45524691\n",
      " 0.44259259 0.22592593 0.52777778 0.43518519]\n",
      "----------------------------------------\n",
      "Trial 129\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 138, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=138,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.2962963  0.75154321 0.51697531 0.7808642  0.55246914\n",
      " 0.45925926 0.38518519 0.51296296 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 130\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 193, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=193,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63636364 0.55246914 0.49228395 0.54320988 0.59567901 0.52314815\n",
      " 0.6462963  0.42777778 0.48148148 0.47592593]\n",
      "----------------------------------------\n",
      "Trial 131\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 92, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=92,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62181818 0.44444444 0.37037037 0.60802469 0.44444444 0.53395062\n",
      " 0.32222222 0.32962963 0.53333333 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 132\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 75, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=75,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61090909 0.41975309 0.51234568 0.6882716  0.59567901 0.50617284\n",
      " 0.46666667 0.26296296 0.55925926 0.57407407]\n",
      "----------------------------------------\n",
      "Trial 133\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 193, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=193, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.70545455 0.40432099 0.65432099 0.37808642 0.58950617 0.35802469\n",
      " 0.44074074 0.47592593 0.48148148 0.22592593]\n",
      "----------------------------------------\n",
      "Trial 134\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 48, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=48,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.69454545 0.41975309 0.67283951 0.72222222 0.66358025 0.57716049\n",
      " 0.41111111 0.33703704 0.54074074 0.5962963 ]\n",
      "----------------------------------------\n",
      "Trial 135\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 80, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=80, random_state=100))])\n",
      "cv score: [0.75272727 0.57098765 0.51234568 0.64814815 0.53549383 0.48765432\n",
      " 0.51481481 0.24814815 0.43703704 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 136\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 109, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=109, random_state=100))])\n",
      "cv score: [0.71272727 0.63888889 0.62654321 0.72222222 0.58333333 0.47839506\n",
      " 0.46666667 0.27777778 0.45185185 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 137\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 114, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=114, random_state=100))])\n",
      "cv score: [0.66909091 0.39814815 0.63271605 0.87654321 0.66666667 0.60185185\n",
      " 0.27037037 0.38148148 0.52222222 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 138\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 132, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=132,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76545455 0.61728395 0.56018519 0.64814815 0.63580247 0.4845679\n",
      " 0.48888889 0.36851852 0.54814815 0.45      ]\n",
      "----------------------------------------\n",
      "Trial 139\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 64, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            n_estimators=64, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.69454545 0.49691358 0.63888889 0.86111111 0.74074074 0.55246914\n",
      " 0.34814815 0.36296296 0.55185185 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 140\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 129, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=129,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64363636 0.33641975 0.63271605 0.72839506 0.61419753 0.46296296\n",
      " 0.33703704 0.2962963  0.60740741 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 141\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            n_estimators=108,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.71272727 0.4845679  0.73302469 0.45679012 0.67901235 0.51080247\n",
      " 0.40925926 0.16481481 0.34814815 0.77222222]\n",
      "----------------------------------------\n",
      "Trial 142\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 52, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=52,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57454545 0.53703704 0.5617284  0.6882716  0.44444444 0.47839506\n",
      " 0.30740741 0.38518519 0.64074074 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 143\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 59, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=59,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66181818 0.35802469 0.56481481 0.60493827 0.58641975 0.55246914\n",
      " 0.41111111 0.3037037  0.5037037  0.50740741]\n",
      "----------------------------------------\n",
      "Trial 144\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 123, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=123,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.59272727 0.54320988 0.52006173 0.72530864 0.50925926 0.57407407\n",
      " 0.5037037  0.34074074 0.61481481 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 145\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 72, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=72, random_state=100))])\n",
      "cv score: [0.71636364 0.37345679 0.625      0.83950617 0.7037037  0.5617284\n",
      " 0.2962963  0.38888889 0.5962963  0.5       ]\n",
      "----------------------------------------\n",
      "Trial 146\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 147, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=147, random_state=100))])\n",
      "cv score: [0.67636364 0.36419753 0.62345679 0.87037037 0.74074074 0.52160494\n",
      " 0.42592593 0.42592593 0.52592593 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 147\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 169, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=169,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58727273 0.54475309 0.51851852 0.60185185 0.59722222 0.44598765\n",
      " 0.54259259 0.41111111 0.64814815 0.49444444]\n",
      "----------------------------------------\n",
      "Trial 148\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 160, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=160,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66363636 0.57407407 0.69907407 0.47530864 0.625      0.55092593\n",
      " 0.52777778 0.27592593 0.40925926 0.68518519]\n",
      "----------------------------------------\n",
      "Trial 149\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 69, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=69,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.64363636 0.35493827 0.69753086 0.66666667 0.72222222 0.38888889\n",
      " 0.45925926 0.43703704 0.54444444 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 150\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 38, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=38,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63272727 0.41049383 0.55246914 0.75       0.54320988 0.5\n",
      " 0.33333333 0.44074074 0.55925926 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 151\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 123, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            n_estimators=123, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.68727273 0.47839506 0.57407407 0.7345679  0.62654321 0.5308642\n",
      " 0.25555556 0.30555556 0.55185185 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 152\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 12, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, n_estimators=12,\n",
      "                                            random_state=100, subsample=0.8))])\n",
      "cv score: [0.72363636 0.4845679  0.76851852 0.77777778 0.4537037  0.52777778\n",
      " 0.5        0.25925926 0.57037037 0.69259259]\n",
      "----------------------------------------\n",
      "Trial 153\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 185, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=185, random_state=100))])\n",
      "cv score: [0.68       0.60802469 0.59259259 0.7037037  0.57716049 0.4691358\n",
      " 0.44444444 0.34814815 0.5037037  0.47037037]\n",
      "----------------------------------------\n",
      "Trial 154\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 130, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=130,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65818182 0.40123457 0.44135802 0.66975309 0.4537037  0.33333333\n",
      " 0.25925926 0.36666667 0.56666667 0.55555556]\n",
      "----------------------------------------\n",
      "Trial 155\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56       0.55092593 0.49691358 0.56944444 0.55246914 0.58024691\n",
      " 0.52962963 0.29074074 0.60185185 0.50185185]\n",
      "----------------------------------------\n",
      "Trial 156\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 171, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=171, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.54909091 0.4691358  0.68209877 0.74074074 0.66975309 0.43518519\n",
      " 0.38148148 0.41111111 0.48888889 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 157\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 32, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=32, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.74909091 0.39969136 0.61882716 0.52469136 0.60802469 0.37962963\n",
      " 0.34444444 0.31296296 0.5        0.48888889]\n",
      "----------------------------------------\n",
      "Trial 158\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 141, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=141, random_state=100))])\n",
      "cv score: [0.65454545 0.48148148 0.56790123 0.83641975 0.75617284 0.51851852\n",
      " 0.34814815 0.40740741 0.51481481 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 159\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=197, random_state=100))])\n",
      "cv score: [0.67272727 0.53395062 0.59567901 0.66975309 0.55864198 0.45987654\n",
      " 0.32592593 0.35555556 0.56666667 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 160\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 38, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            n_estimators=38, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.68727273 0.37962963 0.68518519 0.77160494 0.73765432 0.60185185\n",
      " 0.41111111 0.28518519 0.59259259 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 161\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 84, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=84, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.72       0.62037037 0.58024691 0.60493827 0.44135802 0.5\n",
      " 0.40740741 0.37037037 0.45555556 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 162\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 116, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=116, random_state=100))])\n",
      "cv score: [0.71272727 0.44135802 0.57098765 0.76851852 0.72839506 0.57098765\n",
      " 0.27777778 0.42962963 0.55925926 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 163\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            n_estimators=68, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.64727273 0.34259259 0.70679012 0.7345679  0.76851852 0.41975309\n",
      " 0.29259259 0.2962963  0.62222222 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 164\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 140, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=140, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.53818182 0.50925926 0.71604938 0.7654321  0.70987654 0.4691358\n",
      " 0.45925926 0.37407407 0.55185185 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 165\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 128, 'gb__subsample': 0.85, 'gb__learning_rate': 0.1, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=2, max_features='sqrt',\n",
      "                                            n_estimators=128, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.64       0.45061728 0.70061728 0.65740741 0.58641975 0.36419753\n",
      " 0.31851852 0.33333333 0.59259259 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 166\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=16, random_state=100))])\n",
      "cv score: [0.65818182 0.50308642 0.60802469 0.77777778 0.62654321 0.43209877\n",
      " 0.25555556 0.19259259 0.37777778 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 167\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.41358025 0.57098765 0.74074074 0.60493827 0.53703704\n",
      " 0.38888889 0.28518519 0.57037037 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 168\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 128, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=128,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65454545 0.35185185 0.50308642 0.66358025 0.71604938 0.4537037\n",
      " 0.2962963  0.41851852 0.44814815 0.61851852]\n",
      "----------------------------------------\n",
      "Trial 169\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 79, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=79, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.79272727 0.44753086 0.5308642  0.69444444 0.59876543 0.4845679\n",
      " 0.25185185 0.35925926 0.47777778 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 170\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 151, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=151, random_state=100))])\n",
      "cv score: [0.67272727 0.35802469 0.62037037 0.87037037 0.73765432 0.52469136\n",
      " 0.41851852 0.43333333 0.51851852 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 171\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 56, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=56, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.44363636 0.38888889 0.62345679 0.42283951 0.80246914 0.28395062\n",
      " 0.48888889 0.35555556 0.6037037  0.57407407]\n",
      "----------------------------------------\n",
      "Trial 172\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 12, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=12,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58545455 0.46296296 0.48148148 0.55092593 0.46296296 0.46296296\n",
      " 0.48148148 0.41666667 0.51666667 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 173\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 44, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=44,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72363636 0.50925926 0.37962963 0.47222222 0.50925926 0.5\n",
      " 0.47222222 0.46296296 0.42407407 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 174\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.64363636 0.42283951 0.61111111 0.76851852 0.39197531 0.36728395\n",
      " 0.35185185 0.75555556 0.52592593 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 175\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 193, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=193, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.69454545 0.42592593 0.6882716  0.82407407 0.67901235 0.42283951\n",
      " 0.31111111 0.41481481 0.52222222 0.51851852]\n",
      "----------------------------------------\n",
      "Trial 176\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 49, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=49,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65090909 0.40432099 0.5308642  0.64197531 0.66975309 0.50925926\n",
      " 0.38518519 0.28518519 0.41481481 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 177\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 26, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=26, random_state=100))])\n",
      "cv score: [0.78909091 0.4845679  0.64197531 0.74382716 0.58950617 0.69444444\n",
      " 0.38518519 0.24074074 0.52962963 0.6       ]\n",
      "----------------------------------------\n",
      "Trial 178\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 164, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            n_estimators=164, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.73090909 0.48765432 0.58950617 0.64506173 0.58641975 0.56018519\n",
      " 0.34814815 0.33333333 0.46666667 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 179\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 184, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=184,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.81454545 0.46296296 0.68209877 0.69135802 0.50925926 0.39506173\n",
      " 0.31851852 0.43333333 0.71851852 0.51851852]\n",
      "----------------------------------------\n",
      "Trial 180\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 196, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=5, n_estimators=196,\n",
      "                                            random_state=100, subsample=0.9))])\n",
      "cv score: [0.66545455 0.46296296 0.6882716  0.83641975 0.72530864 0.44135802\n",
      " 0.4962963  0.42592593 0.55555556 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 181\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 39, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=39, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.67272727 0.54320988 0.74074074 0.64197531 0.63580247 0.4845679\n",
      " 0.3037037  0.48148148 0.54814815 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 182\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 39, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=39, random_state=100))])\n",
      "cv score: [0.82181818 0.49382716 0.64814815 0.84876543 0.54320988 0.50617284\n",
      " 0.40740741 0.48518519 0.55555556 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 183\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73454545 0.52160494 0.5308642  0.68518519 0.57407407 0.44753086\n",
      " 0.39259259 0.36666667 0.44074074 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 184\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 171, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=171,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58909091 0.37037037 0.50925926 0.70987654 0.53703704 0.49382716\n",
      " 0.38888889 0.32222222 0.61851852 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 185\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 80, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=80,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5        0.48148148 0.48148148 0.5        0.48148148 0.46296296\n",
      " 0.5        0.46296296 0.48148148 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 186\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 144, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=144,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.53858025 0.52006173 0.61728395 0.59876543 0.60493827\n",
      " 0.55       0.38888889 0.61296296 0.58888889]\n",
      "----------------------------------------\n",
      "Trial 187\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.82545455 0.46296296 0.44135802 0.76851852 0.60493827 0.48765432\n",
      " 0.22962963 0.55185185 0.44814815 0.36296296]\n",
      "----------------------------------------\n",
      "Trial 188\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 88, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            n_estimators=88, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.77454545 0.42592593 0.54012346 0.71296296 0.50617284 0.47222222\n",
      " 0.28148148 0.61851852 0.4        0.52222222]\n",
      "----------------------------------------\n",
      "Trial 189\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=198, random_state=100))])\n",
      "cv score: [0.65818182 0.45061728 0.64506173 0.75       0.62654321 0.60802469\n",
      " 0.34074074 0.25925926 0.54814815 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 190\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 153, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=153, random_state=100))])\n",
      "cv score: [0.67272727 0.35493827 0.61728395 0.88271605 0.73765432 0.51851852\n",
      " 0.40740741 0.44074074 0.52962963 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 191\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=102, random_state=100))])\n",
      "cv score: [0.62909091 0.40432099 0.63271605 0.86111111 0.64197531 0.58950617\n",
      " 0.4        0.37777778 0.47777778 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 192\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 25, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=25, random_state=100))])\n",
      "cv score: [0.63818182 0.58487654 0.47067901 0.69444444 0.59104938 0.47993827\n",
      " 0.62222222 0.26481481 0.54444444 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 193\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 61, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            n_estimators=61, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.62909091 0.45987654 0.61419753 0.82407407 0.7345679  0.55864198\n",
      " 0.34814815 0.35925926 0.6        0.49259259]\n",
      "----------------------------------------\n",
      "Trial 194\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 24, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=24,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66363636 0.57407407 0.69907407 0.47530864 0.625      0.54783951\n",
      " 0.52777778 0.27592593 0.40925926 0.68518519]\n",
      "----------------------------------------\n",
      "Trial 195\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 163, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=163,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66545455 0.36419753 0.7345679  0.65432099 0.57716049 0.50308642\n",
      " 0.4037037  0.32222222 0.57777778 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 196\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 121, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=121, random_state=100))])\n",
      "cv score: [0.64727273 0.54320988 0.60802469 0.61728395 0.61728395 0.55555556\n",
      " 0.38888889 0.31111111 0.52962963 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 197\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 103, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=103, random_state=100))])\n",
      "cv score: [0.71272727 0.4537037  0.63271605 0.78703704 0.61419753 0.60802469\n",
      " 0.38518519 0.25555556 0.51481481 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 198\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 86, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=86, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.55636364 0.41975309 0.54938272 0.79012346 0.60802469 0.49382716\n",
      " 0.43333333 0.35555556 0.57037037 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 199\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 112, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=112,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.76363636 0.39814815 0.5462963  0.72222222 0.59567901 0.48148148\n",
      " 0.35925926 0.28518519 0.51481481 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 200\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 190, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=2, n_estimators=190,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.65))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.75272727 0.55246914 0.5617284  0.75617284 0.67283951 0.24382716\n",
      " 0.26296296 0.2962963  0.76666667 0.61851852]\n",
      "----------------------------------------\n",
      "Trial 201\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 151, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=151,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70727273 0.51697531 0.57098765 0.66666667 0.60802469 0.50617284\n",
      " 0.35555556 0.32592593 0.53888889 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 202\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 94, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=94, random_state=100))])\n",
      "cv score: [0.72363636 0.59876543 0.58333333 0.65740741 0.57407407 0.51234568\n",
      " 0.46296296 0.3037037  0.43518519 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 203\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54545455 0.35185185 0.48765432 0.64814815 0.48148148 0.52469136\n",
      " 0.22222222 0.2962963  0.56666667 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 204\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66545455 0.45679012 0.62654321 0.79938272 0.47839506 0.53395062\n",
      " 0.36666667 0.44814815 0.5        0.38888889]\n",
      "----------------------------------------\n",
      "Trial 205\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 199, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=199,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.75636364 0.38888889 0.62037037 0.66666667 0.5        0.50308642\n",
      " 0.28148148 0.45185185 0.45185185 0.45555556]\n",
      "----------------------------------------\n",
      "Trial 206\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=183, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.64727273 0.34876543 0.66666667 0.79938272 0.63888889 0.57098765\n",
      " 0.44444444 0.41851852 0.3962963  0.45925926]\n",
      "----------------------------------------\n",
      "Trial 207\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68363636 0.43209877 0.5154321  0.69753086 0.4537037  0.39197531\n",
      " 0.25555556 0.32962963 0.60740741 0.55555556]\n",
      "----------------------------------------\n",
      "Trial 208\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 165, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=165, random_state=100))])\n",
      "cv score: [0.69454545 0.40740741 0.57098765 0.75308642 0.72839506 0.57098765\n",
      " 0.3        0.46296296 0.51111111 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 209\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.70909091 0.40432099 0.47839506 0.75       0.63271605 0.4691358\n",
      " 0.31851852 0.58518519 0.50740741 0.37037037]\n",
      "----------------------------------------\n",
      "Trial 210\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 55, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=55,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.78545455 0.51234568 0.59876543 0.72839506 0.45987654 0.48765432\n",
      " 0.47037037 0.45185185 0.58518519 0.39259259]\n",
      "----------------------------------------\n",
      "Trial 211\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 51, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=51,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61090909 0.44444444 0.52469136 0.54320988 0.56790123 0.5308642\n",
      " 0.66111111 0.37037037 0.57962963 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 212\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 27, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=27, random_state=100))])\n",
      "cv score: [0.57090909 0.35185185 0.61111111 0.62345679 0.58333333 0.54320988\n",
      " 0.48888889 0.08518519 0.57037037 0.66666667]\n",
      "----------------------------------------\n",
      "Trial 213\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=115,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.48148148 0.49074074 0.5        0.48148148 0.5462963\n",
      " 0.5        0.47222222 0.5        0.41481481]\n",
      "----------------------------------------\n",
      "Trial 214\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 75, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=75,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67272727 0.4537037  0.51851852 0.74074074 0.5154321  0.52469136\n",
      " 0.37407407 0.37037037 0.52962963 0.57037037]\n",
      "----------------------------------------\n",
      "Trial 215\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 40, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=40,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64181818 0.43518519 0.54166667 0.5462963  0.47839506 0.55092593\n",
      " 0.59074074 0.38333333 0.57037037 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 216\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 145, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=145,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72909091 0.53858025 0.56481481 0.67438272 0.59567901 0.50771605\n",
      " 0.47037037 0.33703704 0.54074074 0.50185185]\n",
      "----------------------------------------\n",
      "Trial 217\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 167, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=167,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61454545 0.5154321  0.48148148 0.71296296 0.48765432 0.53395062\n",
      " 0.47777778 0.34814815 0.54444444 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 218\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 116, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=116, random_state=100))])\n",
      "cv score: [0.69090909 0.4537037  0.59876543 0.7808642  0.66358025 0.53395062\n",
      " 0.32962963 0.38518519 0.57777778 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 219\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 20, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=20,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62181818 0.44444444 0.5632716  0.54320988 0.47839506 0.60493827\n",
      " 0.63888889 0.4962963  0.62777778 0.42407407]\n",
      "----------------------------------------\n",
      "Trial 220\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69818182 0.51697531 0.52006173 0.75462963 0.37808642 0.56635802\n",
      " 0.6962963  0.24444444 0.58148148 0.58333333]\n",
      "----------------------------------------\n",
      "Trial 221\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 68, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=68,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69090909 0.44444444 0.51851852 0.54320988 0.46450617 0.52160494\n",
      " 0.58888889 0.40185185 0.61851852 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 222\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 132, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=132, random_state=100))])\n",
      "cv score: [0.70909091 0.60493827 0.62962963 0.72839506 0.56790123 0.49074074\n",
      " 0.44444444 0.31481481 0.51111111 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 223\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 54, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=54,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.8        0.48765432 0.78395062 0.69135802 0.66358025 0.50308642\n",
      " 0.36296296 0.39259259 0.41111111 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 224\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 175, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=175,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53454545 0.47685185 0.52160494 0.49691358 0.51388889 0.54475309\n",
      " 0.54444444 0.34074074 0.57222222 0.57592593]\n",
      "----------------------------------------\n",
      "Trial 225\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 85, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=85,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.2962963  0.75154321 0.51697531 0.7808642  0.55246914\n",
      " 0.46296296 0.38518519 0.51296296 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 226\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 24, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=24,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60727273 0.44444444 0.52777778 0.5462963  0.49382716 0.5617284\n",
      " 0.62407407 0.2462963  0.48148148 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 227\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            n_estimators=183, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.64363636 0.41049383 0.62654321 0.77777778 0.62962963 0.50925926\n",
      " 0.28148148 0.29259259 0.58518519 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 228\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 140, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=140,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66727273 0.5787037  0.63888889 0.55709877 0.61111111 0.54475309\n",
      " 0.52222222 0.16666667 0.32592593 0.53518519]\n",
      "----------------------------------------\n",
      "Trial 229\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 135, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=135, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.72727273 0.56481481 0.49228395 0.63888889 0.59876543 0.48302469\n",
      " 0.53148148 0.3037037  0.53888889 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 230\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 144, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt', n_estimators=144,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.67636364 0.37654321 0.61728395 0.76234568 0.66975309 0.53395062\n",
      " 0.44074074 0.37037037 0.58888889 0.63703704]\n",
      "----------------------------------------\n",
      "Trial 231\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 58, 'gb__subsample': 0.85, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, max_features='sqrt',\n",
      "                                            n_estimators=58, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.64363636 0.36111111 0.63271605 0.75       0.57716049 0.51851852\n",
      " 0.47777778 0.45925926 0.36296296 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 232\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 57, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=57, random_state=100))])\n",
      "cv score: [0.76363636 0.59876543 0.46604938 0.63271605 0.57253086 0.48148148\n",
      " 0.52222222 0.28888889 0.47037037 0.3962963 ]\n",
      "----------------------------------------\n",
      "Trial 233\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 110, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=5,\n",
      "                                            n_estimators=110,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.73090909 0.52777778 0.52777778 0.62345679 0.79938272 0.50617284\n",
      " 0.41851852 0.51481481 0.54444444 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 234\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 13, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=13,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.46181818 0.63888889 0.52777778 0.61574074 0.5        0.61728395\n",
      " 0.25555556 0.35555556 0.41851852 0.31851852]\n",
      "----------------------------------------\n",
      "Trial 235\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 15, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            n_estimators=15,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.67454545 0.50925926 0.51388889 0.66358025 0.59567901 0.48611111\n",
      " 0.5        0.38333333 0.4        0.38703704]\n",
      "----------------------------------------\n",
      "Trial 236\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.64       0.55555556 0.69753086 0.62037037 0.64506173 0.40432099\n",
      " 0.43703704 0.72962963 0.54444444 0.38518519]\n",
      "----------------------------------------\n",
      "Trial 237\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 103, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=103, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.63636364 0.47530864 0.77160494 0.62345679 0.52777778 0.36111111\n",
      " 0.28888889 0.42222222 0.50740741 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 238\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=183, random_state=100))])\n",
      "cv score: [0.68       0.44444444 0.58950617 0.79012346 0.71296296 0.5462963\n",
      " 0.3962963  0.35555556 0.5962963  0.48518519]\n",
      "----------------------------------------\n",
      "Trial 239\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 27, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=27,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72363636 0.50925926 0.37962963 0.47222222 0.50925926 0.5\n",
      " 0.47222222 0.46296296 0.42407407 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 240\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters {'xgb__n_estimators': 18, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=18,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53090909 0.40123457 0.43209877 0.60802469 0.55864198 0.57098765\n",
      " 0.32962963 0.41111111 0.47407407 0.58518519]\n",
      "----------------------------------------\n",
      "Trial 241\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 184, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=184,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57272727 0.50771605 0.51851852 0.6712963  0.55401235 0.45679012\n",
      " 0.55185185 0.32222222 0.59259259 0.49814815]\n",
      "----------------------------------------\n",
      "Trial 242\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            n_estimators=115, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.69090909 0.45061728 0.66049383 0.83641975 0.67901235 0.48148148\n",
      " 0.3037037  0.25925926 0.52222222 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 243\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 151, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=151,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.82181818 0.32407407 0.5462963  0.74382716 0.57098765 0.51234568\n",
      " 0.28518519 0.45555556 0.4962963  0.46296296]\n",
      "----------------------------------------\n",
      "Trial 244\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 123, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=123, random_state=100))])\n",
      "cv score: [0.61818182 0.41358025 0.64197531 0.81790123 0.65123457 0.58333333\n",
      " 0.39259259 0.36666667 0.5        0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 245\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 10, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=10, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.45818182 0.37654321 0.74382716 0.40740741 0.49691358 0.70679012\n",
      " 0.38518519 0.57777778 0.57407407 0.18148148]\n",
      "----------------------------------------\n",
      "Trial 246\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 45, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=45, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.64363636 0.30555556 0.69444444 0.75925926 0.7037037  0.5\n",
      " 0.41851852 0.25185185 0.54074074 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 247\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 194, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=194,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66181818 0.31790123 0.66975309 0.68518519 0.63271605 0.48148148\n",
      " 0.38148148 0.3037037  0.58518519 0.6       ]\n",
      "----------------------------------------\n",
      "Trial 248\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 55, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, max_features='sqrt',\n",
      "                                            n_estimators=55, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.61454545 0.36111111 0.59259259 0.60802469 0.7654321  0.47839506\n",
      " 0.50740741 0.41851852 0.58518519 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 249\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 149, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=149, random_state=100))])\n",
      "cv score: [0.70545455 0.40740741 0.57098765 0.74382716 0.73765432 0.54320988\n",
      " 0.28518519 0.47407407 0.51111111 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 250\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67272727 0.39197531 0.54320988 0.7345679  0.54938272 0.51851852\n",
      " 0.48148148 0.30740741 0.62222222 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 251\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 20, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=20,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.39814815 0.58950617 0.65740741 0.66358025 0.65432099\n",
      " 0.37037037 0.32962963 0.52592593 0.64444444]\n",
      "----------------------------------------\n",
      "Trial 252\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 32, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=32, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.58545455 0.50925926 0.59876543 0.70987654 0.58641975 0.54938272\n",
      " 0.39259259 0.5        0.35185185 0.39259259]\n",
      "----------------------------------------\n",
      "Trial 253\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 173, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=173, random_state=100))])\n",
      "cv score: [0.72       0.41049383 0.65740741 0.83641975 0.64814815 0.57098765\n",
      " 0.34444444 0.35925926 0.50740741 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 254\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 125, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=125, random_state=100))])\n",
      "cv score: [0.64727273 0.5462963  0.60493827 0.61728395 0.61728395 0.54938272\n",
      " 0.4037037  0.31111111 0.52962963 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 255\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 109, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=12,\n",
      "                                            n_estimators=109, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.63272727 0.52777778 0.66666667 0.81481481 0.65123457 0.52777778\n",
      " 0.22592593 0.41851852 0.48518519 0.34074074]\n",
      "----------------------------------------\n",
      "Trial 256\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 141, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            n_estimators=141, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.68       0.4382716  0.65432099 0.75       0.61728395 0.49382716\n",
      " 0.48518519 0.51111111 0.32962963 0.32592593]\n",
      "----------------------------------------\n",
      "Trial 257\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 86, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=86, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.82545455 0.39814815 0.74691358 0.71296296 0.67592593 0.45061728\n",
      " 0.47407407 0.3962963  0.34814815 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 258\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 162, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=162, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.66181818 0.37654321 0.48919753 0.62037037 0.4382716  0.67283951\n",
      " 0.33703704 0.75925926 0.41111111 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 259\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 182, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=182,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70545455 0.49382716 0.59876543 0.67283951 0.61111111 0.47222222\n",
      " 0.31851852 0.2962963  0.52962963 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 260\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 29, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=29, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.71272727 0.44135802 0.60802469 0.70833333 0.5154321  0.47530864\n",
      " 0.32777778 0.32222222 0.44444444 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 261\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=52, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.69636364 0.60185185 0.52777778 0.48148148 0.57407407 0.43364198\n",
      " 0.55925926 0.37037037 0.54259259 0.49444444]\n",
      "----------------------------------------\n",
      "Trial 262\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 184, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=184,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66545455 0.33024691 0.68209877 0.6882716  0.63271605 0.47839506\n",
      " 0.37777778 0.30740741 0.58888889 0.6037037 ]\n",
      "----------------------------------------\n",
      "Trial 263\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 130, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=130, random_state=100))])\n",
      "cv score: [0.76727273 0.61574074 0.52932099 0.6882716  0.49691358 0.54475309\n",
      " 0.41111111 0.36666667 0.4537037  0.40740741]\n",
      "----------------------------------------\n",
      "Trial 264\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 153, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=153,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54181818 0.44753086 0.47530864 0.64506173 0.38580247 0.50925926\n",
      " 0.28148148 0.27777778 0.47037037 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 265\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63090909 0.53395062 0.51080247 0.67283951 0.54166667 0.59567901\n",
      " 0.56851852 0.32962963 0.63703704 0.58148148]\n",
      "----------------------------------------\n",
      "Trial 266\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 12, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=12, random_state=100))])\n",
      "cv score: [0.62545455 0.51851852 0.62037037 0.75925926 0.68981481 0.42283951\n",
      " 0.33333333 0.52037037 0.41666667 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 267\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 186, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=186,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68727273 0.52777778 0.51080247 0.55709877 0.56481481 0.50771605\n",
      " 0.62777778 0.33518519 0.60740741 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 268\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 65, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=65,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72363636 0.50925926 0.37962963 0.47222222 0.50925926 0.5\n",
      " 0.47222222 0.46296296 0.42407407 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 269\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 88, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=88,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69090909 0.40432099 0.62345679 0.74382716 0.50617284 0.42283951\n",
      " 0.38148148 0.44074074 0.3962963  0.54814815]\n",
      "----------------------------------------\n",
      "Trial 270\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 99, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=99,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81818182 0.59567901 0.56481481 0.62962963 0.63888889 0.4845679\n",
      " 0.50740741 0.39259259 0.54074074 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 271\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 47, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=47, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60727273 0.25       0.66975309 0.65123457 0.55246914 0.55246914\n",
      " 0.42962963 0.37037037 0.51851852 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 272\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 151, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=151,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65818182 0.39506173 0.65123457 0.70679012 0.54938272 0.48765432\n",
      " 0.25555556 0.44814815 0.44074074 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 273\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 144, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=144, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.73454545 0.54012346 0.59567901 0.71604938 0.55555556 0.47839506\n",
      " 0.29259259 0.37407407 0.51111111 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 274\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 47, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=47, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.53454545 0.48765432 0.69444444 0.58024691 0.54320988 0.43518519\n",
      " 0.31481481 0.41111111 0.54814815 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 275\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 129, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=129, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.62909091 0.45061728 0.77777778 0.83950617 0.56790123 0.54938272\n",
      " 0.45925926 0.42962963 0.46666667 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 276\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 39, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            n_estimators=39, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.63636364 0.55555556 0.60185185 0.57407407 0.63580247 0.5\n",
      " 0.32222222 0.30740741 0.6037037  0.48148148]\n",
      "----------------------------------------\n",
      "Trial 277\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 11, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=11, random_state=100))])\n",
      "cv score: [0.62181818 0.47530864 0.5308642  0.65432099 0.66666667 0.44135802\n",
      " 0.33333333 0.08518519 0.4962963  0.61111111]\n",
      "----------------------------------------\n",
      "Trial 278\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 75, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=75,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63272727 0.37345679 0.56481481 0.70061728 0.58641975 0.4691358\n",
      " 0.36666667 0.53703704 0.45555556 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 279\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 73, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            n_estimators=73,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.68       0.49382716 0.58641975 0.83024691 0.79938272 0.50308642\n",
      " 0.41111111 0.41851852 0.66296296 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 280\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 185, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=185, random_state=100))])\n",
      "cv score: [0.66909091 0.41666667 0.62962963 0.74382716 0.64814815 0.57407407\n",
      " 0.35925926 0.3037037  0.55185185 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 281\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.64       0.34259259 0.58024691 0.69135802 0.59259259 0.56481481\n",
      " 0.34814815 0.3        0.54814815 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 282\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 184, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=184,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60545455 0.49228395 0.5154321  0.54012346 0.52314815 0.46141975\n",
      " 0.61666667 0.37222222 0.50740741 0.45740741]\n",
      "----------------------------------------\n",
      "Trial 283\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63090909 0.4537037  0.5154321  0.54012346 0.47530864 0.52932099\n",
      " 0.66111111 0.47962963 0.55       0.51296296]\n",
      "----------------------------------------\n",
      "Trial 284\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 20, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=20, random_state=100))])\n",
      "cv score: [0.77818182 0.54012346 0.59567901 0.7191358  0.68518519 0.41666667\n",
      " 0.21851852 0.48518519 0.46296296 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 285\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 42, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=42,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63090909 0.44444444 0.51851852 0.7191358  0.44444444 0.45987654\n",
      " 0.65925926 0.38703704 0.55925926 0.42037037]\n",
      "----------------------------------------\n",
      "Trial 286\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 137, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=137,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58909091 0.40123457 0.54012346 0.72839506 0.54012346 0.49691358\n",
      " 0.3962963  0.32222222 0.58148148 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 287\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 178, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=178, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.52363636 0.38271605 0.53703704 0.87654321 0.63888889 0.5154321\n",
      " 0.3962963  0.41851852 0.51851852 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 288\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 193, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=193, random_state=100))])\n",
      "cv score: [0.66545455 0.45061728 0.63888889 0.74382716 0.62345679 0.61111111\n",
      " 0.34074074 0.27037037 0.54814815 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 289\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 67, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=67,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.71636364 0.47530864 0.56790123 0.61728395 0.61111111 0.5\n",
      " 0.35555556 0.28333333 0.53333333 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 290\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 112, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            n_estimators=112, random_state=100,\n",
      "                                            subsample=0.75))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62545455 0.4537037  0.70987654 0.68518519 0.69753086 0.40740741\n",
      " 0.18888889 0.57777778 0.61481481 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 291\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=7,\n",
      "                                            n_estimators=115, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.66545455 0.53395062 0.69444444 0.87654321 0.72222222 0.30246914\n",
      " 0.43703704 0.40740741 0.37777778 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 292\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 122, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=122,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63636364 0.44444444 0.54320988 0.54012346 0.44444444 0.46141975\n",
      " 0.62407407 0.40740741 0.48333333 0.40925926]\n",
      "----------------------------------------\n",
      "Trial 293\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54181818 0.38271605 0.47222222 0.70679012 0.53703704 0.54320988\n",
      " 0.55925926 0.47407407 0.43703704 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 294\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 141, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=141, random_state=100))])\n",
      "cv score: [0.65454545 0.48148148 0.56790123 0.83641975 0.75617284 0.51851852\n",
      " 0.34814815 0.40740741 0.51481481 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 295\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 76, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=76, random_state=100))])\n",
      "cv score: [0.64363636 0.39814815 0.62808642 0.85185185 0.68209877 0.55864198\n",
      " 0.36666667 0.40555556 0.46666667 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 296\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 67, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=67,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.2962963  0.75154321 0.51697531 0.7808642  0.55246914\n",
      " 0.45925926 0.38518519 0.51296296 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 297\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 29, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=29,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63272727 0.33024691 0.56790123 0.75308642 0.52777778 0.52777778\n",
      " 0.33703704 0.39259259 0.34814815 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 298\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 81, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=81,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60727273 0.5154321  0.52160494 0.54320988 0.50925926 0.5308642\n",
      " 0.61296296 0.39074074 0.56851852 0.47592593]\n",
      "----------------------------------------\n",
      "Trial 299\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 116, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(n_estimators=116, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.74181818 0.43518519 0.65740741 0.76234568 0.61419753 0.22530864\n",
      " 0.35555556 0.33703704 0.77777778 0.54814815]\n",
      "----------------------------------------\n",
      "Trial 300\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 140, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=140,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60727273 0.5154321  0.44444444 0.66358025 0.47222222 0.41049383\n",
      " 0.31111111 0.28518519 0.47777778 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 301\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 40, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=40,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72363636 0.41666667 0.77777778 0.61419753 0.56790123 0.4845679\n",
      " 0.51111111 0.32592593 0.6037037  0.57037037]\n",
      "----------------------------------------\n",
      "Trial 302\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72       0.43518519 0.56790123 0.73148148 0.58950617 0.46604938\n",
      " 0.29259259 0.42222222 0.43333333 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 303\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68363636 0.46604938 0.53703704 0.74382716 0.54012346 0.49074074\n",
      " 0.23333333 0.41481481 0.38518519 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 304\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 26, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=26,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.59272727 0.33024691 0.62037037 0.64506173 0.71296296 0.46604938\n",
      " 0.31481481 0.39259259 0.49259259 0.62592593]\n",
      "----------------------------------------\n",
      "Trial 305\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 182, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=182,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63272727 0.42901235 0.62345679 0.65123457 0.61728395 0.50617284\n",
      " 0.28518519 0.28888889 0.55185185 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 306\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=159,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.67272727 0.38271605 0.7345679  0.66666667 0.57407407 0.49691358\n",
      " 0.40740741 0.31481481 0.58148148 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 307\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 116, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=116,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65818182 0.39814815 0.75308642 0.64506173 0.57407407 0.45987654\n",
      " 0.40740741 0.32222222 0.57777778 0.57407407]\n",
      "----------------------------------------\n",
      "Trial 308\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 30, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=30,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.68363636 0.51388889 0.49691358 0.69135802 0.61111111 0.55401235\n",
      " 0.48703704 0.33148148 0.55740741 0.46851852]\n",
      "----------------------------------------\n",
      "Trial 309\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 92, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=92,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.7        0.59876543 0.52469136 0.52777778 0.51697531 0.56790123\n",
      " 0.59444444 0.42962963 0.5962963  0.50925926]\n",
      "----------------------------------------\n",
      "Trial 310\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=178, random_state=100))])\n",
      "cv score: [0.65454545 0.39814815 0.54320988 0.74074074 0.6882716  0.48148148\n",
      " 0.36296296 0.42592593 0.54074074 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 311\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=95, random_state=100,\n",
      "                                            subsample=0.75))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.54909091 0.54938272 0.60802469 0.49691358 0.49382716 0.51080247\n",
      " 0.47222222 0.55925926 0.38888889 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 312\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 24, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=24,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.64727273 0.33641975 0.66049383 0.77469136 0.60802469 0.52777778\n",
      " 0.43333333 0.24074074 0.49444444 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 313\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 180, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=180, random_state=100))])\n",
      "cv score: [0.66181818 0.40432099 0.64814815 0.81790123 0.66666667 0.49691358\n",
      " 0.40740741 0.40740741 0.51111111 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 314\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62909091 0.48765432 0.55092593 0.66975309 0.54166667 0.66975309\n",
      " 0.47777778 0.48888889 0.54444444 0.61111111]\n",
      "----------------------------------------\n",
      "Trial 315\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.64       0.36728395 0.74074074 0.8117284  0.72222222 0.44444444\n",
      " 0.42592593 0.5037037  0.53703704 0.37407407]\n",
      "----------------------------------------\n",
      "Trial 316\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 32, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=32,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.78545455 0.55555556 0.53240741 0.58950617 0.61111111 0.50308642\n",
      " 0.50925926 0.42222222 0.58518519 0.47962963]\n",
      "----------------------------------------\n",
      "Trial 317\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 96, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=96, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.61090909 0.45987654 0.63580247 0.80864198 0.61728395 0.48765432\n",
      " 0.44444444 0.45185185 0.47777778 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 318\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 77, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=77,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57454545 0.58641975 0.47993827 0.67283951 0.49228395 0.5617284\n",
      " 0.53148148 0.41111111 0.60555556 0.60925926]\n",
      "----------------------------------------\n",
      "Trial 319\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 16, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=16,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.67636364 0.41358025 0.63271605 0.75617284 0.58333333 0.50617284\n",
      " 0.32222222 0.30740741 0.54814815 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 320\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 164, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            n_estimators=164, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.77454545 0.47530864 0.63888889 0.6882716  0.58950617 0.19444444\n",
      " 0.28148148 0.28148148 0.66296296 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 321\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.68       0.37037037 0.54012346 0.62191358 0.53395062 0.47222222\n",
      " 0.52222222 0.3037037  0.58888889 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 322\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 192, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=192,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70545455 0.39506173 0.63271605 0.6882716  0.64506173 0.53395062\n",
      " 0.4        0.37777778 0.6        0.59259259]\n",
      "----------------------------------------\n",
      "Trial 323\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 113, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=113, random_state=100))])\n",
      "cv score: [0.72363636 0.37654321 0.62654321 0.85802469 0.66666667 0.61111111\n",
      " 0.35925926 0.37407407 0.52222222 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 324\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.86909091 0.32098765 0.5462963  0.50308642 0.61111111 0.48765432\n",
      " 0.22222222 0.43703704 0.76296296 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 325\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=108, random_state=100))])\n",
      "cv score: [0.8        0.53395062 0.59259259 0.79320988 0.62345679 0.50925926\n",
      " 0.24444444 0.26296296 0.6        0.5       ]\n",
      "----------------------------------------\n",
      "Trial 326\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=58, random_state=100))])\n",
      "cv score: [0.67272727 0.36728395 0.66666667 0.82098765 0.66666667 0.58333333\n",
      " 0.35555556 0.45185185 0.52592593 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 327\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 39, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=39,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60181818 0.53240741 0.5154321  0.54012346 0.49382716 0.54938272\n",
      " 0.62037037 0.23888889 0.59074074 0.5962963 ]\n",
      "----------------------------------------\n",
      "Trial 328\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 139, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=139,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.76363636 0.37345679 0.46296296 0.64197531 0.44135802 0.48765432\n",
      " 0.24814815 0.4        0.53333333 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 329\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 158, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=158, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.62545455 0.50308642 0.58024691 0.75617284 0.62962963 0.5308642\n",
      " 0.37037037 0.52592593 0.45185185 0.45555556]\n",
      "----------------------------------------\n",
      "Trial 330\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 85, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=85, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.73454545 0.48148148 0.63888889 0.80555556 0.58641975 0.40123457\n",
      " 0.34444444 0.37037037 0.46296296 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 331\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 103, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=103,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65818182 0.39506173 0.5617284  0.7808642  0.61728395 0.50617284\n",
      " 0.44444444 0.33703704 0.4962963  0.62962963]\n",
      "----------------------------------------\n",
      "Trial 332\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 82, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=82, random_state=100,\n",
      "                                            subsample=0.75))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67272727 0.50308642 0.4382716  0.6882716  0.54938272 0.39814815\n",
      " 0.43703704 0.39814815 0.42222222 0.32222222]\n",
      "----------------------------------------\n",
      "Trial 333\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57818182 0.46296296 0.55246914 0.47222222 0.44444444 0.5308642\n",
      " 0.60740741 0.40740741 0.49074074 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 334\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 138, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=138, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.68363636 0.59722222 0.56635802 0.62345679 0.60185185 0.50154321\n",
      " 0.46666667 0.34814815 0.48888889 0.48518519]\n",
      "----------------------------------------\n",
      "Trial 335\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 176, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=176, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.62181818 0.37037037 0.71604938 0.8117284  0.7345679  0.51851852\n",
      " 0.4037037  0.36666667 0.48888889 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 336\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 191, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=191,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73636364 0.55401235 0.57716049 0.67438272 0.58796296 0.47376543\n",
      " 0.47407407 0.34444444 0.55555556 0.49814815]\n",
      "----------------------------------------\n",
      "Trial 337\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 31, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=31,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73090909 0.44907407 0.54166667 0.52006173 0.45987654 0.64197531\n",
      " 0.61111111 0.42962963 0.62962963 0.39259259]\n",
      "----------------------------------------\n",
      "Trial 338\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 195, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=195,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.76       0.40740741 0.51234568 0.66666667 0.52777778 0.32098765\n",
      " 0.27777778 0.36666667 0.54074074 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 339\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.62545455 0.37654321 0.70987654 0.75617284 0.67901235 0.49074074\n",
      " 0.41481481 0.27037037 0.6        0.47407407]\n",
      "----------------------------------------\n",
      "Trial 340\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 73, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=73,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61454545 0.42901235 0.45679012 0.6882716  0.49074074 0.42283951\n",
      " 0.34814815 0.31111111 0.5037037  0.48148148]\n",
      "----------------------------------------\n",
      "Trial 341\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.59636364 0.38580247 0.5617284  0.72222222 0.53703704 0.53703704\n",
      " 0.4962963  0.32962963 0.6        0.53333333]\n",
      "----------------------------------------\n",
      "Trial 342\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 45, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=45,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76       0.41049383 0.65740741 0.65740741 0.63888889 0.5\n",
      " 0.4037037  0.27777778 0.69259259 0.70740741]\n",
      "----------------------------------------\n",
      "Trial 343\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 47, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=47,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62       0.59259259 0.52623457 0.5462963  0.47530864 0.60648148\n",
      " 0.6037037  0.42407407 0.58888889 0.46851852]\n",
      "----------------------------------------\n",
      "Trial 344\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58909091 0.34876543 0.5        0.76851852 0.64506173 0.50617284\n",
      " 0.27407407 0.31851852 0.52222222 0.51851852]\n",
      "----------------------------------------\n",
      "Trial 345\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=81, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.64       0.39197531 0.66358025 0.76851852 0.63888889 0.60802469\n",
      " 0.3962963  0.36666667 0.57037037 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 346\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 188, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=188, random_state=100))])\n",
      "cv score: [0.69818182 0.39814815 0.63271605 0.81790123 0.65432099 0.54938272\n",
      " 0.32962963 0.42222222 0.5037037  0.46666667]\n",
      "----------------------------------------\n",
      "Trial 347\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 33, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=33, random_state=100))])\n",
      "cv score: [0.77454545 0.48148148 0.66820988 0.86728395 0.70833333 0.64197531\n",
      " 0.37777778 0.38703704 0.45740741 0.54074074]\n",
      "----------------------------------------\n",
      "Trial 348\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 104, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=2,\n",
      "                                            n_estimators=104, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.67272727 0.50308642 0.57407407 0.68209877 0.67283951 0.58024691\n",
      " 0.33703704 0.37777778 0.63703704 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 349\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 123, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=9,\n",
      "                                            n_estimators=123, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.67636364 0.37654321 0.63888889 0.73148148 0.70061728 0.34567901\n",
      " 0.45555556 0.36666667 0.3        0.45185185]\n",
      "----------------------------------------\n",
      "Trial 350\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=95, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.77818182 0.42901235 0.66049383 0.62654321 0.56790123 0.44753086\n",
      " 0.4037037  0.40740741 0.48518519 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 351\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 24, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=24, random_state=100))])\n",
      "cv score: [0.71272727 0.30864198 0.69753086 0.80555556 0.58641975 0.62654321\n",
      " 0.37037037 0.50740741 0.5037037  0.58518519]\n",
      "----------------------------------------\n",
      "Trial 352\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 119, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=119,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.73090909 0.35493827 0.59876543 0.74382716 0.64506173 0.49382716\n",
      " 0.35925926 0.41851852 0.3962963  0.45555556]\n",
      "----------------------------------------\n",
      "Trial 353\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 78, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=78, random_state=100))])\n",
      "cv score: [0.76       0.66049383 0.63271605 0.68518519 0.57098765 0.48765432\n",
      " 0.47407407 0.26666667 0.42592593 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 354\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 123, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=123,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64       0.4537037  0.54320988 0.65432099 0.5462963  0.47530864\n",
      " 0.5        0.3        0.5962963  0.55185185]\n",
      "----------------------------------------\n",
      "Trial 355\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 157, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=157,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63272727 0.35185185 0.64814815 0.73765432 0.60493827 0.4845679\n",
      " 0.35555556 0.2962963  0.59259259 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 356\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 74, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=74,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66363636 0.59722222 0.62037037 0.45987654 0.62962963 0.52932099\n",
      " 0.52222222 0.25740741 0.37962963 0.8537037 ]\n",
      "----------------------------------------\n",
      "Trial 357\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 97, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=97,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63636364 0.30246914 0.53703704 0.73148148 0.46604938 0.58024691\n",
      " 0.40740741 0.51481481 0.52222222 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 358\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 162, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            n_estimators=162, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.6        0.4537037  0.67592593 0.78395062 0.71604938 0.51851852\n",
      " 0.3        0.33333333 0.43703704 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 359\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64727273 0.51851852 0.49074074 0.62654321 0.45061728 0.53703704\n",
      " 0.52962963 0.1962963  0.62592593 0.48703704]\n",
      "----------------------------------------\n",
      "Trial 360\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.69818182 0.38271605 0.62654321 0.78703704 0.71604938 0.50308642\n",
      " 0.32592593 0.35925926 0.56666667 0.54814815]\n",
      "----------------------------------------\n",
      "Trial 361\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=197, random_state=100))])\n",
      "cv score: [0.59636364 0.40740741 0.63888889 0.77160494 0.65740741 0.54012346\n",
      " 0.31111111 0.43333333 0.48518519 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 362\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 155, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=155,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.74909091 0.37654321 0.54012346 0.6882716  0.65432099 0.42592593\n",
      " 0.34074074 0.42592593 0.5037037  0.45555556]\n",
      "----------------------------------------\n",
      "Trial 363\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 22, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=22,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.69636364 0.5        0.49228395 0.65895062 0.58796296 0.52469136\n",
      " 0.46851852 0.33148148 0.56296296 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 364\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 181, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=181, random_state=100))])\n",
      "cv score: [0.68       0.41358025 0.62962963 0.75308642 0.64197531 0.57407407\n",
      " 0.35555556 0.30740741 0.55555556 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 365\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 37, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=37,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61818182 0.37962963 0.6882716  0.64197531 0.66203704 0.53703704\n",
      " 0.44444444 0.2962963  0.60740741 0.61111111]\n",
      "----------------------------------------\n",
      "Trial 366\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 162, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=162,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66545455 0.32098765 0.52160494 0.75       0.61419753 0.49691358\n",
      " 0.35555556 0.36666667 0.46296296 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 367\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 138, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            n_estimators=138, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.56727273 0.48148148 0.65740741 0.83333333 0.66358025 0.5462963\n",
      " 0.35185185 0.39259259 0.54814815 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 368\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 153, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=153,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.35185185 0.5617284  0.70679012 0.58024691 0.38271605\n",
      " 0.2962963  0.36666667 0.53333333 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 369\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 122, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=122,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66545455 0.3117284  0.58333333 0.73148148 0.54320988 0.52160494\n",
      " 0.26296296 0.35185185 0.4962963  0.38518519]\n",
      "----------------------------------------\n",
      "Trial 370\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 107, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=107, random_state=100))])\n",
      "cv score: [0.70545455 0.42283951 0.66666667 0.85493827 0.69135802 0.57098765\n",
      " 0.32962963 0.47777778 0.52592593 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 371\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 188, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=188,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.72       0.37345679 0.59876543 0.65123457 0.58333333 0.48148148\n",
      " 0.3        0.45185185 0.37777778 0.35555556]\n",
      "----------------------------------------\n",
      "Trial 372\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 173, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='log2',\n",
      "                                            n_estimators=173, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.77818182 0.41049383 0.67283951 0.7808642  0.65123457 0.35185185\n",
      " 0.4037037  0.41111111 0.65555556 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 373\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.76727273 0.39197531 0.62345679 0.72530864 0.64814815 0.47530864\n",
      " 0.24814815 0.36666667 0.48148148 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 374\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=159,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.71454545 0.5787037  0.43055556 0.47222222 0.51851852 0.54012346\n",
      " 0.52222222 0.17592593 0.49444444 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 375\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 64, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=64,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.67636364 0.36111111 0.56790123 0.62654321 0.70679012 0.62654321\n",
      " 0.45555556 0.55185185 0.41111111 0.54074074]\n",
      "----------------------------------------\n",
      "Trial 376\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69090909 0.44753086 0.62037037 0.64197531 0.65432099 0.35802469\n",
      " 0.4        0.41111111 0.45555556 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 377\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 41, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=41,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.78545455 0.57098765 0.51080247 0.62962963 0.62808642 0.49691358\n",
      " 0.52222222 0.42222222 0.5537037  0.47962963]\n",
      "----------------------------------------\n",
      "Trial 378\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.67272727 0.4382716  0.62654321 0.80555556 0.58333333 0.48148148\n",
      " 0.40740741 0.2962963  0.54074074 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 379\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 24, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=24, random_state=100))])\n",
      "cv score: [0.59272727 0.42901235 0.63271605 0.60185185 0.59876543 0.54320988\n",
      " 0.48148148 0.06296296 0.51111111 0.65925926]\n",
      "----------------------------------------\n",
      "Trial 380\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 72, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=72,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.2962963  0.75154321 0.51697531 0.7808642  0.55246914\n",
      " 0.45925926 0.35185185 0.51296296 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 381\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 135, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            n_estimators=135, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.56363636 0.41975309 0.74074074 0.76851852 0.75       0.5\n",
      " 0.43333333 0.37037037 0.45185185 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 382\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 53, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=53,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.63636364 0.46604938 0.51851852 0.58333333 0.58950617 0.4691358\n",
      " 0.39259259 0.33703704 0.57777778 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 383\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 36, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=36,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64363636 0.50308642 0.57407407 0.55555556 0.64814815 0.55555556\n",
      " 0.44444444 0.34259259 0.55925926 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 384\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 130, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=130,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.51851852 0.37962963 0.47222222 0.50925926 0.47685185\n",
      " 0.5        0.46296296 0.47222222 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 385\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 39, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=39,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70909091 0.34567901 0.5462963  0.62345679 0.56018519 0.48148148\n",
      " 0.45555556 0.21481481 0.6037037  0.46296296]\n",
      "----------------------------------------\n",
      "Trial 386\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 63, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=63, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.64363636 0.29938272 0.63888889 0.83641975 0.64814815 0.53395062\n",
      " 0.36666667 0.37777778 0.57777778 0.55555556]\n",
      "----------------------------------------\n",
      "Trial 387\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 28, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=28,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.77454545 0.53395062 0.60185185 0.64506173 0.40740741 0.48765432\n",
      " 0.37777778 0.30740741 0.56296296 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 388\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 156, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=156,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74181818 0.29938272 0.59259259 0.76851852 0.65432099 0.50617284\n",
      " 0.41111111 0.41481481 0.48148148 0.34444444]\n",
      "----------------------------------------\n",
      "Trial 389\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 189, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            n_estimators=189, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.70181818 0.34259259 0.66666667 0.77469136 0.71604938 0.59259259\n",
      " 0.42592593 0.22592593 0.54444444 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 390\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 188, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=188,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.76       0.38888889 0.60185185 0.74382716 0.61111111 0.48148148\n",
      " 0.37037037 0.45185185 0.51481481 0.35925926]\n",
      "----------------------------------------\n",
      "Trial 391\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 84, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            n_estimators=84,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.58       0.47530864 0.72530864 0.49845679 0.61574074 0.51697531\n",
      " 0.42407407 0.34259259 0.41481481 0.61851852]\n",
      "----------------------------------------\n",
      "Trial 392\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 143, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=143,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65818182 0.51234568 0.61111111 0.7962963  0.57716049 0.63580247\n",
      " 0.45555556 0.41481481 0.45555556 0.37777778]\n",
      "----------------------------------------\n",
      "Trial 393\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 106, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=106,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69090909 0.52777778 0.50462963 0.52777778 0.46450617 0.57561728\n",
      " 0.53888889 0.43703704 0.62037037 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 394\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 178, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=178,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63272727 0.41666667 0.43518519 0.62037037 0.39814815 0.37654321\n",
      " 0.29259259 0.28518519 0.57407407 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 395\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            n_estimators=99,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.54       0.34259259 0.72530864 0.65123457 0.75       0.53240741\n",
      " 0.62962963 0.32037037 0.62037037 0.58703704]\n",
      "----------------------------------------\n",
      "Trial 396\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 66, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            n_estimators=66, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.65454545 0.48765432 0.59876543 0.78395062 0.67283951 0.52469136\n",
      " 0.3962963  0.27777778 0.51111111 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 397\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 42, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=42,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58545455 0.49074074 0.5308642  0.59876543 0.61111111 0.4537037\n",
      " 0.32592593 0.32222222 0.45925926 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 398\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 107, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, max_features='log2',\n",
      "                                            n_estimators=107, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.70181818 0.41049383 0.71604938 0.76851852 0.65740741 0.43518519\n",
      " 0.47407407 0.38888889 0.45555556 0.3962963 ]\n",
      "----------------------------------------\n",
      "Trial 399\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 123, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=123,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66181818 0.35493827 0.69753086 0.7191358  0.63271605 0.5\n",
      " 0.4        0.33703704 0.63333333 0.64074074]\n",
      "----------------------------------------\n",
      "Trial 400\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61090909 0.44444444 0.51234568 0.54012346 0.44444444 0.46141975\n",
      " 0.60555556 0.3962963  0.50740741 0.59074074]\n",
      "----------------------------------------\n",
      "Trial 401\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 131, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=131,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.77454545 0.35493827 0.56481481 0.66358025 0.59567901 0.4691358\n",
      " 0.28518519 0.38518519 0.45925926 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 402\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 163, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=163, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.65818182 0.46296296 0.72530864 0.70987654 0.72222222 0.36111111\n",
      " 0.38148148 0.38148148 0.57037037 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 403\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 22, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=22, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.36       0.62037037 0.41358025 0.53395062 0.53703704 0.15123457\n",
      " 0.37407407 0.50740741 0.40740741 0.30740741]\n",
      "----------------------------------------\n",
      "Trial 404\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=58, random_state=100))])\n",
      "cv score: [0.70181818 0.59259259 0.59567901 0.65432099 0.59567901 0.57253086\n",
      " 0.36666667 0.31111111 0.53703704 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 405\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 93, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=93, random_state=100))])\n",
      "cv score: [0.71636364 0.45061728 0.57716049 0.76234568 0.77777778 0.50308642\n",
      " 0.30740741 0.41481481 0.55555556 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 406\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='log2',\n",
      "                                            n_estimators=81,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.67272727 0.40432099 0.63888889 0.64814815 0.59259259 0.36419753\n",
      " 0.31851852 0.42592593 0.54074074 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 407\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.70909091 0.45987654 0.72222222 0.82098765 0.75308642 0.55864198\n",
      " 0.45925926 0.41851852 0.42592593 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 408\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.58181818 0.34876543 0.71604938 0.6882716  0.70987654 0.37962963\n",
      " 0.39259259 0.41851852 0.48888889 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 409\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 87, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=87, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.57090909 0.58024691 0.45061728 0.47839506 0.7654321  0.5308642\n",
      " 0.42592593 0.42222222 0.37777778 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 410\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 53, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=53,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.6        0.47530864 0.70833333 0.57407407 0.63734568 0.55555556\n",
      " 0.59814815 0.45555556 0.41481481 0.60740741]\n",
      "----------------------------------------\n",
      "Trial 411\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            random_state=100, subsample=0.7))])\n",
      "cv score: [0.59272727 0.44135802 0.65432099 0.58950617 0.67901235 0.50925926\n",
      " 0.4        0.41851852 0.32592593 0.34814815]\n",
      "----------------------------------------\n",
      "Trial 412\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 31, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=31,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63090909 0.53395062 0.60339506 0.75771605 0.58950617 0.52469136\n",
      " 0.31111111 0.28518519 0.58888889 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 413\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 142, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=142, random_state=100))])\n",
      "cv score: [0.72363636 0.41049383 0.66666667 0.86111111 0.67283951 0.57098765\n",
      " 0.35185185 0.44444444 0.46296296 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 414\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 164, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=164, random_state=100))])\n",
      "cv score: [0.69454545 0.4537037  0.60802469 0.8117284  0.70061728 0.5462963\n",
      " 0.38888889 0.36666667 0.58518519 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 415\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 92, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=92,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71636364 0.48765432 0.61419753 0.85185185 0.64506173 0.40740741\n",
      " 0.32592593 0.47777778 0.54814815 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 416\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 80, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=80,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68       0.56790123 0.66049383 0.63888889 0.50617284 0.47530864\n",
      " 0.25555556 0.5        0.63703704 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 417\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 161, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=161, random_state=100))])\n",
      "cv score: [0.73454545 0.38888889 0.63580247 0.84876543 0.66049383 0.54320988\n",
      " 0.34814815 0.37407407 0.51481481 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 418\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 167, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=167, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.67272727 0.33641975 0.66049383 0.82716049 0.73765432 0.5462963\n",
      " 0.38148148 0.34074074 0.58148148 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 419\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 149, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=149,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65090909 0.34876543 0.64506173 0.73148148 0.60493827 0.4845679\n",
      " 0.33703704 0.29259259 0.6037037  0.53333333]\n",
      "----------------------------------------\n",
      "Trial 420\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 131, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=131, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.43636364 0.31790123 0.85493827 0.42901235 0.68518519 0.38271605\n",
      " 0.28888889 0.18518519 0.44074074 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 421\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 130, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=130, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.62181818 0.41975309 0.75       0.7654321  0.70061728 0.4691358\n",
      " 0.42222222 0.34074074 0.57407407 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 422\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 39, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=39,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66909091 0.47222222 0.44444444 0.58950617 0.48148148 0.4691358\n",
      " 0.45185185 0.38148148 0.6        0.46666667]\n",
      "----------------------------------------\n",
      "Trial 423\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 141, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=141,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.75272727 0.42283951 0.49691358 0.74382716 0.52469136 0.53395062\n",
      " 0.4        0.43333333 0.53703704 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 424\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 151, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=151,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65818182 0.34876543 0.66975309 0.7037037  0.62345679 0.5\n",
      " 0.45185185 0.34444444 0.62962963 0.66296296]\n",
      "----------------------------------------\n",
      "Trial 425\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 60, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=60, random_state=100))])\n",
      "cv score: [0.74545455 0.58641975 0.48765432 0.61419753 0.57561728 0.49691358\n",
      " 0.50740741 0.28888889 0.46666667 0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 426\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=2,\n",
      "                                            n_estimators=91, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.74181818 0.54320988 0.55864198 0.65895062 0.6095679  0.54012346\n",
      " 0.51666667 0.33703704 0.40925926 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 427\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 17, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=17, random_state=100))])\n",
      "cv score: [0.63272727 0.4367284  0.63271605 0.75       0.72067901 0.5462963\n",
      " 0.47037037 0.33703704 0.51666667 0.54259259]\n",
      "----------------------------------------\n",
      "Trial 428\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 106, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=106,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.64727273 0.50925926 0.77160494 0.75925926 0.72530864 0.39814815\n",
      " 0.5037037  0.45185185 0.54814815 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 429\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 131, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=131, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.54909091 0.41975309 0.57407407 0.82716049 0.69753086 0.58950617\n",
      " 0.42222222 0.53703704 0.39259259 0.39259259]\n",
      "----------------------------------------\n",
      "Trial 430\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 99, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=99,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70363636 0.60648148 0.52160494 0.52469136 0.52623457 0.57098765\n",
      " 0.55740741 0.42777778 0.5962963  0.52222222]\n",
      "----------------------------------------\n",
      "Trial 431\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 131, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=131,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64       0.37345679 0.55864198 0.75       0.62962963 0.5308642\n",
      " 0.31851852 0.41851852 0.54814815 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 432\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 172, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=172,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.77454545 0.38271605 0.60493827 0.80246914 0.62345679 0.48148148\n",
      " 0.35555556 0.61111111 0.58148148 0.4       ]\n",
      "----------------------------------------\n",
      "Trial 433\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 116, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=116,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63818182 0.46296296 0.61574074 0.54012346 0.4537037  0.5308642\n",
      " 0.63888889 0.40740741 0.58518519 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 434\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 150, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=150,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68727273 0.38271605 0.51234568 0.69753086 0.68518519 0.49074074\n",
      " 0.34074074 0.44074074 0.52592593 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 435\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 19, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=19,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57454545 0.5617284  0.60802469 0.56790123 0.52160494 0.43518519\n",
      " 0.28518519 0.35925926 0.61111111 0.67037037]\n",
      "----------------------------------------\n",
      "Trial 436\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 110, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=110,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.61454545 0.37345679 0.63888889 0.74691358 0.65123457 0.53703704\n",
      " 0.31481481 0.30740741 0.52222222 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 437\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56       0.37345679 0.53395062 0.66358025 0.56481481 0.49691358\n",
      " 0.37407407 0.31851852 0.61851852 0.58888889]\n",
      "----------------------------------------\n",
      "Trial 438\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 136, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=136, random_state=100))])\n",
      "cv score: [0.68       0.36728395 0.61728395 0.88580247 0.74382716 0.54320988\n",
      " 0.38888889 0.41111111 0.49259259 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 439\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63818182 0.48148148 0.52006173 0.54012346 0.4537037  0.46141975\n",
      " 0.53518519 0.38333333 0.59444444 0.42037037]\n",
      "----------------------------------------\n",
      "Trial 440\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 131, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=131,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.70545455 0.41666667 0.52160494 0.7654321  0.5462963  0.42901235\n",
      " 0.32592593 0.38888889 0.54444444 0.38148148]\n",
      "----------------------------------------\n",
      "Trial 441\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 54, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=54,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62909091 0.36419753 0.55864198 0.7191358  0.54012346 0.47530864\n",
      " 0.37777778 0.26666667 0.61851852 0.57407407]\n",
      "----------------------------------------\n",
      "Trial 442\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 50, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=50, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.65090909 0.27777778 0.67901235 0.69444444 0.7191358  0.4845679\n",
      " 0.34814815 0.4        0.64074074 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 443\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 169, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=169, random_state=100))])\n",
      "cv score: [0.68       0.40432099 0.66666667 0.82407407 0.66975309 0.50617284\n",
      " 0.4        0.41481481 0.51111111 0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 444\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=178, random_state=100))])\n",
      "cv score: [0.67272727 0.36728395 0.60185185 0.86728395 0.72222222 0.5462963\n",
      " 0.40740741 0.43703704 0.52592593 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 445\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 132, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=132,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64727273 0.39814815 0.74382716 0.65123457 0.58950617 0.4691358\n",
      " 0.38888889 0.29259259 0.58888889 0.58518519]\n",
      "----------------------------------------\n",
      "Trial 446\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 27, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=27,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66909091 0.35493827 0.50308642 0.6882716  0.63271605 0.46296296\n",
      " 0.35185185 0.21851852 0.47407407 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 447\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 48, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=48, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.70181818 0.38888889 0.63271605 0.6882716  0.60493827 0.39814815\n",
      " 0.24814815 0.38888889 0.34814815 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 448\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.80363636 0.38580247 0.54320988 0.80864198 0.51234568 0.49691358\n",
      " 0.31481481 0.54444444 0.57037037 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 449\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 37, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=37, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.70545455 0.42592593 0.69135802 0.76234568 0.66666667 0.59567901\n",
      " 0.32962963 0.32222222 0.43333333 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 450\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 179, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, max_features='sqrt',\n",
      "                                            n_estimators=179, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62545455 0.49382716 0.6882716  0.71296296 0.56790123 0.48148148\n",
      " 0.3962963  0.41111111 0.35185185 0.34814815]\n",
      "----------------------------------------\n",
      "Trial 451\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 157, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=157,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.69818182 0.46604938 0.65123457 0.78703704 0.70987654 0.39814815\n",
      " 0.37407407 0.37407407 0.51111111 0.35555556]\n",
      "----------------------------------------\n",
      "Trial 452\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 118, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=118,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72363636 0.50925926 0.37962963 0.47222222 0.50925926 0.5\n",
      " 0.47222222 0.46296296 0.42407407 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 453\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 57, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=57, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.64363636 0.44135802 0.72222222 0.68518519 0.61111111 0.35185185\n",
      " 0.3037037  0.37037037 0.57407407 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 454\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 179, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=179, random_state=100))])\n",
      "cv score: [0.66181818 0.45679012 0.57098765 0.81790123 0.75308642 0.52160494\n",
      " 0.32962963 0.42592593 0.53333333 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 455\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 119, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=119,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71272727 0.38888889 0.53703704 0.70061728 0.54320988 0.49074074\n",
      " 0.28888889 0.25555556 0.47037037 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 456\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 121, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=121,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70909091 0.47530864 0.57407407 0.66666667 0.60802469 0.51234568\n",
      " 0.34444444 0.29259259 0.53333333 0.51851852]\n",
      "----------------------------------------\n",
      "Trial 457\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 134, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=134,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6        0.47530864 0.70833333 0.57407407 0.63734568 0.55246914\n",
      " 0.59814815 0.45185185 0.41481481 0.6037037 ]\n",
      "----------------------------------------\n",
      "Trial 458\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 33, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=33, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.69454545 0.50617284 0.57407407 0.72685185 0.69907407 0.40740741\n",
      " 0.3462963  0.32407407 0.45925926 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 459\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6        0.42901235 0.53703704 0.81481481 0.54012346 0.60185185\n",
      " 0.4037037  0.52962963 0.31481481 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 460\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 74, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=74,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61818182 0.2808642  0.55864198 0.61111111 0.60185185 0.55246914\n",
      " 0.42222222 0.24074074 0.60740741 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 461\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 117, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=117,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61090909 0.45987654 0.54012346 0.66358025 0.48765432 0.56481481\n",
      " 0.47407407 0.34074074 0.62222222 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 462\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 175, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=175,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.80545455 0.61728395 0.55401235 0.67901235 0.62962963 0.48148148\n",
      " 0.50555556 0.38518519 0.56296296 0.46111111]\n",
      "----------------------------------------\n",
      "Trial 463\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 99, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=99,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73454545 0.4845679  0.53703704 0.87654321 0.52469136 0.52777778\n",
      " 0.32592593 0.35185185 0.57037037 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 464\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 131, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=131,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66181818 0.35493827 0.66666667 0.75617284 0.67283951 0.52469136\n",
      " 0.44814815 0.38888889 0.57407407 0.64074074]\n",
      "----------------------------------------\n",
      "Trial 465\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 10, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            n_estimators=10, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.74545455 0.34567901 0.65123457 0.73765432 0.64506173 0.53703704\n",
      " 0.36666667 0.4037037  0.62592593 0.71851852]\n",
      "----------------------------------------\n",
      "Trial 466\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 45, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=45,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.39197531 0.58024691 0.69753086 0.58641975 0.46604938\n",
      " 0.36296296 0.25185185 0.55185185 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 467\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.57818182 0.40432099 0.58333333 0.7191358  0.58641975 0.37037037\n",
      " 0.43703704 0.48148148 0.38148148 0.37777778]\n",
      "----------------------------------------\n",
      "Trial 468\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=102, random_state=100))])\n",
      "cv score: [0.67272727 0.47839506 0.60493827 0.78703704 0.66975309 0.4691358\n",
      " 0.32962963 0.39259259 0.51111111 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 469\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 48, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=48,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.54545455 0.58024691 0.48611111 0.68518519 0.45061728 0.52469136\n",
      " 0.56851852 0.43148148 0.62407407 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 470\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 191, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=191,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73454545 0.36419753 0.53703704 0.7345679  0.62037037 0.52469136\n",
      " 0.3962963  0.43703704 0.50740741 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 471\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 33, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=33,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67272727 0.33024691 0.52160494 0.70987654 0.54938272 0.48765432\n",
      " 0.36296296 0.5037037  0.6        0.42222222]\n",
      "----------------------------------------\n",
      "Trial 472\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 30, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=30, random_state=100))])\n",
      "cv score: [0.78363636 0.48765432 0.66820988 0.86574074 0.6867284  0.625\n",
      " 0.30925926 0.39814815 0.44074074 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 473\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 179, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=179, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.64727273 0.34259259 0.69444444 0.8117284  0.75925926 0.52160494\n",
      " 0.38518519 0.40740741 0.5        0.49259259]\n",
      "----------------------------------------\n",
      "Trial 474\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 155, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=155, random_state=100))])\n",
      "cv score: [0.68727273 0.5154321  0.62345679 0.66975309 0.52160494 0.47222222\n",
      " 0.27037037 0.31111111 0.56666667 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 475\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 33, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            n_estimators=33, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.67636364 0.49382716 0.73148148 0.77777778 0.79012346 0.50617284\n",
      " 0.41481481 0.2962963  0.54814815 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 476\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 61, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=61,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63272727 0.32716049 0.53395062 0.64814815 0.58024691 0.49074074\n",
      " 0.35925926 0.28148148 0.64074074 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 477\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 27, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=27, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.68363636 0.45987654 0.55864198 0.7962963  0.52160494 0.37962963\n",
      " 0.42962963 0.2962963  0.52962963 0.59259259]\n",
      "----------------------------------------\n",
      "Trial 478\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.74909091 0.33641975 0.68209877 0.78395062 0.66358025 0.52160494\n",
      " 0.42962963 0.37037037 0.51851852 0.63333333]\n",
      "----------------------------------------\n",
      "Trial 479\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 80, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=80, random_state=100,\n",
      "                                            subsample=0.75))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61454545 0.51851852 0.70061728 0.63271605 0.44135802 0.25925926\n",
      " 0.56296296 0.53703704 0.38518519 0.22222222]\n",
      "----------------------------------------\n",
      "Trial 480\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 11, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=11,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6        0.47530864 0.71141975 0.57407407 0.63734568 0.56018519\n",
      " 0.59814815 0.45185185 0.41481481 0.60555556]\n",
      "----------------------------------------\n",
      "Trial 481\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66545455 0.36111111 0.56790123 0.71296296 0.60185185 0.47222222\n",
      " 0.25555556 0.31111111 0.52962963 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 482\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 157, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=157, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.73818182 0.50617284 0.63580247 0.7191358  0.58333333 0.43518519\n",
      " 0.27407407 0.32592593 0.48148148 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 483\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 64, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            n_estimators=64, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.48727273 0.43518519 0.67901235 0.69135802 0.69753086 0.35802469\n",
      " 0.44074074 0.3962963  0.47777778 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 484\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 175, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=175,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73272727 0.56018519 0.57407407 0.68055556 0.59567901 0.47376543\n",
      " 0.45185185 0.34074074 0.55925926 0.50555556]\n",
      "----------------------------------------\n",
      "Trial 485\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 92, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=92,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60363636 0.4845679  0.56790123 0.66820988 0.58950617 0.52006173\n",
      " 0.4962963  0.25740741 0.71111111 0.58148148]\n",
      "----------------------------------------\n",
      "Trial 486\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 67, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=67, random_state=100))])\n",
      "cv score: [0.73454545 0.37962963 0.62808642 0.83333333 0.66049383 0.56790123\n",
      " 0.30740741 0.4037037  0.55185185 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 487\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 178, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=178,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69454545 0.36728395 0.50617284 0.73148148 0.57098765 0.47530864\n",
      " 0.35555556 0.45555556 0.53703704 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 488\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 153, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=153,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.59090909 0.46296296 0.52006173 0.5462963  0.54938272 0.48765432\n",
      " 0.57222222 0.3        0.62962963 0.49444444]\n",
      "----------------------------------------\n",
      "Trial 489\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 118, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=118,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73636364 0.54166667 0.56790123 0.68518519 0.60339506 0.49074074\n",
      " 0.47037037 0.32962963 0.52592593 0.52407407]\n",
      "----------------------------------------\n",
      "Trial 490\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=2, n_estimators=183,\n",
      "                                            random_state=100, subsample=0.8))])\n",
      "cv score: [0.76       0.45061728 0.65123457 0.72222222 0.54012346 0.25925926\n",
      " 0.22592593 0.36296296 0.71851852 0.60740741]\n",
      "----------------------------------------\n",
      "Trial 491\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 18, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=18,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57818182 0.4537037  0.52777778 0.66049383 0.50925926 0.5308642\n",
      " 0.50740741 0.24814815 0.57407407 0.62222222]\n",
      "----------------------------------------\n",
      "Trial 492\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 20, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=20,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65272727 0.57716049 0.49228395 0.54012346 0.41203704 0.57561728\n",
      " 0.55555556 0.36666667 0.47407407 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 493\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 194, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=194,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.77454545 0.57716049 0.53395062 0.66049383 0.39197531 0.45987654\n",
      " 0.32222222 0.47777778 0.5        0.43333333]\n",
      "----------------------------------------\n",
      "Trial 494\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 173, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=173,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56727273 0.40740741 0.58024691 0.66975309 0.4845679  0.50925926\n",
      " 0.39259259 0.31111111 0.55925926 0.58518519]\n",
      "----------------------------------------\n",
      "Trial 495\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 158, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=158, random_state=100))])\n",
      "cv score: [0.73454545 0.38580247 0.63888889 0.83950617 0.65740741 0.54320988\n",
      " 0.35555556 0.37777778 0.51481481 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 496\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 188, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=188,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66545455 0.32716049 0.54320988 0.66666667 0.60185185 0.5154321\n",
      " 0.27407407 0.41851852 0.47037037 0.37407407]\n",
      "----------------------------------------\n",
      "Trial 497\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=91,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.71090909 0.56790123 0.51080247 0.65277778 0.6404321  0.56790123\n",
      " 0.37037037 0.26296296 0.51666667 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 498\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 133, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=133,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69454545 0.37345679 0.53395062 0.74074074 0.54012346 0.50308642\n",
      " 0.32222222 0.57037037 0.4037037  0.43703704]\n",
      "----------------------------------------\n",
      "Trial 499\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 176, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=176,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.42901235 0.62654321 0.65432099 0.61728395 0.50617284\n",
      " 0.2962963  0.28518519 0.54814815 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 500\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 29, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=29, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.67272727 0.38580247 0.66975309 0.75308642 0.63271605 0.52160494\n",
      " 0.4        0.28518519 0.49259259 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 501\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 82, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=82,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72       0.49074074 0.44444444 0.70061728 0.56481481 0.49382716\n",
      " 0.32592593 0.37407407 0.53333333 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 502\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=51, random_state=100))])\n",
      "cv score: [0.74181818 0.59722222 0.57407407 0.69135802 0.56018519 0.5632716\n",
      " 0.48148148 0.2962963  0.44814815 0.4       ]\n",
      "----------------------------------------\n",
      "Trial 503\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 92, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=92,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73454545 0.37037037 0.52160494 0.73765432 0.66049383 0.45061728\n",
      " 0.3037037  0.32592593 0.52222222 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 504\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 187, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=10,\n",
      "                                            n_estimators=187, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.50909091 0.42592593 0.69444444 0.70061728 0.66358025 0.46296296\n",
      " 0.34814815 0.47037037 0.48148148 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 505\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 62, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=62,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.8        0.49382716 0.52160494 0.72530864 0.56790123 0.48148148\n",
      " 0.52222222 0.47777778 0.51111111 0.31481481]\n",
      "----------------------------------------\n",
      "Trial 506\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 13, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=13,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62727273 0.32561728 0.59876543 0.66666667 0.61265432 0.42283951\n",
      " 0.29074074 0.27962963 0.65185185 0.58148148]\n",
      "----------------------------------------\n",
      "Trial 507\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 180, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=180,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64       0.38888889 0.50925926 0.66049383 0.5462963  0.50308642\n",
      " 0.37037037 0.33703704 0.62592593 0.57037037]\n",
      "----------------------------------------\n",
      "Trial 508\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 87, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=14,\n",
      "                                            n_estimators=87, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.70909091 0.50925926 0.71296296 0.69753086 0.62654321 0.4845679\n",
      " 0.31851852 0.35185185 0.57407407 0.48518519]\n",
      "----------------------------------------\n",
      "Trial 509\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 112, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=112, random_state=100))])\n",
      "cv score: [0.69818182 0.52777778 0.62654321 0.66358025 0.50925926 0.44444444\n",
      " 0.29259259 0.27407407 0.52962963 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 510\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.39197531 0.58024691 0.7191358  0.52160494 0.61728395\n",
      " 0.31111111 0.31481481 0.48888889 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 511\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 162, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=162, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.69090909 0.62345679 0.5308642  0.62345679 0.62654321 0.5154321\n",
      " 0.34814815 0.35185185 0.51851852 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 512\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 167, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=167, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.65818182 0.41049383 0.73148148 0.81481481 0.73148148 0.44135802\n",
      " 0.39259259 0.31481481 0.44444444 0.45555556]\n",
      "----------------------------------------\n",
      "Trial 513\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 189, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=189,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.78181818 0.38888889 0.51234568 0.7962963  0.48765432 0.47222222\n",
      " 0.29259259 0.41851852 0.41481481 0.39259259]\n",
      "----------------------------------------\n",
      "Trial 514\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 150, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=150,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.71272727 0.41975309 0.66975309 0.67901235 0.64197531 0.50617284\n",
      " 0.3962963  0.33333333 0.55555556 0.6       ]\n",
      "----------------------------------------\n",
      "Trial 515\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 67, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=67, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57090909 0.42283951 0.53703704 0.86111111 0.45987654 0.42283951\n",
      " 0.54444444 0.58148148 0.5962963  0.43333333]\n",
      "----------------------------------------\n",
      "Trial 516\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 112, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=112,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70181818 0.33641975 0.57716049 0.7191358  0.63580247 0.52777778\n",
      " 0.35555556 0.41851852 0.4962963  0.43333333]\n",
      "----------------------------------------\n",
      "Trial 517\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 25, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=25, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.60363636 0.41666667 0.72222222 0.60185185 0.63888889 0.60185185\n",
      " 0.53333333 0.41481481 0.53333333 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 518\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 131, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=131,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66909091 0.41666667 0.5617284  0.70679012 0.62037037 0.42592593\n",
      " 0.31851852 0.37777778 0.49259259 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 519\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74181818 0.36419753 0.5308642  0.72530864 0.56481481 0.53703704\n",
      " 0.27407407 0.35925926 0.47037037 0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 520\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 187, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=187, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.77454545 0.53703704 0.77469136 0.5462963  0.69135802 0.39506173\n",
      " 0.3        0.44814815 0.53703704 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 521\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 128, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=128, random_state=100))])\n",
      "cv score: [0.66545455 0.43209877 0.61111111 0.86419753 0.66049383 0.58950617\n",
      " 0.28518519 0.40740741 0.52592593 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 522\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 180, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=180,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57454545 0.42592593 0.53395062 0.64197531 0.60493827 0.41358025\n",
      " 0.44074074 0.5037037  0.57037037 0.54074074]\n",
      "----------------------------------------\n",
      "Trial 523\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 50, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=50,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.54909091 0.60185185 0.69444444 0.89814815 0.66666667 0.37654321\n",
      " 0.41481481 0.42222222 0.62222222 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 524\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 54, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=54, random_state=100))])\n",
      "cv score: [0.66545455 0.45061728 0.65740741 0.80864198 0.63580247 0.57716049\n",
      " 0.34444444 0.30740741 0.5037037  0.51111111]\n",
      "----------------------------------------\n",
      "Trial 525\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 171, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=171,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.76       0.44753086 0.51234568 0.79938272 0.39506173 0.45061728\n",
      " 0.21111111 0.5037037  0.37777778 0.3962963 ]\n",
      "----------------------------------------\n",
      "Trial 526\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 66, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=8, max_features='sqrt',\n",
      "                                            n_estimators=66, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.60727273 0.44444444 0.82098765 0.7191358  0.54320988 0.49691358\n",
      " 0.54814815 0.35185185 0.52962963 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 527\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=168, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.58181818 0.4845679  0.55864198 0.7808642  0.60493827 0.52160494\n",
      " 0.35555556 0.54074074 0.44444444 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 528\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 110, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=2, n_estimators=110,\n",
      "                                            random_state=100, subsample=0.7))])\n",
      "cv score: [0.74181818 0.51851852 0.63271605 0.70061728 0.44135802 0.32098765\n",
      " 0.2        0.25925926 0.6037037  0.62962963]\n",
      "----------------------------------------\n",
      "Trial 529\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 109, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=109, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.73818182 0.59259259 0.86419753 0.46759259 0.55092593 0.30555556\n",
      " 0.56296296 0.40740741 0.55925926 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 530\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 114, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=114,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66909091 0.45987654 0.5154321  0.70679012 0.42901235 0.46296296\n",
      " 0.27407407 0.42962963 0.53703704 0.37407407]\n",
      "----------------------------------------\n",
      "Trial 531\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 114, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=114,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67636364 0.30864198 0.5        0.66666667 0.72839506 0.41049383\n",
      " 0.34074074 0.42222222 0.51111111 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 532\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 170, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=170, random_state=100))])\n",
      "cv score: [0.67636364 0.40123457 0.66358025 0.82407407 0.66975309 0.50617284\n",
      " 0.4        0.41481481 0.50740741 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 533\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 56, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=56,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.80181818 0.58179012 0.59567901 0.66358025 0.63734568 0.52932099\n",
      " 0.52222222 0.42037037 0.55       0.47962963]\n",
      "----------------------------------------\n",
      "Trial 534\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 179, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=179, random_state=100))])\n",
      "cv score: [0.67636364 0.5154321  0.58641975 0.62037037 0.61419753 0.55555556\n",
      " 0.4037037  0.31111111 0.54074074 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 535\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 53, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=53,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58363636 0.53240741 0.56635802 0.67746914 0.49845679 0.59722222\n",
      " 0.51666667 0.50185185 0.55185185 0.60740741]\n",
      "----------------------------------------\n",
      "Trial 536\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 101, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=101,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54909091 0.55246914 0.42592593 0.70679012 0.46296296 0.50925926\n",
      " 0.38888889 0.24074074 0.49259259 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 537\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 162, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=162,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.67272727 0.33024691 0.67901235 0.69444444 0.63580247 0.49691358\n",
      " 0.37777778 0.3        0.58148148 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 538\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 184, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, max_features='log2',\n",
      "                                            n_estimators=184, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.57090909 0.41049383 0.64197531 0.79012346 0.76851852 0.45987654\n",
      " 0.43703704 0.38518519 0.51111111 0.51851852]\n",
      "----------------------------------------\n",
      "Trial 539\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 18, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            n_estimators=18, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.63272727 0.51851852 0.72839506 0.80246914 0.58950617 0.58641975\n",
      " 0.38888889 0.46296296 0.55925926 0.58518519]\n",
      "----------------------------------------\n",
      "Trial 540\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 189, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=189,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63272727 0.42592593 0.62345679 0.63888889 0.61728395 0.50308642\n",
      " 0.28888889 0.28518519 0.55185185 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 541\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 184, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=184,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.81818182 0.47530864 0.59567901 0.74382716 0.5154321  0.5\n",
      " 0.34814815 0.45555556 0.68518519 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 542\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 79, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=79, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.48363636 0.4537037  0.54938272 0.58179012 0.30092593 0.51851852\n",
      " 0.54814815 0.65185185 0.68148148 0.23888889]\n",
      "----------------------------------------\n",
      "Trial 543\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.83636364 0.38580247 0.54320988 0.77777778 0.5308642  0.45679012\n",
      " 0.32222222 0.48518519 0.36296296 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 544\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 25, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt', n_estimators=25,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.74909091 0.41666667 0.57407407 0.70061728 0.55555556 0.5308642\n",
      " 0.40740741 0.43703704 0.56666667 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 545\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 18, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=18,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66909091 0.56635802 0.56790123 0.68209877 0.56944444 0.50154321\n",
      " 0.47592593 0.28888889 0.53333333 0.52037037]\n",
      "----------------------------------------\n",
      "Trial 546\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 195, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=195, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.31636364 0.53395062 0.49074074 0.67592593 0.70679012 0.50925926\n",
      " 0.51851852 0.57407407 0.42962963 0.38148148]\n",
      "----------------------------------------\n",
      "Trial 547\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 153, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=153,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.71272727 0.4845679  0.58333333 0.68209877 0.61728395 0.49074074\n",
      " 0.31111111 0.28148148 0.52962963 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 548\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=133, random_state=100))])\n",
      "cv score: [0.71272727 0.56481481 0.54320988 0.66666667 0.53395062 0.52160494\n",
      " 0.45925926 0.27777778 0.49259259 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 549\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.61728395 0.52777778 0.54320988 0.50925926 0.58487654\n",
      " 0.61851852 0.36296296 0.6        0.38333333]\n",
      "----------------------------------------\n",
      "Trial 550\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 43, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=43,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.72727273 0.46296296 0.54938272 0.66512346 0.75       0.48765432\n",
      " 0.35185185 0.33148148 0.40740741 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 551\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 42, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=42, random_state=100))])\n",
      "cv score: [0.63090909 0.41666667 0.63888889 0.83333333 0.66358025 0.5308642\n",
      " 0.4        0.33518519 0.47777778 0.57962963]\n",
      "----------------------------------------\n",
      "Trial 552\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 111, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=111,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.69454545 0.45061728 0.67283951 0.69135802 0.63580247 0.52777778\n",
      " 0.38148148 0.36666667 0.52962963 0.58518519]\n",
      "----------------------------------------\n",
      "Trial 553\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 37, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=37,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.78181818 0.38580247 0.56481481 0.59259259 0.64506173 0.55246914\n",
      " 0.36296296 0.43333333 0.44814815 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 554\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 69, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            n_estimators=69, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.74909091 0.49382716 0.58641975 0.69444444 0.69444444 0.50925926\n",
      " 0.37037037 0.30555556 0.52777778 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 555\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 184, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=184,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74909091 0.47222222 0.66666667 0.59876543 0.67901235 0.54012346\n",
      " 0.38148148 0.49259259 0.5        0.29259259]\n",
      "----------------------------------------\n",
      "Trial 556\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 34, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=34,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58909091 0.32407407 0.59876543 0.66666667 0.58950617 0.45679012\n",
      " 0.35555556 0.35185185 0.46666667 0.3962963 ]\n",
      "----------------------------------------\n",
      "Trial 557\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 60, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=60, random_state=100))])\n",
      "cv score: [0.76727273 0.44135802 0.61419753 0.84567901 0.61728395 0.48765432\n",
      " 0.41851852 0.42592593 0.57037037 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 558\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 38, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=38, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.78909091 0.56790123 0.57098765 0.52314815 0.48302469 0.49074074\n",
      " 0.44444444 0.4        0.51851852 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 559\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 106, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=106,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.72727273 0.41049383 0.64197531 0.66975309 0.70679012 0.49691358\n",
      " 0.32962963 0.35925926 0.49259259 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 560\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 25, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=25, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.72727273 0.58641975 0.76234568 0.74691358 0.70987654 0.66666667\n",
      " 0.5        0.28148148 0.56666667 0.51851852]\n",
      "----------------------------------------\n",
      "Trial 561\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58909091 0.59259259 0.48765432 0.64969136 0.48302469 0.57098765\n",
      " 0.56296296 0.39814815 0.57592593 0.59259259]\n",
      "----------------------------------------\n",
      "Trial 562\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 93, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=93, random_state=100))])\n",
      "cv score: [0.69818182 0.47530864 0.59259259 0.78703704 0.66666667 0.45987654\n",
      " 0.29259259 0.3962963  0.52222222 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 563\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=101,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60909091 0.37962963 0.70679012 0.50771605 0.81944444 0.57253086\n",
      " 0.51111111 0.34814815 0.4962963  0.60555556]\n",
      "----------------------------------------\n",
      "Trial 564\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 91, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=91,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75454545 0.56635802 0.55864198 0.67901235 0.63425926 0.49382716\n",
      " 0.5037037  0.32777778 0.52222222 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 565\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 160, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=160,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60727273 0.45987654 0.52777778 0.79938272 0.58950617 0.5462963\n",
      " 0.36296296 0.50740741 0.41481481 0.37037037]\n",
      "----------------------------------------\n",
      "Trial 566\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52727273 0.51851852 0.54012346 0.70679012 0.73765432 0.58333333\n",
      " 0.3037037  0.49259259 0.59259259 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 567\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=197, random_state=100))])\n",
      "cv score: [0.66545455 0.36419753 0.62962963 0.85493827 0.72839506 0.54938272\n",
      " 0.4        0.42222222 0.56296296 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 568\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 136, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=136,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61818182 0.33950617 0.67283951 0.65432099 0.61728395 0.54320988\n",
      " 0.36296296 0.3037037  0.58148148 0.6037037 ]\n",
      "----------------------------------------\n",
      "Trial 569\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 85, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=85, random_state=100))])\n",
      "cv score: [0.67636364 0.41975309 0.62037037 0.88888889 0.74382716 0.5154321\n",
      " 0.34814815 0.35555556 0.52222222 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 570\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 75, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=75,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.71454545 0.51851852 0.52160494 0.68209877 0.60802469 0.53395062\n",
      " 0.40740741 0.32037037 0.51666667 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 571\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 145, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=145,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62181818 0.44444444 0.51234568 0.5462963  0.50925926 0.45524691\n",
      " 0.65925926 0.48148148 0.57777778 0.39074074]\n",
      "----------------------------------------\n",
      "Trial 572\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 18, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=18,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62545455 0.47222222 0.54938272 0.69135802 0.41666667 0.45216049\n",
      " 0.52592593 0.25925926 0.5037037  0.51481481]\n",
      "----------------------------------------\n",
      "Trial 573\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.58545455 0.38580247 0.54320988 0.71296296 0.52469136 0.45987654\n",
      " 0.61111111 0.5        0.17037037 0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 574\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 123, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=123,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65090909 0.33641975 0.62962963 0.7345679  0.61111111 0.47839506\n",
      " 0.33333333 0.3037037  0.60740741 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 575\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 149, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=149,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.68727273 0.36111111 0.60802469 0.76234568 0.66358025 0.52777778\n",
      " 0.43333333 0.37407407 0.6        0.63333333]\n",
      "----------------------------------------\n",
      "Trial 576\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 120, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=120,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.70545455 0.32407407 0.70061728 0.80555556 0.80555556 0.47530864\n",
      " 0.51851852 0.52962963 0.37407407 0.36666667]\n",
      "----------------------------------------\n",
      "Trial 577\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 187, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=187, random_state=100))])\n",
      "cv score: [0.65454545 0.41975309 0.58641975 0.8117284  0.7654321  0.53703704\n",
      " 0.32222222 0.42592593 0.54444444 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 578\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.66909091 0.36419753 0.66666667 0.68209877 0.63271605 0.54320988\n",
      " 0.39259259 0.42222222 0.51851852 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 579\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 155, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=155,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68727273 0.46604938 0.52469136 0.75       0.42901235 0.5154321\n",
      " 0.35925926 0.47037037 0.57037037 0.58148148]\n",
      "----------------------------------------\n",
      "Trial 580\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 69, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=69, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.69818182 0.55555556 0.62345679 0.61728395 0.65123457 0.39197531\n",
      " 0.31481481 0.3037037  0.72222222 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 581\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 144, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=144, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.60909091 0.28395062 0.4845679  0.48611111 0.45987654 0.35493827\n",
      " 0.44814815 0.41851852 0.52222222 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 582\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 103, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=103,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6        0.47530864 0.70833333 0.57407407 0.63734568 0.55555556\n",
      " 0.59814815 0.45185185 0.41481481 0.6037037 ]\n",
      "----------------------------------------\n",
      "Trial 583\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 66, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=66,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.76       0.47839506 0.52160494 0.85802469 0.59567901 0.60185185\n",
      " 0.41111111 0.37407407 0.52222222 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 584\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=81, random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.76727273 0.37962963 0.81481481 0.69444444 0.62962963 0.61419753\n",
      " 0.40740741 0.55925926 0.50740741 0.32222222]\n",
      "----------------------------------------\n",
      "Trial 585\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 30, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=30, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.76363636 0.41975309 0.66049383 0.73148148 0.55864198 0.56481481\n",
      " 0.28148148 0.27407407 0.58518519 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 586\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 195, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=195,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.41358025 0.56790123 0.71604938 0.58950617 0.58641975\n",
      " 0.4        0.27407407 0.55925926 0.57407407]\n",
      "----------------------------------------\n",
      "Trial 587\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 151, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=151,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72363636 0.50925926 0.37962963 0.47222222 0.50925926 0.5\n",
      " 0.47222222 0.46296296 0.42407407 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 588\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 36, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=36, random_state=100))])\n",
      "cv score: [0.70909091 0.37345679 0.59876543 0.85802469 0.59259259 0.56790123\n",
      " 0.33333333 0.33333333 0.51111111 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 589\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 35, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=35,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58181818 0.47222222 0.55709877 0.47222222 0.46296296 0.46296296\n",
      " 0.47222222 0.41666667 0.58148148 0.37777778]\n",
      "----------------------------------------\n",
      "Trial 590\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 114, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=114,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53818182 0.42901235 0.56790123 0.6882716  0.44753086 0.66358025\n",
      " 0.42222222 0.41481481 0.58518519 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 591\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 194, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=194, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.59636364 0.38888889 0.7037037  0.7654321  0.68209877 0.5\n",
      " 0.40740741 0.36666667 0.55925926 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 592\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.62181818 0.39814815 0.70679012 0.70679012 0.62345679 0.4691358\n",
      " 0.51851852 0.41481481 0.52592593 0.35555556]\n",
      "----------------------------------------\n",
      "Trial 593\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66909091 0.37037037 0.45987654 0.62962963 0.5        0.39506173\n",
      " 0.25185185 0.39259259 0.52592593 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 594\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61454545 0.4537037  0.5462963  0.72839506 0.57098765 0.5\n",
      " 0.35555556 0.38888889 0.45925926 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 595\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=115,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.71454545 0.5787037  0.43055556 0.47222222 0.51851852 0.54012346\n",
      " 0.52222222 0.17592593 0.49444444 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 596\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 199, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=199,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70545455 0.54012346 0.62654321 0.76851852 0.32716049 0.44135802\n",
      " 0.32592593 0.64074074 0.47407407 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 597\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 171, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            n_estimators=171, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.63272727 0.42283951 0.62345679 0.8117284  0.65123457 0.49691358\n",
      " 0.36296296 0.3        0.55555556 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 598\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=178,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72       0.51388889 0.58333333 0.67283951 0.61111111 0.50925926\n",
      " 0.35185185 0.32222222 0.53703704 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 599\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 199, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=199, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.62909091 0.55555556 0.81481481 0.77777778 0.64197531 0.52160494\n",
      " 0.46296296 0.47777778 0.48148148 0.17037037]\n",
      "----------------------------------------\n",
      "Trial 600\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 56, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            n_estimators=56, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.68363636 0.45679012 0.58024691 0.77469136 0.63888889 0.54320988\n",
      " 0.42962963 0.32222222 0.49259259 0.51851852]\n",
      "----------------------------------------\n",
      "Trial 601\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 27, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=27,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56363636 0.28703704 0.48765432 0.76234568 0.5462963  0.51234568\n",
      " 0.42222222 0.47407407 0.52962963 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 602\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 55, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=55, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.34545455 0.50925926 0.51851852 0.74074074 0.38888889 0.5154321\n",
      " 0.47407407 0.61111111 0.36666667 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 603\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 37, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=37,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60545455 0.52469136 0.5154321  0.52469136 0.49382716 0.54938272\n",
      " 0.62037037 0.28333333 0.59444444 0.60555556]\n",
      "----------------------------------------\n",
      "Trial 604\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 88, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=88,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66545455 0.59876543 0.52469136 0.52469136 0.51697531 0.56481481\n",
      " 0.59074074 0.44444444 0.58888889 0.52037037]\n",
      "----------------------------------------\n",
      "Trial 605\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 123, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, max_features='sqrt',\n",
      "                                            n_estimators=123, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.58181818 0.43518519 0.72839506 0.85493827 0.70679012 0.39814815\n",
      " 0.51481481 0.42592593 0.51851852 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 606\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 175, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=175,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.53240741 0.51080247 0.54012346 0.50925926 0.54320988\n",
      " 0.5962963  0.38518519 0.6        0.37592593]\n",
      "----------------------------------------\n",
      "Trial 607\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 35, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=35, random_state=100))])\n",
      "cv score: [0.67636364 0.56790123 0.60802469 0.62345679 0.49382716 0.38888889\n",
      " 0.25555556 0.25555556 0.54444444 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 608\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 123, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=123, random_state=100))])\n",
      "cv score: [0.68363636 0.4382716  0.63271605 0.86419753 0.59259259 0.5154321\n",
      " 0.38888889 0.4037037  0.55925926 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 609\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 189, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=189, random_state=100))])\n",
      "cv score: [0.65454545 0.39197531 0.66975309 0.81790123 0.67283951 0.50308642\n",
      " 0.39259259 0.40740741 0.4962963  0.44444444]\n",
      "----------------------------------------\n",
      "Trial 610\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 23, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=23,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.64727273 0.31481481 0.68518519 0.66975309 0.75925926 0.47839506\n",
      " 0.44814815 0.25925926 0.56666667 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 611\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 92, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            n_estimators=92, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.64727273 0.46296296 0.73148148 0.8117284  0.69753086 0.49382716\n",
      " 0.37037037 0.36666667 0.4        0.51481481]\n",
      "----------------------------------------\n",
      "Trial 612\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 84, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=84,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.48148148 0.49074074 0.5        0.48148148 0.5462963\n",
      " 0.5        0.47222222 0.5        0.41481481]\n",
      "----------------------------------------\n",
      "Trial 613\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 64, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=64,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.48148148 0.49074074 0.5        0.48148148 0.5462963\n",
      " 0.5        0.47222222 0.5        0.41481481]\n",
      "----------------------------------------\n",
      "Trial 614\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 74, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=74,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.74181818 0.39506173 0.41975309 0.70987654 0.46296296 0.5154321\n",
      " 0.30740741 0.4        0.46666667 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 615\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 118, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=118,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.78181818 0.37962963 0.5462963  0.74074074 0.62345679 0.47222222\n",
      " 0.41481481 0.54814815 0.41851852 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 616\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71272727 0.41358025 0.54938272 0.64506173 0.64506173 0.39814815\n",
      " 0.31111111 0.33333333 0.51111111 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 617\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 109, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=109, random_state=100))])\n",
      "cv score: [0.66909091 0.40432099 0.63580247 0.87962963 0.66666667 0.61728395\n",
      " 0.27407407 0.37407407 0.51851852 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 618\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=178, random_state=100))])\n",
      "cv score: [0.63636364 0.4537037  0.64197531 0.75925926 0.61728395 0.60802469\n",
      " 0.33703704 0.24814815 0.55925926 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 619\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 76, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=76,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70909091 0.38271605 0.47222222 0.62962963 0.5462963  0.41975309\n",
      " 0.25185185 0.35925926 0.51481481 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 620\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.58181818 0.52160494 0.61419753 0.77469136 0.69753086 0.60802469\n",
      " 0.41481481 0.42222222 0.52222222 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 621\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 199, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=199, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.70909091 0.33024691 0.7191358  0.49074074 0.55092593 0.41975309\n",
      " 0.58148148 0.47037037 0.62592593 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 622\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 149, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=149,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68363636 0.37962963 0.50925926 0.70987654 0.66666667 0.42901235\n",
      " 0.34814815 0.45555556 0.52962963 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 623\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 138, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=138,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.63636364 0.38271605 0.57098765 0.7191358  0.56481481 0.57716049\n",
      " 0.43703704 0.32222222 0.62222222 0.58888889]\n",
      "----------------------------------------\n",
      "Trial 624\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 199, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=199,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72       0.34259259 0.52160494 0.64814815 0.68518519 0.48148148\n",
      " 0.28888889 0.35925926 0.53333333 0.51851852]\n",
      "----------------------------------------\n",
      "Trial 625\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            n_estimators=115, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.72727273 0.47530864 0.57253086 0.67438272 0.6558642  0.5462963\n",
      " 0.30740741 0.21666667 0.48518519 0.46851852]\n",
      "----------------------------------------\n",
      "Trial 626\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 35, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=35, random_state=100))])\n",
      "cv score: [0.77090909 0.63580247 0.59259259 0.68518519 0.55555556 0.53549383\n",
      " 0.50925926 0.21666667 0.42962963 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 627\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 190, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            n_estimators=190, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.57090909 0.43209877 0.7345679  0.7808642  0.74382716 0.51234568\n",
      " 0.44074074 0.35925926 0.45185185 0.48518519]\n",
      "----------------------------------------\n",
      "Trial 628\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 83, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=83, random_state=100))])\n",
      "cv score: [0.75272727 0.66049383 0.62345679 0.69444444 0.57407407 0.4537037\n",
      " 0.4962963  0.25185185 0.41851852 0.45555556]\n",
      "----------------------------------------\n",
      "Trial 629\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=102,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.68363636 0.36728395 0.68209877 0.7037037  0.60802469 0.45061728\n",
      " 0.34074074 0.32222222 0.55555556 0.62962963]\n",
      "----------------------------------------\n",
      "Trial 630\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 86, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=86,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73818182 0.41049383 0.58950617 0.7037037  0.62962963 0.42592593\n",
      " 0.34814815 0.34814815 0.48888889 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 631\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 155, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=155,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.61818182 0.44444444 0.66049383 0.82407407 0.71604938 0.40123457\n",
      " 0.35925926 0.4        0.57777778 0.38518519]\n",
      "----------------------------------------\n",
      "Trial 632\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72       0.31790123 0.57407407 0.72839506 0.61728395 0.5308642\n",
      " 0.36296296 0.43333333 0.52592593 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 633\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 26, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=26,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.63818182 0.41666667 0.5308642  0.54012346 0.40740741 0.5308642\n",
      " 0.58703704 0.48888889 0.60555556 0.50555556]\n",
      "----------------------------------------\n",
      "Trial 634\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 103, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            n_estimators=103, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.72       0.41049383 0.66358025 0.69135802 0.66358025 0.54938272\n",
      " 0.29259259 0.26296296 0.57037037 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 635\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=178, random_state=100))])\n",
      "cv score: [0.73090909 0.63117284 0.50925926 0.7037037  0.51234568 0.49074074\n",
      " 0.42222222 0.35555556 0.52592593 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 636\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 74, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=74,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59818182 0.59259259 0.52160494 0.52777778 0.47839506 0.59876543\n",
      " 0.56296296 0.28703704 0.54444444 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 637\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 112, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=112,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60909091 0.37962963 0.70679012 0.50771605 0.81944444 0.57253086\n",
      " 0.51111111 0.35185185 0.4962963  0.60555556]\n",
      "----------------------------------------\n",
      "Trial 638\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 174, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=174, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.70545455 0.45061728 0.59876543 0.67283951 0.58950617 0.49691358\n",
      " 0.30740741 0.37407407 0.51851852 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 639\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 40, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=40,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.8        0.40123457 0.5154321  0.71604938 0.56481481 0.48148148\n",
      " 0.41481481 0.35925926 0.52222222 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 640\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 143, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=143, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.67272727 0.43209877 0.69135802 0.77777778 0.74691358 0.58333333\n",
      " 0.4        0.35555556 0.51111111 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 641\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 176, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='sqrt',\n",
      "                                            n_estimators=176,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.77454545 0.39506173 0.62654321 0.70061728 0.68209877 0.37654321\n",
      " 0.35185185 0.4037037  0.52222222 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 642\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 25, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=25,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.51851852 0.37962963 0.47222222 0.50925926 0.47685185\n",
      " 0.5        0.46296296 0.47222222 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 643\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 167, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=167, random_state=100))])\n",
      "cv score: [0.64       0.44753086 0.57407407 0.73148148 0.59259259 0.49691358\n",
      " 0.3        0.32222222 0.54814815 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 644\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 190, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=190, random_state=100))])\n",
      "cv score: [0.69818182 0.41049383 0.66666667 0.83950617 0.67901235 0.58333333\n",
      " 0.33333333 0.41111111 0.49259259 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 645\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 111, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=111,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66363636 0.59722222 0.62037037 0.45987654 0.62962963 0.52932099\n",
      " 0.52222222 0.25740741 0.37962963 0.8537037 ]\n",
      "----------------------------------------\n",
      "Trial 646\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 89, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=89, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.72363636 0.33641975 0.74382716 0.71604938 0.74382716 0.55555556\n",
      " 0.3962963  0.36666667 0.52962963 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 647\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.66909091 0.41975309 0.73765432 0.70987654 0.66049383 0.47530864\n",
      " 0.31111111 0.32592593 0.55185185 0.6037037 ]\n",
      "----------------------------------------\n",
      "Trial 648\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=159, random_state=100))])\n",
      "cv score: [0.68363636 0.41049383 0.65123457 0.82407407 0.68518519 0.47839506\n",
      " 0.41481481 0.41481481 0.51111111 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 649\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58545455 0.5632716  0.5154321  0.51697531 0.59876543 0.44907407\n",
      " 0.53888889 0.41481481 0.65185185 0.57222222]\n",
      "----------------------------------------\n",
      "Trial 650\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 107, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=107,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72363636 0.50925926 0.37962963 0.47222222 0.50925926 0.5\n",
      " 0.47222222 0.46296296 0.42407407 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 651\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 195, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=195, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.64363636 0.38271605 0.70061728 0.79012346 0.76234568 0.46604938\n",
      " 0.42962963 0.45555556 0.48148148 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 652\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 116, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=116,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.2962963  0.75308642 0.51697531 0.7808642  0.55246914\n",
      " 0.45925926 0.38703704 0.51296296 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 653\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=174, random_state=100))])\n",
      "cv score: [0.67636364 0.41049383 0.62654321 0.75       0.64506173 0.57716049\n",
      " 0.35555556 0.31111111 0.54814815 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 654\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 180, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=180, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.63636364 0.45679012 0.71604938 0.77160494 0.70061728 0.33641975\n",
      " 0.37037037 0.42222222 0.55185185 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 655\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57454545 0.42283951 0.35802469 0.7654321  0.49691358 0.44444444\n",
      " 0.41481481 0.30740741 0.5962963  0.59259259]\n",
      "----------------------------------------\n",
      "Trial 656\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 36, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=36, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.68727273 0.57098765 0.62345679 0.66049383 0.55246914 0.67283951\n",
      " 0.34444444 0.2037037  0.52222222 0.55555556]\n",
      "----------------------------------------\n",
      "Trial 657\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 70, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=70,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70909091 0.38271605 0.59567901 0.69444444 0.69444444 0.47222222\n",
      " 0.32962963 0.38888889 0.4        0.46296296]\n",
      "----------------------------------------\n",
      "Trial 658\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60363636 0.54783951 0.51851852 0.54012346 0.50925926 0.53703704\n",
      " 0.5962963  0.3962963  0.57777778 0.47222222]\n",
      "----------------------------------------\n",
      "Trial 659\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 35, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            n_estimators=35, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.69454545 0.46296296 0.61111111 0.69444444 0.58641975 0.50617284\n",
      " 0.44074074 0.4962963  0.56666667 0.60740741]\n",
      "----------------------------------------\n",
      "Trial 660\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 77, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=77,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62909091 0.50617284 0.4691358  0.75308642 0.50925926 0.5\n",
      " 0.31111111 0.32592593 0.53333333 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 661\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=101, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.68727273 0.50308642 0.55246914 0.69753086 0.62345679 0.50617284\n",
      " 0.43333333 0.35555556 0.50740741 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 662\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 66, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=66, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.63636364 0.42283951 0.61419753 0.72839506 0.59259259 0.4845679\n",
      " 0.36666667 0.43703704 0.41111111 0.32962963]\n",
      "----------------------------------------\n",
      "Trial 663\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 137, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=137,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73636364 0.53858025 0.56790123 0.67438272 0.60030864 0.50771605\n",
      " 0.47037037 0.33703704 0.53703704 0.50185185]\n",
      "----------------------------------------\n",
      "Trial 664\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 125, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=125, random_state=100))])\n",
      "cv score: [0.72363636 0.58950617 0.57407407 0.62345679 0.62654321 0.50617284\n",
      " 0.4037037  0.30740741 0.47407407 0.38148148]\n",
      "----------------------------------------\n",
      "Trial 665\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 49, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=49,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70909091 0.36728395 0.77469136 0.63580247 0.57098765 0.52160494\n",
      " 0.46666667 0.2962963  0.60740741 0.58148148]\n",
      "----------------------------------------\n",
      "Trial 666\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 100, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.72727273 0.37654321 0.62962963 0.82407407 0.67283951 0.57098765\n",
      " 0.36296296 0.36481481 0.55925926 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 667\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 19, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='log2',\n",
      "                                            n_estimators=19, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.83636364 0.50925926 0.64506173 0.65740741 0.58641975 0.54938272\n",
      " 0.28148148 0.33703704 0.41481481 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 668\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 70, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=70, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.69454545 0.41358025 0.65740741 0.80555556 0.7345679  0.45061728\n",
      " 0.48888889 0.38888889 0.59259259 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 669\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 194, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=194, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.56       0.47530864 0.69444444 0.7808642  0.6882716  0.38888889\n",
      " 0.46666667 0.42222222 0.44074074 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 670\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 114, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=114, random_state=100))])\n",
      "cv score: [0.66545455 0.36111111 0.61111111 0.88580247 0.74691358 0.54938272\n",
      " 0.34444444 0.4037037  0.5037037  0.56666667]\n",
      "----------------------------------------\n",
      "Trial 671\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 190, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=190,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70181818 0.49382716 0.51234568 0.66049383 0.53395062 0.47530864\n",
      " 0.43703704 0.24814815 0.51111111 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 672\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 42, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=10,\n",
      "                                            n_estimators=42, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.61090909 0.54938272 0.67283951 0.84876543 0.69753086 0.53395062\n",
      " 0.4962963  0.46296296 0.57407407 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 673\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 181, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(n_estimators=181, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.76727273 0.45061728 0.72222222 0.79938272 0.66049383 0.4382716\n",
      " 0.27777778 0.25925926 0.58888889 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 674\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 101, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=101,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.48765432 0.58641975 0.77777778 0.54012346 0.49382716\n",
      " 0.3        0.46666667 0.32962963 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 675\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 69, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=69, random_state=100))])\n",
      "cv score: [0.69090909 0.5        0.60802469 0.76851852 0.61419753 0.64814815\n",
      " 0.30740741 0.24814815 0.50740741 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 676\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 65, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=65,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.77454545 0.37345679 0.52777778 0.64814815 0.58950617 0.55864198\n",
      " 0.32962963 0.3        0.46296296 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 677\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 94, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=94,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.38888889 0.50925926 0.67283951 0.55864198 0.44135802\n",
      " 0.36296296 0.31111111 0.64444444 0.48518519]\n",
      "----------------------------------------\n",
      "Trial 678\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 75, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=75, random_state=100))])\n",
      "cv score: [0.70909091 0.37345679 0.61882716 0.82716049 0.70061728 0.53703704\n",
      " 0.3        0.4037037  0.6        0.52222222]\n",
      "----------------------------------------\n",
      "Trial 679\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 60, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=60, random_state=100))])\n",
      "cv score: [0.76727273 0.44135802 0.61419753 0.84567901 0.61728395 0.48765432\n",
      " 0.41851852 0.42592593 0.57037037 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 680\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64727273 0.37037037 0.49691358 0.6882716  0.58333333 0.46296296\n",
      " 0.34814815 0.32592593 0.57777778 0.45555556]\n",
      "----------------------------------------\n",
      "Trial 681\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 127, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=127,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76545455 0.61111111 0.55246914 0.63271605 0.63580247 0.4845679\n",
      " 0.47407407 0.36851852 0.55185185 0.4537037 ]\n",
      "----------------------------------------\n",
      "Trial 682\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 154, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            n_estimators=154, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.55636364 0.44135802 0.62654321 0.78703704 0.63580247 0.54320988\n",
      " 0.32962963 0.37407407 0.55555556 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 683\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 89, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=89, random_state=100))])\n",
      "cv score: [0.70181818 0.35802469 0.66049383 0.88580247 0.66358025 0.5617284\n",
      " 0.27777778 0.45185185 0.51481481 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 684\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.6        0.53549383 0.5462963  0.5154321  0.63580247 0.62191358\n",
      " 0.56111111 0.33703704 0.63333333 0.55740741]\n",
      "----------------------------------------\n",
      "Trial 685\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 164, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=164,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71636364 0.45679012 0.53395062 0.69444444 0.56790123 0.40123457\n",
      " 0.36666667 0.37777778 0.53333333 0.38148148]\n",
      "----------------------------------------\n",
      "Trial 686\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=91, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.70545455 0.32098765 0.64814815 0.7654321  0.75       0.5\n",
      " 0.37407407 0.4        0.58888889 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 687\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 74, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=74, random_state=100))])\n",
      "cv score: [0.72       0.45679012 0.62037037 0.83333333 0.64197531 0.48148148\n",
      " 0.36666667 0.44074074 0.61111111 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 688\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 152, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=152, random_state=100))])\n",
      "cv score: [0.70181818 0.40740741 0.58641975 0.74074074 0.75308642 0.55555556\n",
      " 0.2962963  0.46666667 0.50740741 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 689\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 38, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=38,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59818182 0.44907407 0.52469136 0.54012346 0.53395062 0.54938272\n",
      " 0.5962963  0.37777778 0.66111111 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 690\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 137, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=137, random_state=100))])\n",
      "cv score: [0.66545455 0.45679012 0.63580247 0.77160494 0.63271605 0.61728395\n",
      " 0.34814815 0.25925926 0.54074074 0.5962963 ]\n",
      "----------------------------------------\n",
      "Trial 691\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 97, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=97, random_state=100))])\n",
      "cv score: [0.72       0.51851852 0.64814815 0.67901235 0.55864198 0.57098765\n",
      " 0.34814815 0.26666667 0.49259259 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 692\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 82, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=82,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64       0.52623457 0.49074074 0.68518519 0.60493827 0.52932099\n",
      " 0.57777778 0.41296296 0.56851852 0.61481481]\n",
      "----------------------------------------\n",
      "Trial 693\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 158, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=158,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66909091 0.37962963 0.73148148 0.66666667 0.57407407 0.49074074\n",
      " 0.40740741 0.31481481 0.58518519 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 694\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 87, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=87,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70545455 0.44753086 0.50308642 0.6882716  0.68209877 0.5154321\n",
      " 0.35555556 0.38518519 0.52592593 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 695\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 184, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=184,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70181818 0.39814815 0.50925926 0.60185185 0.55864198 0.42283951\n",
      " 0.26296296 0.33703704 0.43703704 0.54074074]\n",
      "----------------------------------------\n",
      "Trial 696\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 169, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=169, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62545455 0.37037037 0.68209877 0.77160494 0.6882716  0.50308642\n",
      " 0.41481481 0.35555556 0.53333333 0.54814815]\n",
      "----------------------------------------\n",
      "Trial 697\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 179, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=179, random_state=100))])\n",
      "cv score: [0.65454545 0.40123457 0.54320988 0.74691358 0.69444444 0.47839506\n",
      " 0.36296296 0.42592593 0.54074074 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 698\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=183,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.80545455 0.61728395 0.55092593 0.68518519 0.62962963 0.48148148\n",
      " 0.50925926 0.38518519 0.56296296 0.46111111]\n",
      "----------------------------------------\n",
      "Trial 699\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 17, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=17, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.48363636 0.4537037  0.59259259 0.55246914 0.46604938 0.45987654\n",
      " 0.22592593 0.4        0.61481481 0.54814815]\n",
      "----------------------------------------\n",
      "Trial 700\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 179, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=179,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62909091 0.34567901 0.64506173 0.74074074 0.60185185 0.47839506\n",
      " 0.34444444 0.29259259 0.6        0.54444444]\n",
      "----------------------------------------\n",
      "Trial 701\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 187, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=187,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.68727273 0.33333333 0.62962963 0.75308642 0.64197531 0.51851852\n",
      " 0.41481481 0.37777778 0.60740741 0.64444444]\n",
      "----------------------------------------\n",
      "Trial 702\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 191, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=191, random_state=100))])\n",
      "cv score: [0.70545455 0.38888889 0.67592593 0.81790123 0.65123457 0.57407407\n",
      " 0.33703704 0.37777778 0.52592593 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 703\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 198, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=198,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65818182 0.44444444 0.53395062 0.7191358  0.59722222 0.5\n",
      " 0.6537037  0.28148148 0.64074074 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 704\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, max_features='log2',\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.69818182 0.45061728 0.68518519 0.8117284  0.70061728 0.47530864\n",
      " 0.38888889 0.45925926 0.45555556 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 705\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 70, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=70,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63272727 0.52469136 0.52623457 0.61419753 0.58950617 0.53858025\n",
      " 0.55925926 0.33333333 0.66666667 0.58888889]\n",
      "----------------------------------------\n",
      "Trial 706\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 73, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=73, random_state=100))])\n",
      "cv score: [0.63272727 0.41666667 0.62962963 0.83641975 0.64197531 0.61419753\n",
      " 0.36666667 0.42222222 0.46296296 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 707\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 56, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=56,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.80181818 0.58179012 0.59567901 0.66358025 0.63734568 0.52932099\n",
      " 0.52222222 0.42037037 0.55       0.47962963]\n",
      "----------------------------------------\n",
      "Trial 708\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 195, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=195,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.77454545 0.39197531 0.59876543 0.61419753 0.59876543 0.37345679\n",
      " 0.25185185 0.37037037 0.58148148 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 709\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.72       0.4382716  0.7345679  0.78395062 0.75       0.43518519\n",
      " 0.37777778 0.40740741 0.45925926 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 710\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 87, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=87, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.74545455 0.38580247 0.59567901 0.70061728 0.61111111 0.4691358\n",
      " 0.30740741 0.34814815 0.48148148 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 711\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 106, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=106, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.72727273 0.46604938 0.63271605 0.5462963  0.62962963 0.47839506\n",
      " 0.26666667 0.38518519 0.48518519 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 712\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 30, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            n_estimators=30, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.64363636 0.57098765 0.66975309 0.72530864 0.71604938 0.46604938\n",
      " 0.45185185 0.35555556 0.46666667 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 713\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 88, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=88,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.71636364 0.34259259 0.69135802 0.69135802 0.59567901 0.4537037\n",
      " 0.34814815 0.33333333 0.55185185 0.65185185]\n",
      "----------------------------------------\n",
      "Trial 714\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 128, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=128, random_state=100))])\n",
      "cv score: [0.67272727 0.45061728 0.5462963  0.73765432 0.69753086 0.49691358\n",
      " 0.32592593 0.41851852 0.55925926 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 715\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 72, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=72,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.44444444 0.52777778 0.7191358  0.50925926 0.45987654\n",
      " 0.66481481 0.42407407 0.55925926 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 716\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=51, random_state=100))])\n",
      "cv score: [0.69090909 0.5617284  0.59567901 0.73765432 0.70987654 0.55246914\n",
      " 0.35555556 0.47037037 0.57777778 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 717\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 195, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=195,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72363636 0.40740741 0.49382716 0.72222222 0.67283951 0.48765432\n",
      " 0.27777778 0.4037037  0.50740741 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 718\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 148, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=148,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.68363636 0.34259259 0.50308642 0.67283951 0.4691358  0.45987654\n",
      " 0.27407407 0.33333333 0.56296296 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 719\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 33, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=33,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.59272727 0.34567901 0.68518519 0.76234568 0.66975309 0.64814815\n",
      " 0.44074074 0.34444444 0.64074074 0.58888889]\n",
      "----------------------------------------\n",
      "Trial 720\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 148, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=148, random_state=100))])\n",
      "cv score: [0.67636364 0.36728395 0.62345679 0.87037037 0.74074074 0.52160494\n",
      " 0.42592593 0.42592593 0.52222222 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 721\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 88, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=88,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63818182 0.46296296 0.54320988 0.54320988 0.4537037  0.44907407\n",
      " 0.68703704 0.38148148 0.57962963 0.41296296]\n",
      "----------------------------------------\n",
      "Trial 722\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 34, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            n_estimators=34, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.57454545 0.41666667 0.71604938 0.73765432 0.60493827 0.47222222\n",
      " 0.3        0.3962963  0.54814815 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 723\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=68, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.51272727 0.60185185 0.60493827 0.81790123 0.7037037  0.52777778\n",
      " 0.5        0.40740741 0.38888889 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 724\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 42, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, max_features='sqrt',\n",
      "                                            n_estimators=42,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.64       0.44444444 0.68209877 0.74074074 0.65740741 0.51234568\n",
      " 0.5037037  0.42222222 0.54444444 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 725\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 86, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=86,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57454545 0.45679012 0.54012346 0.62345679 0.53703704 0.61728395\n",
      " 0.49259259 0.33703704 0.56666667 0.65185185]\n",
      "----------------------------------------\n",
      "Trial 726\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 50, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, n_estimators=50,\n",
      "                                            random_state=100, subsample=0.9))])\n",
      "cv score: [0.71636364 0.27160494 0.49074074 0.79012346 0.41049383 0.53395062\n",
      " 0.28888889 0.31111111 0.56296296 0.34444444]\n",
      "----------------------------------------\n",
      "Trial 727\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 147, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=147,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.68       0.34259259 0.6882716  0.69135802 0.63580247 0.4537037\n",
      " 0.37777778 0.28148148 0.55185185 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 728\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.69454545 0.51851852 0.5617284  0.6882716  0.58641975 0.50617284\n",
      " 0.51111111 0.51111111 0.37407407 0.38518519]\n",
      "----------------------------------------\n",
      "Trial 729\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 20, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=20, random_state=100))])\n",
      "cv score: [0.58727273 0.6095679  0.49537037 0.5617284  0.58487654 0.45216049\n",
      " 0.63148148 0.20925926 0.54814815 0.32407407]\n",
      "----------------------------------------\n",
      "Trial 730\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 21, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=21,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6        0.47530864 0.71141975 0.57407407 0.63734568 0.55555556\n",
      " 0.59814815 0.45925926 0.41481481 0.6037037 ]\n",
      "----------------------------------------\n",
      "Trial 731\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 197, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=197, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.63636364 0.43518519 0.69135802 0.87654321 0.75308642 0.46296296\n",
      " 0.42962963 0.3962963  0.53333333 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 732\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56       0.42901235 0.55555556 0.75925926 0.48148148 0.57098765\n",
      " 0.32962963 0.28888889 0.52962963 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 733\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61090909 0.32716049 0.54320988 0.64814815 0.63580247 0.48148148\n",
      " 0.2962963  0.27777778 0.57777778 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 734\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 174, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            n_estimators=174, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.66181818 0.55864198 0.70987654 0.64506173 0.55555556 0.54012346\n",
      " 0.46666667 0.41851852 0.48148148 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 735\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 16, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=16, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.45454545 0.50925926 0.72530864 0.62037037 0.55864198 0.63271605\n",
      " 0.35555556 0.64814815 0.45555556 0.37037037]\n",
      "----------------------------------------\n",
      "Trial 736\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 55, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=55, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.48       0.35185185 0.69135802 0.57098765 0.68518519 0.49382716\n",
      " 0.37777778 0.34814815 0.53703704 0.34814815]\n",
      "----------------------------------------\n",
      "Trial 737\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 194, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=194, random_state=100))])\n",
      "cv score: [0.68       0.41975309 0.62654321 0.74691358 0.64506173 0.57407407\n",
      " 0.35185185 0.32222222 0.55925926 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 738\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            n_estimators=52, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.58909091 0.5617284  0.23765432 0.51697531 0.62037037 0.43981481\n",
      " 0.51111111 0.21851852 0.43333333 0.71851852]\n",
      "----------------------------------------\n",
      "Trial 739\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 15, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=15,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.64       0.58024691 0.36419753 0.77469136 0.53395062 0.3117284\n",
      " 0.2962963  0.42592593 0.5037037  0.67037037]\n",
      "----------------------------------------\n",
      "Trial 740\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.50545455 0.47839506 0.59567901 0.5617284  0.61728395 0.37654321\n",
      " 0.37407407 0.41111111 0.56666667 0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 741\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 108, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=108,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.39506173 0.52160494 0.72222222 0.62654321 0.47839506\n",
      " 0.37037037 0.35925926 0.52962963 0.38148148]\n",
      "----------------------------------------\n",
      "Trial 742\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 151, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=151, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.65090909 0.38580247 0.67592593 0.80246914 0.63580247 0.52777778\n",
      " 0.46296296 0.31111111 0.52962963 0.54074074]\n",
      "----------------------------------------\n",
      "Trial 743\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61454545 0.52777778 0.49382716 0.73148148 0.42592593 0.54938272\n",
      " 0.4962963  0.42777778 0.55555556 0.60740741]\n",
      "----------------------------------------\n",
      "Trial 744\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 21, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=21, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.68       0.49074074 0.65740741 0.7808642  0.50308642 0.54012346\n",
      " 0.37037037 0.3        0.45925926 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 745\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 144, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=144,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74181818 0.43518519 0.51851852 0.71296296 0.54320988 0.49382716\n",
      " 0.32222222 0.44814815 0.51481481 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 746\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=108,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.68727273 0.44753086 0.67283951 0.69135802 0.62654321 0.50617284\n",
      " 0.38148148 0.37407407 0.52962963 0.6       ]\n",
      "----------------------------------------\n",
      "Trial 747\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 179, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=179,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57454545 0.42901235 0.55555556 0.67592593 0.58641975 0.58950617\n",
      " 0.38888889 0.28888889 0.55185185 0.58148148]\n",
      "----------------------------------------\n",
      "Trial 748\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=174, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.64727273 0.45679012 0.63580247 0.75925926 0.61728395 0.60185185\n",
      " 0.35185185 0.25185185 0.55185185 0.54814815]\n",
      "----------------------------------------\n",
      "Trial 749\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 139, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=139,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72       0.36111111 0.57407407 0.69135802 0.5462963  0.4845679\n",
      " 0.35185185 0.39259259 0.44814815 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 750\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 155, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=155, random_state=100))])\n",
      "cv score: [0.69090909 0.40432099 0.63271605 0.83641975 0.65740741 0.47839506\n",
      " 0.41481481 0.41851852 0.52592593 0.39259259]\n",
      "----------------------------------------\n",
      "Trial 751\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 73, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=73,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.83272727 0.38580247 0.46296296 0.60802469 0.55555556 0.43518519\n",
      " 0.35185185 0.40740741 0.64074074 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 752\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 29, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=29,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73454545 0.35802469 0.46296296 0.58641975 0.60185185 0.48148148\n",
      " 0.37407407 0.31111111 0.62962963 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 753\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 88, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=88, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.68       0.4537037  0.49382716 0.65740741 0.55555556 0.45679012\n",
      " 0.40740741 0.34814815 0.45925926 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 754\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 117, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            n_estimators=117, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.52727273 0.41049383 0.77160494 0.73148148 0.66358025 0.5308642\n",
      " 0.42962963 0.38518519 0.54814815 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 755\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 45, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=45,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61454545 0.44444444 0.55555556 0.54320988 0.61419753 0.5308642\n",
      " 0.65185185 0.36111111 0.57962963 0.42037037]\n",
      "----------------------------------------\n",
      "Trial 756\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 11, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, n_estimators=11,\n",
      "                                            random_state=100, subsample=0.8))])\n",
      "cv score: [0.81818182 0.55555556 0.57098765 0.66975309 0.63271605 0.61419753\n",
      " 0.47777778 0.35925926 0.57777778 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 757\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=159,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.71454545 0.5787037  0.43055556 0.47222222 0.51851852 0.54012346\n",
      " 0.52222222 0.17592593 0.49444444 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 758\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 121, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=121,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.51851852 0.37962963 0.47222222 0.50925926 0.47685185\n",
      " 0.5        0.46296296 0.47222222 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 759\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 135, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            n_estimators=135,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.75636364 0.42283951 0.70987654 0.84259259 0.75925926 0.42283951\n",
      " 0.53333333 0.39259259 0.74444444 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 760\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 161, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=161, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.8        0.44444444 0.5787037  0.64351852 0.58950617 0.53395062\n",
      " 0.44074074 0.58888889 0.47037037 0.4537037 ]\n",
      "----------------------------------------\n",
      "Trial 761\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 162, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            n_estimators=162, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.67636364 0.4382716  0.68209877 0.79938272 0.62962963 0.54012346\n",
      " 0.32222222 0.28148148 0.48888889 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 762\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 63, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=63,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72727273 0.4382716  0.6882716  0.7191358  0.62654321 0.46296296\n",
      " 0.40740741 0.3037037  0.67037037 0.7       ]\n",
      "----------------------------------------\n",
      "Trial 763\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 114, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=114,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.27777778 0.70216049 0.49074074 0.77932099 0.55246914\n",
      " 0.59074074 0.35555556 0.42222222 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 764\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72363636 0.32716049 0.49382716 0.74691358 0.53703704 0.40740741\n",
      " 0.27407407 0.38518519 0.6        0.46666667]\n",
      "----------------------------------------\n",
      "Trial 765\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 168, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=168, random_state=100))])\n",
      "cv score: [0.6        0.39197531 0.62654321 0.78703704 0.65123457 0.55864198\n",
      " 0.35555556 0.41481481 0.48888889 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 766\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 154, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=154,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66363636 0.59722222 0.62037037 0.45987654 0.62962963 0.52623457\n",
      " 0.52222222 0.25740741 0.37962963 0.8537037 ]\n",
      "----------------------------------------\n",
      "Trial 767\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.66181818 0.33024691 0.69444444 0.69753086 0.70987654 0.5154321\n",
      " 0.34444444 0.41481481 0.56666667 0.57037037]\n",
      "----------------------------------------\n",
      "Trial 768\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 105, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=105,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.36728395 0.76851852 0.66049383 0.58024691 0.44135802\n",
      " 0.41111111 0.31481481 0.59259259 0.57037037]\n",
      "----------------------------------------\n",
      "Trial 769\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 139, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=139, random_state=100))])\n",
      "cv score: [0.62181818 0.39814815 0.64506173 0.80246914 0.68518519 0.55555556\n",
      " 0.36666667 0.44074074 0.48888889 0.54074074]\n",
      "----------------------------------------\n",
      "Trial 770\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.50545455 0.43209877 0.6882716  0.4382716  0.85339506 0.35802469\n",
      " 0.40740741 0.4        0.53333333 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 771\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 83, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            n_estimators=83, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.49818182 0.4537037  0.70061728 0.72530864 0.70061728 0.63271605\n",
      " 0.38148148 0.36666667 0.46666667 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 772\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 15, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=15, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.60727273 0.5308642  0.7191358  0.87037037 0.57098765 0.56790123\n",
      " 0.3962963  0.43703704 0.56296296 0.45555556]\n",
      "----------------------------------------\n",
      "Trial 773\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=183, random_state=100))])\n",
      "cv score: [0.72       0.57716049 0.56481481 0.63580247 0.61728395 0.49382716\n",
      " 0.39259259 0.31481481 0.51111111 0.3962963 ]\n",
      "----------------------------------------\n",
      "Trial 774\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=197,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6        0.47530864 0.70833333 0.57407407 0.63734568 0.55246914\n",
      " 0.59814815 0.44814815 0.41481481 0.60740741]\n",
      "----------------------------------------\n",
      "Trial 775\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61454545 0.41975309 0.55864198 0.70679012 0.57407407 0.45061728\n",
      " 0.45555556 0.29259259 0.48148148 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 776\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 95, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=95,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62727273 0.43364198 0.51234568 0.65740741 0.51851852 0.47993827\n",
      " 0.55555556 0.37037037 0.62037037 0.55740741]\n",
      "----------------------------------------\n",
      "Trial 777\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 126, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=126, random_state=100))])\n",
      "cv score: [0.6        0.44135802 0.62962963 0.80555556 0.68518519 0.60493827\n",
      " 0.32962963 0.42592593 0.5        0.49814815]\n",
      "----------------------------------------\n",
      "Trial 778\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 160, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=160, random_state=100))])\n",
      "cv score: [0.69090909 0.36111111 0.60802469 0.87654321 0.74382716 0.50617284\n",
      " 0.41851852 0.44444444 0.51111111 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 779\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 199, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=199, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.69454545 0.36419753 0.65740741 0.7808642  0.64197531 0.51851852\n",
      " 0.41481481 0.33333333 0.55185185 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 780\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 117, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=117,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66727273 0.45061728 0.55864198 0.73148148 0.56944444 0.54166667\n",
      " 0.4462963  0.27592593 0.55925926 0.55740741]\n",
      "----------------------------------------\n",
      "Trial 781\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, max_features='log2',\n",
      "                                            n_estimators=183, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.63272727 0.41975309 0.69753086 0.82716049 0.70679012 0.49382716\n",
      " 0.45185185 0.41851852 0.42592593 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 782\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 169, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=169,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59272727 0.44135802 0.5308642  0.64660494 0.56944444 0.5\n",
      " 0.56851852 0.30740741 0.60740741 0.47962963]\n",
      "----------------------------------------\n",
      "Trial 783\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 86, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=86, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.63636364 0.34259259 0.61111111 0.76234568 0.68518519 0.56481481\n",
      " 0.43703704 0.32222222 0.57037037 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 784\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 91, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=91,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72363636 0.54012346 0.50308642 0.76851852 0.55246914 0.59876543\n",
      " 0.32592593 0.40740741 0.48148148 0.54074074]\n",
      "----------------------------------------\n",
      "Trial 785\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 196, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=196,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64727273 0.34567901 0.64506173 0.7191358  0.61419753 0.48765432\n",
      " 0.34074074 0.3        0.58888889 0.55555556]\n",
      "----------------------------------------\n",
      "Trial 786\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 196, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=196,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65818182 0.37962963 0.5462963  0.69135802 0.66666667 0.4845679\n",
      " 0.34074074 0.44444444 0.48148148 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 787\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 107, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=107,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.80363636 0.46604938 0.5        0.80864198 0.64506173 0.47839506\n",
      " 0.37407407 0.41851852 0.53703704 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 788\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 151, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=151,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70727273 0.51697531 0.57098765 0.66666667 0.60802469 0.50617284\n",
      " 0.35555556 0.32592593 0.53888889 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 789\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 148, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=148,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61090909 0.3117284  0.51234568 0.65432099 0.66666667 0.47530864\n",
      " 0.25185185 0.28518519 0.54814815 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 790\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 144, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=144,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.67636364 0.41666667 0.68209877 0.79938272 0.76234568 0.39814815\n",
      " 0.34444444 0.41111111 0.54074074 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 791\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, max_features='sqrt',\n",
      "                                            n_estimators=52, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.64363636 0.44135802 0.64197531 0.75       0.66049383 0.41975309\n",
      " 0.48518519 0.34074074 0.44074074 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 792\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 188, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=188, random_state=100))])\n",
      "cv score: [0.71636364 0.5462963  0.52469136 0.66358025 0.55555556 0.50308642\n",
      " 0.44074074 0.32222222 0.49259259 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 793\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=174,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66363636 0.57407407 0.69907407 0.47530864 0.625      0.54783951\n",
      " 0.52777778 0.27592593 0.40925926 0.68518519]\n",
      "----------------------------------------\n",
      "Trial 794\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 124, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=124,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66909091 0.53703704 0.51851852 0.70524691 0.5462963  0.63425926\n",
      " 0.58518519 0.31666667 0.64444444 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 795\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 128, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=128, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.27272727 0.41358025 0.66049383 0.65740741 0.78703704 0.41049383\n",
      " 0.44074074 0.42222222 0.43333333 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 796\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07,\n",
      "                                            n_estimators=170, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.66545455 0.44444444 0.75308642 0.75925926 0.60493827 0.33333333\n",
      " 0.32592593 0.31481481 0.65925926 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 797\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 33, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=6,\n",
      "                                            n_estimators=33, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.73090909 0.45987654 0.64506173 0.75925926 0.67901235 0.57098765\n",
      " 0.26296296 0.29259259 0.58518519 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 798\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 142, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=142, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.68727273 0.50617284 0.58024691 0.63888889 0.57716049 0.47530864\n",
      " 0.27037037 0.37407407 0.44814815 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 799\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 72, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, max_features='sqrt',\n",
      "                                            n_estimators=72, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.73454545 0.44444444 0.64197531 0.77469136 0.54938272 0.31790123\n",
      " 0.43333333 0.33703704 0.45925926 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 800\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.72727273 0.45061728 0.63271605 0.7962963  0.59259259 0.47839506\n",
      " 0.34814815 0.42962963 0.45555556 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 801\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 122, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=122,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.75636364 0.40432099 0.54012346 0.67283951 0.65123457 0.34259259\n",
      " 0.27037037 0.35925926 0.53333333 0.54814815]\n",
      "----------------------------------------\n",
      "Trial 802\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 110, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=110,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.51851852 0.37962963 0.47222222 0.50925926 0.47685185\n",
      " 0.5        0.46296296 0.47222222 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 803\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 56, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=56, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.78181818 0.37037037 0.73148148 0.82098765 0.60802469 0.50617284\n",
      " 0.4037037  0.40740741 0.63703704 0.65185185]\n",
      "----------------------------------------\n",
      "Trial 804\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 23, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=23,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61636364 0.48302469 0.53395062 0.54012346 0.52777778 0.60493827\n",
      " 0.62407407 0.4962963  0.61296296 0.4537037 ]\n",
      "----------------------------------------\n",
      "Trial 805\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 39, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=7, n_estimators=39,\n",
      "                                            random_state=100, subsample=0.8))])\n",
      "cv score: [0.56363636 0.46604938 0.66975309 0.87345679 0.7345679  0.5\n",
      " 0.41851852 0.31481481 0.61851852 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 806\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 57, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=57,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.81454545 0.32716049 0.62345679 0.64814815 0.63271605 0.46296296\n",
      " 0.35555556 0.37407407 0.47037037 0.48518519]\n",
      "----------------------------------------\n",
      "Trial 807\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 111, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=111,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58363636 0.5154321  0.5308642  0.54320988 0.4845679  0.52777778\n",
      " 0.64444444 0.31481481 0.57407407 0.39444444]\n",
      "----------------------------------------\n",
      "Trial 808\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 106, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=106,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57636364 0.49074074 0.53240741 0.5462963  0.54783951 0.53240741\n",
      " 0.66111111 0.32592593 0.56666667 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 809\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 76, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, n_estimators=76,\n",
      "                                            random_state=100, subsample=0.8))])\n",
      "cv score: [0.58545455 0.48148148 0.7345679  0.84567901 0.7962963  0.58641975\n",
      " 0.4037037  0.3962963  0.53703704 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 810\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71272727 0.41666667 0.56790123 0.7808642  0.56481481 0.51234568\n",
      " 0.3037037  0.40740741 0.45555556 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 811\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 149, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=149, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.71636364 0.35185185 0.68209877 0.76234568 0.71604938 0.50308642\n",
      " 0.29259259 0.36666667 0.5962963  0.64814815]\n",
      "----------------------------------------\n",
      "Trial 812\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 194, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=194, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.67272727 0.4382716  0.69135802 0.87345679 0.7345679  0.40432099\n",
      " 0.42962963 0.43703704 0.55925926 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 813\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 179, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=179,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57090909 0.44135802 0.49691358 0.66975309 0.5        0.56790123\n",
      " 0.32592593 0.33703704 0.5962963  0.57407407]\n",
      "----------------------------------------\n",
      "Trial 814\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 85, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=85,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69090909 0.36111111 0.57716049 0.68518519 0.60185185 0.51234568\n",
      " 0.31851852 0.23703704 0.59259259 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 815\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=133, random_state=100))])\n",
      "cv score: [0.76727273 0.61265432 0.52932099 0.6882716  0.49691358 0.54166667\n",
      " 0.41111111 0.3537037  0.45740741 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 816\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 148, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=148,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72727273 0.43209877 0.5308642  0.72839506 0.55246914 0.38888889\n",
      " 0.27407407 0.35555556 0.53333333 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 817\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 187, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=187, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.70181818 0.41358025 0.63580247 0.8117284  0.65740741 0.56790123\n",
      " 0.35555556 0.34444444 0.52222222 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 818\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 129, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=129, random_state=100))])\n",
      "cv score: [0.69090909 0.41358025 0.65123457 0.85802469 0.67283951 0.58641975\n",
      " 0.33703704 0.42592593 0.50740741 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 819\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 87, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=87,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.27777778 0.70216049 0.49074074 0.77932099 0.55246914\n",
      " 0.59074074 0.35555556 0.42222222 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 820\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65272727 0.47530864 0.54475309 0.66975309 0.52777778 0.50462963\n",
      " 0.54259259 0.2962963  0.57037037 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 821\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 98, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=98, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.58545455 0.5154321  0.59259259 0.60802469 0.65123457 0.48765432\n",
      " 0.34814815 0.27777778 0.47037037 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 822\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 188, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=6,\n",
      "                                            n_estimators=188, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.63272727 0.4691358  0.71296296 0.81790123 0.75       0.46296296\n",
      " 0.46296296 0.36666667 0.48888889 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 823\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 34, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=34,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.73090909 0.58333333 0.52932099 0.62962963 0.66203704 0.55401235\n",
      " 0.42592593 0.3037037  0.49814815 0.50555556]\n",
      "----------------------------------------\n",
      "Trial 824\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 65, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            n_estimators=65, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.48363636 0.47839506 0.62345679 0.58333333 0.65123457 0.33641975\n",
      " 0.37037037 0.43333333 0.5962963  0.35555556]\n",
      "----------------------------------------\n",
      "Trial 825\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 102, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=102, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.66181818 0.44753086 0.39506173 0.76234568 0.72839506 0.56790123\n",
      " 0.46296296 0.44444444 0.43703704 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 826\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 107, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=107, random_state=100))])\n",
      "cv score: [0.65454545 0.54320988 0.60802469 0.63580247 0.55864198 0.57407407\n",
      " 0.4        0.31481481 0.51111111 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 827\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 19, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=19, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.67454545 0.57561728 0.47839506 0.61882716 0.52623457 0.41049383\n",
      " 0.56666667 0.37222222 0.37592593 0.35925926]\n",
      "----------------------------------------\n",
      "Trial 828\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.72363636 0.45061728 0.5462963  0.77469136 0.52160494 0.4845679\n",
      " 0.4037037  0.49259259 0.59259259 0.38148148]\n",
      "----------------------------------------\n",
      "Trial 829\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 59, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=59, random_state=100))])\n",
      "cv score: [0.67272727 0.46604938 0.59259259 0.7962963  0.6882716  0.40740741\n",
      " 0.38518519 0.37037037 0.49259259 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 830\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 11, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=11, random_state=100))])\n",
      "cv score: [0.79636364 0.5462963  0.44290123 0.63117284 0.5308642  0.51080247\n",
      " 0.59259259 0.26296296 0.32777778 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 831\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 141, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=141,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76545455 0.60493827 0.56018519 0.66666667 0.63580247 0.4845679\n",
      " 0.51666667 0.36851852 0.57037037 0.45      ]\n",
      "----------------------------------------\n",
      "Trial 832\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 45, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=45,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68       0.34259259 0.56481481 0.66049383 0.48765432 0.39506173\n",
      " 0.39259259 0.26296296 0.53703704 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 833\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 138, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=138,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70545455 0.38271605 0.51234568 0.72222222 0.44444444 0.42901235\n",
      " 0.36666667 0.37037037 0.41481481 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 834\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 98, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=98,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81818182 0.59567901 0.56481481 0.62962963 0.63888889 0.4845679\n",
      " 0.50740741 0.39259259 0.54074074 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 835\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 114, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            n_estimators=114, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.59636364 0.36111111 0.65432099 0.77777778 0.64197531 0.57716049\n",
      " 0.4037037  0.32962963 0.55185185 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 836\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 56, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=8, n_estimators=56,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.73818182 0.49074074 0.71296296 0.75308642 0.68518519 0.4537037\n",
      " 0.34074074 0.36296296 0.48888889 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 837\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.83272727 0.5308642  0.37654321 0.79320988 0.54320988 0.40740741\n",
      " 0.36666667 0.74444444 0.52962963 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 838\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 120, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=120, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.66545455 0.52469136 0.59876543 0.65123457 0.54938272 0.33641975\n",
      " 0.21111111 0.30740741 0.55185185 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 839\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 50, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=50,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.75636364 0.36419753 0.55864198 0.66358025 0.60802469 0.50617284\n",
      " 0.33333333 0.35185185 0.54074074 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 840\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 92, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=92,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70181818 0.45216049 0.53240741 0.74691358 0.5632716  0.47993827\n",
      " 0.4962963  0.28148148 0.64814815 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 841\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 43, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=43, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.66181818 0.33641975 0.77777778 0.80246914 0.59876543 0.47839506\n",
      " 0.47037037 0.37777778 0.38888889 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 842\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 120, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=120,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66363636 0.57407407 0.69907407 0.47530864 0.625      0.54783951\n",
      " 0.52777778 0.27592593 0.40925926 0.68518519]\n",
      "----------------------------------------\n",
      "Trial 843\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 117, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=117, random_state=100))])\n",
      "cv score: [0.80363636 0.52160494 0.59876543 0.7962963  0.64814815 0.53703704\n",
      " 0.24074074 0.25185185 0.6037037  0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 844\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72       0.35802469 0.58950617 0.7345679  0.65123457 0.48148148\n",
      " 0.30740741 0.39259259 0.4037037  0.4       ]\n",
      "----------------------------------------\n",
      "Trial 845\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=133, random_state=100))])\n",
      "cv score: [0.62545455 0.4845679  0.59567901 0.7345679  0.55864198 0.5154321\n",
      " 0.31111111 0.34074074 0.55925926 0.45555556]\n",
      "----------------------------------------\n",
      "Trial 846\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 116, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=116,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62545455 0.42592593 0.5        0.67901235 0.65740741 0.49691358\n",
      " 0.32592593 0.42592593 0.53703704 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 847\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 84, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=84, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.60727273 0.36728395 0.65740741 0.73148148 0.66358025 0.60802469\n",
      " 0.45185185 0.48888889 0.54444444 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 848\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 132, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=132, random_state=100))])\n",
      "cv score: [0.68       0.51234568 0.62962963 0.66666667 0.50925926 0.47530864\n",
      " 0.25555556 0.2962963  0.57777778 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 849\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 87, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=87, random_state=100))])\n",
      "cv score: [0.65454545 0.42592593 0.65432099 0.84876543 0.64814815 0.60493827\n",
      " 0.35185185 0.34444444 0.49259259 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 850\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 110, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=110,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.8        0.43209877 0.45061728 0.83024691 0.53703704 0.44753086\n",
      " 0.48148148 0.44444444 0.43333333 0.37037037]\n",
      "----------------------------------------\n",
      "Trial 851\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 118, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=118,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64       0.51080247 0.70216049 0.47839506 0.69753086 0.47685185\n",
      " 0.52037037 0.32777778 0.41666667 0.69074074]\n",
      "----------------------------------------\n",
      "Trial 852\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68363636 0.40123457 0.54320988 0.68518519 0.57098765 0.42901235\n",
      " 0.27777778 0.35555556 0.56666667 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 853\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=183, random_state=100))])\n",
      "cv score: [0.65454545 0.40123457 0.55246914 0.73765432 0.69444444 0.48148148\n",
      " 0.35185185 0.43703704 0.53703704 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 854\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.61818182 0.45987654 0.73765432 0.74691358 0.67901235 0.44444444\n",
      " 0.40740741 0.39259259 0.61111111 0.58888889]\n",
      "----------------------------------------\n",
      "Trial 855\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 84, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=84,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60727273 0.43518519 0.5154321  0.61419753 0.58950617 0.4691358\n",
      " 0.28888889 0.55925926 0.45185185 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 856\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 154, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=154,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.39197531 0.47839506 0.70061728 0.53395062 0.41975309\n",
      " 0.28518519 0.26296296 0.55925926 0.51851852]\n",
      "----------------------------------------\n",
      "Trial 857\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 136, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=136, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.86545455 0.19135802 0.54938272 0.66666667 0.4845679  0.45679012\n",
      " 0.32962963 0.44074074 0.6        0.44444444]\n",
      "----------------------------------------\n",
      "Trial 858\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 42, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=42, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.68       0.41666667 0.70061728 0.66666667 0.59876543 0.44753086\n",
      " 0.47407407 0.45185185 0.54444444 0.37407407]\n",
      "----------------------------------------\n",
      "Trial 859\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 93, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            n_estimators=93, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.77818182 0.7654321  0.5462963  0.65432099 0.3117284  0.63425926\n",
      " 0.74444444 0.4962963  0.5962963  0.55925926]\n",
      "----------------------------------------\n",
      "Trial 860\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 19, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=19,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61090909 0.46759259 0.53395062 0.54012346 0.5462963  0.55092593\n",
      " 0.61666667 0.48518519 0.66481481 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 861\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 88, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=88,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53090909 0.38271605 0.5462963  0.63271605 0.59876543 0.4537037\n",
      " 0.32962963 0.27407407 0.6        0.57037037]\n",
      "----------------------------------------\n",
      "Trial 862\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 13, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=13,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.65636364 0.45679012 0.65432099 0.5787037  0.53703704 0.49228395\n",
      " 0.37777778 0.37037037 0.55925926 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 863\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58       0.49537037 0.52314815 0.5462963  0.57716049 0.49845679\n",
      " 0.61481481 0.27962963 0.64074074 0.45740741]\n",
      "----------------------------------------\n",
      "Trial 864\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 12, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=12,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58545455 0.46296296 0.56790123 0.46296296 0.46296296 0.5308642\n",
      " 0.5462963  0.41666667 0.59074074 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 865\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 190, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=190,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72727273 0.36111111 0.58641975 0.77160494 0.69135802 0.49074074\n",
      " 0.37407407 0.42222222 0.42222222 0.45555556]\n",
      "----------------------------------------\n",
      "Trial 866\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 88, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=88, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.61090909 0.36728395 0.66975309 0.79012346 0.72530864 0.4382716\n",
      " 0.34074074 0.31481481 0.48888889 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 867\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 37, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=37,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61818182 0.37962963 0.6882716  0.64197531 0.66203704 0.53703704\n",
      " 0.44444444 0.2962963  0.60740741 0.61111111]\n",
      "----------------------------------------\n",
      "Trial 868\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 36, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=36, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.53090909 0.66666667 0.60185185 0.67283951 0.5154321  0.45061728\n",
      " 0.67407407 0.38148148 0.55925926 0.21111111]\n",
      "----------------------------------------\n",
      "Trial 869\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 56, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=56,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.68727273 0.5462963  0.42283951 0.7037037  0.56481481 0.49691358\n",
      " 0.44814815 0.42962963 0.4962963  0.27037037]\n",
      "----------------------------------------\n",
      "Trial 870\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 101, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=101,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70545455 0.51851852 0.62962963 0.69753086 0.34567901 0.5462963\n",
      " 0.34074074 0.40740741 0.54444444 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 871\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 35, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=35,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.47222222 0.5        0.48148148]\n",
      "----------------------------------------\n",
      "Trial 872\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 190, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=190,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.82545455 0.39197531 0.57407407 0.75308642 0.50617284 0.54938272\n",
      " 0.31111111 0.44814815 0.51481481 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 873\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 71, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=71,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.70181818 0.34567901 0.73148148 0.7037037  0.67901235 0.62962963\n",
      " 0.46296296 0.45185185 0.5962963  0.48148148]\n",
      "----------------------------------------\n",
      "Trial 874\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 166, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=166, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.66181818 0.6867284  0.66975309 0.77469136 0.59567901 0.39814815\n",
      " 0.45555556 0.43333333 0.60740741 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 875\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66909091 0.38271605 0.49074074 0.58950617 0.57716049 0.41358025\n",
      " 0.2962963  0.30740741 0.51851852 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 876\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 80, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=80,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.76727273 0.38888889 0.5462963  0.7345679  0.45987654 0.50617284\n",
      " 0.54814815 0.38888889 0.48148148 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 877\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 196, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=196,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73454545 0.54783951 0.57407407 0.67438272 0.58796296 0.47376543\n",
      " 0.43703704 0.34074074 0.55555556 0.49444444]\n",
      "----------------------------------------\n",
      "Trial 878\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.74909091 0.2962963  0.52160494 0.78395062 0.39814815 0.49382716\n",
      " 0.34074074 0.51111111 0.35555556 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 879\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58909091 0.46604938 0.51388889 0.72222222 0.55555556 0.54475309\n",
      " 0.56111111 0.3        0.64444444 0.47592593]\n",
      "----------------------------------------\n",
      "Trial 880\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 37, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=37,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74909091 0.36728395 0.5462963  0.59259259 0.71604938 0.45987654\n",
      " 0.35925926 0.39259259 0.4037037  0.62222222]\n",
      "----------------------------------------\n",
      "Trial 881\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 43, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=43, random_state=100))])\n",
      "cv score: [0.69818182 0.52160494 0.59567901 0.70061728 0.65740741 0.58333333\n",
      " 0.36666667 0.44074074 0.61851852 0.3962963 ]\n",
      "----------------------------------------\n",
      "Trial 882\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 112, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=112,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68363636 0.52623457 0.54320988 0.68055556 0.53240741 0.50154321\n",
      " 0.56851852 0.31851852 0.55555556 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 883\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 92, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            n_estimators=92, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.66181818 0.50308642 0.59259259 0.72839506 0.63580247 0.53703704\n",
      " 0.21481481 0.30555556 0.57407407 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 884\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 184, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=184, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.66909091 0.57716049 0.55246914 0.67592593 0.67283951 0.49382716\n",
      " 0.43333333 0.4        0.47037037 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 885\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 130, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=130,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66545455 0.35185185 0.68518519 0.7037037  0.62962963 0.44444444\n",
      " 0.37037037 0.2962963  0.54074074 0.6037037 ]\n",
      "----------------------------------------\n",
      "Trial 886\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 160, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=160, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.72363636 0.44135802 0.59567901 0.67592593 0.7191358  0.41049383\n",
      " 0.31481481 0.33703704 0.5037037  0.5       ]\n",
      "----------------------------------------\n",
      "Trial 887\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 144, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=144,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65636364 0.41666667 0.55246914 0.5462963  0.59104938 0.52777778\n",
      " 0.64444444 0.31481481 0.62962963 0.48333333]\n",
      "----------------------------------------\n",
      "Trial 888\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 70, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=70,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50181818 0.51080247 0.55709877 0.66975309 0.57716049 0.53395062\n",
      " 0.54074074 0.34814815 0.63703704 0.62592593]\n",
      "----------------------------------------\n",
      "Trial 889\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 39, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=39, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.6        0.31790123 0.6882716  0.77469136 0.55864198 0.61111111\n",
      " 0.43333333 0.34444444 0.35555556 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 890\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 29, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=14,\n",
      "                                            n_estimators=29, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.66909091 0.30246914 0.57407407 0.77777778 0.74691358 0.71296296\n",
      " 0.48148148 0.32962963 0.57037037 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 891\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.70909091 0.39197531 0.67901235 0.85185185 0.62654321 0.59259259\n",
      " 0.45925926 0.44074074 0.52592593 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 892\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 178, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=14,\n",
      "                                            n_estimators=178, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.65454545 0.49691358 0.70679012 0.75308642 0.66666667 0.51234568\n",
      " 0.37037037 0.32222222 0.5        0.47777778]\n",
      "----------------------------------------\n",
      "Trial 893\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 83, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=83,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.74727273 0.55092593 0.56790123 0.61111111 0.60339506 0.49382716\n",
      " 0.5        0.32777778 0.51851852 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 894\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72       0.37345679 0.57098765 0.70061728 0.63580247 0.46296296\n",
      " 0.32222222 0.33333333 0.44074074 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 895\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=13,\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.63272727 0.4382716  0.64197531 0.69135802 0.62962963 0.64814815\n",
      " 0.35185185 0.42592593 0.48148148 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 896\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 14, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=14, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.62909091 0.35802469 0.69135802 0.65123457 0.5462963  0.50925926\n",
      " 0.36666667 0.19259259 0.41851852 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 897\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 73, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            n_estimators=73, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.71636364 0.30864198 0.67283951 0.76234568 0.75617284 0.60185185\n",
      " 0.42592593 0.22592593 0.54814815 0.51851852]\n",
      "----------------------------------------\n",
      "Trial 898\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 30, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=30,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67636364 0.30864198 0.58333333 0.6882716  0.5617284  0.49074074\n",
      " 0.4        0.21851852 0.6        0.53703704]\n",
      "----------------------------------------\n",
      "Trial 899\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72363636 0.36419753 0.49691358 0.73765432 0.63271605 0.53395062\n",
      " 0.26666667 0.36296296 0.44074074 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 900\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.61454545 0.4691358  0.77469136 0.64506173 0.44444444 0.44135802\n",
      " 0.34444444 0.45555556 0.64074074 0.5962963 ]\n",
      "----------------------------------------\n",
      "Trial 901\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 149, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=12,\n",
      "                                            n_estimators=149, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.47636364 0.55555556 0.42901235 0.7191358  0.53703704 0.35802469\n",
      " 0.4037037  0.48888889 0.55185185 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 902\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=38, random_state=100))])\n",
      "cv score: [0.66181818 0.56481481 0.59259259 0.66049383 0.50617284 0.40432099\n",
      " 0.3        0.27037037 0.57407407 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 903\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52       0.44444444 0.60339506 0.54012346 0.44444444 0.46296296\n",
      " 0.58333333 0.40740741 0.54259259 0.58888889]\n",
      "----------------------------------------\n",
      "Trial 904\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 23, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=23,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60727273 0.38580247 0.5154321  0.59567901 0.74691358 0.41666667\n",
      " 0.37777778 0.38148148 0.52222222 0.55555556]\n",
      "----------------------------------------\n",
      "Trial 905\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 37, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=37,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73818182 0.50617284 0.60185185 0.68518519 0.59876543 0.39197531\n",
      " 0.24074074 0.4037037  0.51481481 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 906\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 28, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=28, random_state=100))])\n",
      "cv score: [0.66727273 0.4537037  0.67592593 0.78703704 0.6882716  0.48148148\n",
      " 0.37037037 0.41481481 0.48703704 0.59814815]\n",
      "----------------------------------------\n",
      "Trial 907\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 15, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=15,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56363636 0.45679012 0.49074074 0.67901235 0.47222222 0.52160494\n",
      " 0.2962963  0.41481481 0.61481481 0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 908\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 185, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=185, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.64727273 0.33950617 0.66358025 0.80246914 0.64197531 0.57407407\n",
      " 0.44814815 0.41481481 0.4        0.45925926]\n",
      "----------------------------------------\n",
      "Trial 909\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 117, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=117,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72       0.41358025 0.62345679 0.68518519 0.50617284 0.35493827\n",
      " 0.25555556 0.43703704 0.39259259 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 910\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 43, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=43, random_state=100))])\n",
      "cv score: [0.64363636 0.48765432 0.65740741 0.87962963 0.68209877 0.4691358\n",
      " 0.32962963 0.38888889 0.55555556 0.62592593]\n",
      "----------------------------------------\n",
      "Trial 911\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 66, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=66, random_state=100))])\n",
      "cv score: [0.70545455 0.52777778 0.57716049 0.65432099 0.48148148 0.48765432\n",
      " 0.36666667 0.30740741 0.47407407 0.4       ]\n",
      "----------------------------------------\n",
      "Trial 912\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 138, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=138,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.51851852 0.52623457 0.57716049 0.58179012 0.58796296\n",
      " 0.5037037  0.2962963  0.59074074 0.61666667]\n",
      "----------------------------------------\n",
      "Trial 913\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 105, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=105,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66363636 0.59722222 0.62037037 0.45987654 0.62962963 0.52623457\n",
      " 0.52222222 0.25740741 0.37962963 0.8537037 ]\n",
      "----------------------------------------\n",
      "Trial 914\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 147, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=147, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.72       0.44753086 0.66666667 0.75617284 0.66666667 0.41666667\n",
      " 0.4037037  0.33333333 0.65925926 0.51851852]\n",
      "----------------------------------------\n",
      "Trial 915\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 111, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=111,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61272727 0.47685185 0.52469136 0.52006173 0.53549383 0.43055556\n",
      " 0.56111111 0.35       0.55555556 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 916\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 120, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            n_estimators=120, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.50909091 0.48148148 0.71296296 0.75617284 0.74382716 0.41358025\n",
      " 0.38888889 0.32592593 0.46666667 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 917\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 56, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=56, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.78181818 0.61265432 0.49228395 0.64814815 0.47222222 0.50154321\n",
      " 0.51111111 0.29814815 0.45555556 0.39074074]\n",
      "----------------------------------------\n",
      "Trial 918\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 18, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=18, random_state=100))])\n",
      "cv score: [0.58545455 0.41049383 0.60802469 0.68209877 0.66049383 0.42592593\n",
      " 0.32592593 0.38518519 0.52592593 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 919\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 188, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=188,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.77454545 0.37345679 0.54938272 0.66666667 0.53703704 0.52469136\n",
      " 0.37407407 0.43333333 0.41111111 0.41111111]\n",
      "----------------------------------------\n",
      "Trial 920\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 141, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=141,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.76727273 0.46604938 0.53395062 0.73148148 0.46604938 0.37962963\n",
      " 0.35925926 0.4962963  0.52592593 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 921\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 104, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=104,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.68363636 0.37037037 0.70987654 0.70061728 0.62962963 0.45679012\n",
      " 0.34074074 0.32222222 0.55185185 0.62962963]\n",
      "----------------------------------------\n",
      "Trial 922\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 69, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=69,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.2962963  0.75154321 0.51697531 0.7808642  0.55246914\n",
      " 0.45925926 0.38518519 0.51296296 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 923\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70545455 0.35185185 0.54938272 0.71604938 0.64197531 0.49382716\n",
      " 0.2962963  0.32962963 0.51851852 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 924\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 10, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            n_estimators=10, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.71272727 0.35030864 0.81018519 0.74228395 0.69753086 0.5154321\n",
      " 0.32962963 0.40185185 0.57777778 0.50555556]\n",
      "----------------------------------------\n",
      "Trial 925\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 30, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=30,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69090909 0.31790123 0.58333333 0.7191358  0.47839506 0.42901235\n",
      " 0.34444444 0.27037037 0.42592593 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 926\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 189, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=189,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.76363636 0.37962963 0.59876543 0.73765432 0.69135802 0.49691358\n",
      " 0.36296296 0.42222222 0.54444444 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 927\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 49, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            n_estimators=49, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.75272727 0.38271605 0.5308642  0.65432099 0.75925926 0.48148148\n",
      " 0.58888889 0.48888889 0.48148148 0.48703704]\n",
      "----------------------------------------\n",
      "Trial 928\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 169, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=169,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.81090909 0.41358025 0.61111111 0.72530864 0.48148148 0.4691358\n",
      " 0.34444444 0.43703704 0.35185185 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 929\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 124, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=124,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56363636 0.51851852 0.51388889 0.57098765 0.49228395 0.55092593\n",
      " 0.53518519 0.37962963 0.58888889 0.53888889]\n",
      "----------------------------------------\n",
      "Trial 930\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 138, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=138,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74181818 0.40123457 0.55555556 0.67592593 0.61728395 0.4691358\n",
      " 0.33333333 0.35555556 0.47407407 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 931\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 53, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=53,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76727273 0.44753086 0.71296296 0.72530864 0.60802469 0.50925926\n",
      " 0.41111111 0.24814815 0.68518519 0.70740741]\n",
      "----------------------------------------\n",
      "Trial 932\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 112, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=112,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.37345679 0.75617284 0.65740741 0.57407407 0.45987654\n",
      " 0.40740741 0.30740741 0.57407407 0.57037037]\n",
      "----------------------------------------\n",
      "Trial 933\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 171, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=171, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.58181818 0.38888889 0.73148148 0.67592593 0.59259259 0.44135802\n",
      " 0.38148148 0.38148148 0.47407407 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 934\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 178, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, max_features='sqrt',\n",
      "                                            n_estimators=178, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.55636364 0.38580247 0.65740741 0.83333333 0.68518519 0.49691358\n",
      " 0.4        0.44444444 0.4        0.3962963 ]\n",
      "----------------------------------------\n",
      "Trial 935\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.68545455 0.56790123 0.50154321 0.68364198 0.51851852 0.54783951\n",
      " 0.61851852 0.31851852 0.65555556 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 936\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 28, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=28,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72363636 0.49074074 0.64814815 0.71296296 0.54938272 0.52160494\n",
      " 0.40740741 0.42222222 0.57777778 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 937\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.60727273 0.38888889 0.86728395 0.63271605 0.64506173 0.50617284\n",
      " 0.2962963  0.45555556 0.49259259 0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 938\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 94, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            n_estimators=94, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.63272727 0.47839506 0.57098765 0.76851852 0.78395062 0.41358025\n",
      " 0.3037037  0.34074074 0.51481481 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 939\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 148, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=148,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64       0.51080247 0.70216049 0.47839506 0.69753086 0.47685185\n",
      " 0.52037037 0.32777778 0.41666667 0.69074074]\n",
      "----------------------------------------\n",
      "Trial 940\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.64363636 0.37037037 0.60493827 0.72839506 0.65123457 0.37345679\n",
      " 0.38518519 0.42962963 0.53333333 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 941\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=101,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76363636 0.46604938 0.55864198 0.66358025 0.61111111 0.5154321\n",
      " 0.33703704 0.28888889 0.55185185 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 942\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 20, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=20,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73818182 0.53703704 0.54320988 0.7037037  0.55864198 0.38888889\n",
      " 0.28888889 0.29259259 0.43333333 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 943\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 93, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=93,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69454545 0.36419753 0.57407407 0.67283951 0.57407407 0.30246914\n",
      " 0.26296296 0.37407407 0.59259259 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 944\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 38, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=38, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.54181818 0.36419753 0.62345679 0.65123457 0.63271605 0.4382716\n",
      " 0.45185185 0.31481481 0.53333333 0.62222222]\n",
      "----------------------------------------\n",
      "Trial 945\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 122, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=122,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61090909 0.57407407 0.49691358 0.76234568 0.44444444 0.44753086\n",
      " 0.34444444 0.5        0.4962963  0.40740741]\n",
      "----------------------------------------\n",
      "Trial 946\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 85, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=85,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62181818 0.49228395 0.52314815 0.7191358  0.49382716 0.51234568\n",
      " 0.64259259 0.39814815 0.54814815 0.46111111]\n",
      "----------------------------------------\n",
      "Trial 947\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=198, random_state=100))])\n",
      "cv score: [0.74909091 0.63271605 0.5154321  0.69444444 0.51851852 0.49382716\n",
      " 0.45185185 0.37037037 0.52222222 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 948\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 49, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            n_estimators=49, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.49818182 0.50617284 0.49691358 0.74382716 0.71296296 0.40432099\n",
      " 0.47407407 0.42962963 0.44074074 0.26666667]\n",
      "----------------------------------------\n",
      "Trial 949\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 137, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=137,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.39197531 0.48148148 0.66975309 0.63888889 0.45987654\n",
      " 0.35555556 0.47037037 0.53703704 0.4       ]\n",
      "----------------------------------------\n",
      "Trial 950\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 163, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=163, random_state=100))])\n",
      "cv score: [0.64727273 0.51851852 0.61111111 0.62345679 0.61419753 0.56481481\n",
      " 0.4        0.31111111 0.52222222 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 951\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 158, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=158,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71272727 0.30246914 0.55246914 0.72839506 0.5308642  0.39814815\n",
      " 0.34074074 0.4037037  0.57777778 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 952\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=178,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64       0.51080247 0.70216049 0.47839506 0.69753086 0.47685185\n",
      " 0.52037037 0.32777778 0.41666667 0.69074074]\n",
      "----------------------------------------\n",
      "Trial 953\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 48, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=48,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59454545 0.53240741 0.49074074 0.59259259 0.45679012 0.62808642\n",
      " 0.52777778 0.38148148 0.7037037  0.6462963 ]\n",
      "----------------------------------------\n",
      "Trial 954\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=171, random_state=100))])\n",
      "cv score: [0.67636364 0.41358025 0.62654321 0.75925926 0.64814815 0.57407407\n",
      " 0.35555556 0.30740741 0.54814815 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 955\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 93, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            n_estimators=93, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65818182 0.42901235 0.64197531 0.79012346 0.55555556 0.5462963\n",
      " 0.28148148 0.24444444 0.52962963 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 956\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 48, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=48,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69090909 0.38271605 0.50617284 0.63580247 0.74074074 0.5462963\n",
      " 0.29259259 0.37037037 0.58518519 0.61851852]\n",
      "----------------------------------------\n",
      "Trial 957\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 157, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=157, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.56727273 0.37962963 0.75925926 0.70987654 0.7037037  0.42592593\n",
      " 0.41851852 0.43333333 0.52222222 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 958\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 191, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=191, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.69454545 0.40123457 0.74074074 0.74074074 0.62654321 0.28395062\n",
      " 0.33333333 0.36666667 0.67407407 0.61851852]\n",
      "----------------------------------------\n",
      "Trial 959\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 176, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=176, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.65454545 0.27777778 0.62654321 0.66975309 0.55864198 0.19135802\n",
      " 0.30740741 0.44074074 0.57037037 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 960\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=102,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76       0.4691358  0.5617284  0.66358025 0.61111111 0.51234568\n",
      " 0.33703704 0.3037037  0.55185185 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 961\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74545455 0.52160494 0.58950617 0.72222222 0.5617284  0.46296296\n",
      " 0.35925926 0.43703704 0.44444444 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 962\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 75, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=75,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70181818 0.38271605 0.76851852 0.61419753 0.57407407 0.47839506\n",
      " 0.40740741 0.3        0.60740741 0.58888889]\n",
      "----------------------------------------\n",
      "Trial 963\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 57, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=57, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.75272727 0.33333333 0.77469136 0.5154321  0.71604938 0.46604938\n",
      " 0.17777778 0.35185185 0.65555556 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 964\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 58, 'gb__subsample': 0.95, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, n_estimators=58,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.63636364 0.44753086 0.72839506 0.85493827 0.72222222 0.57716049\n",
      " 0.41481481 0.31111111 0.64814815 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 965\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=14,\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.61818182 0.42283951 0.55555556 0.8117284  0.7191358  0.55864198\n",
      " 0.35555556 0.39259259 0.58518519 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 966\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.68       0.53703704 0.63580247 0.78395062 0.53703704 0.43518519\n",
      " 0.54814815 0.4        0.45185185 0.31851852]\n",
      "----------------------------------------\n",
      "Trial 967\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 65, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=65,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61454545 0.44444444 0.52777778 0.54320988 0.61419753 0.45987654\n",
      " 0.62777778 0.37037037 0.57592593 0.36666667]\n",
      "----------------------------------------\n",
      "Trial 968\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 123, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=123,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66181818 0.35493827 0.69753086 0.7191358  0.63271605 0.5\n",
      " 0.4        0.33703704 0.63333333 0.64074074]\n",
      "----------------------------------------\n",
      "Trial 969\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 21, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=21, random_state=100))])\n",
      "cv score: [0.57454545 0.40123457 0.66049383 0.67592593 0.63888889 0.41666667\n",
      " 0.32962963 0.41111111 0.5037037  0.42222222]\n",
      "----------------------------------------\n",
      "Trial 970\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 110, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=110,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.79272727 0.4691358  0.55555556 0.65432099 0.57407407 0.42283951\n",
      " 0.31481481 0.34074074 0.51851852 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 971\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=5, n_estimators=118,\n",
      "                                            random_state=100, subsample=0.8))])\n",
      "cv score: [0.69818182 0.52777778 0.69753086 0.82407407 0.74691358 0.41666667\n",
      " 0.40740741 0.30740741 0.6        0.42592593]\n",
      "----------------------------------------\n",
      "Trial 972\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66181818 0.4367284  0.57407407 0.65123457 0.49845679 0.4058642\n",
      " 0.54444444 0.27407407 0.66666667 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 973\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 179, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            n_estimators=179,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.8        0.48148148 0.73148148 0.71296296 0.70061728 0.29012346\n",
      " 0.32592593 0.3037037  0.73333333 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 974\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 14, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=14, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.66545455 0.44135802 0.6882716  0.54320988 0.53703704 0.44753086\n",
      " 0.24074074 0.46666667 0.45555556 0.34074074]\n",
      "----------------------------------------\n",
      "Trial 975\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=183, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.64       0.39506173 0.67592593 0.61728395 0.63271605 0.46296296\n",
      " 0.26666667 0.33333333 0.56296296 0.54814815]\n",
      "----------------------------------------\n",
      "Trial 976\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 57, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=57, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67272727 0.46604938 0.57407407 0.80864198 0.67592593 0.41049383\n",
      " 0.38888889 0.37407407 0.49259259 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 977\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 185, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=185, random_state=100))])\n",
      "cv score: [0.64727273 0.4537037  0.64506173 0.75       0.62345679 0.61111111\n",
      " 0.33703704 0.24074074 0.55185185 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 978\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56727273 0.37037037 0.57098765 0.67592593 0.59259259 0.59567901\n",
      " 0.41851852 0.27222222 0.53703704 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 979\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 119, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=8, max_features='sqrt',\n",
      "                                            n_estimators=119, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.59636364 0.4845679  0.74074074 0.77160494 0.68209877 0.4537037\n",
      " 0.49259259 0.41481481 0.42592593 0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 980\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 41, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=41, random_state=100))])\n",
      "cv score: [0.79636364 0.64351852 0.43518519 0.60185185 0.46296296 0.54320988\n",
      " 0.49074074 0.30925926 0.44444444 0.42407407]\n",
      "----------------------------------------\n",
      "Trial 981\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 169, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=169, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.51636364 0.37654321 0.60493827 0.5154321  0.45216049 0.59567901\n",
      " 0.44074074 0.4037037  0.41851852 0.27407407]\n",
      "----------------------------------------\n",
      "Trial 982\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 191, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=191, random_state=100))])\n",
      "cv score: [0.67636364 0.42901235 0.57407407 0.75       0.72222222 0.57407407\n",
      " 0.31481481 0.45555556 0.5037037  0.5       ]\n",
      "----------------------------------------\n",
      "Trial 983\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 45, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=45, random_state=100))])\n",
      "cv score: [0.68       0.58024691 0.55555556 0.66358025 0.4845679  0.38271605\n",
      " 0.3962963  0.31111111 0.53703704 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 984\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 56, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=56,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70909091 0.35185185 0.77160494 0.63271605 0.59876543 0.51234568\n",
      " 0.46296296 0.2962963  0.61111111 0.58888889]\n",
      "----------------------------------------\n",
      "Trial 985\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 131, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=131,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.76       0.40432099 0.45061728 0.7037037  0.58641975 0.38271605\n",
      " 0.35185185 0.37037037 0.53703704 0.45555556]\n",
      "----------------------------------------\n",
      "Trial 986\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57454545 0.38888889 0.49691358 0.70679012 0.50617284 0.58333333\n",
      " 0.4037037  0.32962963 0.6037037  0.56666667]\n",
      "----------------------------------------\n",
      "Trial 987\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 22, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=22,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.77454545 0.33333333 0.58333333 0.73765432 0.48148148 0.50308642\n",
      " 0.47037037 0.4037037  0.49259259 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 988\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 16, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=16,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.64363636 0.44135802 0.65432099 0.68209877 0.54012346 0.50925926\n",
      " 0.43333333 0.37037037 0.58703704 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 989\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 146, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=146, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.56       0.45987654 0.5154321  0.81790123 0.61111111 0.52777778\n",
      " 0.55555556 0.51111111 0.33333333 0.34814815]\n",
      "----------------------------------------\n",
      "Trial 990\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.67636364 0.4537037  0.49382716 0.66049383 0.53703704 0.46604938\n",
      " 0.41111111 0.31481481 0.45185185 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 991\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 176, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=176, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.63636364 0.41049383 0.62345679 0.75308642 0.64197531 0.54320988\n",
      " 0.42962963 0.43703704 0.54444444 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 992\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 79, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=79,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.69454545 0.37654321 0.77469136 0.61419753 0.57716049 0.4691358\n",
      " 0.41111111 0.3037037  0.61111111 0.58888889]\n",
      "----------------------------------------\n",
      "Trial 993\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=198, random_state=100))])\n",
      "cv score: [0.68727273 0.40123457 0.62654321 0.81790123 0.65740741 0.53703704\n",
      " 0.30740741 0.42222222 0.5        0.47407407]\n",
      "----------------------------------------\n",
      "Trial 994\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=115, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.62545455 0.41049383 0.67592593 0.71296296 0.66358025 0.52160494\n",
      " 0.3037037  0.39259259 0.50740741 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 995\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 40, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=40, random_state=100))])\n",
      "cv score: [0.77818182 0.44135802 0.64351852 0.86265432 0.6882716  0.59259259\n",
      " 0.38333333 0.41111111 0.51481481 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 996\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 98, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=98,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72       0.5308642  0.52777778 0.66820988 0.60030864 0.50154321\n",
      " 0.38518519 0.27592593 0.50555556 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 997\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 85, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=85, random_state=100))])\n",
      "cv score: [0.66181818 0.54012346 0.58641975 0.74691358 0.57716049 0.39814815\n",
      " 0.28888889 0.31481481 0.54814815 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 998\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 25, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=25,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69272727 0.47839506 0.51080247 0.60648148 0.42438272 0.55246914\n",
      " 0.56666667 0.50555556 0.50740741 0.49444444]\n",
      "----------------------------------------\n",
      "Trial 999\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 30, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=30,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66727273 0.5787037  0.63888889 0.57253086 0.61111111 0.54475309\n",
      " 0.52222222 0.16666667 0.32592593 0.53518519]\n",
      "----------------------------------------\n",
      "Trial 1000\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 54, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            n_estimators=54,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.72909091 0.52160494 0.58333333 0.62808642 0.62037037 0.43364198\n",
      " 0.40555556 0.30925926 0.54259259 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 1001\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 73, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=73,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.73818182 0.30864198 0.70679012 0.69135802 0.61419753 0.46604938\n",
      " 0.36666667 0.35925926 0.55555556 0.68148148]\n",
      "----------------------------------------\n",
      "Trial 1002\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 114, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=114, random_state=100))])\n",
      "cv score: [0.70545455 0.4382716  0.57407407 0.77160494 0.72222222 0.57716049\n",
      " 0.28148148 0.42222222 0.56296296 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 1003\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 175, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=175,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62909091 0.35185185 0.66975309 0.64814815 0.62654321 0.51851852\n",
      " 0.35925926 0.3037037  0.61481481 0.58148148]\n",
      "----------------------------------------\n",
      "Trial 1004\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 98, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=98, random_state=100))])\n",
      "cv score: [0.69818182 0.37654321 0.65432099 0.87962963 0.66975309 0.57716049\n",
      " 0.2962963  0.47407407 0.51851852 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 1005\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 130, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=130,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58545455 0.40740741 0.5617284  0.69135802 0.54320988 0.60493827\n",
      " 0.44074074 0.31851852 0.58518519 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 1006\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=70,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.73818182 0.31790123 0.72530864 0.6882716  0.60802469 0.46604938\n",
      " 0.36666667 0.35555556 0.52962963 0.69259259]\n",
      "----------------------------------------\n",
      "Trial 1007\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 147, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=147, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.8        0.42283951 0.5787037  0.64351852 0.58950617 0.53395062\n",
      " 0.45185185 0.54814815 0.47037037 0.4537037 ]\n",
      "----------------------------------------\n",
      "Trial 1008\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 122, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=122,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67272727 0.37654321 0.53703704 0.69444444 0.6882716  0.47839506\n",
      " 0.36296296 0.42962963 0.41481481 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 1009\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 124, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=124,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58909091 0.31481481 0.5462963  0.67901235 0.59259259 0.58024691\n",
      " 0.47777778 0.25925926 0.64814815 0.58148148]\n",
      "----------------------------------------\n",
      "Trial 1010\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 169, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=169,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64       0.35185185 0.66049383 0.64814815 0.62037037 0.52469136\n",
      " 0.36296296 0.30740741 0.6037037  0.57777778]\n",
      "----------------------------------------\n",
      "Trial 1011\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 39, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=39,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61090909 0.39197531 0.62962963 0.61111111 0.49691358 0.39814815\n",
      " 0.42592593 0.28148148 0.41851852 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 1012\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 100, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2',\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66909091 0.38271605 0.75617284 0.66358025 0.58024691 0.4537037\n",
      " 0.4        0.32222222 0.6037037  0.57037037]\n",
      "----------------------------------------\n",
      "Trial 1013\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 105, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=105,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.69090909 0.40123457 0.66975309 0.75925926 0.66666667 0.5154321\n",
      " 0.41851852 0.37407407 0.55925926 0.6       ]\n",
      "----------------------------------------\n",
      "Trial 1014\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 181, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=181, random_state=100))])\n",
      "cv score: [0.68       0.37345679 0.62962963 0.86728395 0.71604938 0.5462963\n",
      " 0.41851852 0.41851852 0.51851852 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 1015\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64727273 0.41358025 0.49691358 0.66358025 0.43209877 0.4537037\n",
      " 0.27407407 0.2962963  0.5        0.53333333]\n",
      "----------------------------------------\n",
      "Trial 1016\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 26, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=26,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62909091 0.59259259 0.47530864 0.5462963  0.58796296 0.61882716\n",
      " 0.58148148 0.43703704 0.62592593 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 1017\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67272727 0.34876543 0.63580247 0.73765432 0.4845679  0.33950617\n",
      " 0.32962963 0.31111111 0.58148148 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 1018\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 15, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=15,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69090909 0.41666667 0.52777778 0.77469136 0.4691358  0.56481481\n",
      " 0.52962963 0.41481481 0.46296296 0.74074074]\n",
      "----------------------------------------\n",
      "Trial 1019\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 45, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=45,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61636364 0.50462963 0.57407407 0.5462963  0.50925926 0.60648148\n",
      " 0.62037037 0.43703704 0.65       0.46296296]\n",
      "----------------------------------------\n",
      "Trial 1020\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 71, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=71,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.38888889 0.57407407 0.79320988 0.59567901 0.4845679\n",
      " 0.42592593 0.2962963  0.51481481 0.64444444]\n",
      "----------------------------------------\n",
      "Trial 1021\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 148, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=148, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.58909091 0.33641975 0.72839506 0.75617284 0.72839506 0.5308642\n",
      " 0.38148148 0.32222222 0.60740741 0.54074074]\n",
      "----------------------------------------\n",
      "Trial 1022\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 195, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            n_estimators=195, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.67636364 0.40740741 0.65432099 0.7808642  0.75925926 0.59876543\n",
      " 0.44074074 0.26296296 0.55925926 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 1023\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 35, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=35, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.78909091 0.50462963 0.60030864 0.67901235 0.52006173 0.42283951\n",
      " 0.37962963 0.29259259 0.51111111 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 1024\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71636364 0.48765432 0.49691358 0.47839506 0.56481481 0.27160494\n",
      " 0.20740741 0.3        0.55925926 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 1025\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 15, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, max_features='sqrt',\n",
      "                                            n_estimators=15,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.56       0.46604938 0.78703704 0.64197531 0.70987654 0.47839506\n",
      " 0.26296296 0.29259259 0.54074074 0.61851852]\n",
      "----------------------------------------\n",
      "Trial 1026\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 123, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=123,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.85454545 0.37037037 0.5308642  0.75       0.55555556 0.36728395\n",
      " 0.34074074 0.36666667 0.50740741 0.62962963]\n",
      "----------------------------------------\n",
      "Trial 1027\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 62, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=62, random_state=100))])\n",
      "cv score: [0.68727273 0.47530864 0.58950617 0.80555556 0.69135802 0.41666667\n",
      " 0.37777778 0.36666667 0.49259259 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 1028\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 79, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=79,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.78545455 0.43518519 0.5308642  0.75308642 0.50617284 0.50617284\n",
      " 0.32962963 0.45555556 0.52962963 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 1029\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 23, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=23,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65454545 0.51851852 0.37962963 0.47222222 0.50925926 0.47685185\n",
      " 0.5        0.46296296 0.47222222 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 1030\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 144, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=144,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64       0.51080247 0.70216049 0.47839506 0.69753086 0.47685185\n",
      " 0.52037037 0.32777778 0.41666667 0.69074074]\n",
      "----------------------------------------\n",
      "Trial 1031\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 55, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=55, random_state=100))])\n",
      "cv score: [0.67272727 0.46296296 0.66358025 0.87654321 0.63888889 0.60802469\n",
      " 0.37777778 0.32592593 0.47777778 0.54814815]\n",
      "----------------------------------------\n",
      "Trial 1032\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 85, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=85,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.41358025 0.62654321 0.78395062 0.54320988 0.51234568\n",
      " 0.28148148 0.45555556 0.51851852 0.35555556]\n",
      "----------------------------------------\n",
      "Trial 1033\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66       0.53858025 0.50462963 0.52777778 0.54938272 0.60030864\n",
      " 0.52777778 0.4037037  0.61666667 0.5962963 ]\n",
      "----------------------------------------\n",
      "Trial 1034\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 194, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=194,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65090909 0.5462963  0.50617284 0.68055556 0.58024691 0.49537037\n",
      " 0.57592593 0.43333333 0.63148148 0.45740741]\n",
      "----------------------------------------\n",
      "Trial 1035\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 150, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=150,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65818182 0.34876543 0.66975309 0.7037037  0.62345679 0.50308642\n",
      " 0.45555556 0.34444444 0.62962963 0.65925926]\n",
      "----------------------------------------\n",
      "Trial 1036\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 153, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=153,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.34567901 0.66975309 0.7037037  0.62037037 0.5\n",
      " 0.45555556 0.34074074 0.61851852 0.67037037]\n",
      "----------------------------------------\n",
      "Trial 1037\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 88, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=88,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.77818182 0.47530864 0.59567901 0.75308642 0.62345679 0.41975309\n",
      " 0.41481481 0.48888889 0.5        0.48518519]\n",
      "----------------------------------------\n",
      "Trial 1038\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 182, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=182,\n",
      "                                            random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.69454545 0.34876543 0.72222222 0.75617284 0.58950617 0.33024691\n",
      " 0.33703704 0.42222222 0.38518519 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 1039\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 138, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=138,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68727273 0.37037037 0.55864198 0.7345679  0.66049383 0.48148148\n",
      " 0.32592593 0.37407407 0.50740741 0.45555556]\n",
      "----------------------------------------\n",
      "Trial 1040\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 37, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, max_features='log2',\n",
      "                                            n_estimators=37, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.62545455 0.41975309 0.57716049 0.78703704 0.62654321 0.5\n",
      " 0.37037037 0.43333333 0.40740741 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 1041\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 54, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=54, random_state=100))])\n",
      "cv score: [0.78181818 0.44753086 0.64197531 0.85802469 0.5308642  0.47530864\n",
      " 0.44074074 0.42592593 0.6        0.45185185]\n",
      "----------------------------------------\n",
      "Trial 1042\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 166, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=166,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.75818182 0.60185185 0.55709877 0.67901235 0.62962963 0.48148148\n",
      " 0.52777778 0.37777778 0.56296296 0.45      ]\n",
      "----------------------------------------\n",
      "Trial 1043\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 75, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=75, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.61090909 0.41975309 0.6882716  0.70679012 0.62654321 0.51851852\n",
      " 0.3962963  0.36666667 0.44814815 0.57407407]\n",
      "----------------------------------------\n",
      "Trial 1044\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 34, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=34, random_state=100))])\n",
      "cv score: [0.71272727 0.44753086 0.69444444 0.81790123 0.67901235 0.56481481\n",
      " 0.36296296 0.42592593 0.45555556 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 1045\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 126, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=126,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62       0.58024691 0.50925926 0.5462963  0.52932099 0.51080247\n",
      " 0.63703704 0.4        0.56666667 0.46111111]\n",
      "----------------------------------------\n",
      "Trial 1046\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=171, random_state=100))])\n",
      "cv score: [0.64727273 0.50617284 0.58641975 0.62345679 0.60802469 0.55864198\n",
      " 0.4037037  0.31111111 0.54444444 0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 1047\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 88, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=88, random_state=100))])\n",
      "cv score: [0.74909091 0.54012346 0.51851852 0.63580247 0.53858025 0.47530864\n",
      " 0.48148148 0.25555556 0.42962963 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 1048\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 34, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=34,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.71454545 0.5787037  0.43055556 0.47222222 0.51851852 0.54012346\n",
      " 0.52222222 0.17592593 0.49444444 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 1049\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 77, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=77,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.64727273 0.58333333 0.42592593 0.80246914 0.57098765 0.46296296\n",
      " 0.32962963 0.47407407 0.38148148 0.22222222]\n",
      "----------------------------------------\n",
      "Trial 1050\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 185, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=185, random_state=100))])\n",
      "cv score: [0.65454545 0.43518519 0.58333333 0.81790123 0.7654321  0.54012346\n",
      " 0.32962963 0.41851852 0.54074074 0.47777778]\n",
      "----------------------------------------\n",
      "Trial 1051\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, max_features='log2',\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.54545455 0.44753086 0.62345679 0.66049383 0.74691358 0.50617284\n",
      " 0.4962963  0.55555556 0.48888889 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 1052\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 57, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=57,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62363636 0.5154321  0.5154321  0.61265432 0.55401235 0.50154321\n",
      " 0.59259259 0.31666667 0.54444444 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 1053\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=101, random_state=100))])\n",
      "cv score: [0.71272727 0.54938272 0.52469136 0.65432099 0.53858025 0.48148148\n",
      " 0.45925926 0.25555556 0.45555556 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 1054\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 52, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=52,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57090909 0.44444444 0.60030864 0.54012346 0.44444444 0.5308642\n",
      " 0.61111111 0.40740741 0.54259259 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 1055\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 121, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=121,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59272727 0.45061728 0.51234568 0.65740741 0.54012346 0.50308642\n",
      " 0.28518519 0.35185185 0.6037037  0.49259259]\n",
      "----------------------------------------\n",
      "Trial 1056\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=101, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.75636364 0.4845679  0.66049383 0.73765432 0.59876543 0.43209877\n",
      " 0.34074074 0.32222222 0.46296296 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 1057\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72363636 0.59259259 0.54012346 0.7654321  0.7037037  0.4537037\n",
      " 0.32962963 0.57407407 0.41111111 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 1058\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.72       0.35802469 0.5308642  0.75       0.4382716  0.5308642\n",
      " 0.49259259 0.42962963 0.44814815 0.35185185]\n",
      "----------------------------------------\n",
      "Trial 1059\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 116, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=116, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.69090909 0.33950617 0.62962963 0.80555556 0.62345679 0.45679012\n",
      " 0.3        0.35555556 0.48888889 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 1060\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 40, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=40, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.70545455 0.45679012 0.68209877 0.64814815 0.48148148 0.49382716\n",
      " 0.3037037  0.51481481 0.55555556 0.57407407]\n",
      "----------------------------------------\n",
      "Trial 1061\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 196, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=14,\n",
      "                                            n_estimators=196, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.76363636 0.55555556 0.4537037  0.45061728 0.77777778 0.6882716\n",
      " 0.62962963 0.53703704 0.40740741 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 1062\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.64       0.37654321 0.74691358 0.84876543 0.79012346 0.43518519\n",
      " 0.41481481 0.4037037  0.53333333 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 1063\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 34, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=34, random_state=100))])\n",
      "cv score: [0.80363636 0.54012346 0.54320988 0.80555556 0.63271605 0.48148148\n",
      " 0.26666667 0.4037037  0.50740741 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 1064\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 198, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=198,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.81090909 0.33950617 0.63271605 0.7037037  0.56481481 0.5\n",
      " 0.3        0.52222222 0.46666667 0.32962963]\n",
      "----------------------------------------\n",
      "Trial 1065\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 41, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=41,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.39197531 0.55555556 0.71604938 0.62345679 0.42592593\n",
      " 0.28148148 0.31481481 0.6037037  0.46666667]\n",
      "----------------------------------------\n",
      "Trial 1066\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.69454545 0.36419753 0.63580247 0.6882716  0.59567901 0.48765432\n",
      " 0.34074074 0.38148148 0.58888889 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 1067\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 116, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=116,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63272727 0.40123457 0.44135802 0.64814815 0.36728395 0.30555556\n",
      " 0.28888889 0.33333333 0.57777778 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 1068\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 84, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=84, random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57090909 0.2962963  0.63271605 0.8117284  0.67901235 0.58950617\n",
      " 0.44444444 0.36296296 0.62962963 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 1069\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 79, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=79,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59454545 0.59259259 0.51851852 0.52777778 0.47839506 0.53703704\n",
      " 0.57037037 0.29444444 0.55555556 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 1070\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 98, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=98,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66545455 0.34567901 0.47839506 0.59567901 0.60493827 0.4382716\n",
      " 0.31481481 0.39259259 0.48148148 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 1071\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 64, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=64,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65454545 0.51851852 0.37962963 0.47222222 0.50925926 0.47685185\n",
      " 0.5        0.46296296 0.47222222 0.46481481]\n",
      "----------------------------------------\n",
      "Trial 1072\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 142, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            n_estimators=142, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.70181818 0.44753086 0.62037037 0.66358025 0.69444444 0.54012346\n",
      " 0.27407407 0.21481481 0.5962963  0.55555556]\n",
      "----------------------------------------\n",
      "Trial 1073\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 82, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=82, random_state=100))])\n",
      "cv score: [0.76       0.57098765 0.52160494 0.64814815 0.53240741 0.49382716\n",
      " 0.51481481 0.24444444 0.43333333 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 1074\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 144, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=144, random_state=100))])\n",
      "cv score: [0.79636364 0.50617284 0.62962963 0.7345679  0.62962963 0.52777778\n",
      " 0.31851852 0.25185185 0.6        0.48518519]\n",
      "----------------------------------------\n",
      "Trial 1075\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 43, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=43,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58545455 0.46296296 0.61728395 0.54012346 0.4537037  0.46141975\n",
      " 0.53888889 0.31296296 0.60185185 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 1076\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 93, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=93, random_state=100))])\n",
      "cv score: [0.65454545 0.57098765 0.62037037 0.64197531 0.58024691 0.57407407\n",
      " 0.35555556 0.32222222 0.52222222 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 1077\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.35185185 0.52469136 0.64814815 0.51851852 0.40123457\n",
      " 0.24074074 0.34814815 0.65185185 0.3962963 ]\n",
      "----------------------------------------\n",
      "Trial 1078\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 78, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=78, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66181818 0.39814815 0.6404321  0.84876543 0.67592593 0.57098765\n",
      " 0.36296296 0.39259259 0.47407407 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 1079\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 139, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=139,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74545455 0.41049383 0.52469136 0.66358025 0.43518519 0.4537037\n",
      " 0.37037037 0.4962963  0.48888889 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 1080\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 31, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=31,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.81090909 0.48765432 0.69753086 0.69444444 0.59567901 0.53395062\n",
      " 0.3037037  0.4        0.59259259 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 1081\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 15, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=15,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62727273 0.4537037  0.52006173 0.54012346 0.47222222 0.5308642\n",
      " 0.64814815 0.42222222 0.52037037 0.62962963]\n",
      "----------------------------------------\n",
      "Trial 1082\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 55, 'gb__subsample': 0.95, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, max_features='sqrt',\n",
      "                                            n_estimators=55, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.64727273 0.50925926 0.56481481 0.74382716 0.67592593 0.41666667\n",
      " 0.46296296 0.44814815 0.63703704 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 1083\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 190, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=5, n_estimators=190,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.67636364 0.48765432 0.72222222 0.80864198 0.7191358  0.48765432\n",
      " 0.42222222 0.26666667 0.44814815 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 1084\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=58, random_state=100))])\n",
      "cv score: [0.67636364 0.5617284  0.50308642 0.62962963 0.4691358  0.45061728\n",
      " 0.39259259 0.31851852 0.4962963  0.4       ]\n",
      "----------------------------------------\n",
      "Trial 1085\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 53, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=53, random_state=100))])\n",
      "cv score: [0.77454545 0.5154321  0.57098765 0.87345679 0.63580247 0.44753086\n",
      " 0.34074074 0.4        0.48148148 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 1086\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 27, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=27,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.67636364 0.35802469 0.75308642 0.59567901 0.57716049 0.52777778\n",
      " 0.52592593 0.31851852 0.5962963  0.52222222]\n",
      "----------------------------------------\n",
      "Trial 1087\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 74, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=74,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66181818 0.35493827 0.62962963 0.73765432 0.62345679 0.49382716\n",
      " 0.31851852 0.27407407 0.57407407 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 1088\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 19, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=19,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64727273 0.40740741 0.66666667 0.62037037 0.67283951 0.62191358\n",
      " 0.28518519 0.34814815 0.57037037 0.67037037]\n",
      "----------------------------------------\n",
      "Trial 1089\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 73, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=73,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.72363636 0.33641975 0.57407407 0.72530864 0.60493827 0.47530864\n",
      " 0.37037037 0.35925926 0.61111111 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 1090\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 188, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=188,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67636364 0.37654321 0.62345679 0.75       0.63580247 0.52469136\n",
      " 0.31111111 0.65555556 0.54444444 0.34444444]\n",
      "----------------------------------------\n",
      "Trial 1091\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 154, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            n_estimators=154, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.72       0.42592593 0.64814815 0.74691358 0.63271605 0.55555556\n",
      " 0.31111111 0.26296296 0.54814815 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 1092\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 82, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=82, random_state=100))])\n",
      "cv score: [0.65818182 0.53703704 0.58950617 0.75925926 0.57098765 0.39506173\n",
      " 0.26666667 0.28888889 0.54814815 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 1093\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, n_estimators=121,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.56       0.50617284 0.63580247 0.80246914 0.75308642 0.5\n",
      " 0.47407407 0.41111111 0.65185185 0.56296296]\n",
      "----------------------------------------\n",
      "Trial 1094\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 131, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=131, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.65454545 0.36419753 0.74691358 0.66666667 0.61728395 0.54320988\n",
      " 0.34074074 0.33703704 0.64814815 0.61481481]\n",
      "----------------------------------------\n",
      "Trial 1095\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 91, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=91,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48363636 0.38580247 0.49074074 0.63888889 0.46604938 0.51851852\n",
      " 0.27407407 0.26666667 0.57407407 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 1096\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            random_state=100, subsample=0.6))])\n",
      "cv score: [0.6        0.46296296 0.51851852 0.69135802 0.57716049 0.4691358\n",
      " 0.42962963 0.49259259 0.52592593 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 1097\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 84, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=84,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67636364 0.43209877 0.55864198 0.64814815 0.58024691 0.31481481\n",
      " 0.30740741 0.27037037 0.62962963 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 1098\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 134, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=134,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61818182 0.33024691 0.67283951 0.65740741 0.62654321 0.54012346\n",
      " 0.36666667 0.30740741 0.59259259 0.61111111]\n",
      "----------------------------------------\n",
      "Trial 1099\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 48, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt', n_estimators=48,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.76363636 0.45679012 0.72222222 0.69135802 0.57407407 0.55864198\n",
      " 0.37777778 0.4        0.6        0.52962963]\n",
      "----------------------------------------\n",
      "Trial 1100\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 166, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            n_estimators=166,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.69818182 0.47839506 0.67592593 0.64506173 0.74691358 0.42283951\n",
      " 0.2962963  0.33703704 0.55925926 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 1101\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 158, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=7,\n",
      "                                            n_estimators=158, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.6        0.47839506 0.74074074 0.8117284  0.68518519 0.4845679\n",
      " 0.28518519 0.25555556 0.43333333 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 1102\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 96, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=96, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.62545455 0.45061728 0.70987654 0.75       0.68518519 0.38580247\n",
      " 0.41481481 0.31481481 0.66296296 0.58148148]\n",
      "----------------------------------------\n",
      "Trial 1103\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 141, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=141, random_state=100))])\n",
      "cv score: [0.66181818 0.44753086 0.64197531 0.77160494 0.62962963 0.60802469\n",
      " 0.34074074 0.26296296 0.54074074 0.59259259]\n",
      "----------------------------------------\n",
      "Trial 1104\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 26, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=26, random_state=100))])\n",
      "cv score: [0.75454545 0.47839506 0.56790123 0.69135802 0.57716049 0.57253086\n",
      " 0.49444444 0.29259259 0.42777778 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 1105\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            n_estimators=115, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.75636364 0.39814815 0.58024691 0.73148148 0.61419753 0.30864198\n",
      " 0.27407407 0.28888889 0.62222222 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 1106\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64363636 0.58487654 0.48302469 0.74228395 0.52314815 0.56944444\n",
      " 0.59814815 0.32592593 0.66851852 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 1107\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 130, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=130, random_state=100))])\n",
      "cv score: [0.64727273 0.54012346 0.61419753 0.61419753 0.60802469 0.58641975\n",
      " 0.41111111 0.31481481 0.52962963 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 1108\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 27, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=27, random_state=100))])\n",
      "cv score: [0.66       0.48302469 0.69135802 0.79012346 0.67438272 0.4845679\n",
      " 0.35925926 0.46296296 0.5037037  0.62777778]\n",
      "----------------------------------------\n",
      "Trial 1109\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.70545455 0.33024691 0.7345679  0.71604938 0.75       0.5617284\n",
      " 0.42222222 0.36666667 0.52222222 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 1110\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 189, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=189,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73454545 0.33641975 0.52160494 0.69753086 0.58641975 0.51234568\n",
      " 0.33703704 0.36666667 0.55925926 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 1111\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 114, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=114,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61090909 0.35493827 0.52160494 0.69135802 0.58950617 0.57407407\n",
      " 0.31111111 0.31111111 0.52592593 0.48518519]\n",
      "----------------------------------------\n",
      "Trial 1112\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 160, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=160,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.57818182 0.39814815 0.66975309 0.74691358 0.77160494 0.57407407\n",
      " 0.45925926 0.37407407 0.55555556 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 1113\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 71, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=71, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.71636364 0.4845679  0.72839506 0.70987654 0.69444444 0.22530864\n",
      " 0.38888889 0.35555556 0.48888889 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 1114\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 193, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=193,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58545455 0.54475309 0.5154321  0.57407407 0.49845679 0.64814815\n",
      " 0.53148148 0.47407407 0.58518519 0.57592593]\n",
      "----------------------------------------\n",
      "Trial 1115\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 92, 'gb__subsample': 0.85, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, max_features='sqrt',\n",
      "                                            n_estimators=92, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.59272727 0.41975309 0.74382716 0.7037037  0.71296296 0.57716049\n",
      " 0.43333333 0.38148148 0.46296296 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 1116\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 77, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=77,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70181818 0.5        0.45987654 0.73148148 0.48148148 0.42901235\n",
      " 0.3037037  0.54814815 0.41851852 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 1117\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 29, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, max_features='sqrt',\n",
      "                                            n_estimators=29,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.64       0.42283951 0.7808642  0.71604938 0.7345679  0.38271605\n",
      " 0.38518519 0.36296296 0.55555556 0.51111111]\n",
      "----------------------------------------\n",
      "Trial 1118\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 187, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=187, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.46545455 0.41358025 0.7808642  0.69135802 0.5617284  0.4691358\n",
      " 0.57407407 0.50740741 0.35185185 0.28888889]\n",
      "----------------------------------------\n",
      "Trial 1119\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.45818182 0.33641975 0.49382716 0.57716049 0.63888889 0.4845679\n",
      " 0.5037037  0.49259259 0.42962963 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 1120\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 12, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=12,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66363636 0.57407407 0.69907407 0.47530864 0.625      0.55709877\n",
      " 0.52777778 0.27592593 0.40925926 0.68518519]\n",
      "----------------------------------------\n",
      "Trial 1121\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 116, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            n_estimators=116,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.54545455 0.36728395 0.61419753 0.86111111 0.83024691 0.53703704\n",
      " 0.29259259 0.37407407 0.57777778 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 1122\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 119, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=119, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67636364 0.44444444 0.63271605 0.77469136 0.64197531 0.62037037\n",
      " 0.35185185 0.25185185 0.53333333 0.57037037]\n",
      "----------------------------------------\n",
      "Trial 1123\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 157, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=157, random_state=100))])\n",
      "cv score: [0.68       0.56481481 0.52160494 0.66666667 0.54320988 0.50925926\n",
      " 0.46296296 0.3        0.48518519 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 1124\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 25, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=25,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57818182 0.57716049 0.49537037 0.55864198 0.48148148 0.54938272\n",
      " 0.62037037 0.47222222 0.56481481 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 1125\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 52, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=52,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.2962963  0.75154321 0.51697531 0.7808642  0.55246914\n",
      " 0.45925926 0.38703704 0.51296296 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 1126\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 190, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=190, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.72727273 0.56635802 0.50617284 0.7191358  0.86419753 0.52006173\n",
      " 0.29259259 0.42962963 0.71111111 0.34444444]\n",
      "----------------------------------------\n",
      "Trial 1127\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 94, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=94,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71272727 0.36111111 0.4845679  0.67283951 0.60185185 0.46296296\n",
      " 0.32222222 0.29259259 0.5037037  0.54814815]\n",
      "----------------------------------------\n",
      "Trial 1128\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 150, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=150,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72363636 0.50925926 0.37962963 0.47222222 0.50925926 0.5\n",
      " 0.47222222 0.46296296 0.42407407 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 1129\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 79, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='sqrt',\n",
      "                                            n_estimators=79, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.74909091 0.45679012 0.64506173 0.8117284  0.63580247 0.25925926\n",
      " 0.33703704 0.32962963 0.58518519 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 1130\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 125, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=125, random_state=100))])\n",
      "cv score: [0.71272727 0.61111111 0.63580247 0.73148148 0.57407407 0.49691358\n",
      " 0.43703704 0.28148148 0.5037037  0.46666667]\n",
      "----------------------------------------\n",
      "Trial 1131\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 129, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=129, random_state=100))])\n",
      "cv score: [0.70545455 0.41049383 0.63888889 0.85802469 0.66666667 0.5617284\n",
      " 0.31111111 0.34814815 0.53333333 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 1132\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57454545 0.35185185 0.5308642  0.65432099 0.60802469 0.4537037\n",
      " 0.21481481 0.3037037  0.58148148 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 1133\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 157, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=157, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.71636364 0.54012346 0.53395062 0.66358025 0.65740741 0.47839506\n",
      " 0.38518519 0.34814815 0.4962963  0.47777778]\n",
      "----------------------------------------\n",
      "Trial 1134\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 35, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=35,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.63272727 0.51851852 0.66049383 0.72839506 0.80555556 0.55246914\n",
      " 0.42962963 0.48888889 0.53703704 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 1135\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 126, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            n_estimators=126, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.68       0.42592593 0.58950617 0.80555556 0.58641975 0.49074074\n",
      " 0.33333333 0.21851852 0.43703704 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 1136\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 139, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=139, random_state=100))])\n",
      "cv score: [0.69454545 0.42592593 0.66049383 0.84567901 0.64197531 0.52469136\n",
      " 0.41481481 0.4037037  0.53333333 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 1137\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68727273 0.35185185 0.50308642 0.6882716  0.6882716  0.50308642\n",
      " 0.34074074 0.47407407 0.47407407 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 1138\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.64545455 0.44444444 0.54938272 0.54012346 0.44444444 0.46141975\n",
      " 0.52592593 0.40740741 0.47222222 0.41296296]\n",
      "----------------------------------------\n",
      "Trial 1139\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 193, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=4,\n",
      "                                            n_estimators=193, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.66909091 0.61728395 0.59567901 0.64506173 0.6882716  0.41975309\n",
      " 0.42777778 0.22592593 0.52222222 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 1140\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=183, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.69818182 0.38580247 0.7345679  0.77469136 0.67592593 0.5154321\n",
      " 0.37777778 0.34814815 0.48888889 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 1141\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.66545455 0.50617284 0.55555556 0.74074074 0.65432099 0.42901235\n",
      " 0.35925926 0.54444444 0.55185185 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 1142\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 141, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=141,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.71272727 0.44444444 0.52160494 0.64814815 0.60493827 0.37962963\n",
      " 0.33703704 0.44814815 0.46666667 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 1143\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 88, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=7,\n",
      "                                            n_estimators=88, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65818182 0.50925926 0.75       0.76851852 0.65740741 0.41666667\n",
      " 0.26666667 0.34444444 0.4037037  0.42962963]\n",
      "----------------------------------------\n",
      "Trial 1144\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 165, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=165, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.82545455 0.5        0.65740741 0.7654321  0.61419753 0.34567901\n",
      " 0.37407407 0.57037037 0.62592593 0.44074074]\n",
      "----------------------------------------\n",
      "Trial 1145\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 163, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=163,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66545455 0.36419753 0.7345679  0.65432099 0.57716049 0.50308642\n",
      " 0.4037037  0.32222222 0.57777778 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 1146\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 182, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=182,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.2962963  0.75154321 0.51697531 0.7808642  0.55246914\n",
      " 0.45925926 0.38518519 0.51296296 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 1147\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.70181818 0.44753086 0.7654321  0.79320988 0.58641975 0.35185185\n",
      " 0.41851852 0.43703704 0.2962963  0.30740741]\n",
      "----------------------------------------\n",
      "Trial 1148\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 192, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=192,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66909091 0.40123457 0.46604938 0.62962963 0.58641975 0.34567901\n",
      " 0.23333333 0.3037037  0.58148148 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 1149\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 180, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=180,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.35802469 0.64814815 0.70679012 0.61111111 0.5\n",
      " 0.44444444 0.34074074 0.62222222 0.68518519]\n",
      "----------------------------------------\n",
      "Trial 1150\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 157, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=157, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.70909091 0.57098765 0.58024691 0.62037037 0.52777778 0.50617284\n",
      " 0.33703704 0.37407407 0.55185185 0.45555556]\n",
      "----------------------------------------\n",
      "Trial 1151\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 194, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=194, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.66181818 0.43209877 0.69444444 0.74691358 0.59259259 0.32407407\n",
      " 0.41111111 0.34814815 0.50740741 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 1152\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 67, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=67,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.69090909 0.43209877 0.67283951 0.70987654 0.62345679 0.59567901\n",
      " 0.42962963 0.33703704 0.51481481 0.58518519]\n",
      "----------------------------------------\n",
      "Trial 1153\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 181, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=181,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70181818 0.49382716 0.60185185 0.66975309 0.61111111 0.47222222\n",
      " 0.31481481 0.2962963  0.52962963 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 1154\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 107, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=107, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.49454545 0.41358025 0.82098765 0.63888889 0.44135802 0.55246914\n",
      " 0.44074074 0.46296296 0.4962963  0.41481481]\n",
      "----------------------------------------\n",
      "Trial 1155\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 123, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=123,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.62181818 0.33024691 0.52160494 0.66975309 0.69135802 0.46296296\n",
      " 0.26666667 0.28518519 0.62592593 0.65185185]\n",
      "----------------------------------------\n",
      "Trial 1156\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 44, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=44, random_state=100))])\n",
      "cv score: [0.70181818 0.42901235 0.70061728 0.7962963  0.63580247 0.55401235\n",
      " 0.35925926 0.5        0.54259259 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 1157\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 152, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=152, random_state=100))])\n",
      "cv score: [0.64727273 0.46296296 0.58641975 0.81790123 0.75308642 0.52160494\n",
      " 0.34074074 0.4037037  0.52222222 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 1158\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 39, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=39, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.74181818 0.58641975 0.56635802 0.70216049 0.69753086 0.45679012\n",
      " 0.41851852 0.31666667 0.51296296 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 1159\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65818182 0.49691358 0.44444444 0.75308642 0.59567901 0.48148148\n",
      " 0.31481481 0.51111111 0.45185185 0.34814815]\n",
      "----------------------------------------\n",
      "Trial 1160\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 194, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            n_estimators=194,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.54909091 0.55246914 0.7808642  0.92283951 0.73765432 0.44753086\n",
      " 0.40740741 0.42962963 0.44074074 0.55185185]\n",
      "----------------------------------------\n",
      "Trial 1161\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 11, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=11, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.72363636 0.49382716 0.60185185 0.57407407 0.62962963 0.5617284\n",
      " 0.41111111 0.38148148 0.5037037  0.45555556]\n",
      "----------------------------------------\n",
      "Trial 1162\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58909091 0.55555556 0.5308642  0.49691358 0.43981481 0.60493827\n",
      " 0.61666667 0.44259259 0.66296296 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 1163\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 189, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=189,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62545455 0.43518519 0.47530864 0.62345679 0.61111111 0.48765432\n",
      " 0.37407407 0.36666667 0.55555556 0.57407407]\n",
      "----------------------------------------\n",
      "Trial 1164\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=133, random_state=100))])\n",
      "cv score: [0.66181818 0.43518519 0.61419753 0.85802469 0.66666667 0.59567901\n",
      " 0.3037037  0.41111111 0.51481481 0.50740741]\n",
      "----------------------------------------\n",
      "Trial 1165\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=58,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.74181818 0.44135802 0.70061728 0.71604938 0.62962963 0.4845679\n",
      " 0.4        0.26666667 0.67407407 0.68888889]\n",
      "----------------------------------------\n",
      "Trial 1166\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 72, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=72,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.78181818 0.37654321 0.48148148 0.62345679 0.63580247 0.49074074\n",
      " 0.29259259 0.32222222 0.51481481 0.5962963 ]\n",
      "----------------------------------------\n",
      "Trial 1167\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 142, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=142, random_state=100))])\n",
      "cv score: [0.73818182 0.39197531 0.64814815 0.84259259 0.66049383 0.57098765\n",
      " 0.37407407 0.35185185 0.52222222 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 1168\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 70, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            n_estimators=70, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.65818182 0.32407407 0.67283951 0.80246914 0.7345679  0.53395062\n",
      " 0.42222222 0.24444444 0.59259259 0.57037037]\n",
      "----------------------------------------\n",
      "Trial 1169\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 190, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=190, random_state=100))])\n",
      "cv score: [0.65090909 0.4537037  0.64197531 0.74691358 0.62654321 0.60493827\n",
      " 0.33703704 0.25185185 0.54814815 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 1170\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 168, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=168, random_state=100))])\n",
      "cv score: [0.69818182 0.44444444 0.59259259 0.8117284  0.69753086 0.55864198\n",
      " 0.38888889 0.35925926 0.60740741 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 1171\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 10, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=10,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.63636364 0.30555556 0.49382716 0.67283951 0.52160494 0.46296296\n",
      " 0.27037037 0.2        0.43333333 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 1172\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 157, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=157, random_state=100))])\n",
      "cv score: [0.72       0.55246914 0.55864198 0.62654321 0.60802469 0.5\n",
      " 0.37777778 0.31481481 0.47777778 0.38518519]\n",
      "----------------------------------------\n",
      "Trial 1173\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.53818182 0.4845679  0.71296296 0.75308642 0.74691358 0.41666667\n",
      " 0.39259259 0.31481481 0.47407407 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 1174\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70545455 0.40123457 0.55864198 0.71604938 0.62654321 0.44444444\n",
      " 0.38518519 0.42592593 0.52592593 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 1175\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 45, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=14,\n",
      "                                            n_estimators=45, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.61454545 0.54320988 0.69753086 0.83641975 0.76234568 0.51851852\n",
      " 0.47407407 0.4        0.45555556 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 1176\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 138, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=138, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.71272727 0.42592593 0.57716049 0.75617284 0.72530864 0.56790123\n",
      " 0.2962963  0.45185185 0.52592593 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 1177\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 37, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=37, random_state=100))])\n",
      "cv score: [0.65818182 0.4537037  0.67901235 0.86111111 0.68518519 0.47839506\n",
      " 0.3037037  0.38518519 0.52592593 0.59259259]\n",
      "----------------------------------------\n",
      "Trial 1178\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 16, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=16,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59636364 0.36728395 0.45987654 0.66666667 0.55864198 0.66049383\n",
      " 0.27777778 0.42592593 0.54074074 0.31481481]\n",
      "----------------------------------------\n",
      "Trial 1179\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 80, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=80,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.72363636 0.50925926 0.37962963 0.47222222 0.50925926 0.5\n",
      " 0.47222222 0.46296296 0.42407407 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 1180\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 72, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=72,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70545455 0.4691358  0.58024691 0.62345679 0.61111111 0.5154321\n",
      " 0.35555556 0.28333333 0.55555556 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 1181\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=58, random_state=100))])\n",
      "cv score: [0.61818182 0.49691358 0.57407407 0.75617284 0.52777778 0.45061728\n",
      " 0.34444444 0.37407407 0.5037037  0.58148148]\n",
      "----------------------------------------\n",
      "Trial 1182\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 24, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            n_estimators=24, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.71454545 0.42283951 0.54938272 0.65740741 0.60493827 0.55092593\n",
      " 0.32962963 0.19074074 0.57037037 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 1183\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 90, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=90,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.70181818 0.4382716  0.57716049 0.67283951 0.64197531 0.42283951\n",
      " 0.22222222 0.33703704 0.49259259 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 1184\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 114, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=114,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.69454545 0.4382716  0.67592593 0.6882716  0.62654321 0.50925926\n",
      " 0.4        0.37037037 0.52962963 0.58518519]\n",
      "----------------------------------------\n",
      "Trial 1185\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62909091 0.36728395 0.55864198 0.63580247 0.55555556 0.49691358\n",
      " 0.48888889 0.2962963  0.57037037 0.64444444]\n",
      "----------------------------------------\n",
      "Trial 1186\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 55, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=55,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62909091 0.33950617 0.66975309 0.64814815 0.63888889 0.53395062\n",
      " 0.44814815 0.3        0.57037037 0.63333333]\n",
      "----------------------------------------\n",
      "Trial 1187\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=38,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.72363636 0.50925926 0.37962963 0.47222222 0.50925926 0.5\n",
      " 0.47222222 0.46296296 0.42407407 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 1188\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 77, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=77, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.66909091 0.42283951 0.67901235 0.70061728 0.67592593 0.36419753\n",
      " 0.48148148 0.38148148 0.5962963  0.47407407]\n",
      "----------------------------------------\n",
      "Trial 1189\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 172, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=172,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64363636 0.35185185 0.65740741 0.69753086 0.60802469 0.50925926\n",
      " 0.45185185 0.34444444 0.61111111 0.68148148]\n",
      "----------------------------------------\n",
      "Trial 1190\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 152, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=152,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64727273 0.35185185 0.66975309 0.64814815 0.61419753 0.5308642\n",
      " 0.36666667 0.31481481 0.6037037  0.6       ]\n",
      "----------------------------------------\n",
      "Trial 1191\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 107, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=8, n_estimators=107,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.69090909 0.46604938 0.72839506 0.79320988 0.68209877 0.47530864\n",
      " 0.35185185 0.35185185 0.46666667 0.39259259]\n",
      "----------------------------------------\n",
      "Trial 1192\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=108, random_state=100))])\n",
      "cv score: [0.62909091 0.40740741 0.64197531 0.83641975 0.64506173 0.60493827\n",
      " 0.38888889 0.37037037 0.48148148 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 1193\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 28, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=28, random_state=100))])\n",
      "cv score: [0.66909091 0.59876543 0.61419753 0.66049383 0.50925926 0.42592593\n",
      " 0.28518519 0.23333333 0.48148148 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 1194\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 28, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=28,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.43518519 0.57407407 0.67592593 0.5462963  0.48148148\n",
      " 0.35925926 0.28518519 0.46666667 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 1195\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 19, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=19,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66909091 0.33024691 0.55401235 0.6712963  0.58024691 0.55246914\n",
      " 0.48888889 0.35555556 0.48518519 0.69259259]\n",
      "----------------------------------------\n",
      "Trial 1196\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 83, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=83,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.2962963  0.75154321 0.51697531 0.7808642  0.55246914\n",
      " 0.46296296 0.38518519 0.51296296 0.53703704]\n",
      "----------------------------------------\n",
      "Trial 1197\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 71, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=71,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.81636364 0.58796296 0.55864198 0.63888889 0.63117284 0.50771605\n",
      " 0.51296296 0.43518519 0.53148148 0.46851852]\n",
      "----------------------------------------\n",
      "Trial 1198\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 125, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=125,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.69090909 0.43209877 0.68518519 0.6882716  0.63580247 0.5308642\n",
      " 0.38888889 0.34444444 0.53333333 0.6       ]\n",
      "----------------------------------------\n",
      "Trial 1199\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 95, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=95,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.66727273 0.5787037  0.63888889 0.55709877 0.61111111 0.54475309\n",
      " 0.52222222 0.16666667 0.32592593 0.53518519]\n",
      "----------------------------------------\n",
      "Trial 1200\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 137, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=137,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61818182 0.33641975 0.67283951 0.65740741 0.61728395 0.54320988\n",
      " 0.36296296 0.31111111 0.57777778 0.6037037 ]\n",
      "----------------------------------------\n",
      "Trial 1201\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            n_estimators=168, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.58545455 0.48148148 0.7037037  0.85493827 0.79012346 0.62037037\n",
      " 0.49259259 0.32962963 0.46666667 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 1202\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 88, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=88,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60545455 0.44444444 0.53549383 0.54012346 0.44444444 0.46141975\n",
      " 0.63333333 0.39259259 0.56296296 0.42037037]\n",
      "----------------------------------------\n",
      "Trial 1203\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 42, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=42, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.62181818 0.35802469 0.43518519 0.60030864 0.41049383 0.77469136\n",
      " 0.44074074 0.68148148 0.57777778 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 1204\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 154, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, max_features='log2',\n",
      "                                            n_estimators=154, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.63272727 0.48148148 0.69135802 0.87654321 0.64197531 0.50308642\n",
      " 0.47037037 0.41481481 0.45555556 0.38148148]\n",
      "----------------------------------------\n",
      "Trial 1205\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 182, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='sqrt',\n",
      "                                            n_estimators=182, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.72363636 0.37962963 0.75       0.65740741 0.64814815 0.39814815\n",
      " 0.27407407 0.42592593 0.52592593 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 1206\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 172, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=172,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70181818 0.39506173 0.63271605 0.67901235 0.64814815 0.52160494\n",
      " 0.40740741 0.37037037 0.57407407 0.57777778]\n",
      "----------------------------------------\n",
      "Trial 1207\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 19, 'gb__subsample': 0.85, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, max_features='sqrt',\n",
      "                                            n_estimators=19, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.55272727 0.34876543 0.50925926 0.65123457 0.6882716  0.50617284\n",
      " 0.31481481 0.35925926 0.56296296 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 1208\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=102, random_state=100))])\n",
      "cv score: [0.72363636 0.37037037 0.62962963 0.81790123 0.67283951 0.56481481\n",
      " 0.35925926 0.37222222 0.56666667 0.5037037 ]\n",
      "----------------------------------------\n",
      "Trial 1209\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 13, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=13,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64       0.51080247 0.70216049 0.47839506 0.69753086 0.47685185\n",
      " 0.52037037 0.32777778 0.41666667 0.69074074]\n",
      "----------------------------------------\n",
      "Trial 1210\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 141, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=141, random_state=100))])\n",
      "cv score: [0.61818182 0.38888889 0.64197531 0.8117284  0.68518519 0.55555556\n",
      " 0.35925926 0.44074074 0.48888889 0.53148148]\n",
      "----------------------------------------\n",
      "Trial 1211\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 79, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=79,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64727273 0.33950617 0.63271605 0.73765432 0.62345679 0.4845679\n",
      " 0.3        0.26296296 0.53333333 0.54814815]\n",
      "----------------------------------------\n",
      "Trial 1212\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 42, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=12,\n",
      "                                            n_estimators=42,\n",
      "                                            random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.69454545 0.29320988 0.73765432 0.84104938 0.6882716  0.58641975\n",
      " 0.43333333 0.22592593 0.54259259 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 1213\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 47, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=47,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60363636 0.35185185 0.49691358 0.71604938 0.63580247 0.49382716\n",
      " 0.27777778 0.25185185 0.60740741 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 1214\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 139, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=139,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.76545455 0.60493827 0.56018519 0.64814815 0.63580247 0.48765432\n",
      " 0.51666667 0.36851852 0.56666667 0.45      ]\n",
      "----------------------------------------\n",
      "Trial 1215\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 80, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=80, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.48909091 0.41666667 0.79320988 0.5154321  0.29320988 0.5617284\n",
      " 0.6        0.36666667 0.62222222 0.47962963]\n",
      "----------------------------------------\n",
      "Trial 1216\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 40, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=40, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.74181818 0.42592593 0.69135802 0.52469136 0.62962963 0.49691358\n",
      " 0.2962963  0.42962963 0.52592593 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 1217\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 105, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=105,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60545455 0.50462963 0.56635802 0.54012346 0.44444444 0.46141975\n",
      " 0.61296296 0.48148148 0.49814815 0.37592593]\n",
      "----------------------------------------\n",
      "Trial 1218\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 46, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=46, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.68363636 0.53703704 0.57098765 0.4845679  0.57098765 0.40740741\n",
      " 0.35925926 0.34074074 0.5037037  0.52962963]\n",
      "----------------------------------------\n",
      "Trial 1219\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 149, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=149, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.64363636 0.39814815 0.72530864 0.72839506 0.7037037  0.39814815\n",
      " 0.3962963  0.35185185 0.4962963  0.43703704]\n",
      "----------------------------------------\n",
      "Trial 1220\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 75, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=75, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.68       0.33950617 0.60802469 0.83641975 0.59567901 0.5154321\n",
      " 0.42222222 0.49259259 0.58518519 0.6       ]\n",
      "----------------------------------------\n",
      "Trial 1221\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 139, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=139,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.67272727 0.38580247 0.57098765 0.71296296 0.56790123 0.57098765\n",
      " 0.31851852 0.31851852 0.47037037 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 1222\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 145, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=145,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.72       0.38271605 0.56790123 0.72222222 0.53703704 0.52777778\n",
      " 0.43703704 0.3962963  0.56296296 0.42222222]\n",
      "----------------------------------------\n",
      "Trial 1223\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 150, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=150, random_state=100))])\n",
      "cv score: [0.67272727 0.36419753 0.62345679 0.87037037 0.74074074 0.5154321\n",
      " 0.42222222 0.43333333 0.52222222 0.51481481]\n",
      "----------------------------------------\n",
      "Trial 1224\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 87, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=87,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.61818182 0.5308642  0.45987654 0.65740741 0.50925926 0.38888889\n",
      " 0.36296296 0.36296296 0.5        0.51851852]\n",
      "----------------------------------------\n",
      "Trial 1225\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 161, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=161,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64363636 0.35185185 0.66975309 0.69753086 0.62037037 0.5\n",
      " 0.45925926 0.33703704 0.62222222 0.67407407]\n",
      "----------------------------------------\n",
      "Trial 1226\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 30, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=30,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60363636 0.4691358  0.50308642 0.59259259 0.55864198 0.57098765\n",
      " 0.23703704 0.2962963  0.47777778 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 1227\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 92, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=92,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.65454545 0.39506173 0.62037037 0.68209877 0.65123457 0.5154321\n",
      " 0.47407407 0.41111111 0.48518519 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 1228\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=108, random_state=100))])\n",
      "cv score: [0.70545455 0.46604938 0.62345679 0.86728395 0.60493827 0.49382716\n",
      " 0.4037037  0.42222222 0.56666667 0.44814815]\n",
      "----------------------------------------\n",
      "Trial 1229\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 77, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=77,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.6        0.36419753 0.6882716  0.74382716 0.7191358  0.62654321\n",
      " 0.38148148 0.37037037 0.60740741 0.66666667]\n",
      "----------------------------------------\n",
      "Trial 1230\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65818182 0.52469136 0.51080247 0.70833333 0.39506173 0.62654321\n",
      " 0.52222222 0.45185185 0.58333333 0.58518519]\n",
      "----------------------------------------\n",
      "Trial 1231\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 96, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=96,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.64727273 0.41049383 0.46296296 0.67901235 0.57407407 0.46296296\n",
      " 0.34444444 0.36296296 0.58888889 0.52222222]\n",
      "----------------------------------------\n",
      "Trial 1232\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 17, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=17, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.63272727 0.36419753 0.60493827 0.62345679 0.61111111 0.49382716\n",
      " 0.56296296 0.41481481 0.51481481 0.67037037]\n",
      "----------------------------------------\n",
      "Trial 1233\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 27, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=27,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.67272727 0.38271605 0.57098765 0.74382716 0.46604938 0.41512346\n",
      " 0.42592593 0.34259259 0.51481481 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 1234\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 85, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=85,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.66363636 0.59722222 0.62037037 0.45987654 0.62962963 0.52932099\n",
      " 0.52222222 0.25740741 0.37962963 0.8537037 ]\n",
      "----------------------------------------\n",
      "Trial 1235\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 140, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            n_estimators=140,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.74545455 0.44753086 0.6882716  0.71296296 0.7808642  0.51851852\n",
      " 0.45925926 0.43333333 0.41851852 0.6       ]\n",
      "----------------------------------------\n",
      "Trial 1236\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 41, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=41,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59818182 0.44907407 0.52006173 0.52469136 0.53395062 0.54938272\n",
      " 0.6037037  0.38148148 0.66111111 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 1237\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 20, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=20, random_state=100))])\n",
      "cv score: [0.57090909 0.40740741 0.61728395 0.65432099 0.66049383 0.40123457\n",
      " 0.34814815 0.41481481 0.51111111 0.43703704]\n",
      "----------------------------------------\n",
      "Trial 1238\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='sqrt',\n",
      "                                            n_estimators=81, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.55636364 0.5617284  0.62654321 0.66358025 0.61111111 0.33333333\n",
      " 0.37777778 0.45185185 0.64814815 0.4       ]\n",
      "----------------------------------------\n",
      "Trial 1239\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 123, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, n_estimators=123,\n",
      "                                            random_state=100, subsample=0.9))])\n",
      "cv score: [0.62181818 0.47530864 0.66666667 0.87654321 0.75       0.55246914\n",
      " 0.42222222 0.4        0.58518519 0.48888889]\n",
      "----------------------------------------\n",
      "Trial 1240\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 171, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=171,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57090909 0.41358025 0.58333333 0.68518519 0.48148148 0.65432099\n",
      " 0.34814815 0.41111111 0.52962963 0.52962963]\n",
      "----------------------------------------\n",
      "Trial 1241\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 176, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=176, random_state=100))])\n",
      "cv score: [0.66181818 0.45679012 0.57716049 0.81790123 0.75925926 0.52469136\n",
      " 0.31851852 0.42962963 0.52962963 0.43333333]\n",
      "----------------------------------------\n",
      "Trial 1242\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, max_features='log2',\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.65090909 0.58024691 0.65432099 0.75       0.76234568 0.32716049\n",
      " 0.38518519 0.41111111 0.5037037  0.3962963 ]\n",
      "----------------------------------------\n",
      "Trial 1243\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 136, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=136,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.52727273 0.41666667 0.50308642 0.66975309 0.47222222 0.63888889\n",
      " 0.41851852 0.4037037  0.61851852 0.6       ]\n",
      "----------------------------------------\n",
      "Trial 1244\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 79, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=79,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.64363636 0.3117284  0.64814815 0.64814815 0.64197531 0.52777778\n",
      " 0.41481481 0.33333333 0.5962963  0.63703704]\n",
      "----------------------------------------\n",
      "Trial 1245\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=133,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.63636364 0.27777778 0.70216049 0.49074074 0.77932099 0.55246914\n",
      " 0.58703704 0.35555556 0.42222222 0.54444444]\n",
      "----------------------------------------\n",
      "Trial 1246\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 44, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=44, random_state=100))])\n",
      "cv score: [0.61454545 0.53395062 0.57407407 0.69753086 0.58641975 0.48148148\n",
      " 0.42962963 0.36666667 0.53333333 0.61481481]\n",
      "----------------------------------------\n",
      "Trial 1247\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=171, random_state=100))])\n",
      "cv score: [0.66909091 0.36419753 0.61419753 0.87037037 0.72839506 0.54012346\n",
      " 0.41851852 0.42222222 0.5037037  0.48518519]\n",
      "----------------------------------------\n",
      "Trial 1248\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 122, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=122, random_state=100))])\n",
      "cv score: [0.72363636 0.42592593 0.56790123 0.76851852 0.71604938 0.55864198\n",
      " 0.28888889 0.42592593 0.53703704 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 1249\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 64, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt', n_estimators=64,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70545455 0.45987654 0.74691358 0.75       0.63580247 0.53395062\n",
      " 0.41851852 0.42592593 0.59259259 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 1250\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 181, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=181,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.68727273 0.41049383 0.4537037  0.64814815 0.70679012 0.5308642\n",
      " 0.34444444 0.37777778 0.55185185 0.61851852]\n",
      "----------------------------------------\n",
      "Trial 1251\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 182, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=182,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62181818 0.34876543 0.66975309 0.65432099 0.62654321 0.52777778\n",
      " 0.37407407 0.32222222 0.61481481 0.56666667]\n",
      "----------------------------------------\n",
      "Trial 1252\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=52, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.70181818 0.30555556 0.65432099 0.78395062 0.69753086 0.39197531\n",
      " 0.43333333 0.59259259 0.54074074 0.21851852]\n",
      "----------------------------------------\n",
      "Trial 1253\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 190, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=190,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.47222222 0.5        0.48148148]\n",
      "----------------------------------------\n",
      "Trial 1254\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 15, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=15,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62545455 0.44444444 0.5941358  0.53240741 0.47530864 0.5308642\n",
      " 0.63148148 0.4962963  0.66111111 0.51666667]\n",
      "----------------------------------------\n",
      "Trial 1255\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 51, 'gb__subsample': 0.95, 'gb__learning_rate': 0.1, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=7, max_features='sqrt',\n",
      "                                            n_estimators=51, random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.64       0.42901235 0.73765432 0.73148148 0.68518519 0.36111111\n",
      " 0.35555556 0.44444444 0.64444444 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 1256\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 187, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=187,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69818182 0.35185185 0.51851852 0.71296296 0.55555556 0.54320988\n",
      " 0.29259259 0.37037037 0.53703704 0.46666667]\n",
      "----------------------------------------\n",
      "Trial 1257\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 195, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=195, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.68363636 0.52469136 0.6882716  0.5617284  0.56481481 0.26851852\n",
      " 0.58148148 0.48518519 0.52592593 0.41851852]\n",
      "----------------------------------------\n",
      "Trial 1258\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 85, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=85, random_state=100))])\n",
      "cv score: [0.67636364 0.47222222 0.56481481 0.72222222 0.75       0.50925926\n",
      " 0.31111111 0.41481481 0.55185185 0.55925926]\n",
      "----------------------------------------\n",
      "Trial 1259\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 103, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=103, random_state=100))])\n",
      "cv score: [0.70909091 0.55864198 0.5154321  0.65432099 0.54012346 0.47839506\n",
      " 0.45925926 0.27407407 0.44074074 0.41481481]\n",
      "----------------------------------------\n",
      "Trial 1260\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 89, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=89,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.70909091 0.4382716  0.66975309 0.69135802 0.63271605 0.51851852\n",
      " 0.4        0.35925926 0.53333333 0.61481481]\n",
      "----------------------------------------\n",
      "Trial 1261\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 184, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=5,\n",
      "                                            n_estimators=184, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.61090909 0.46604938 0.69753086 0.8117284  0.70679012 0.26851852\n",
      " 0.37777778 0.23333333 0.42962963 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 1262\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 191, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=191,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.77454545 0.37962963 0.48148148 0.75617284 0.60185185 0.35493827\n",
      " 0.32222222 0.50740741 0.43333333 0.48148148]\n",
      "----------------------------------------\n",
      "Trial 1263\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=7, max_features='log2',\n",
      "                                            n_estimators=81, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.59636364 0.42901235 0.71604938 0.7962963  0.65123457 0.44753086\n",
      " 0.45555556 0.46666667 0.42222222 0.42962963]\n",
      "----------------------------------------\n",
      "Trial 1264\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 24, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=24,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.66181818 0.60802469 0.48148148 0.76851852 0.58024691 0.59259259\n",
      " 0.4        0.46296296 0.47037037 0.54814815]\n",
      "----------------------------------------\n",
      "Trial 1265\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 172, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=172,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.69818182 0.34876543 0.47530864 0.69444444 0.71604938 0.50308642\n",
      " 0.36666667 0.46296296 0.52592593 0.4962963 ]\n",
      "----------------------------------------\n",
      "Trial 1266\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 63, 'gb__subsample': 0.95, 'gb__learning_rate': 0.1, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=7, n_estimators=63,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.62545455 0.47530864 0.7037037  0.83333333 0.74691358 0.47222222\n",
      " 0.45555556 0.37407407 0.5962963  0.48888889]\n",
      "----------------------------------------\n",
      "Trial 1267\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 48, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=48,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.62181818 0.33333333 0.65740741 0.64197531 0.64197531 0.53395062\n",
      " 0.44814815 0.28888889 0.54814815 0.62962963]\n",
      "----------------------------------------\n",
      "Trial 1268\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 106, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=106, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.49454545 0.34567901 0.65432099 0.73148148 0.77160494 0.47222222\n",
      " 0.41481481 0.30740741 0.45185185 0.4037037 ]\n",
      "----------------------------------------\n",
      "Trial 1269\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 194, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            n_estimators=194, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.73454545 0.4845679  0.57407407 0.66049383 0.59259259 0.44753086\n",
      " 0.44814815 0.29259259 0.47777778 0.46296296]\n",
      "----------------------------------------\n",
      "Trial 1270\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 94, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=94,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.69090909 0.42901235 0.47530864 0.60185185 0.61728395 0.50308642\n",
      " 0.30740741 0.41111111 0.55185185 0.4       ]\n",
      "----------------------------------------\n",
      "Trial 1271\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 106, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=106,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.65454545 0.36111111 0.48148148 0.72530864 0.60493827 0.45987654\n",
      " 0.27037037 0.32222222 0.48888889 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 1272\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 171, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=171,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.74181818 0.35802469 0.51234568 0.69135802 0.60802469 0.4382716\n",
      " 0.3037037  0.33703704 0.56666667 0.47407407]\n",
      "----------------------------------------\n",
      "Trial 1273\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 132, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            n_estimators=132, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.50181818 0.39197531 0.79938272 0.7345679  0.65123457 0.50617284\n",
      " 0.43703704 0.34814815 0.55555556 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 1274\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=198, random_state=100))])\n",
      "cv score: [0.78909091 0.51851852 0.60185185 0.74382716 0.64506173 0.51851852\n",
      " 0.38888889 0.33703704 0.58518519 0.48518519]\n",
      "----------------------------------------\n",
      "Trial 1275\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 131, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=131, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.67636364 0.44753086 0.63888889 0.85493827 0.63580247 0.52469136\n",
      " 0.38888889 0.4037037  0.53703704 0.45185185]\n",
      "----------------------------------------\n",
      "Trial 1276\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 52, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=52,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62181818 0.55401235 0.50925926 0.5462963  0.46450617 0.54938272\n",
      " 0.6        0.43518519 0.61851852 0.45925926]\n",
      "----------------------------------------\n",
      "Trial 1277\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=5,\n",
      "                                            n_estimators=115, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.68727273 0.41358025 0.64814815 0.75308642 0.63888889 0.41049383\n",
      " 0.28888889 0.27777778 0.58888889 0.52592593]\n",
      "----------------------------------------\n",
      "Trial 1278\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 97, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=97,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.65090909 0.37962963 0.57716049 0.78395062 0.58950617 0.50925926\n",
      " 0.41851852 0.33333333 0.5037037  0.63703704]\n",
      "----------------------------------------\n",
      "Trial 1279\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 194, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=194, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.59636364 0.39506173 0.77160494 0.7808642  0.77777778 0.41975309\n",
      " 0.45185185 0.47777778 0.52222222 0.40740741]\n",
      "----------------------------------------\n",
      "Trial 1280\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 39, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=39,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.75636364 0.49691358 0.46296296 0.61728395 0.54938272 0.52469136\n",
      " 0.42962963 0.44444444 0.57037037 0.42592593]\n",
      "----------------------------------------\n",
      "Trial 1281\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 41, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=41,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.62545455 0.44444444 0.59876543 0.54320988 0.44444444 0.5308642\n",
      " 0.61296296 0.48148148 0.57592593 0.40925926]\n",
      "----------------------------------------\n",
      "Trial 1282\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.54545455 0.4382716  0.36728395 0.58333333 0.75308642 0.34567901\n",
      " 0.39259259 0.42592593 0.5037037  0.54814815]\n",
      "----------------------------------------\n",
      "Trial 1283\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=115, random_state=100))])\n",
      "cv score: [0.66909091 0.40123457 0.63271605 0.87654321 0.66358025 0.60493827\n",
      " 0.26666667 0.38148148 0.51851852 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 1284\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.69454545 0.40123457 0.55864198 0.72839506 0.52777778 0.5154321\n",
      " 0.38888889 0.50740741 0.41851852 0.47037037]\n",
      "----------------------------------------\n",
      "Trial 1285\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 141, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            n_estimators=141, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.6        0.33641975 0.37037037 0.58024691 0.58950617 0.1712963\n",
      " 0.33333333 0.6037037  0.50740741 0.53333333]\n",
      "----------------------------------------\n",
      "Trial 1286\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 196, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            n_estimators=196, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.64363636 0.45987654 0.72530864 0.84259259 0.68518519 0.55555556\n",
      " 0.37037037 0.2962963  0.4962963  0.45555556]\n",
      "----------------------------------------\n",
      "Trial 1287\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 58, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=58,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.73818182 0.33024691 0.50617284 0.74074074 0.4691358  0.58333333\n",
      " 0.42962963 0.4962963  0.34074074 0.26296296]\n",
      "----------------------------------------\n",
      "Trial 1288\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 177, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=177,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.67272727 0.4691358  0.6882716  0.80555556 0.75       0.36419753\n",
      " 0.33333333 0.43333333 0.54074074 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 1289\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 153, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07,\n",
      "                                            n_estimators=153, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.71272727 0.44444444 0.70061728 0.75       0.64506173 0.29938272\n",
      " 0.31111111 0.28888889 0.60740741 0.49259259]\n",
      "----------------------------------------\n",
      "Trial 1290\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 128, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=128,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    }
   ],
   "source": [
    "# do the search\n",
    "_,_, best_estimator_rec = mmh.randomized_search_cv(X_rec_rest, y_rec_rest, \n",
    "                                                   search_space, \n",
    "                                                   cv=cv_10,\n",
    "                                                   refit=True,\n",
    "                                                   n_iter=5000, \n",
    "                                                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627d5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.get_test_scores(X_rec_rest, y_rec_rest, X_rec_test, y_rec_test, best_estimator_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rec_test = confusion_matrix(y_rec_test, best_estimator_rec.predict(X_rec_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_rec_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e56a5",
   "metadata": {},
   "source": [
    "---\n",
    "## Predicting $T$ (drain) from controls $X, W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_drain_full = csdh_data['drain']\n",
    "X_drain_full = csdh_data.drop(['drain', 'recurrence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de811c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation set and rest\n",
    "X_drain_rest, X_drain_val, y_drain_rest, y_drain_val = train_test_split(X_drain_full, y_drain_full, \n",
    "                                                                        test_size=0.20,\n",
    "                                                                        random_state=random_state,\n",
    "                                                                        stratify=y_drain_full)\n",
    "\n",
    "# Split rest into train and test set\n",
    "X_drain_train, X_drain_test, y_drain_train, y_drain_test = train_test_split(X_drain_rest, y_drain_rest, \n",
    "                                                                            test_size=0.20,\n",
    "                                                                            random_state=random_state,\n",
    "                                                                            stratify=y_drain_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "drain_training_scores, drain_val_scores = mmh.train_and_validate_classifiers(X_drain_train, \n",
    "                                                                             y_drain_train,\n",
    "                                                                             X_drain_val,\n",
    "                                                                             y_drain_val,\n",
    "                                                                             names,\n",
    "                                                                             classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.print_metrics_table(drain_training_scores, drain_val_scores, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dcb2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_drain_test = confusion_matrix(y_drain_test, classifiers[5].predict(X_drain_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_drain_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a22017d",
   "metadata": {},
   "source": [
    "## `model_t` K-Fold cross validation for hyperparameter tuning and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8571cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the search\n",
    "_,_, best_estimator_drain = mmh.randomized_search_cv(X_drain_rest, y_drain_rest, \n",
    "                                                     search_space, \n",
    "                                                     cv=cv_10,\n",
    "                                                     refit=True,\n",
    "                                                     score='roc_auc',\n",
    "                                                     n_iter=5000, \n",
    "                                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383126b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.get_test_scores(X_drain_rest, y_drain_rest, X_drain_test, y_drain_test, best_estimator_drain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc4268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_drain_test = confusion_matrix(y_drain_test, best_estimator_drain.predict(X_drain_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_drain_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afaa29e",
   "metadata": {},
   "source": [
    "# _Doubly Robust Learning_: include `drain` as a feature into `model_y`.\n",
    "- In doubly robust estimators of ATEs and CATES, the treatment variable is included in `model_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8930e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full = csdh_doc['recurrence']\n",
    "X_full = csdh_doc.drop(['recurrence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3162b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation set and rest\n",
    "X_rest, X_val, y_rest, y_val = train_test_split(X_full, y_full, \n",
    "                                                test_size=0.20,\n",
    "                                                random_state=random_state,\n",
    "                                                stratify=y_full)\n",
    "\n",
    "# Split rest into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rest, y_rest, \n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=y_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores, val_scores = mmh.train_and_validate_classifiers(X_train, \n",
    "                                                                 y_train,\n",
    "                                                                 X_val,\n",
    "                                                                 y_val,\n",
    "                                                                 names,\n",
    "                                                                 classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ccb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.print_metrics_table(training_scores, val_scores, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test, classifiers[5].predict(X_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2517915",
   "metadata": {},
   "source": [
    "## `model_y` K-Fold cross validation for hyperparameter tuning and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4765883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the search\n",
    "_,_, best_estimator = mmh.randomized_search_cv(X_rest, y_rest, \n",
    "                                               search_space, \n",
    "                                               cv=cv_10,\n",
    "                                               refit=True,\n",
    "                                               score='roc_auc',\n",
    "                                               n_iter=5000, \n",
    "                                               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72300f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.get_test_scores(X_rest, y_rest, X_test, y_test, best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test, best_estimator.predict(X_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_test, [0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
