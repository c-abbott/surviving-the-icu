{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "981dbcd1",
   "metadata": {},
   "source": [
    "# CATE meta-model selection\n",
    "The purpose of this notebook is to discern which statistical/ML model(s) we should use in our CATE estimators.\n",
    "\n",
    "### CATE Estimators\n",
    " - Double machine learning CATE estimators predict $Y$ from $X,W \\rightarrow$ `model_y`, as well as predict $T$ from $X,W \\rightarrow$ `model_t` to estiamte the CATE\n",
    "\n",
    " - Doubly robust methods are similar to double machine learning, however the treatment variable $T$ is included as a feature in `model_y`. There is also a `model_final` which amalgamates these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e19d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports to get us started\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Utilities\n",
    "import os \n",
    "import sys\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "random_state = 100 # Ensure reproducible results\n",
    "\n",
    "# DoWhy\n",
    "import pygraphviz\n",
    "from IPython.display import Image, display\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import econml\n",
    "\n",
    "# Generic ML imports\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB\n",
    "from sklearn.linear_model import LassoCV, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, recall_score, f1_score, roc_auc_score, confusion_matrix, plot_roc_curve\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Import custom dowhy helper functions module\n",
    "cwd = Path().resolve()\n",
    "PARENT_DIR = os.path.dirname(cwd)\n",
    "SCRIPT_DIR = os.path.join(PARENT_DIR, 'helpers')\n",
    "sys.path.append(SCRIPT_DIR)\n",
    "import meta_model_helpers as mmh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b91270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O Stuff\n",
    "DATA_FILENAME = \"csdh_final.csv\"\n",
    "DATA_FILEPATH = \"/Users/callum/Uni/GitHubRepos/surviving-the-icu/datasets/drain_data/\" + DATA_FILENAME\n",
    "csdh = pd.read_csv(DATA_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78eb9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIN DAG features\n",
    "min_features = ['age', 'thickness_sum', 'antiplatelet', 'drain', 'recurrence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f17f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical type conversion\n",
    "categorical_features = ['stroke', 'antiplatelet', 'ihd', 'metalvalve', 'membranes', 'optype', 'recurrence',\n",
    "                        'drain', 'hospital', 'bedrest', 'warfarin', 'density', 'membranes', 'burrhole_num',\n",
    "                        'bedrest']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    col = pd.Categorical(csdh[feature])\n",
    "    csdh[feature] = col.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14114ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reduced datasets\n",
    "csdh_min = csdh[min_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae8daaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_model = CausalModel(data=csdh_min, \n",
    "                        treatment='drain', \n",
    "                        outcome='recurrence', \n",
    "                        graph='../causal_graphs/min_dag.dot'.replace(\"\\n\", \" \"))\n",
    "min_model.view_model()\n",
    "display(Image(filename=\"causal_model.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909f87f",
   "metadata": {},
   "source": [
    "---\n",
    "## Define set of classifiers to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28884673",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Dummy', 'LR', 'Linear SVM', 'RBF SVM', 'GB', 'RF', 'XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c3cd7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes exluded due to mixture of variable types\n",
    "classifiers = [\n",
    "    DummyClassifier(strategy='most_frequent'),\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    SVC(kernel=\"linear\", probability=True, random_state=random_state),\n",
    "    SVC(kernel='rbf', probability=True, random_state=random_state),\n",
    "    GradientBoostingClassifier(random_state=random_state),\n",
    "    RandomForestClassifier(random_state=random_state),\n",
    "    XGBClassifier(random_state=random_state),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037526f",
   "metadata": {},
   "source": [
    "# _Double Machine Learning:_ finding `model_y` and `model_t`.\n",
    "- `model_y` models $\\mathbb{E}[Y \\mid X,W]$ where the treatment variable $T$ is omitted from the covariates\n",
    "- `model_t` is the propensity model and involves estimating $P[T=1\\mid X,W]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e31722",
   "metadata": {},
   "source": [
    "## Predicting $Y$ (recurrence) from controls $X, W$; `model_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "616e06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rec_full = csdh_min['recurrence']\n",
    "X_rec_full = csdh_min.drop(['drain', 'recurrence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc55a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation set and rest\n",
    "X_rec_rest, X_rec_val, y_rec_rest, y_rec_val = train_test_split(X_rec_full, y_rec_full, \n",
    "                                                                test_size=0.15,\n",
    "                                                                random_state=random_state,\n",
    "                                                                stratify=y_rec_full)\n",
    "\n",
    "# Split rest into train and test set\n",
    "X_rec_train, X_rec_test, y_rec_train, y_rec_test = train_test_split(X_rec_rest, y_rec_rest, \n",
    "                                                                    test_size=0.15,\n",
    "                                                                    random_state=random_state,\n",
    "                                                                    stratify=y_rec_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30169fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:21:43] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "rec_training_scores, rec_val_scores = mmh.train_and_validate_classifiers(X_rec_train, \n",
    "                                                                         y_rec_train,\n",
    "                                                                         X_rec_val,\n",
    "                                                                         y_rec_val,\n",
    "                                                                         names,\n",
    "                                                                         classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffcebb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set: \n",
      "\n",
      "             ----------------Validation-----------------   -----------------Training------------------\n",
      "Method         Acc↑   AUROC↑  Recall↑      F1↑      LL↓     Acc↑   AUROC↑  Recall↑      F1↑      LL↓\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dummy         0.911    0.500    0.000    0.000   3.084    0.907    0.500    0.000    0.000    3.210\n",
      "LR            0.911    0.500    0.000    0.000   3.084    0.907    0.500    0.000    0.000    3.210\n",
      "Linear SVM    0.911    0.500    0.000    0.000   3.084    0.907    0.500    0.000    0.000    3.210\n",
      "RBF SVM       0.911    0.500    0.000    0.000   3.084    0.907    0.500    0.000    0.000    3.210\n",
      "GB            0.911    0.500    0.000    0.000   3.084    0.928    0.610    0.220    0.361    2.504\n",
      "RF            0.893    0.490    0.000    0.000   3.701    0.974    0.860    0.720    0.837    0.899\n",
      "XGB           0.893    0.490    0.000    0.000   3.701    0.954    0.768    0.540    0.684    1.605\n"
     ]
    }
   ],
   "source": [
    "mmh.print_metrics_table(rec_training_scores, rec_val_scores, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be29369c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_rec_test = confusion_matrix(y_rec_test, classifiers[4].predict(X_rec_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_rec_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85222656",
   "metadata": {},
   "source": [
    "## `model_y` K-Fold cross validation for hyperparameter tuning and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf6c0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross-validation structure\n",
    "cv_5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "cv_10 = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87c90577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classifiers and hyperparameters to search over\n",
    "rf = RandomForestClassifier()\n",
    "params_rf = {\n",
    "    # randomly sample numbers from 10 to 200 estimators\n",
    "    'rf__n_estimators':randint(10, 200),\n",
    "    \n",
    "    ### DONT TUNE THESE DUE TO DATASET SIZE ###\n",
    "    # minimum number of samples required to split an internal node\n",
    "    #'rf__min_samples_split':randint(1, 12),\n",
    "    # minimum number of samples required to split a leaf\n",
    "    #'rf__min_samples_leaf':randint(1, 50),\n",
    "    # The maximum depth of the individual regression estimators.\n",
    "    \n",
    "    'rf__max_depth':randint(2, 15),\n",
    "    # The number of features to consider when looking for the best split\n",
    "    'rf__max_features':['sqrt', 'log2', None],\n",
    "    # random seed\n",
    "    'rf__random_state':[random_state],\n",
    "    # Whether bootstrap samples are used when building trees\n",
    "    'rf__bootstrap':[True, False]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "params_gb = {\n",
    "    # randomly sample numbers from 10 to 200 estimators\n",
    "    'gb__n_estimators':randint(10, 200),\n",
    "    # fraction of samples to be used for fitting individual base learners\n",
    "    'gb__subsample':[0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1],\n",
    "    # learning rate\n",
    "    'gb__learning_rate':[0.001, 0.003, 0.01, 0.03, 0.07, 0.1, 0.3, 0.7, 1.0],\n",
    "        \n",
    "    ### DONT TUNE THESE DUE TO DATASET SIZE ###\n",
    "    # minimum number of samples required to split an internal node\n",
    "    #'gb__min_samples_split':randint(1, 12),\n",
    "    # minimum number of samples required to split a leaf\n",
    "    #'gb__min_samples_leaf':randint(1, 50),\n",
    "    # The maximum depth of the individual regression estimators\n",
    "    \n",
    "    'gb__max_depth':randint(2, 15),\n",
    "    # The number of features to consider when looking for the best split\n",
    "    'gb__max_features':['sqrt', 'log2', None],\n",
    "    # random seed\n",
    "    'gb__random_state':[random_state]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "params_xgb = {\n",
    "    # randomly sample numbers from 10 to 200 estimators\n",
    "    'xgb__n_estimators':randint(10, 200),\n",
    "    # fraction of samples to be used for fitting individual base learners\n",
    "    'xgb__subsample':[0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1],\n",
    "    # learning rate\n",
    "    'xgb__learning_rate':[0.001, 0.003, 0.01, 0.03, 0.07, 0.1, 0.3, 0.7, 1],\n",
    "    # min_split_loss\n",
    "    'xgb__gamma':[0.001, 0.003, 0.01, 0.03, 0.07, 0.1, 0.3],\n",
    " \n",
    "    ### DONT TUNE THESE DUE TO DATASET SIZE ###\n",
    "    # minimum number of samples required to split an internal node\n",
    "    #'gb__min_samples_split':randint(1, 12),\n",
    "    # minimum number of samples required to split a leaf\n",
    "    #'gb__min_samples_leaf':randint(1, 50),\n",
    "    # The maximum depth of the individual regression estimators\n",
    "    \n",
    "    'xgb__max_depth':randint(2, 15),\n",
    "    # analagous to max_features in rf and gb\n",
    "    'xgb__colsample_bytree':[0.6, 0.7, 0.8, 0.9, 1],\n",
    "    # random seed\n",
    "    'xgb__random_state':[random_state],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b09326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search spaces for random search tuning\n",
    "search_space = [('rf', rf, params_rf), ('gb', gb, params_gb), ('xgb', xgb, params_xgb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7354391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv strategy StratifiedKFold(n_splits=10, random_state=100, shuffle=True)\n",
      "----------------------------------------\n",
      "Trial 0\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 17, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=17,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.37356322 0.42528736 0.49655172 0.49415205 0.60380117\n",
      " 0.5380117  0.64473684 0.34795322 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 1\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37068966 0.35632184 0.65086207 0.63448276 0.51023392 0.53508772\n",
      " 0.46637427 0.46491228 0.39181287 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 2\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=121,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.5316092  0.50862069 0.60775862 0.62068966 0.70321637 0.5994152\n",
      " 0.27339181 0.50584795 0.50584795 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 3\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 130, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=130, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.43390805 0.48994253 0.65517241 0.46896552 0.46052632 0.46929825\n",
      " 0.46345029 0.63596491 0.37573099 0.48391813]\n",
      "----------------------------------------\n",
      "Trial 4\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 128, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=128, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.49137931 0.36781609 0.52442529 0.62068966 0.59502924 0.62280702\n",
      " 0.32017544 0.49415205 0.46783626 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 5\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.31609195 0.33908046 0.40517241 0.57241379 0.47222222 0.58918129\n",
      " 0.55994152 0.37719298 0.4122807  0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 6\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52586207 0.41522989 0.54597701 0.49310345 0.55847953 0.58333333\n",
      " 0.52192982 0.66666667 0.46783626 0.51900585]\n",
      "----------------------------------------\n",
      "Trial 7\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 93, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=93, random_state=100))])\n",
      "cv score: [0.45689655 0.40229885 0.4612069  0.54482759 0.7002924  0.47368421\n",
      " 0.26169591 0.52923977 0.44736842 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 8\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 78, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=78, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49712644 0.4454023  0.45258621 0.56206897 0.66520468 0.47222222\n",
      " 0.29678363 0.54093567 0.34064327 0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 9\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.28448276 0.40229885 0.42672414 0.56724138 0.54532164 0.62719298\n",
      " 0.53654971 0.48976608 0.53654971 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 10\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 68, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=68, random_state=100))])\n",
      "cv score: [0.51149425 0.51436782 0.51293103 0.63448276 0.51900585 0.5877193\n",
      " 0.39035088 0.57017544 0.45321637 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 11\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 80, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=80, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.64655172 0.47701149 0.36350575 0.55862069 0.63450292 0.3128655\n",
      " 0.46052632 0.35964912 0.45906433 0.46783626]\n",
      "----------------------------------------\n",
      "Trial 12\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 110, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=110,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56321839 0.46551724 0.60344828 0.49827586 0.48245614 0.50730994\n",
      " 0.5497076  0.67397661 0.46491228 0.52631579]\n",
      "----------------------------------------\n",
      "Trial 13\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 63, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=63, random_state=100))])\n",
      "cv score: [0.46408046 0.45114943 0.54310345 0.52586207 0.55555556 0.50584795\n",
      " 0.44444444 0.55263158 0.4502924  0.52339181]\n",
      "----------------------------------------\n",
      "Trial 14\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 53, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=53,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.38074713 0.49137931 0.48965517 0.48245614 0.46052632\n",
      " 0.57602339 0.64181287 0.46491228 0.44736842]\n",
      "----------------------------------------\n",
      "Trial 15\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 172, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=172,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37356322 0.41666667 0.44396552 0.51034483 0.5248538  0.59064327\n",
      " 0.47222222 0.56140351 0.4005848  0.38596491]\n",
      "----------------------------------------\n",
      "Trial 16\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 149, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=149,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.52586207 0.46551724 0.57471264 0.50862069 0.6871345  0.4619883\n",
      " 0.50292398 0.66081871 0.55409357 0.52339181]\n",
      "----------------------------------------\n",
      "Trial 17\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 155, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=155, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.54885057 0.45977011 0.60775862 0.72413793 0.62719298 0.62865497\n",
      " 0.3377193  0.50292398 0.47076023 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 18\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42241379 0.37643678 0.57902299 0.5862069  0.63888889 0.53216374\n",
      " 0.34356725 0.55555556 0.37719298 0.26608187]\n",
      "----------------------------------------\n",
      "Trial 19\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 161, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=161,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.53017241 0.55747126 0.56034483 0.66959064 0.43859649\n",
      " 0.37280702 0.61549708 0.61988304 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 20\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 41, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=41,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.27298851 0.52873563 0.39655172 0.46896552 0.6754386  0.47953216\n",
      " 0.46491228 0.60233918 0.60233918 0.49561404]\n",
      "----------------------------------------\n",
      "Trial 21\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 98, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=98, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.57183908 0.39655172 0.48706897 0.66551724 0.55994152 0.58187135\n",
      " 0.37865497 0.4619883  0.49122807 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 22\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 154, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=154,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41091954 0.31034483 0.61063218 0.63793103 0.68859649 0.50584795\n",
      " 0.32309942 0.52339181 0.42397661 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 23\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 166, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=166, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.56321839 0.50574713 0.46695402 0.54137931 0.66520468 0.56432749\n",
      " 0.43128655 0.4122807  0.42105263 0.62280702]\n",
      "----------------------------------------\n",
      "Trial 24\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 19, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=5,\n",
      "                                            n_estimators=19, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.38793103 0.32758621 0.53017241 0.48275862 0.63304094 0.57017544\n",
      " 0.39035088 0.42105263 0.52923977 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 25\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 13, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=13,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.39655172 0.44827586 0.56752874 0.53103448 0.48391813 0.61988304\n",
      " 0.36988304 0.54678363 0.45614035 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 26\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 142, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=142, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.48994253 0.43965517 0.68103448 0.37413793 0.25438596 0.55701754\n",
      " 0.29239766 0.50438596 0.62573099 0.60526316]\n",
      "----------------------------------------\n",
      "Trial 27\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 29, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=29,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42816092 0.33908046 0.56178161 0.56896552 0.65643275 0.43567251\n",
      " 0.29093567 0.47953216 0.40643275 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 28\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 39, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            n_estimators=39, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.48706897 0.51005747 0.43534483 0.46724138 0.65789474 0.35672515\n",
      " 0.37719298 0.45906433 0.58333333 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 29\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 125, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=125, random_state=100))])\n",
      "cv score: [0.50862069 0.44827586 0.58189655 0.70689655 0.63011696 0.56432749\n",
      " 0.30263158 0.56432749 0.43274854 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 30\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.85, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='log2',\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.5545977  0.3908046  0.63362069 0.74482759 0.53362573 0.65789474\n",
      " 0.36695906 0.45321637 0.49122807 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 31\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 89, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=89,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36781609 0.35344828 0.5933908  0.67931034 0.54239766 0.56140351\n",
      " 0.46052632 0.48245614 0.33625731 0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 32\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 65, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=65, random_state=100))])\n",
      "cv score: [0.5158046  0.47126437 0.50718391 0.53793103 0.6505848  0.49122807\n",
      " 0.32894737 0.56725146 0.4254386  0.31578947]\n",
      "----------------------------------------\n",
      "Trial 33\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42241379 0.37643678 0.66810345 0.6137931  0.6125731  0.53508772\n",
      " 0.40497076 0.5        0.35672515 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 34\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 41, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='sqrt',\n",
      "                                            n_estimators=41, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.46264368 0.42816092 0.61063218 0.63793103 0.55116959 0.55847953\n",
      " 0.34356725 0.54385965 0.48684211 0.42397661]\n",
      "----------------------------------------\n",
      "Trial 35\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 44, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            n_estimators=44, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.40804598 0.43678161 0.45258621 0.56724138 0.73830409 0.52046784\n",
      " 0.30263158 0.43567251 0.49415205 0.4005848 ]\n",
      "----------------------------------------\n",
      "Trial 36\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 31, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=31, random_state=100))])\n",
      "cv score: [0.40229885 0.48563218 0.45258621 0.59655172 0.70321637 0.47660819\n",
      " 0.26754386 0.54385965 0.47368421 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 37\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 194, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=194,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38505747 0.31609195 0.6795977  0.60344828 0.65643275 0.4502924\n",
      " 0.3377193  0.49122807 0.33918129 0.22807018]\n",
      "----------------------------------------\n",
      "Trial 38\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 110, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=110,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34195402 0.32758621 0.50431034 0.55862069 0.50438596 0.58479532\n",
      " 0.60087719 0.39181287 0.42836257 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 39\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 68, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=68,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40804598 0.39367816 0.66235632 0.70344828 0.68859649 0.61111111\n",
      " 0.55116959 0.43859649 0.29532164 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 40\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 150, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=150, random_state=100))])\n",
      "cv score: [0.47701149 0.44109195 0.50287356 0.61034483 0.67105263 0.46345029\n",
      " 0.31140351 0.61403509 0.36695906 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 41\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 96, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=96,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57758621 0.47701149 0.54022989 0.38275862 0.62573099 0.5\n",
      " 0.36403509 0.40350877 0.30701754 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 42\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 83, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=83,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.48563218 0.45833333 0.59913793 0.65172414 0.73976608 0.58187135\n",
      " 0.29824561 0.45321637 0.49415205 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 43\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 146, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=146, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.52011494 0.44827586 0.62787356 0.63103448 0.70614035 0.58479532\n",
      " 0.29678363 0.53508772 0.43859649 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 44\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 23, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            n_estimators=23,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.50862069 0.31609195 0.36925287 0.65862069 0.74707602 0.49707602\n",
      " 0.29385965 0.5        0.48830409 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 45\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 187, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=187,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.29885057 0.46551724 0.4841954  0.56034483 0.60087719 0.56140351\n",
      " 0.50730994 0.54678363 0.47368421 0.43567251]\n",
      "----------------------------------------\n",
      "Trial 46\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=12,\n",
      "                                            n_estimators=52, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.50574713 0.50574713 0.43247126 0.50689655 0.73830409 0.45614035\n",
      " 0.2880117  0.45321637 0.49415205 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 47\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 46, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=46,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53735632 0.49425287 0.55172414 0.62413793 0.72807018 0.55409357\n",
      " 0.23830409 0.5        0.49561404 0.45467836]\n",
      "----------------------------------------\n",
      "Trial 48\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 166, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            n_estimators=166, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.38793103 0.49425287 0.46408046 0.55862069 0.70906433 0.46783626\n",
      " 0.26461988 0.51754386 0.44152047 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 49\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 191, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=191,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49425287 0.42241379 0.60775862 0.67241379 0.72076023 0.60526316\n",
      " 0.30994152 0.4619883  0.47953216 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 50\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 172, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            n_estimators=172, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.48563218 0.43965517 0.50431034 0.57586207 0.66812865 0.50584795\n",
      " 0.27046784 0.43274854 0.47660819 0.28947368]\n",
      "----------------------------------------\n",
      "Trial 51\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57327586 0.56609195 0.60344828 0.51724138 0.66374269 0.43274854\n",
      " 0.46491228 0.63157895 0.57309942 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 52\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=121, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.31321839 0.45545977 0.39798851 0.40172414 0.5380117  0.50292398\n",
      " 0.60380117 0.52339181 0.51169591 0.39327485]\n",
      "----------------------------------------\n",
      "Trial 53\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 104, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=5,\n",
      "                                            n_estimators=104, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.45402299 0.44252874 0.59626437 0.64827586 0.72660819 0.59064327\n",
      " 0.31871345 0.45321637 0.5497076  0.31578947]\n",
      "----------------------------------------\n",
      "Trial 54\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 144, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=144, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.52011494 0.48563218 0.59913793 0.65172414 0.67105263 0.59356725\n",
      " 0.21783626 0.48245614 0.46783626 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 55\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 82, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=82, random_state=100))])\n",
      "cv score: [0.48706897 0.44252874 0.52729885 0.52068966 0.55847953 0.52192982\n",
      " 0.43274854 0.54385965 0.48684211 0.48391813]\n",
      "----------------------------------------\n",
      "Trial 56\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 29, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=29, random_state=100))])\n",
      "cv score: [0.55890805 0.50287356 0.42816092 0.63448276 0.58918129 0.60818713\n",
      " 0.42836257 0.56432749 0.5994152  0.45175439]\n",
      "----------------------------------------\n",
      "Trial 57\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 122, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=122,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.48275862 0.44827586 0.58189655 0.65172414 0.73538012 0.57894737\n",
      " 0.29532164 0.44444444 0.48099415 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 58\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 104, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=104,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49712644 0.41091954 0.61637931 0.67931034 0.73245614 0.5994152\n",
      " 0.31578947 0.4619883  0.49122807 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 59\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 109, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=109,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54166667 0.46551724 0.56178161 0.67758621 0.63011696 0.59649123\n",
      " 0.34795322 0.48245614 0.50292398 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 60\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 134, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            n_estimators=134, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.47988506 0.49425287 0.48132184 0.56206897 0.70906433 0.49707602\n",
      " 0.31432749 0.5        0.51754386 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 61\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 32, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=32,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51293103 0.55028736 0.50287356 0.59482759 0.64766082 0.62426901\n",
      " 0.47222222 0.5628655  0.55994152 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 62\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 60, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=60, random_state=100))])\n",
      "cv score: [0.41091954 0.40229885 0.52729885 0.64482759 0.69152047 0.50584795\n",
      " 0.30263158 0.54678363 0.41520468 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 63\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 25, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=25, random_state=100))])\n",
      "cv score: [0.61063218 0.49425287 0.50574713 0.63448276 0.57309942 0.60818713\n",
      " 0.40497076 0.7251462  0.46637427 0.35526316]\n",
      "----------------------------------------\n",
      "Trial 64\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=16,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49856322 0.54166667 0.49281609 0.56896552 0.64473684 0.61842105\n",
      " 0.46783626 0.60964912 0.5497076  0.45321637]\n",
      "----------------------------------------\n",
      "Trial 65\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.5316092  0.50574713 0.55603448 0.66551724 0.63888889 0.64035088\n",
      " 0.30263158 0.50877193 0.46491228 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 66\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 67, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=67, random_state=100))])\n",
      "cv score: [0.50287356 0.51149425 0.44683908 0.58275862 0.54385965 0.55555556\n",
      " 0.4254386  0.5628655  0.5380117  0.47660819]\n",
      "----------------------------------------\n",
      "Trial 67\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 143, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            n_estimators=143, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.47413793 0.43965517 0.58764368 0.51724138 0.69736842 0.45906433\n",
      " 0.25584795 0.56725146 0.48245614 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 68\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 183, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=183,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3591954  0.37068966 0.65373563 0.66551724 0.50146199 0.66081871\n",
      " 0.50730994 0.44736842 0.41520468 0.29239766]\n",
      "----------------------------------------\n",
      "Trial 69\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            n_estimators=170,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.43678161 0.45258621 0.50143678 0.48103448 0.74415205 0.34210526\n",
      " 0.36695906 0.37134503 0.5497076  0.32163743]\n",
      "----------------------------------------\n",
      "Trial 70\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 26, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=26,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.38505747 0.33333333 0.54741379 0.56551724 0.37719298 0.66081871\n",
      " 0.53654971 0.58479532 0.31578947 0.26900585]\n",
      "----------------------------------------\n",
      "Trial 71\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 114, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=114, random_state=100))])\n",
      "cv score: [0.48850575 0.40229885 0.44971264 0.58965517 0.73245614 0.48245614\n",
      " 0.32602339 0.49707602 0.46783626 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 72\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 119, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=119, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.4137931  0.37931034 0.53591954 0.48448276 0.39181287 0.54385965\n",
      " 0.39327485 0.45321637 0.48099415 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 73\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 158, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=158, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.49425287 0.52873563 0.44683908 0.62068966 0.55409357 0.60233918\n",
      " 0.35818713 0.64035088 0.51608187 0.47076023]\n",
      "----------------------------------------\n",
      "Trial 74\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 15, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=15, random_state=100))])\n",
      "cv score: [0.68103448 0.46408046 0.57902299 0.7        0.63157895 0.59210526\n",
      " 0.37865497 0.53508772 0.49269006 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 75\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 170, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=170,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.32758621 0.69683908 0.6        0.61549708 0.54678363\n",
      " 0.47222222 0.46783626 0.33918129 0.28947368]\n",
      "----------------------------------------\n",
      "Trial 76\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 57, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=57, random_state=100))])\n",
      "cv score: [0.56321839 0.34626437 0.60488506 0.63103448 0.64473684 0.55263158\n",
      " 0.38157895 0.48830409 0.41081871 0.31432749]\n",
      "----------------------------------------\n",
      "Trial 77\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 66, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            n_estimators=66, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.47988506 0.35632184 0.54166667 0.56896552 0.77923977 0.58479532\n",
      " 0.36111111 0.30116959 0.38011696 0.62280702]\n",
      "----------------------------------------\n",
      "Trial 78\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            n_estimators=168, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.40229885 0.37068966 0.49568966 0.63448276 0.67397661 0.56725146\n",
      " 0.33187135 0.46783626 0.57309942 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 79\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 35, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=35, random_state=100))])\n",
      "cv score: [0.41954023 0.4137931  0.38936782 0.67586207 0.73830409 0.47368421\n",
      " 0.32894737 0.52631579 0.47076023 0.29385965]\n",
      "----------------------------------------\n",
      "Trial 80\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 148, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=148,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52298851 0.51293103 0.56896552 0.42413793 0.50584795 0.48830409\n",
      " 0.5877193  0.61403509 0.4751462  0.42105263]\n",
      "----------------------------------------\n",
      "Trial 81\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 189, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=189,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.37068966 0.32758621 0.65948276 0.63448276 0.54532164 0.6754386\n",
      " 0.51315789 0.43274854 0.40350877 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 82\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41091954 0.37356322 0.66235632 0.57931034 0.64473684 0.43567251\n",
      " 0.2997076  0.54678363 0.38304094 0.29532164]\n",
      "----------------------------------------\n",
      "Trial 83\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 62, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=62, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.53448276 0.52873563 0.59913793 0.62068966 0.66812865 0.52631579\n",
      " 0.28216374 0.52923977 0.45321637 0.43274854]\n",
      "----------------------------------------\n",
      "Trial 84\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 114, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=114,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.54597701 0.41091954 0.57614943 0.69310345 0.6622807  0.64035088\n",
      " 0.38450292 0.44444444 0.50877193 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 85\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 86, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=86, random_state=100))])\n",
      "cv score: [0.50143678 0.44252874 0.45689655 0.55172414 0.6505848  0.47222222\n",
      " 0.27046784 0.57163743 0.40350877 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 86\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 74, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=74,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5545977  0.54885057 0.57471264 0.49827586 0.66374269 0.4619883\n",
      " 0.50292398 0.6754386  0.53947368 0.49122807]\n",
      "----------------------------------------\n",
      "Trial 87\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 73, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=6,\n",
      "                                            n_estimators=73, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.47701149 0.44252874 0.49568966 0.55517241 0.76754386 0.55555556\n",
      " 0.28508772 0.47660819 0.54385965 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 88\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 39, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=39,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54741379 0.55172414 0.50431034 0.63965517 0.63888889 0.53508772\n",
      " 0.38888889 0.52046784 0.53508772 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 89\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 77, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, max_features='sqrt',\n",
      "                                            n_estimators=77, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.57471264 0.38218391 0.53017241 0.66896552 0.65643275 0.62865497\n",
      " 0.34356725 0.46783626 0.43567251 0.40935673]\n",
      "----------------------------------------\n",
      "Trial 90\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 109, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=109, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.52298851 0.44252874 0.5704023  0.7        0.6125731  0.61111111\n",
      " 0.32017544 0.57017544 0.46491228 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 91\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 148, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            n_estimators=148, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.5        0.42816092 0.49568966 0.58275862 0.64181287 0.49122807\n",
      " 0.32309942 0.53508772 0.48538012 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 92\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 175, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=175, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.48850575 0.45402299 0.4454023  0.57068966 0.59356725 0.57017544\n",
      " 0.45760234 0.57602339 0.49415205 0.44736842]\n",
      "----------------------------------------\n",
      "Trial 93\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 93, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=93,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55890805 0.54885057 0.54597701 0.46724138 0.46491228 0.50730994\n",
      " 0.5497076  0.65789474 0.61842105 0.5248538 ]\n",
      "----------------------------------------\n",
      "Trial 94\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 124, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=124,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51005747 0.54022989 0.51724138 0.57413793 0.62719298 0.62134503\n",
      " 0.42690058 0.59649123 0.55116959 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 95\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 76, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            n_estimators=76, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.40517241 0.40517241 0.55890805 0.67068966 0.4751462  0.44444444\n",
      " 0.73245614 0.59064327 0.54678363 0.19152047]\n",
      "----------------------------------------\n",
      "Trial 96\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 81, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=81,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61781609 0.58333333 0.58045977 0.54137931 0.71345029 0.40204678\n",
      " 0.44152047 0.63157895 0.61695906 0.57894737]\n",
      "----------------------------------------\n",
      "Trial 97\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 76, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=76,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52442529 0.47557471 0.63936782 0.63275862 0.72222222 0.55701754\n",
      " 0.22660819 0.43274854 0.48245614 0.35818713]\n",
      "----------------------------------------\n",
      "Trial 98\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 84, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=84,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56609195 0.42385057 0.57471264 0.49482759 0.45614035 0.50438596\n",
      " 0.56140351 0.66374269 0.51461988 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 99\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35632184 0.39367816 0.62212644 0.63448276 0.50730994 0.66959064\n",
      " 0.51608187 0.4122807  0.41520468 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 100\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 150, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=150, random_state=100))])\n",
      "cv score: [0.47988506 0.43678161 0.51724138 0.52413793 0.56871345 0.54678363\n",
      " 0.44444444 0.54678363 0.49122807 0.45906433]\n",
      "----------------------------------------\n",
      "Trial 101\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 12, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=12, random_state=100))])\n",
      "cv score: [0.52729885 0.38218391 0.37356322 0.67586207 0.67690058 0.58918129\n",
      " 0.30994152 0.40350877 0.50877193 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 102\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 93, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=93, random_state=100))])\n",
      "cv score: [0.5316092  0.42241379 0.5387931  0.62758621 0.68128655 0.52046784\n",
      " 0.30263158 0.5994152  0.43274854 0.27631579]\n",
      "----------------------------------------\n",
      "Trial 103\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 97, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=97, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.54597701 0.4683908  0.47270115 0.56551724 0.65643275 0.51169591\n",
      " 0.2880117  0.51754386 0.42105263 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 104\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 193, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=193,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36206897 0.31896552 0.65373563 0.55517241 0.54239766 0.64912281\n",
      " 0.68274854 0.37426901 0.44005848 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 105\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.22126437 0.46551724 0.37931034 0.50517241 0.59502924 0.55409357\n",
      " 0.67397661 0.55409357 0.51315789 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 106\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=133,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.30316092 0.56752874 0.40373563 0.54310345 0.54532164 0.42690058\n",
      " 0.44152047 0.67690058 0.63450292 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 107\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 69, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=69, random_state=100))])\n",
      "cv score: [0.52298851 0.54022989 0.45689655 0.59827586 0.55555556 0.60233918\n",
      " 0.39619883 0.52339181 0.46052632 0.4122807 ]\n",
      "----------------------------------------\n",
      "Trial 108\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 18, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=18, random_state=100))])\n",
      "cv score: [0.49137931 0.49425287 0.46982759 0.59137931 0.65204678 0.52631579\n",
      " 0.43274854 0.64035088 0.50877193 0.4371345 ]\n",
      "----------------------------------------\n",
      "Trial 109\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 29, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=29,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5        0.49137931 0.49137931 0.48275862 0.48245614 0.43274854\n",
      " 0.5        0.5        0.48245614 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 110\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=68, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.5316092  0.47988506 0.51005747 0.68965517 0.63011696 0.60233918\n",
      " 0.36695906 0.50584795 0.50877193 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 111\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 176, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=176, random_state=100))])\n",
      "cv score: [0.49712644 0.42528736 0.52729885 0.61724138 0.6622807  0.48830409\n",
      " 0.28070175 0.55847953 0.38011696 0.2997076 ]\n",
      "----------------------------------------\n",
      "Trial 112\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 175, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=175, random_state=100))])\n",
      "cv score: [0.41666667 0.47701149 0.45258621 0.61724138 0.60672515 0.54385965\n",
      " 0.3494152  0.54093567 0.52046784 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 113\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.38218391 0.32471264 0.66522989 0.68965517 0.6125731  0.57309942\n",
      " 0.36988304 0.47953216 0.38011696 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 114\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 154, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=154, random_state=100))])\n",
      "cv score: [0.45977011 0.45977011 0.45977011 0.55       0.59064327 0.57602339\n",
      " 0.44590643 0.57894737 0.49707602 0.4502924 ]\n",
      "----------------------------------------\n",
      "Trial 115\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 50, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=50,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60201149 0.56321839 0.57471264 0.53103448 0.6871345  0.46783626\n",
      " 0.46491228 0.64035088 0.6374269  0.53362573]\n",
      "----------------------------------------\n",
      "Trial 116\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 148, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=148, random_state=100))])\n",
      "cv score: [0.41666667 0.41666667 0.44109195 0.63793103 0.71491228 0.50877193\n",
      " 0.31140351 0.51754386 0.47368421 0.27192982]\n",
      "----------------------------------------\n",
      "Trial 117\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=101, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.53448276 0.41954023 0.58189655 0.57931034 0.7002924  0.51169591\n",
      " 0.32602339 0.51461988 0.45614035 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 118\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 21, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=21, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.50862069 0.48563218 0.61925287 0.71034483 0.58333333 0.58187135\n",
      " 0.28216374 0.49707602 0.45906433 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 119\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 63, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            n_estimators=63, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.48994253 0.54022989 0.51293103 0.48965517 0.44005848 0.47953216\n",
      " 0.31871345 0.48538012 0.49415205 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 120\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 56, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=56, random_state=100))])\n",
      "cv score: [0.4137931  0.43103448 0.4295977  0.61034483 0.62134503 0.52339181\n",
      " 0.31432749 0.53216374 0.43859649 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 121\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 190, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=190,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40804598 0.39942529 0.60775862 0.53793103 0.59210526 0.5\n",
      " 0.41666667 0.52923977 0.3625731  0.24561404]\n",
      "----------------------------------------\n",
      "Trial 122\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 63, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=63,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53304598 0.47270115 0.48706897 0.68448276 0.59356725 0.60087719\n",
      " 0.33625731 0.51754386 0.50730994 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 123\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 142, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=142,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.30316092 0.56752874 0.40373563 0.54310345 0.54532164 0.42690058\n",
      " 0.44152047 0.67690058 0.63450292 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 124\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 181, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=181, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.52586207 0.49425287 0.55890805 0.57241379 0.66812865 0.54093567\n",
      " 0.36403509 0.56140351 0.40935673 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 125\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 153, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=153,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.44252874 0.36206897 0.625      0.55517241 0.61842105 0.50877193\n",
      " 0.32309942 0.51754386 0.25730994 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 126\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33045977 0.39655172 0.51005747 0.54482759 0.48684211 0.60526316\n",
      " 0.59795322 0.56140351 0.38888889 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 127\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 127, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=127, random_state=100))])\n",
      "cv score: [0.48563218 0.43678161 0.48706897 0.57241379 0.71491228 0.45614035\n",
      " 0.32163743 0.50877193 0.4619883  0.23391813]\n",
      "----------------------------------------\n",
      "Trial 128\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 79, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            n_estimators=79, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.40229885 0.40373563 0.35775862 0.53448276 0.64766082 0.5\n",
      " 0.36111111 0.44152047 0.50292398 0.24561404]\n",
      "----------------------------------------\n",
      "Trial 129\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 123, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=123,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.47988506 0.49712644 0.61350575 0.67586207 0.72660819 0.59649123\n",
      " 0.31140351 0.42982456 0.50877193 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 130\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 126, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=126, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.53735632 0.4137931  0.52155172 0.76206897 0.60672515 0.62865497\n",
      " 0.36988304 0.52923977 0.47368421 0.4005848 ]\n",
      "----------------------------------------\n",
      "Trial 131\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 117, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=117,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55747126 0.45977011 0.54597701 0.49655172 0.55847953 0.50877193\n",
      " 0.53654971 0.67251462 0.54824561 0.50146199]\n",
      "----------------------------------------\n",
      "Trial 132\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=108,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51005747 0.54310345 0.51724138 0.57413793 0.62719298 0.61842105\n",
      " 0.43274854 0.59649123 0.55409357 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 133\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 112, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=112,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3591954  0.35632184 0.60488506 0.60689655 0.54532164 0.60818713\n",
      " 0.46345029 0.46783626 0.4502924  0.34795322]\n",
      "----------------------------------------\n",
      "Trial 134\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 82, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=82,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.47844828 0.41666667 0.59770115 0.42413793 0.55409357 0.57309942\n",
      " 0.5497076  0.66374269 0.48538012 0.50730994]\n",
      "----------------------------------------\n",
      "Trial 135\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 106, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=106, random_state=100))])\n",
      "cv score: [0.4683908  0.50287356 0.50718391 0.64827586 0.51315789 0.58479532\n",
      " 0.37865497 0.56432749 0.4371345  0.36549708]\n",
      "----------------------------------------\n",
      "Trial 136\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 62, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=62,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45114943 0.43247126 0.59051724 0.48103448 0.61988304 0.55116959\n",
      " 0.54532164 0.56578947 0.5745614  0.44444444]\n",
      "----------------------------------------\n",
      "Trial 137\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 188, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=188, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.55172414 0.45977011 0.54741379 0.70344828 0.64181287 0.63157895\n",
      " 0.34649123 0.52631579 0.47660819 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 138\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 139, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=139, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.49425287 0.45402299 0.60775862 0.63793103 0.6505848  0.61695906\n",
      " 0.29678363 0.48245614 0.44736842 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 139\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 98, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=98,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5387931  0.55747126 0.50431034 0.63448276 0.63157895 0.60380117\n",
      " 0.39473684 0.59649123 0.55409357 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 140\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 11, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=11,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.54885057 0.49137931 0.46551724 0.48245614 0.43274854\n",
      " 0.45175439 0.58333333 0.47368421 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 141\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 143, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=143, random_state=100))])\n",
      "cv score: [0.44827586 0.51724138 0.47270115 0.60344828 0.60087719 0.59649123\n",
      " 0.39035088 0.58187135 0.45906433 0.41812865]\n",
      "----------------------------------------\n",
      "Trial 142\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 182, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            n_estimators=182, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.45402299 0.42816092 0.43821839 0.5862069  0.72953216 0.49122807\n",
      " 0.25292398 0.50292398 0.51461988 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 143\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=159,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58045977 0.48850575 0.65086207 0.62586207 0.74415205 0.57602339\n",
      " 0.23391813 0.44736842 0.48245614 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 144\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 148, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=148,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43965517 0.33045977 0.77155172 0.65517241 0.58333333 0.66374269\n",
      " 0.59502924 0.39766082 0.4619883  0.4005848 ]\n",
      "----------------------------------------\n",
      "Trial 145\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=115,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.59482759 0.52011494 0.56465517 0.43965517 0.65350877 0.43128655\n",
      " 0.40350877 0.47222222 0.36842105 0.46052632]\n",
      "----------------------------------------\n",
      "Trial 146\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 104, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=104, random_state=100))])\n",
      "cv score: [0.5545977  0.44252874 0.5387931  0.6862069  0.6125731  0.60526316\n",
      " 0.35526316 0.57894737 0.37719298 0.30847953]\n",
      "----------------------------------------\n",
      "Trial 147\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5        0.49137931 0.49137931 0.48275862 0.5        0.43274854\n",
      " 0.5        0.5        0.48245614 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 148\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=14,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51867816 0.49568966 0.54454023 0.67068966 0.64327485 0.60380117\n",
      " 0.33625731 0.46491228 0.50584795 0.36988304]\n",
      "----------------------------------------\n",
      "Trial 149\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            n_estimators=91, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.44252874 0.50287356 0.48994253 0.56206897 0.63304094 0.60526316\n",
      " 0.3874269  0.55263158 0.57017544 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 150\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 57, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=57,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42241379 0.4137931  0.66522989 0.55172414 0.53947368 0.52923977\n",
      " 0.39327485 0.52923977 0.39766082 0.24853801]\n",
      "----------------------------------------\n",
      "Trial 151\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 90, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=90,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40229885 0.38505747 0.51293103 0.4862069  0.62426901 0.45906433\n",
      " 0.3874269  0.59356725 0.24561404 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 152\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 83, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=83, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.54597701 0.44827586 0.60201149 0.63793103 0.68567251 0.63157895\n",
      " 0.33187135 0.45321637 0.45906433 0.4122807 ]\n",
      "----------------------------------------\n",
      "Trial 153\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 26, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            n_estimators=26,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.4612069  0.53304598 0.53591954 0.50517241 0.68421053 0.41081871\n",
      " 0.45321637 0.58187135 0.5994152  0.40497076]\n",
      "----------------------------------------\n",
      "Trial 154\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 97, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=97,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57471264 0.46695402 0.56896552 0.42931034 0.56725146 0.56578947\n",
      " 0.59649123 0.66081871 0.48684211 0.48538012]\n",
      "----------------------------------------\n",
      "Trial 155\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 183, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=183,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38505747 0.35344828 0.69396552 0.58965517 0.68567251 0.55263158\n",
      " 0.41959064 0.49415205 0.36842105 0.24853801]\n",
      "----------------------------------------\n",
      "Trial 156\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 91, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=91,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34482759 0.34195402 0.43247126 0.44482759 0.5497076  0.52777778\n",
      " 0.59795322 0.58333333 0.43128655 0.42251462]\n",
      "----------------------------------------\n",
      "Trial 157\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 65, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=65, random_state=100))])\n",
      "cv score: [0.49137931 0.44827586 0.53591954 0.64137931 0.52046784 0.59356725\n",
      " 0.36988304 0.54678363 0.46491228 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 158\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 68, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=68,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43678161 0.3591954  0.59482759 0.49827586 0.58918129 0.51023392\n",
      " 0.53216374 0.65643275 0.47660819 0.42251462]\n",
      "----------------------------------------\n",
      "Trial 159\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 128, 'gb__subsample': 0.95, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, max_features='sqrt',\n",
      "                                            n_estimators=128, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.49425287 0.42528736 0.46408046 0.71724138 0.67105263 0.64035088\n",
      " 0.35233918 0.4502924  0.50584795 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 160\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41666667 0.35632184 0.7658046  0.63103448 0.67690058 0.50584795\n",
      " 0.40789474 0.53216374 0.41520468 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 161\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 51, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=51, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.46695402 0.37068966 0.5158046  0.74482759 0.30994152 0.31725146\n",
      " 0.48391813 0.33333333 0.52631579 0.66666667]\n",
      "----------------------------------------\n",
      "Trial 162\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 12, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=12, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.54885057 0.43965517 0.50143678 0.64137931 0.64766082 0.58479532\n",
      " 0.24122807 0.42690058 0.47076023 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 163\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 77, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=77,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.37643678 0.36206897 0.62212644 0.69310345 0.63304094 0.65497076\n",
      " 0.48391813 0.49707602 0.3625731  0.23099415]\n",
      "----------------------------------------\n",
      "Trial 164\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 152, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=152,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57183908 0.54885057 0.57471264 0.51206897 0.48245614 0.4619883\n",
      " 0.46491228 0.64035088 0.46491228 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 165\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 57, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=57,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51149425 0.45114943 0.65086207 0.62586207 0.73099415 0.56578947\n",
      " 0.21637427 0.42690058 0.47222222 0.37573099]\n",
      "----------------------------------------\n",
      "Trial 166\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.31034483 0.45689655 0.48275862 0.55862069 0.60233918 0.59356725\n",
      " 0.51900585 0.5497076  0.49415205 0.41812865]\n",
      "----------------------------------------\n",
      "Trial 167\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 185, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=185, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.55172414 0.5        0.55028736 0.67931034 0.5628655  0.64035088\n",
      " 0.38450292 0.54678363 0.48830409 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 168\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 77, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=77,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55316092 0.52586207 0.5        0.68103448 0.61695906 0.62280702\n",
      " 0.39181287 0.54385965 0.48976608 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 169\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 91, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=91, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.58045977 0.47126437 0.56178161 0.64482759 0.65643275 0.54093567\n",
      " 0.25       0.61988304 0.43274854 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 170\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 132, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=132,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52729885 0.56321839 0.50143678 0.61724138 0.63450292 0.60672515\n",
      " 0.39473684 0.59649123 0.55701754 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 171\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 40, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=40, random_state=100))])\n",
      "cv score: [0.56609195 0.4683908  0.63936782 0.6862069  0.59356725 0.51169591\n",
      " 0.2997076  0.5994152  0.49415205 0.36403509]\n",
      "----------------------------------------\n",
      "Trial 172\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 162, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=162,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5        0.45689655 0.5316092  0.48793103 0.64327485 0.50730994\n",
      " 0.47807018 0.65789474 0.60964912 0.50292398]\n",
      "----------------------------------------\n",
      "Trial 173\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=14, random_state=100))])\n",
      "cv score: [0.52155172 0.59626437 0.44109195 0.51724138 0.5        0.63450292\n",
      " 0.51169591 0.5745614  0.50730994 0.39035088]\n",
      "----------------------------------------\n",
      "Trial 174\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 194, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=194, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43390805 0.39942529 0.50718391 0.64482759 0.67690058 0.5\n",
      " 0.26461988 0.47076023 0.43859649 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 175\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 85, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=85,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40517241 0.39367816 0.60201149 0.6        0.59502924 0.4122807\n",
      " 0.32309942 0.59064327 0.30409357 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 176\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 72, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=72,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.36494253 0.64798851 0.65862069 0.66520468 0.55263158\n",
      " 0.37280702 0.48830409 0.48245614 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 177\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58908046 0.54885057 0.57471264 0.51724138 0.66374269 0.4619883\n",
      " 0.46491228 0.62719298 0.62280702 0.52339181]\n",
      "----------------------------------------\n",
      "Trial 178\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 190, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=190,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42241379 0.37643678 0.61063218 0.65517241 0.67397661 0.61111111\n",
      " 0.55116959 0.54678363 0.38011696 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 179\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=168, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.52011494 0.46264368 0.53591954 0.65172414 0.62134503 0.58187135\n",
      " 0.35818713 0.48245614 0.50877193 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 180\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 144, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=144,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.38505747 0.56465517 0.55517241 0.53070175 0.52046784\n",
      " 0.43128655 0.50292398 0.33040936 0.29532164]\n",
      "----------------------------------------\n",
      "Trial 181\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 118, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=118, random_state=100))])\n",
      "cv score: [0.51436782 0.44827586 0.59626437 0.70689655 0.61549708 0.56725146\n",
      " 0.30847953 0.55555556 0.42397661 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 182\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 28, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=28,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56609195 0.54885057 0.57471264 0.50172414 0.66374269 0.4619883\n",
      " 0.46491228 0.64035088 0.53947368 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 183\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 149, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=149, random_state=100))])\n",
      "cv score: [0.47701149 0.44109195 0.50287356 0.61034483 0.67397661 0.46345029\n",
      " 0.31140351 0.61403509 0.36695906 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 184\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 10, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=10, random_state=100))])\n",
      "cv score: [0.56034483 0.47701149 0.54454023 0.61896552 0.57748538 0.5380117\n",
      " 0.37426901 0.43274854 0.53362573 0.39912281]\n",
      "----------------------------------------\n",
      "Trial 185\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 128, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=128,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41091954 0.37643678 0.69396552 0.61034483 0.6505848  0.46783626\n",
      " 0.39912281 0.52339181 0.29824561 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 186\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.34770115 0.72270115 0.61034483 0.6505848  0.47076023\n",
      " 0.38157895 0.48538012 0.3245614  0.21637427]\n",
      "----------------------------------------\n",
      "Trial 187\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57183908 0.54885057 0.57471264 0.51206897 0.66374269 0.4619883\n",
      " 0.46491228 0.64035088 0.46491228 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 188\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 40, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=40,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.47701149 0.46551724 0.52155172 0.64482759 0.7119883  0.6374269\n",
      " 0.32602339 0.46491228 0.50292398 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 189\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=159, random_state=100))])\n",
      "cv score: [0.46264368 0.52586207 0.46695402 0.61034483 0.59502924 0.59356725\n",
      " 0.41374269 0.58187135 0.45906433 0.40350877]\n",
      "----------------------------------------\n",
      "Trial 190\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 10, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=10,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53017241 0.49425287 0.48994253 0.66034483 0.66666667 0.61842105\n",
      " 0.3128655  0.44736842 0.51461988 0.35233918]\n",
      "----------------------------------------\n",
      "Trial 191\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 144, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=144,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.34195402 0.37931034 0.67097701 0.63448276 0.64181287 0.51754386\n",
      " 0.32894737 0.49707602 0.38596491 0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 192\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 71, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=71, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.52873563 0.46264368 0.51005747 0.67758621 0.62134503 0.63450292\n",
      " 0.36111111 0.53947368 0.49269006 0.28947368]\n",
      "----------------------------------------\n",
      "Trial 193\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 117, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=117,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52586207 0.37931034 0.55172414 0.46034483 0.41520468 0.62426901\n",
      " 0.60672515 0.65789474 0.54239766 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 194\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 135, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=135,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35057471 0.36781609 0.63074713 0.63448276 0.60964912 0.49122807\n",
      " 0.40789474 0.48245614 0.33040936 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 195\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 86, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=86,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4683908  0.3045977  0.61063218 0.64655172 0.55116959 0.66374269\n",
      " 0.53070175 0.39181287 0.46491228 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 196\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 101, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=101,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.29885057 0.71695402 0.60344828 0.52777778 0.61111111\n",
      " 0.59795322 0.37134503 0.47953216 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 197\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 110, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features=None,\n",
      "                                        n_estimators=110, random_state=100))])\n",
      "cv score: [0.40517241 0.40804598 0.45258621 0.62413793 0.75877193 0.48830409\n",
      " 0.29385965 0.52046784 0.45321637 0.26608187]\n",
      "----------------------------------------\n",
      "Trial 198\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 107, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=107,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48132184 0.41522989 0.56321839 0.45344828 0.4502924  0.59502924\n",
      " 0.60233918 0.6754386  0.47076023 0.4751462 ]\n",
      "----------------------------------------\n",
      "Trial 199\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 13, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=13, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.50862069 0.45402299 0.64798851 0.71034483 0.70175439 0.54678363\n",
      " 0.25292398 0.52923977 0.48830409 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 200\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 138, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=138,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.5933908  0.47988506 0.66522989 0.59827586 0.73976608 0.58918129\n",
      " 0.25       0.4619883  0.4619883  0.38011696]\n",
      "----------------------------------------\n",
      "Trial 201\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 135, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=135, random_state=100))])\n",
      "cv score: [0.47413793 0.50574713 0.50431034 0.65862069 0.54239766 0.59356725\n",
      " 0.39327485 0.58187135 0.46491228 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 202\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 15, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=15, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.54022989 0.35344828 0.24281609 0.41724138 0.4005848  0.42251462\n",
      " 0.54824561 0.32748538 0.21637427 0.57894737]\n",
      "----------------------------------------\n",
      "Trial 203\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 182, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=182, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.60344828 0.49425287 0.51293103 0.53793103 0.58918129 0.26023392\n",
      " 0.37280702 0.38011696 0.49415205 0.57894737]\n",
      "----------------------------------------\n",
      "Trial 204\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 88, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            n_estimators=88, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.45689655 0.48275862 0.55316092 0.57241379 0.70321637 0.5\n",
      " 0.29093567 0.50292398 0.47076023 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 205\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 33, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=33,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.47413793 0.42528736 0.54454023 0.63793103 0.5745614  0.66081871\n",
      " 0.36111111 0.4619883  0.48538012 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 206\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 122, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=122, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.53448276 0.4683908  0.49856322 0.7137931  0.65350877 0.57894737\n",
      " 0.34356725 0.48245614 0.47953216 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 207\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 172, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=172, random_state=100))])\n",
      "cv score: [0.49712644 0.42528736 0.53017241 0.61034483 0.6622807  0.48245614\n",
      " 0.28070175 0.56432749 0.37719298 0.2997076 ]\n",
      "----------------------------------------\n",
      "Trial 208\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=121, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.46551724 0.53448276 0.56465517 0.74482759 0.70467836 0.45760234\n",
      " 0.43859649 0.6374269  0.52923977 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 209\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 132, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=132, random_state=100))])\n",
      "cv score: [0.48275862 0.44252874 0.48994253 0.57241379 0.72076023 0.4502924\n",
      " 0.3245614  0.50877193 0.45906433 0.23684211]\n",
      "----------------------------------------\n",
      "Trial 210\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 75, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=75,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.59482759 0.52011494 0.56465517 0.43965517 0.65350877 0.43128655\n",
      " 0.40350877 0.46345029 0.36842105 0.46052632]\n",
      "----------------------------------------\n",
      "Trial 211\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 75, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=75, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.49137931 0.47413793 0.57327586 0.62068966 0.6622807  0.59064327\n",
      " 0.29093567 0.51461988 0.42690058 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 212\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=58, random_state=100))])\n",
      "cv score: [0.36206897 0.40517241 0.51005747 0.62068966 0.73538012 0.48538012\n",
      " 0.25584795 0.58187135 0.37426901 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 213\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 120, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=120, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.49137931 0.4137931  0.55603448 0.60689655 0.64473684 0.57309942\n",
      " 0.33187135 0.53508772 0.44444444 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 214\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 64, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=64,\n",
      "                                            random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.52873563 0.31609195 0.65086207 0.69310345 0.62719298 0.59649123\n",
      " 0.2997076  0.53216374 0.4122807  0.37134503]\n",
      "----------------------------------------\n",
      "Trial 215\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 122, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=122, random_state=100))])\n",
      "cv score: [0.47701149 0.45977011 0.50574713 0.60689655 0.67105263 0.47368421\n",
      " 0.31432749 0.5994152  0.37280702 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 216\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 15, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=15, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.60057471 0.41666667 0.50431034 0.7        0.61403509 0.61111111\n",
      " 0.27339181 0.38888889 0.47076023 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 217\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 16, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=16,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.31896552 0.50718391 0.54310345 0.54310345 0.47222222 0.61549708\n",
      " 0.52631579 0.65935673 0.36842105 0.44152047]\n",
      "----------------------------------------\n",
      "Trial 218\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 18, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=18,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57614943 0.50718391 0.54597701 0.42413793 0.43274854 0.45614035\n",
      " 0.56432749 0.60087719 0.52192982 0.52192982]\n",
      "----------------------------------------\n",
      "Trial 219\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 61, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=61,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.37643678 0.53591954 0.4841954  0.55172414 0.63450292 0.55555556\n",
      " 0.47660819 0.67105263 0.57017544 0.52339181]\n",
      "----------------------------------------\n",
      "Trial 220\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=14,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55747126 0.45689655 0.53591954 0.28793103 0.59502924 0.49853801\n",
      " 0.34356725 0.39912281 0.42982456 0.39035088]\n",
      "----------------------------------------\n",
      "Trial 221\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3908046  0.42241379 0.49856322 0.49655172 0.51023392 0.49122807\n",
      " 0.4371345  0.58187135 0.35087719 0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 222\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 48, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=48, random_state=100))])\n",
      "cv score: [0.58908046 0.50862069 0.5933908  0.63448276 0.58187135 0.52339181\n",
      " 0.37280702 0.51169591 0.42397661 0.40497076]\n",
      "----------------------------------------\n",
      "Trial 223\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 164, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            n_estimators=164,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.65517241 0.52442529 0.48706897 0.5862069  0.69298246 0.40935673\n",
      " 0.38304094 0.30701754 0.42690058 0.51900585]\n",
      "----------------------------------------\n",
      "Trial 224\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.36781609 0.36494253 0.71982759 0.64827586 0.6622807  0.47953216\n",
      " 0.35526316 0.51461988 0.30409357 0.25146199]\n",
      "----------------------------------------\n",
      "Trial 225\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 16, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=16,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.49137931 0.49137931 0.43965517 0.45614035 0.54824561\n",
      " 0.56432749 0.67251462 0.47368421 0.43859649]\n",
      "----------------------------------------\n",
      "Trial 226\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 92, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            n_estimators=92, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.45977011 0.46551724 0.4612069  0.59310345 0.71491228 0.51461988\n",
      " 0.31432749 0.47660819 0.46491228 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 227\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 33, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=33, random_state=100))])\n",
      "cv score: [0.60632184 0.55172414 0.48994253 0.59655172 0.59649123 0.61403509\n",
      " 0.38450292 0.60233918 0.49561404 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 228\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39367816 0.4454023  0.60201149 0.52413793 0.58918129 0.4502924\n",
      " 0.35233918 0.58187135 0.39181287 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 229\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 133, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=133, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.50574713 0.47126437 0.54454023 0.69310345 0.69444444 0.66081871\n",
      " 0.34064327 0.4619883  0.47953216 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 230\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 145, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=145,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5        0.48275862 0.49137931 0.52068966 0.48245614 0.43274854\n",
      " 0.46491228 0.5        0.47368421 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 231\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 54, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=54, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.56609195 0.5316092  0.46408046 0.58275862 0.58187135 0.57748538\n",
      " 0.38596491 0.62280702 0.54093567 0.4502924 ]\n",
      "----------------------------------------\n",
      "Trial 232\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 92, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=92, random_state=100))])\n",
      "cv score: [0.52586207 0.44252874 0.52011494 0.59655172 0.69736842 0.48245614\n",
      " 0.30847953 0.60526316 0.40204678 0.26608187]\n",
      "----------------------------------------\n",
      "Trial 233\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 17, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=17, random_state=100))])\n",
      "cv score: [0.53448276 0.47988506 0.56321839 0.60862069 0.6871345  0.60087719\n",
      " 0.3494152  0.49853801 0.4751462  0.38888889]\n",
      "----------------------------------------\n",
      "Trial 234\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 34, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=34,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.33045977 0.31321839 0.60775862 0.63448276 0.63888889 0.57309942\n",
      " 0.40204678 0.61403509 0.47368421 0.39181287]\n",
      "----------------------------------------\n",
      "Trial 235\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 45, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=45, random_state=100))])\n",
      "cv score: [0.53448276 0.45402299 0.5933908  0.6637931  0.50438596 0.56140351\n",
      " 0.39619883 0.57894737 0.46491228 0.35526316]\n",
      "----------------------------------------\n",
      "Trial 236\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 36, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=36,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44971264 0.38649425 0.53735632 0.53275862 0.58187135 0.58333333\n",
      " 0.5994152  0.61695906 0.5745614  0.5380117 ]\n",
      "----------------------------------------\n",
      "Trial 237\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 96, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=96, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.36063218 0.65517241 0.45545977 0.52931034 0.32894737 0.73830409\n",
      " 0.6374269  0.39035088 0.52923977 0.45906433]\n",
      "----------------------------------------\n",
      "Trial 238\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 71, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=71, random_state=100))])\n",
      "cv score: [0.50862069 0.4454023  0.5387931  0.6137931  0.67982456 0.52339181\n",
      " 0.31871345 0.57163743 0.39181287 0.28508772]\n",
      "----------------------------------------\n",
      "Trial 239\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 198, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            n_estimators=198, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.43965517 0.48850575 0.44971264 0.61034483 0.72076023 0.51754386\n",
      " 0.23830409 0.51169591 0.53216374 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 240\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 30, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            n_estimators=30, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.42816092 0.42241379 0.52729885 0.61034483 0.73538012 0.57017544\n",
      " 0.30555556 0.49707602 0.52631579 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 241\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=197,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52873563 0.56321839 0.50431034 0.6        0.63450292 0.59795322\n",
      " 0.38596491 0.59356725 0.54824561 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 242\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 103, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=103, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.61206897 0.30172414 0.44396552 0.55172414 0.5745614  0.60526316\n",
      " 0.43128655 0.45321637 0.38888889 0.49415205]\n",
      "----------------------------------------\n",
      "Trial 243\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 173, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=173, random_state=100))])\n",
      "cv score: [0.48563218 0.52011494 0.4612069  0.61724138 0.6125731  0.60233918\n",
      " 0.41374269 0.57894737 0.46783626 0.41812865]\n",
      "----------------------------------------\n",
      "Trial 244\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 198, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=7,\n",
      "                                            n_estimators=198, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.45402299 0.40517241 0.52155172 0.56206897 0.74122807 0.49707602\n",
      " 0.27631579 0.47076023 0.56140351 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 245\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 124, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=124,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3045977  0.34195402 0.49281609 0.6        0.45760234 0.60818713\n",
      " 0.62719298 0.40350877 0.44590643 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 246\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 106, 'gb__subsample': 0.7, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=106, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.46264368 0.5862069  0.53591954 0.5862069  0.59356725 0.46491228\n",
      " 0.41374269 0.39766082 0.57309942 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 247\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 129, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=129, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.49425287 0.43965517 0.58477011 0.68275862 0.67690058 0.57894737\n",
      " 0.31432749 0.49707602 0.46491228 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 248\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 27, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=27,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.45114943 0.5158046  0.32931034 0.53362573 0.46345029\n",
      " 0.38157895 0.32748538 0.48391813 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 249\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 57, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=57,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36206897 0.36206897 0.54454023 0.62758621 0.57163743 0.65789474\n",
      " 0.40204678 0.50584795 0.41812865 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 250\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 194, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=194,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.63793103 0.4137931  0.5158046  0.70689655 0.58625731 0.56432749\n",
      " 0.46637427 0.4502924  0.51754386 0.43859649]\n",
      "----------------------------------------\n",
      "Trial 251\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 35, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=35,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5704023  0.56034483 0.57471264 0.51551724 0.6871345  0.4619883\n",
      " 0.50292398 0.64035088 0.57309942 0.53362573]\n",
      "----------------------------------------\n",
      "Trial 252\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5        0.48275862 0.49137931 0.52068966 0.48245614 0.43274854\n",
      " 0.46491228 0.5        0.47368421 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 253\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 84, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=84, random_state=100))])\n",
      "cv score: [0.5316092  0.42528736 0.55028736 0.62413793 0.6754386  0.52923977\n",
      " 0.31725146 0.59064327 0.42397661 0.28216374]\n",
      "----------------------------------------\n",
      "Trial 254\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 155, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=155, random_state=100))])\n",
      "cv score: [0.48850575 0.50287356 0.50431034 0.63793103 0.53362573 0.60526316\n",
      " 0.41666667 0.57894737 0.45906433 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 255\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 109, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=109,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.38793103 0.33908046 0.68247126 0.64137931 0.65935673 0.51461988\n",
      " 0.39619883 0.47953216 0.33333333 0.28362573]\n",
      "----------------------------------------\n",
      "Trial 256\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 106, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=106,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.4137931  0.61350575 0.67931034 0.73245614 0.5994152\n",
      " 0.31578947 0.45906433 0.48684211 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 257\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 32, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=32, random_state=100))])\n",
      "cv score: [0.52873563 0.45114943 0.55747126 0.54655172 0.55847953 0.47807018\n",
      " 0.46929825 0.5745614  0.46637427 0.55116959]\n",
      "----------------------------------------\n",
      "Trial 258\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 118, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=118,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40229885 0.40804598 0.53304598 0.67241379 0.71783626 0.54678363\n",
      " 0.42836257 0.54093567 0.36549708 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 259\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 63, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=63,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.60632184 0.5        0.32068966 0.59064327 0.41374269\n",
      " 0.37719298 0.29532164 0.55116959 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 260\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.30747126 0.38793103 0.52155172 0.64137931 0.57163743 0.63450292\n",
      " 0.53654971 0.46783626 0.39473684 0.39181287]\n",
      "----------------------------------------\n",
      "Trial 261\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 75, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=75, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.50862069 0.41666667 0.48994253 0.66551724 0.66812865 0.62865497\n",
      " 0.32602339 0.51169591 0.44444444 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 262\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 161, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=161, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.48275862 0.53735632 0.44971264 0.62068966 0.5994152  0.55555556\n",
      " 0.37573099 0.61988304 0.52777778 0.48538012]\n",
      "----------------------------------------\n",
      "Trial 263\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 113, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=113, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.52873563 0.42241379 0.63649425 0.65862069 0.73538012 0.5994152\n",
      " 0.27923977 0.49122807 0.41520468 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 264\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35632184 0.40229885 0.59626437 0.59655172 0.53947368 0.52046784\n",
      " 0.50730994 0.46491228 0.29824561 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 265\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 175, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=175,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.30316092 0.56752874 0.40373563 0.54310345 0.54532164 0.42690058\n",
      " 0.44152047 0.67690058 0.63450292 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 266\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 92, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=92, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.37787356 0.60057471 0.46695402 0.68103448 0.58918129 0.59502924\n",
      " 0.3377193  0.63450292 0.48245614 0.56140351]\n",
      "----------------------------------------\n",
      "Trial 267\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 44, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=44,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.53017241 0.55747126 0.56034483 0.66959064 0.43859649\n",
      " 0.37280702 0.61549708 0.61988304 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 268\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 11, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=11,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.59482759 0.52011494 0.56465517 0.43965517 0.65350877 0.43128655\n",
      " 0.40350877 0.47222222 0.36842105 0.46052632]\n",
      "----------------------------------------\n",
      "Trial 269\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 165, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=165,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52586207 0.5387931  0.50431034 0.55517241 0.63450292 0.56432749\n",
      " 0.47368421 0.67105263 0.59064327 0.52046784]\n",
      "----------------------------------------\n",
      "Trial 270\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 42, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=42, random_state=100))])\n",
      "cv score: [0.60344828 0.43965517 0.58477011 0.65862069 0.60380117 0.57894737\n",
      " 0.36111111 0.57309942 0.4005848  0.31871345]\n",
      "----------------------------------------\n",
      "Trial 271\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 162, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=162,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57758621 0.48850575 0.65086207 0.62586207 0.74415205 0.57602339\n",
      " 0.23684211 0.44736842 0.48245614 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 272\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 74, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=74,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34482759 0.40948276 0.47988506 0.61551724 0.61842105 0.51169591\n",
      " 0.4751462  0.48245614 0.46637427 0.41812865]\n",
      "----------------------------------------\n",
      "Trial 273\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 83, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            n_estimators=83, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.42241379 0.48275862 0.52442529 0.58965517 0.65643275 0.44736842\n",
      " 0.36403509 0.29532164 0.52923977 0.50292398]\n",
      "----------------------------------------\n",
      "Trial 274\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 173, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=173, random_state=100))])\n",
      "cv score: [0.4683908  0.43678161 0.56752874 0.63793103 0.54824561 0.61403509\n",
      " 0.37865497 0.53216374 0.45614035 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 275\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 94, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            n_estimators=94, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.48275862 0.45689655 0.57902299 0.51724138 0.73245614 0.45321637\n",
      " 0.30555556 0.56725146 0.42397661 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 276\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=183, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.48563218 0.41091954 0.47270115 0.6862069  0.65350877 0.61403509\n",
      " 0.3494152  0.5        0.47953216 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 277\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 105, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=105,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.40229885 0.32183908 0.63649425 0.63793103 0.60672515 0.56140351\n",
      " 0.40497076 0.52339181 0.30701754 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 278\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 100, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56609195 0.54885057 0.57471264 0.48965517 0.48245614 0.43274854\n",
      " 0.5497076  0.63157895 0.57309942 0.49707602]\n",
      "----------------------------------------\n",
      "Trial 279\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 151, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=151,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42528736 0.40804598 0.65086207 0.58275862 0.68274854 0.48538012\n",
      " 0.29385965 0.55847953 0.39766082 0.26900585]\n",
      "----------------------------------------\n",
      "Trial 280\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 161, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=161, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.4295977  0.45402299 0.43390805 0.20862069 0.30994152 0.41666667\n",
      " 0.36111111 0.35672515 0.24561404 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 281\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 150, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=150,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3908046  0.32471264 0.65373563 0.62068966 0.60087719 0.48245614\n",
      " 0.45760234 0.46783626 0.33625731 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 282\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 154, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=154,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5545977  0.5316092  0.51005747 0.6637931  0.62280702 0.59795322\n",
      " 0.39473684 0.55555556 0.50730994 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 283\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 15, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=15,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61063218 0.51436782 0.58908046 0.66551724 0.74561404 0.49122807\n",
      " 0.24122807 0.45906433 0.47076023 0.47660819]\n",
      "----------------------------------------\n",
      "Trial 284\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=14,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61781609 0.58333333 0.58045977 0.54137931 0.71345029 0.40204678\n",
      " 0.44152047 0.63157895 0.61695906 0.57894737]\n",
      "----------------------------------------\n",
      "Trial 285\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 41, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=41,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56609195 0.56034483 0.57471264 0.51551724 0.48245614 0.43274854\n",
      " 0.46491228 0.64035088 0.57309942 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 286\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 99, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=99,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.54166667 0.46551724 0.57183908 0.68448276 0.63596491 0.60526316\n",
      " 0.34795322 0.5        0.51461988 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 287\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 45, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=45,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.47701149 0.38362069 0.39310345 0.60380117 0.33918129\n",
      " 0.40350877 0.57017544 0.62573099 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 288\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 104, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=104, random_state=100))])\n",
      "cv score: [0.53735632 0.43965517 0.5704023  0.65172414 0.6871345  0.52631579\n",
      " 0.30263158 0.58479532 0.41812865 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 289\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52298851 0.41522989 0.54597701 0.47586207 0.61403509 0.53362573\n",
      " 0.54239766 0.66374269 0.52923977 0.47953216]\n",
      "----------------------------------------\n",
      "Trial 290\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=70,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54166667 0.48275862 0.55747126 0.62068966 0.71783626 0.58625731\n",
      " 0.23538012 0.46783626 0.48684211 0.43567251]\n",
      "----------------------------------------\n",
      "Trial 291\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 196, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=196,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55028736 0.46551724 0.54597701 0.4862069  0.6871345  0.45614035\n",
      " 0.50292398 0.66959064 0.53947368 0.52046784]\n",
      "----------------------------------------\n",
      "Trial 292\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 121, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=121,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.30316092 0.56752874 0.40373563 0.54310345 0.54532164 0.42690058\n",
      " 0.44152047 0.67690058 0.63450292 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 293\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 98, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=98,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.32758621 0.35057471 0.54454023 0.61034483 0.56578947 0.62865497\n",
      " 0.3874269  0.50877193 0.41520468 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 294\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 164, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=164,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.47701149 0.38362069 0.39310345 0.60380117 0.33918129\n",
      " 0.40350877 0.57017544 0.62573099 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 295\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 34, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=34,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.42241379 0.34482759 0.61350575 0.59655172 0.67105263 0.36549708\n",
      " 0.32309942 0.50877193 0.29824561 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 296\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=81, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.5        0.40804598 0.51867816 0.66896552 0.65350877 0.60526316\n",
      " 0.32602339 0.45906433 0.47076023 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 297\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 68, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=68, random_state=100))])\n",
      "cv score: [0.53591954 0.46264368 0.57758621 0.58275862 0.68567251 0.5\n",
      " 0.32163743 0.55847953 0.39912281 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 298\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 62, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=62, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.54022989 0.43390805 0.64224138 0.64137931 0.65935673 0.5877193\n",
      " 0.36111111 0.43567251 0.4502924  0.34210526]\n",
      "----------------------------------------\n",
      "Trial 299\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 123, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=123, random_state=100))])\n",
      "cv score: [0.47413793 0.51149425 0.51005747 0.66551724 0.53070175 0.59356725\n",
      " 0.3874269  0.57894737 0.44590643 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 300\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 11, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=11,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3591954  0.47413793 0.54310345 0.52413793 0.34064327 0.46929825\n",
      " 0.4502924  0.56871345 0.37719298 0.52777778]\n",
      "----------------------------------------\n",
      "Trial 301\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 158, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=158, random_state=100))])\n",
      "cv score: [0.48275862 0.44252874 0.51867816 0.6        0.66812865 0.4619883\n",
      " 0.31871345 0.60818713 0.35526316 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 302\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 10, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=10,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50862069 0.49712644 0.54022989 0.65517241 0.69736842 0.56725146\n",
      " 0.27046784 0.43567251 0.55701754 0.39181287]\n",
      "----------------------------------------\n",
      "Trial 303\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=16,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55747126 0.50143678 0.70689655 0.62241379 0.74122807 0.5745614\n",
      " 0.27339181 0.49707602 0.39327485 0.35526316]\n",
      "----------------------------------------\n",
      "Trial 304\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 26, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=26, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.52586207 0.48850575 0.52873563 0.65517241 0.66520468 0.58040936\n",
      " 0.32017544 0.56432749 0.48391813 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 305\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 164, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=164,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57758621 0.48850575 0.65373563 0.62931034 0.74122807 0.57602339\n",
      " 0.23391813 0.44736842 0.48538012 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 306\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 47, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=47,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57327586 0.56609195 0.57471264 0.50517241 0.48245614 0.43274854\n",
      " 0.46491228 0.63157895 0.46491228 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 307\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, n_estimators=74,\n",
      "                                            random_state=100, subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.58045977 0.4454023  0.29166667 0.71034483 0.60380117 0.5994152\n",
      " 0.45467836 0.50292398 0.60964912 0.49415205]\n",
      "----------------------------------------\n",
      "Trial 308\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 193, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=193,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34770115 0.34770115 0.57614943 0.69310345 0.6505848  0.64035088\n",
      " 0.48684211 0.42690058 0.51754386 0.4122807 ]\n",
      "----------------------------------------\n",
      "Trial 309\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 34, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=34,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.50287356 0.47701149 0.49856322 0.65517241 0.58333333 0.62280702\n",
      " 0.31725146 0.51169591 0.48245614 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 310\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 164, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=164, random_state=100))])\n",
      "cv score: [0.42816092 0.45689655 0.46982759 0.62413793 0.70906433 0.46783626\n",
      " 0.29093567 0.52046784 0.41520468 0.24853801]\n",
      "----------------------------------------\n",
      "Trial 311\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 61, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=61, random_state=100))])\n",
      "cv score: [0.47701149 0.37068966 0.52155172 0.5862069  0.70321637 0.50877193\n",
      " 0.24707602 0.54678363 0.41812865 0.24561404]\n",
      "----------------------------------------\n",
      "Trial 312\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 53, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=53,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51149425 0.54885057 0.54597701 0.51551724 0.6871345  0.50877193\n",
      " 0.49269006 0.66081871 0.61403509 0.52777778]\n",
      "----------------------------------------\n",
      "Trial 313\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.4137931  0.75       0.42097701 0.72241379 0.58918129 0.58479532\n",
      " 0.47807018 0.5380117  0.62865497 0.41374269]\n",
      "----------------------------------------\n",
      "Trial 314\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40517241 0.41091954 0.63074713 0.56206897 0.60964912 0.48830409\n",
      " 0.43128655 0.52339181 0.35672515 0.23976608]\n",
      "----------------------------------------\n",
      "Trial 315\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 153, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=153, random_state=100))])\n",
      "cv score: [0.5        0.43390805 0.5387931  0.6137931  0.6622807  0.47807018\n",
      " 0.27777778 0.57017544 0.37719298 0.2880117 ]\n",
      "----------------------------------------\n",
      "Trial 316\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 37, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=37,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56752874 0.48275862 0.49137931 0.47413793 0.48245614 0.43274854\n",
      " 0.46491228 0.63157895 0.47368421 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 317\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 97, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=97, random_state=100))])\n",
      "cv score: [0.5862069  0.45689655 0.55603448 0.66896552 0.57894737 0.54093567\n",
      " 0.36695906 0.56725146 0.42105263 0.37865497]\n",
      "----------------------------------------\n",
      "Trial 318\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 87, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=87,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37931034 0.39942529 0.71408046 0.65172414 0.67397661 0.56725146\n",
      " 0.51900585 0.52046784 0.4619883  0.26900585]\n",
      "----------------------------------------\n",
      "Trial 319\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 133, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=133,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.37068966 0.68247126 0.62413793 0.6125731  0.50877193\n",
      " 0.39327485 0.50877193 0.33333333 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 320\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 126, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            n_estimators=126, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.42241379 0.44252874 0.4841954  0.62068966 0.63888889 0.63157895\n",
      " 0.34649123 0.47368421 0.55555556 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 321\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 94, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=94,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58908046 0.51293103 0.59626437 0.42068966 0.64766082 0.39181287\n",
      " 0.35087719 0.44590643 0.33333333 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 322\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 61, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=61,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55747126 0.45689655 0.53591954 0.28793103 0.59502924 0.49853801\n",
      " 0.34356725 0.39912281 0.42982456 0.39035088]\n",
      "----------------------------------------\n",
      "Trial 323\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 134, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=134,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5387931  0.4683908  0.49712644 0.66896552 0.61111111 0.58333333\n",
      " 0.35672515 0.52923977 0.51461988 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 324\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 158, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=158,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58908046 0.51293103 0.59626437 0.42068966 0.64766082 0.39181287\n",
      " 0.35087719 0.44590643 0.33333333 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 325\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 198, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=198,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37931034 0.36781609 0.63362069 0.56551724 0.7002924  0.51169591\n",
      " 0.33187135 0.46491228 0.40350877 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 326\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 164, 'gb__subsample': 0.85, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, max_features='sqrt',\n",
      "                                            n_estimators=164, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.55172414 0.40804598 0.59051724 0.52413793 0.67397661 0.51461988\n",
      " 0.36695906 0.5380117  0.44444444 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 327\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 111, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=111,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.52873563 0.40086207 0.54597701 0.46551724 0.55847953 0.50877193\n",
      " 0.51461988 0.67251462 0.58625731 0.49707602]\n",
      "----------------------------------------\n",
      "Trial 328\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 189, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=189,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3045977  0.29310345 0.48994253 0.54137931 0.44005848 0.61988304\n",
      " 0.68567251 0.4005848  0.39473684 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 329\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 100, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.43103448 0.40517241 0.43534483 0.61034483 0.6622807  0.50877193\n",
      " 0.3494152  0.52339181 0.45321637 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 330\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 50, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=50,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40229885 0.43103448 0.6795977  0.65517241 0.62719298 0.52923977\n",
      " 0.41959064 0.5        0.44152047 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 331\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 17, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=17, random_state=100))])\n",
      "cv score: [0.45258621 0.4295977  0.57758621 0.60344828 0.58479532 0.43274854\n",
      " 0.25438596 0.51900585 0.46783626 0.26608187]\n",
      "----------------------------------------\n",
      "Trial 332\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 118, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=118, random_state=100))])\n",
      "cv score: [0.58045977 0.4454023  0.55603448 0.66206897 0.58625731 0.56140351\n",
      " 0.35818713 0.54678363 0.42982456 0.36988304]\n",
      "----------------------------------------\n",
      "Trial 333\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 189, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=189,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51149425 0.47413793 0.61637931 0.60689655 0.75584795 0.56725146\n",
      " 0.20614035 0.49269006 0.49122807 0.40350877]\n",
      "----------------------------------------\n",
      "Trial 334\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 174, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=174, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.54310345 0.42241379 0.52155172 0.56896552 0.60087719 0.43274854\n",
      " 0.34649123 0.37719298 0.39181287 0.44152047]\n",
      "----------------------------------------\n",
      "Trial 335\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 165, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=165, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.33477011 0.60632184 0.38074713 0.71034483 0.75       0.52339181\n",
      " 0.55994152 0.47222222 0.60380117 0.52923977]\n",
      "----------------------------------------\n",
      "Trial 336\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.23850575 0.34195402 0.41235632 0.58275862 0.48391813 0.56871345\n",
      " 0.59795322 0.49707602 0.48099415 0.39181287]\n",
      "----------------------------------------\n",
      "Trial 337\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 70, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=70,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43247126 0.40373563 0.52873563 0.44310345 0.56871345 0.56871345\n",
      " 0.55116959 0.60380117 0.41666667 0.39035088]\n",
      "----------------------------------------\n",
      "Trial 338\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 62, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=62, random_state=100))])\n",
      "cv score: [0.5862069  0.45977011 0.52442529 0.64827586 0.6125731  0.60526316\n",
      " 0.3377193  0.57894737 0.4122807  0.31725146]\n",
      "----------------------------------------\n",
      "Trial 339\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 116, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=116,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.43390805 0.53591954 0.49568966 0.55517241 0.63450292 0.56432749\n",
      " 0.45321637 0.66812865 0.57017544 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 340\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 195, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=195, random_state=100))])\n",
      "cv score: [0.48563218 0.47413793 0.45977011 0.57413793 0.59064327 0.57309942\n",
      " 0.44883041 0.56432749 0.49707602 0.44736842]\n",
      "----------------------------------------\n",
      "Trial 341\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 91, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=91,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35632184 0.37643678 0.59051724 0.60344828 0.58625731 0.61988304\n",
      " 0.46345029 0.50584795 0.40643275 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 342\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 62, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=62, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.5        0.47126437 0.61637931 0.63448276 0.69152047 0.61403509\n",
      " 0.2880117  0.42982456 0.48245614 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 343\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4137931  0.40804598 0.67097701 0.6137931  0.64473684 0.57017544\n",
      " 0.41374269 0.49707602 0.37719298 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 344\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 46, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=46, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.52442529 0.5387931  0.45977011 0.63965517 0.61111111 0.62573099\n",
      " 0.38596491 0.60380117 0.56140351 0.45906433]\n",
      "----------------------------------------\n",
      "Trial 345\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 31, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=31, random_state=100))])\n",
      "cv score: [0.41954023 0.4137931  0.37787356 0.65862069 0.76169591 0.45906433\n",
      " 0.33479532 0.53508772 0.49415205 0.29093567]\n",
      "----------------------------------------\n",
      "Trial 346\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 106, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=106,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.4454023  0.59626437 0.64827586 0.74415205 0.57309942\n",
      " 0.29532164 0.45321637 0.48099415 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 347\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 78, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=78,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.53017241 0.55747126 0.56034483 0.66959064 0.43859649\n",
      " 0.37280702 0.61549708 0.61988304 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 348\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 86, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=86,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.35632184 0.38793103 0.52729885 0.54827586 0.54239766 0.52046784\n",
      " 0.36111111 0.54385965 0.33333333 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 349\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 26, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=26, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.53448276 0.47988506 0.51005747 0.64827586 0.62719298 0.4619883\n",
      " 0.37280702 0.49707602 0.43567251 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 350\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 97, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=10,\n",
      "                                            n_estimators=97, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.52298851 0.44252874 0.45833333 0.65862069 0.65643275 0.5380117\n",
      " 0.27923977 0.4619883  0.51169591 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 351\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 97, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=97,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57758621 0.45689655 0.56752874 0.39137931 0.70321637 0.49561404\n",
      " 0.3245614  0.40350877 0.31578947 0.4254386 ]\n",
      "----------------------------------------\n",
      "Trial 352\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 148, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=2,\n",
      "                                            n_estimators=148, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.47126437 0.48275862 0.5316092  0.54310345 0.57163743 0.60526316\n",
      " 0.39035088 0.55555556 0.55994152 0.49122807]\n",
      "----------------------------------------\n",
      "Trial 353\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 160, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=160,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49712644 0.37931034 0.68534483 0.52758621 0.63596491 0.64035088\n",
      " 0.43421053 0.49122807 0.30409357 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 354\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 169, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=169, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.51724138 0.43390805 0.55028736 0.7        0.64181287 0.62573099\n",
      " 0.37865497 0.49415205 0.4619883  0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 355\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 77, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=77,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50431034 0.54885057 0.50862069 0.57413793 0.63304094 0.61842105\n",
      " 0.44736842 0.60233918 0.55116959 0.39181287]\n",
      "----------------------------------------\n",
      "Trial 356\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 185, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=185, random_state=100))])\n",
      "cv score: [0.42528736 0.48275862 0.44683908 0.61724138 0.59795322 0.5380117\n",
      " 0.34356725 0.5380117  0.50584795 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 357\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 111, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=111,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56752874 0.54885057 0.57471264 0.52068966 0.66374269 0.4619883\n",
      " 0.46491228 0.62719298 0.57309942 0.5380117 ]\n",
      "----------------------------------------\n",
      "Trial 358\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 199, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=199,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.65229885 0.37643678 0.51005747 0.44137931 0.49269006 0.51754386\n",
      " 0.36988304 0.38596491 0.4619883  0.53508772]\n",
      "----------------------------------------\n",
      "Trial 359\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 31, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=31, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.51867816 0.54597701 0.47557471 0.57586207 0.58187135 0.54532164\n",
      " 0.42397661 0.60526316 0.57309942 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 360\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 48, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            n_estimators=48,\n",
      "                                            random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.4137931  0.37068966 0.60775862 0.59655172 0.72368421 0.60233918\n",
      " 0.23976608 0.51461988 0.58187135 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 361\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 193, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=193,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37356322 0.41091954 0.4841954  0.45862069 0.49853801 0.5\n",
      " 0.42836257 0.60526316 0.38888889 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 362\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 41, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=41, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.63649425 0.32758621 0.59195402 0.46896552 0.24269006 0.56725146\n",
      " 0.54239766 0.37134503 0.74269006 0.41812865]\n",
      "----------------------------------------\n",
      "Trial 363\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 174, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=2, max_features='log2',\n",
      "                                            n_estimators=174, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.52586207 0.5        0.56752874 0.65862069 0.53654971 0.64035088\n",
      " 0.32894737 0.52339181 0.53508772 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 364\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 119, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=119, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.49137931 0.41954023 0.56752874 0.67586207 0.67982456 0.55847953\n",
      " 0.33187135 0.52339181 0.43274854 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 365\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 112, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=112, random_state=100))])\n",
      "cv score: [0.39942529 0.41091954 0.50718391 0.63448276 0.72660819 0.47660819\n",
      " 0.27631579 0.51754386 0.42982456 0.26608187]\n",
      "----------------------------------------\n",
      "Trial 366\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4137931  0.33333333 0.69971264 0.63793103 0.62426901 0.5994152\n",
      " 0.41374269 0.47660819 0.40935673 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 367\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 149, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=149,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.21264368 0.32183908 0.4066092  0.55517241 0.51169591 0.53070175\n",
      " 0.55555556 0.54093567 0.51608187 0.4005848 ]\n",
      "----------------------------------------\n",
      "Trial 368\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.49712644 0.4683908  0.62787356 0.63103448 0.63888889 0.46783626\n",
      " 0.29093567 0.57309942 0.40643275 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 369\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 158, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=9,\n",
      "                                            n_estimators=158,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.47988506 0.34913793 0.47988506 0.48275862 0.67836257 0.41081871\n",
      " 0.35233918 0.30847953 0.56432749 0.39327485]\n",
      "----------------------------------------\n",
      "Trial 370\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 174, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=174,\n",
      "                                            random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.54597701 0.52298851 0.50718391 0.6862069  0.61842105 0.60233918\n",
      " 0.37280702 0.55263158 0.52777778 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 371\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 22, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=22,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35057471 0.27298851 0.55747126 0.56206897 0.40789474 0.67836257\n",
      " 0.61111111 0.47076023 0.4751462  0.35380117]\n",
      "----------------------------------------\n",
      "Trial 372\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=133, random_state=100))])\n",
      "cv score: [0.4841954  0.45833333 0.50574713 0.54482759 0.6505848  0.46783626\n",
      " 0.31140351 0.60818713 0.41520468 0.2880117 ]\n",
      "----------------------------------------\n",
      "Trial 373\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 162, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=162, random_state=100))])\n",
      "cv score: [0.5316092  0.43390805 0.58189655 0.67241379 0.61842105 0.57894737\n",
      " 0.31432749 0.58187135 0.39473684 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 374\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60344828 0.56321839 0.57471264 0.53448276 0.71637427 0.4619883\n",
      " 0.46491228 0.63888889 0.6374269  0.53362573]\n",
      "----------------------------------------\n",
      "Trial 375\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 153, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=153,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33045977 0.36206897 0.57327586 0.64482759 0.49853801 0.64912281\n",
      " 0.45467836 0.46491228 0.43859649 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 376\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 76, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=76, random_state=100))])\n",
      "cv score: [0.52298851 0.46264368 0.55316092 0.65172414 0.62426901 0.54093567\n",
      " 0.31140351 0.59356725 0.42690058 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 377\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.27298851 0.35344828 0.39798851 0.58965517 0.50146199 0.5628655\n",
      " 0.56725146 0.5497076  0.47222222 0.4005848 ]\n",
      "----------------------------------------\n",
      "Trial 378\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 80, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=80,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.54597701 0.46551724 0.54597701 0.49655172 0.59356725 0.50146199\n",
      " 0.49269006 0.66959064 0.55994152 0.51461988]\n",
      "----------------------------------------\n",
      "Trial 379\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 71, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=71, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.52873563 0.4137931  0.61063218 0.56896552 0.67105263 0.5\n",
      " 0.29678363 0.53216374 0.45321637 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 380\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 188, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=188,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.41091954 0.45833333 0.53793103 0.50438596 0.60233918\n",
      " 0.50146199 0.57309942 0.42105263 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 381\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 146, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=146, random_state=100))])\n",
      "cv score: [0.46982759 0.43678161 0.44827586 0.55517241 0.67982456 0.4619883\n",
      " 0.36111111 0.54093567 0.4502924  0.24269006]\n",
      "----------------------------------------\n",
      "Trial 382\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 32, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=32, random_state=100))])\n",
      "cv score: [0.52873563 0.45114943 0.55747126 0.54655172 0.55847953 0.47807018\n",
      " 0.46929825 0.5745614  0.46637427 0.55116959]\n",
      "----------------------------------------\n",
      "Trial 383\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 149, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=149,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51005747 0.54022989 0.53448276 0.57413793 0.62719298 0.61842105\n",
      " 0.43859649 0.59356725 0.55116959 0.42690058]\n",
      "----------------------------------------\n",
      "Trial 384\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.54310345 0.50287356 0.54741379 0.67758621 0.51315789 0.59356725\n",
      " 0.34356725 0.57602339 0.51754386 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 385\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 46, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt', n_estimators=46,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53735632 0.49425287 0.55172414 0.62413793 0.72807018 0.55409357\n",
      " 0.23830409 0.5        0.49561404 0.45467836]\n",
      "----------------------------------------\n",
      "Trial 386\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 62, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=62, random_state=100))])\n",
      "cv score: [0.54885057 0.43247126 0.59051724 0.62068966 0.65789474 0.52777778\n",
      " 0.30555556 0.54385965 0.42982456 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 387\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 40, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=40,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.30316092 0.56752874 0.40373563 0.54310345 0.54532164 0.42690058\n",
      " 0.44152047 0.67690058 0.63450292 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 388\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 82, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=82,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51149425 0.41666667 0.49137931 0.45862069 0.60526316 0.60087719\n",
      " 0.62573099 0.64619883 0.53216374 0.49707602]\n",
      "----------------------------------------\n",
      "Trial 389\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 131, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, max_features='sqrt',\n",
      "                                            n_estimators=131, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.53735632 0.41954023 0.625      0.60689655 0.62719298 0.5497076\n",
      " 0.32017544 0.5        0.43274854 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 390\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=170, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.52298851 0.4683908  0.57327586 0.65172414 0.67105263 0.57309942\n",
      " 0.30555556 0.50877193 0.43567251 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 391\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 11, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=11, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.49856322 0.43965517 0.61350575 0.71206897 0.64035088 0.64619883\n",
      " 0.26608187 0.65497076 0.48391813 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 392\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 188, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=188,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.45114943 0.5158046  0.33275862 0.53362573 0.46345029\n",
      " 0.38157895 0.32748538 0.48391813 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 393\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 65, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=65,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37356322 0.43965517 0.75143678 0.63103448 0.67397661 0.57017544\n",
      " 0.36988304 0.5380117  0.47368421 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 394\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 29, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=29, random_state=100))])\n",
      "cv score: [0.56034483 0.41954023 0.62643678 0.63448276 0.68128655 0.52923977\n",
      " 0.26023392 0.55409357 0.45760234 0.29385965]\n",
      "----------------------------------------\n",
      "Trial 395\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.35057471 0.66522989 0.62758621 0.51315789 0.69883041\n",
      " 0.63304094 0.36549708 0.44005848 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 396\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 93, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=93,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42528736 0.38505747 0.63362069 0.62413793 0.66520468 0.42397661\n",
      " 0.31140351 0.62865497 0.37426901 0.26608187]\n",
      "----------------------------------------\n",
      "Trial 397\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.5545977  0.42816092 0.5933908  0.70344828 0.67397661 0.61403509\n",
      " 0.33479532 0.47660819 0.40643275 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 398\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 162, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=162,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41091954 0.47701149 0.47270115 0.52068966 0.52192982 0.54824561\n",
      " 0.51169591 0.5877193  0.46783626 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 399\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.4137931  0.27873563 0.64511494 0.64137931 0.67105263 0.55847953\n",
      " 0.50730994 0.47953216 0.3128655  0.38596491]\n",
      "----------------------------------------\n",
      "Trial 400\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 90, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=90,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37931034 0.34195402 0.68534483 0.65172414 0.59502924 0.56432749\n",
      " 0.45467836 0.5        0.45321637 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 401\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 53, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=53, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.55172414 0.47413793 0.49281609 0.67586207 0.56871345 0.60818713\n",
      " 0.32894737 0.59356725 0.48684211 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 402\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 178, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=178, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.56321839 0.50287356 0.52729885 0.68275862 0.5745614  0.64035088\n",
      " 0.38450292 0.56432749 0.49707602 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 403\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=14, random_state=100))])\n",
      "cv score: [0.52155172 0.59626437 0.44109195 0.51724138 0.5        0.63450292\n",
      " 0.51169591 0.5745614  0.50730994 0.39035088]\n",
      "----------------------------------------\n",
      "Trial 404\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 144, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=144,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52729885 0.56896552 0.50431034 0.62068966 0.63450292 0.60964912\n",
      " 0.39473684 0.5994152  0.54824561 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 405\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 32, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=32,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40229885 0.45689655 0.66522989 0.7        0.46637427 0.5497076\n",
      " 0.2997076  0.5380117  0.33333333 0.26315789]\n",
      "----------------------------------------\n",
      "Trial 406\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.49425287 0.48850575 0.41551724 0.59795322 0.51023392\n",
      " 0.51461988 0.65789474 0.50730994 0.41374269]\n",
      "----------------------------------------\n",
      "Trial 407\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 90, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=90, random_state=100))])\n",
      "cv score: [0.5316092  0.36494253 0.54741379 0.62758621 0.64181287 0.53216374\n",
      " 0.34356725 0.53216374 0.39912281 0.31432749]\n",
      "----------------------------------------\n",
      "Trial 408\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 173, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=173,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.44252874 0.46264368 0.76005747 0.65172414 0.65643275 0.61403509\n",
      " 0.55994152 0.44152047 0.33625731 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 409\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 10, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=10, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.47413793 0.4137931  0.42097701 0.63275862 0.62280702 0.64035088\n",
      " 0.32017544 0.56725146 0.49122807 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 410\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 98, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=98,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35632184 0.30172414 0.57327586 0.60344828 0.60964912 0.48830409\n",
      " 0.32602339 0.58187135 0.40935673 0.24561404]\n",
      "----------------------------------------\n",
      "Trial 411\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 11, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            n_estimators=11, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.63362069 0.43103448 0.5158046  0.52413793 0.69444444 0.40643275\n",
      " 0.27339181 0.41520468 0.48245614 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 412\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 10, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=10,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40948276 0.37931034 0.5316092  0.49137931 0.4751462  0.59210526\n",
      " 0.30116959 0.57309942 0.39181287 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 413\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 179, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=179,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50574713 0.46695402 0.63074713 0.65       0.73830409 0.5877193\n",
      " 0.23830409 0.44298246 0.47807018 0.36111111]\n",
      "----------------------------------------\n",
      "Trial 414\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 24, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=24, random_state=100))])\n",
      "cv score: [0.55316092 0.51149425 0.51149425 0.63793103 0.53508772 0.59649123\n",
      " 0.39619883 0.71637427 0.48099415 0.34649123]\n",
      "----------------------------------------\n",
      "Trial 415\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.52586207 0.42528736 0.61063218 0.63448276 0.68859649 0.5877193\n",
      " 0.24122807 0.48245614 0.48830409 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 416\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 19, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=19, random_state=100))])\n",
      "cv score: [0.48275862 0.45977011 0.45402299 0.63965517 0.64327485 0.56140351\n",
      " 0.34064327 0.38596491 0.48245614 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 417\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=52, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.47413793 0.41666667 0.64511494 0.58275862 0.75       0.57309942\n",
      " 0.27046784 0.5        0.47368421 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 418\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 150, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            n_estimators=150, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.46551724 0.42528736 0.49568966 0.56896552 0.74122807 0.50584795\n",
      " 0.26754386 0.50584795 0.57309942 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 419\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 119, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=119, random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.47413793 0.44252874 0.59626437 0.72413793 0.65935673 0.61403509\n",
      " 0.33187135 0.51461988 0.50877193 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 420\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 162, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=162,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4137931  0.31321839 0.6566092  0.61724138 0.63304094 0.54093567\n",
      " 0.47222222 0.4619883  0.45614035 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 421\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 54, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=54, random_state=100))])\n",
      "cv score: [0.52873563 0.4683908  0.55747126 0.55862069 0.65935673 0.4619883\n",
      " 0.29824561 0.51754386 0.43567251 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 422\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 75, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=75, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.58908046 0.67385057 0.33189655 0.54310345 0.62865497 0.49122807\n",
      " 0.58479532 0.43274854 0.61111111 0.46783626]\n",
      "----------------------------------------\n",
      "Trial 423\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 160, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=7,\n",
      "                                            n_estimators=160,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.43390805 0.47701149 0.4612069  0.57241379 0.67690058 0.52046784\n",
      " 0.25292398 0.48830409 0.49707602 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 424\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 51, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=51,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50431034 0.44971264 0.57471264 0.49655172 0.66374269 0.53070175\n",
      " 0.54239766 0.63304094 0.62280702 0.48245614]\n",
      "----------------------------------------\n",
      "Trial 425\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 28, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=28, random_state=100))])\n",
      "cv score: [0.53735632 0.43390805 0.54597701 0.58965517 0.69152047 0.50438596\n",
      " 0.33333333 0.4619883  0.45760234 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 426\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 191, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=191, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.42528736 0.24281609 0.56178161 0.54137931 0.45175439 0.46052632\n",
      " 0.36988304 0.53216374 0.41812865 0.48976608]\n",
      "----------------------------------------\n",
      "Trial 427\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 116, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=116,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37068966 0.37931034 0.625      0.6137931  0.63011696 0.54385965\n",
      " 0.38450292 0.49122807 0.4122807  0.30116959]\n",
      "----------------------------------------\n",
      "Trial 428\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 50, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=50,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.36494253 0.34770115 0.62212644 0.61034483 0.5248538  0.65789474\n",
      " 0.41666667 0.32163743 0.41520468 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 429\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 148, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=148, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.52586207 0.4683908  0.52442529 0.6862069  0.5628655  0.6754386\n",
      " 0.33479532 0.47076023 0.48830409 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 430\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 89, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=89,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.47413793 0.49137931 0.46551724 0.48245614 0.43274854\n",
      " 0.46491228 0.5        0.46491228 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 431\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 10, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=10, random_state=100))])\n",
      "cv score: [0.52298851 0.47988506 0.61350575 0.61724138 0.64181287 0.62280702\n",
      " 0.33479532 0.55409357 0.53947368 0.39327485]\n",
      "----------------------------------------\n",
      "Trial 432\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 62, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=62,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37068966 0.33045977 0.62787356 0.5862069  0.51900585 0.65204678\n",
      " 0.65935673 0.39181287 0.44005848 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 433\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 79, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=79,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56752874 0.54885057 0.57471264 0.51034483 0.66374269 0.43274854\n",
      " 0.50292398 0.65350877 0.57309942 0.49707602]\n",
      "----------------------------------------\n",
      "Trial 434\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 59, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=59,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.45114943 0.5158046  0.33275862 0.53362573 0.46345029\n",
      " 0.38157895 0.32748538 0.48391813 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 435\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 119, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            n_estimators=119, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.50862069 0.48706897 0.4066092  0.53275862 0.6505848  0.38888889\n",
      " 0.38157895 0.49415205 0.57748538 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 436\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34770115 0.37931034 0.45833333 0.48275862 0.55116959 0.49415205\n",
      " 0.32602339 0.59064327 0.41812865 0.22807018]\n",
      "----------------------------------------\n",
      "Trial 437\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 61, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=61,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.40804598 0.43965517 0.60488506 0.55172414 0.57602339 0.57017544\n",
      " 0.4254386  0.59356725 0.42105263 0.26315789]\n",
      "----------------------------------------\n",
      "Trial 438\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=38, random_state=100))])\n",
      "cv score: [0.43247126 0.43390805 0.48994253 0.56206897 0.62426901 0.47807018\n",
      " 0.38157895 0.59649123 0.48684211 0.4005848 ]\n",
      "----------------------------------------\n",
      "Trial 439\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 25, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=25,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56752874 0.54885057 0.57471264 0.50689655 0.48245614 0.50730994\n",
      " 0.46491228 0.63596491 0.53947368 0.50584795]\n",
      "----------------------------------------\n",
      "Trial 440\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 66, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=66,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.47701149 0.38362069 0.39310345 0.60380117 0.33918129\n",
      " 0.40350877 0.57017544 0.62573099 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 441\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 172, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=172,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58908046 0.51293103 0.59626437 0.42068966 0.64766082 0.39181287\n",
      " 0.35087719 0.44590643 0.33333333 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 442\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 78, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=78, random_state=100))])\n",
      "cv score: [0.49712644 0.4454023  0.45258621 0.56206897 0.66520468 0.47222222\n",
      " 0.29678363 0.54093567 0.34064327 0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 443\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34770115 0.32758621 0.66810345 0.6137931  0.58333333 0.58187135\n",
      " 0.40789474 0.45321637 0.47076023 0.27192982]\n",
      "----------------------------------------\n",
      "Trial 444\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 122, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=122,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52873563 0.41522989 0.54597701 0.49655172 0.58187135 0.59356725\n",
      " 0.52777778 0.66666667 0.52046784 0.52192982]\n",
      "----------------------------------------\n",
      "Trial 445\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 24, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=24, random_state=100))])\n",
      "cv score: [0.56609195 0.43678161 0.60344828 0.63448276 0.66374269 0.54239766\n",
      " 0.26023392 0.54239766 0.48391813 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 446\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 37, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, max_features='log2',\n",
      "                                            n_estimators=37,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.48850575 0.51436782 0.52442529 0.68275862 0.68567251 0.62280702\n",
      " 0.27923977 0.49122807 0.48538012 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 447\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 196, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=196,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6091954  0.5862069  0.6091954  0.52758621 0.69298246 0.55994152\n",
      " 0.49122807 0.64035088 0.60526316 0.57017544]\n",
      "----------------------------------------\n",
      "Trial 448\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.52873563 0.44252874 0.59913793 0.71724138 0.67105263 0.64912281\n",
      " 0.35233918 0.42982456 0.5        0.33333333]\n",
      "----------------------------------------\n",
      "Trial 449\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 113, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=113,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.56034483 0.47701149 0.66954023 0.60172414 0.74269006 0.58918129\n",
      " 0.24707602 0.45614035 0.47076023 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 450\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 142, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=142,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5545977  0.53448276 0.51293103 0.67068966 0.62573099 0.59210526\n",
      " 0.39473684 0.54678363 0.51315789 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 451\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 113, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=113,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34482759 0.39655172 0.51867816 0.55517241 0.63596491 0.44736842\n",
      " 0.32602339 0.59064327 0.35672515 0.26608187]\n",
      "----------------------------------------\n",
      "Trial 452\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 72, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            n_estimators=72, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.52011494 0.47988506 0.44109195 0.63103448 0.67982456 0.38304094\n",
      " 0.36403509 0.46783626 0.45321637 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 453\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 126, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=126, random_state=100))])\n",
      "cv score: [0.57471264 0.44827586 0.55316092 0.67931034 0.57748538 0.55555556\n",
      " 0.34649123 0.56725146 0.42982456 0.36403509]\n",
      "----------------------------------------\n",
      "Trial 454\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 155, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=155,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.47701149 0.45689655 0.58764368 0.64482759 0.72953216 0.57602339\n",
      " 0.30409357 0.44152047 0.4751462  0.38596491]\n",
      "----------------------------------------\n",
      "Trial 455\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 25, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=25,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37356322 0.50862069 0.53304598 0.5862069  0.60672515 0.55555556\n",
      " 0.42251462 0.64035088 0.25146199 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 456\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 192, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=192,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50574713 0.5545977  0.52873563 0.57413793 0.63011696 0.60672515\n",
      " 0.43859649 0.5994152  0.54532164 0.43567251]\n",
      "----------------------------------------\n",
      "Trial 457\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 90, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=90,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41666667 0.33045977 0.66522989 0.58965517 0.63596491 0.49415205\n",
      " 0.3377193  0.52339181 0.30701754 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 458\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 74, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=74,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56178161 0.54885057 0.57471264 0.50517241 0.62865497 0.4619883\n",
      " 0.49269006 0.66374269 0.62280702 0.49707602]\n",
      "----------------------------------------\n",
      "Trial 459\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 193, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=193,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49425287 0.42528736 0.61063218 0.66896552 0.71783626 0.60526316\n",
      " 0.30701754 0.4619883  0.47953216 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 460\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 56, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=56,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.31034483 0.34482759 0.52729885 0.5862069  0.46345029 0.50877193\n",
      " 0.65350877 0.35672515 0.35087719 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 461\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 82, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=82, random_state=100))])\n",
      "cv score: [0.47413793 0.5        0.52442529 0.64137931 0.50584795 0.58187135\n",
      " 0.37573099 0.59356725 0.43859649 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 462\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 190, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=190,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6091954  0.5862069  0.6091954  0.52758621 0.69298246 0.55994152\n",
      " 0.49122807 0.64035088 0.60526316 0.57017544]\n",
      "----------------------------------------\n",
      "Trial 463\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=70,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61781609 0.58333333 0.58045977 0.54137931 0.71345029 0.40204678\n",
      " 0.44152047 0.63157895 0.61695906 0.57894737]\n",
      "----------------------------------------\n",
      "Trial 464\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 92, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=92,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52442529 0.56034483 0.50574713 0.62758621 0.64327485 0.59649123\n",
      " 0.39766082 0.59356725 0.55116959 0.29239766]\n",
      "----------------------------------------\n",
      "Trial 465\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4454023  0.40229885 0.66235632 0.60344828 0.58918129 0.5380117\n",
      " 0.39619883 0.51461988 0.38011696 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 466\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 164, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=164,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4137931  0.33908046 0.68534483 0.59655172 0.6505848  0.49415205\n",
      " 0.44298246 0.47076023 0.4005848  0.25438596]\n",
      "----------------------------------------\n",
      "Trial 467\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 123, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=4,\n",
      "                                            n_estimators=123, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.45114943 0.27873563 0.39511494 0.52758621 0.72076023 0.52631579\n",
      " 0.33479532 0.45614035 0.66959064 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 468\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 10, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=10,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43103448 0.4841954  0.57471264 0.50862069 0.64619883 0.59210526\n",
      " 0.4254386  0.65789474 0.5497076  0.51461988]\n",
      "----------------------------------------\n",
      "Trial 469\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=198, random_state=100))])\n",
      "cv score: [0.47413793 0.42241379 0.4841954  0.59310345 0.70321637 0.50584795\n",
      " 0.2880117  0.51754386 0.42105263 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 470\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 74, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=74,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40517241 0.31896552 0.55603448 0.56896552 0.57163743 0.50292398\n",
      " 0.3494152  0.49415205 0.30701754 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 471\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 118, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=118,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56178161 0.54885057 0.57471264 0.51206897 0.48245614 0.4619883\n",
      " 0.50292398 0.67982456 0.46491228 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 472\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 90, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=90, random_state=100))])\n",
      "cv score: [0.52011494 0.43247126 0.54454023 0.58275862 0.67690058 0.47076023\n",
      " 0.28070175 0.55847953 0.38157895 0.27046784]\n",
      "----------------------------------------\n",
      "Trial 473\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 195, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=195, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.58189655 0.68534483 0.56465517 0.7        0.67836257 0.45321637\n",
      " 0.58625731 0.3128655  0.5248538  0.63304094]\n",
      "----------------------------------------\n",
      "Trial 474\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=101, random_state=100))])\n",
      "cv score: [0.54022989 0.38936782 0.54741379 0.63793103 0.62719298 0.55847953\n",
      " 0.34356725 0.52339181 0.40204678 0.32017544]\n",
      "----------------------------------------\n",
      "Trial 475\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 120, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=120, random_state=100))])\n",
      "cv score: [0.41666667 0.40517241 0.40948276 0.64482759 0.72660819 0.51169591\n",
      " 0.31725146 0.52923977 0.48245614 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 476\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=174, random_state=100))])\n",
      "cv score: [0.47413793 0.45977011 0.51436782 0.55517241 0.64766082 0.45906433\n",
      " 0.29824561 0.61403509 0.38888889 0.30847953]\n",
      "----------------------------------------\n",
      "Trial 477\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=183, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.51724138 0.43103448 0.60201149 0.63793103 0.65350877 0.54093567\n",
      " 0.27046784 0.56725146 0.44152047 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 478\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 124, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=124,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54166667 0.47126437 0.56465517 0.68793103 0.63888889 0.59064327\n",
      " 0.34795322 0.48538012 0.50877193 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 479\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 78, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=78,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.56034483 0.48563218 0.6795977  0.61551724 0.71052632 0.57309942\n",
      " 0.25       0.46491228 0.43128655 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 480\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 169, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=169,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.47701149 0.45689655 0.58764368 0.65172414 0.72953216 0.5877193\n",
      " 0.30409357 0.44152047 0.47807018 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 481\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 109, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=109,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54166667 0.46551724 0.56178161 0.67758621 0.63011696 0.59649123\n",
      " 0.34795322 0.48245614 0.50292398 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 482\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.42241379 0.5704023  0.53103448 0.54532164 0.48538012\n",
      " 0.43128655 0.54093567 0.3128655  0.25438596]\n",
      "----------------------------------------\n",
      "Trial 483\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=7,\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.45977011 0.43678161 0.5387931  0.6        0.72076023 0.51169591\n",
      " 0.26461988 0.50584795 0.51461988 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 484\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 186, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=186,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50287356 0.47413793 0.61637931 0.6137931  0.75584795 0.56725146\n",
      " 0.20614035 0.49269006 0.49122807 0.40350877]\n",
      "----------------------------------------\n",
      "Trial 485\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43965517 0.37643678 0.6566092  0.54137931 0.65350877 0.46491228\n",
      " 0.27339181 0.55847953 0.29824561 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 486\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 179, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=179, random_state=100))])\n",
      "cv score: [0.49712644 0.49712644 0.49568966 0.63793103 0.54532164 0.60818713\n",
      " 0.40789474 0.58479532 0.46491228 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 487\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34482759 0.3908046  0.55316092 0.60517241 0.49122807 0.61988304\n",
      " 0.4751462  0.50877193 0.45467836 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 488\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 103, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=103,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.38505747 0.71982759 0.59310345 0.63011696 0.51754386\n",
      " 0.46637427 0.50877193 0.31871345 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 489\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 169, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=169, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49425287 0.45114943 0.54166667 0.67241379 0.68567251 0.60526316\n",
      " 0.31432749 0.45906433 0.45614035 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 490\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 125, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=125,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.48275862 0.45114943 0.58189655 0.65517241 0.73830409 0.57309942\n",
      " 0.29824561 0.44444444 0.48099415 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 491\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 148, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=148,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48275862 0.35057471 0.74568966 0.63793103 0.50730994 0.55555556\n",
      " 0.69444444 0.37134503 0.52339181 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 492\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.49137931 0.49425287 0.61637931 0.67241379 0.64473684 0.48245614\n",
      " 0.31140351 0.59356725 0.42982456 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 493\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 121, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=121,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.31034483 0.43678161 0.46982759 0.54137931 0.52192982 0.55847953\n",
      " 0.51023392 0.57309942 0.47953216 0.43859649]\n",
      "----------------------------------------\n",
      "Trial 494\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 179, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=179,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49425287 0.42528736 0.60775862 0.67586207 0.71783626 0.59649123\n",
      " 0.30701754 0.46491228 0.48538012 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 495\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 179, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=179, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.45833333 0.67528736 0.375      0.59655172 0.48245614 0.39473684\n",
      " 0.58625731 0.55263158 0.30994152 0.70760234]\n",
      "----------------------------------------\n",
      "Trial 496\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 120, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=120, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.54022989 0.44827586 0.53304598 0.54482759 0.66520468 0.41520468\n",
      " 0.32894737 0.35672515 0.40643275 0.48538012]\n",
      "----------------------------------------\n",
      "Trial 497\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 157, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=157, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.39942529 0.53735632 0.55603448 0.64137931 0.57748538 0.55847953\n",
      " 0.41666667 0.54385965 0.41520468 0.43274854]\n",
      "----------------------------------------\n",
      "Trial 498\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 74, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=74, random_state=100))])\n",
      "cv score: [0.43390805 0.37356322 0.4295977  0.59310345 0.7002924  0.51754386\n",
      " 0.31140351 0.57017544 0.46491228 0.26900585]\n",
      "----------------------------------------\n",
      "Trial 499\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 70, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=70,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.47413793 0.48275862 0.49137931 0.47413793 0.48245614 0.43274854\n",
      " 0.46491228 0.5        0.47368421 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 500\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 146, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=146, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.39367816 0.40373563 0.47988506 0.64482759 0.42251462 0.36403509\n",
      " 0.58040936 0.66959064 0.65204678 0.44152047]\n",
      "----------------------------------------\n",
      "Trial 501\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 112, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=112, random_state=100))])\n",
      "cv score: [0.41091954 0.41091954 0.44683908 0.60689655 0.75292398 0.47368421\n",
      " 0.30847953 0.54093567 0.42397661 0.24853801]\n",
      "----------------------------------------\n",
      "Trial 502\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 133, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=133,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4841954  0.46264368 0.51005747 0.42413793 0.53362573 0.60380117\n",
      " 0.55847953 0.65350877 0.39327485 0.46345029]\n",
      "----------------------------------------\n",
      "Trial 503\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 193, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=193,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38793103 0.34195402 0.58189655 0.6        0.62426901 0.47953216\n",
      " 0.37280702 0.52923977 0.38304094 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 504\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44827586 0.34770115 0.76867816 0.70689655 0.53654971 0.63157895\n",
      " 0.65350877 0.36842105 0.43859649 0.44152047]\n",
      "----------------------------------------\n",
      "Trial 505\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 24, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=24,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.53017241 0.55747126 0.56034483 0.66959064 0.43859649\n",
      " 0.37280702 0.61549708 0.61988304 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 506\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 38, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=38,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.54885057 0.49137931 0.4862069  0.48538012 0.51315789\n",
      " 0.60818713 0.67251462 0.46491228 0.44736842]\n",
      "----------------------------------------\n",
      "Trial 507\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 142, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=142,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54166667 0.4683908  0.49712644 0.68275862 0.61111111 0.57748538\n",
      " 0.34502924 0.52631579 0.51315789 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 508\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 57, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=57,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.30316092 0.56752874 0.40373563 0.54310345 0.54532164 0.42690058\n",
      " 0.44152047 0.67690058 0.63450292 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 509\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 178, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=6,\n",
      "                                            n_estimators=178, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.45689655 0.34195402 0.55890805 0.61034483 0.73245614 0.53508772\n",
      " 0.26169591 0.45614035 0.56432749 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 510\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 91, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=91,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47988506 0.39655172 0.54310345 0.47586207 0.53654971 0.4751462\n",
      " 0.56871345 0.62426901 0.57602339 0.45175439]\n",
      "----------------------------------------\n",
      "Trial 511\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 130, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=130, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.49425287 0.48850575 0.5704023  0.64827586 0.68567251 0.59064327\n",
      " 0.29385965 0.4619883  0.42690058 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 512\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.28448276 0.43965517 0.48563218 0.60517241 0.54824561 0.58333333\n",
      " 0.55116959 0.39766082 0.48976608 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 513\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 131, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=131,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.49568966 0.55747126 0.4841954  0.72931034 0.65789474 0.61988304\n",
      " 0.42251462 0.58333333 0.55555556 0.34356725]\n",
      "----------------------------------------\n",
      "Trial 514\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 34, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=34, random_state=100))])\n",
      "cv score: [0.56752874 0.48850575 0.60775862 0.59310345 0.7002924  0.50877193\n",
      " 0.29532164 0.51023392 0.39181287 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 515\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 11, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=11,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60775862 0.51436782 0.52873563 0.66724138 0.72807018 0.48391813\n",
      " 0.29093567 0.49707602 0.51169591 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 516\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 77, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=77, random_state=100))])\n",
      "cv score: [0.41666667 0.41091954 0.51867816 0.61034483 0.71491228 0.47953216\n",
      " 0.29093567 0.5380117  0.39766082 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 517\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 23, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=23,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.49425287 0.49137931 0.44655172 0.46491228 0.55994152\n",
      " 0.61403509 0.58333333 0.42105263 0.4122807 ]\n",
      "----------------------------------------\n",
      "Trial 518\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 191, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=191, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.42528736 0.24281609 0.56178161 0.54137931 0.45175439 0.46052632\n",
      " 0.36988304 0.53216374 0.41812865 0.48976608]\n",
      "----------------------------------------\n",
      "Trial 519\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 52, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=52,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40804598 0.41666667 0.60488506 0.51724138 0.59502924 0.44736842\n",
      " 0.29678363 0.56140351 0.39181287 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 520\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 30, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            n_estimators=30, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.41091954 0.39655172 0.53017241 0.59482759 0.69152047 0.5877193\n",
      " 0.29385965 0.56140351 0.47076023 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 521\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 119, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=119, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.53735632 0.45689655 0.58764368 0.60344828 0.65935673 0.57602339\n",
      " 0.27339181 0.51461988 0.43859649 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 522\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 153, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=153,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3591954  0.35632184 0.7112069  0.60344828 0.58040936 0.52339181\n",
      " 0.48684211 0.47953216 0.35087719 0.29239766]\n",
      "----------------------------------------\n",
      "Trial 523\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 187, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=187, random_state=100))])\n",
      "cv score: [0.56609195 0.45402299 0.56752874 0.70689655 0.57748538 0.57894737\n",
      " 0.33479532 0.52923977 0.4122807  0.35964912]\n",
      "----------------------------------------\n",
      "Trial 524\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 98, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=98,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.53017241 0.55747126 0.56034483 0.66959064 0.43859649\n",
      " 0.37280702 0.61549708 0.61988304 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 525\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 37, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=37, random_state=100))])\n",
      "cv score: [0.51293103 0.51149425 0.41954023 0.60517241 0.58333333 0.59064327\n",
      " 0.41959064 0.54678363 0.56725146 0.45906433]\n",
      "----------------------------------------\n",
      "Trial 526\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 65, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=65,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4137931  0.37068966 0.67385057 0.67586207 0.63596491 0.52046784\n",
      " 0.40497076 0.49707602 0.39473684 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 527\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 193, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=193, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.50287356 0.40517241 0.58189655 0.57931034 0.67397661 0.52339181\n",
      " 0.25584795 0.5497076  0.40643275 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 528\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 171, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=171,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.51436782 0.54885057 0.57471264 0.51551724 0.64912281 0.50730994\n",
      " 0.48830409 0.63888889 0.61549708 0.53070175]\n",
      "----------------------------------------\n",
      "Trial 529\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 166, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=166,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35632184 0.33908046 0.61637931 0.64827586 0.65643275 0.58479532\n",
      " 0.4371345  0.59356725 0.38304094 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 530\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 123, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=123, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.5545977  0.58908046 0.67816092 0.75862069 0.63304094 0.70760234\n",
      " 0.54532164 0.45467836 0.48245614 0.44736842]\n",
      "----------------------------------------\n",
      "Trial 531\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 33, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=33,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50718391 0.4841954  0.52298851 0.66206897 0.66812865 0.60818713\n",
      " 0.32017544 0.51754386 0.47660819 0.35526316]\n",
      "----------------------------------------\n",
      "Trial 532\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 129, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            n_estimators=129,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.72126437 0.52729885 0.47557471 0.57931034 0.68859649 0.42105263\n",
      " 0.37719298 0.34210526 0.43274854 0.51315789]\n",
      "----------------------------------------\n",
      "Trial 533\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 38, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=38,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49856322 0.50574713 0.56609195 0.44827586 0.54385965 0.5497076\n",
      " 0.58479532 0.59649123 0.48830409 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 534\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 104, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=104, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.53448276 0.44252874 0.55316092 0.76551724 0.62280702 0.52777778\n",
      " 0.36695906 0.6374269  0.40643275 0.4502924 ]\n",
      "----------------------------------------\n",
      "Trial 535\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 137, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='log2', n_estimators=137,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57183908 0.49281609 0.63074713 0.62241379 0.74122807 0.57017544\n",
      " 0.23830409 0.44736842 0.47953216 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 536\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 32, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=32,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33333333 0.3362069  0.36637931 0.62068966 0.54093567 0.63157895\n",
      " 0.55994152 0.51169591 0.31140351 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 537\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 190, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=190,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51149425 0.47413793 0.61637931 0.60689655 0.75584795 0.57017544\n",
      " 0.20614035 0.49269006 0.49122807 0.40350877]\n",
      "----------------------------------------\n",
      "Trial 538\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 27, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=27, random_state=100,\n",
      "                                            subsample=0.6))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.50574713 0.44252874 0.66235632 0.64482759 0.67982456 0.54385965\n",
      " 0.32017544 0.57017544 0.47076023 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 539\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 173, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=173,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51293103 0.41522989 0.54022989 0.43103448 0.50584795 0.59064327\n",
      " 0.58918129 0.66374269 0.5380117  0.46929825]\n",
      "----------------------------------------\n",
      "Trial 540\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 117, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=117, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.46551724 0.47988506 0.59051724 0.68275862 0.67690058 0.60526316\n",
      " 0.33187135 0.52631579 0.47076023 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 541\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 38, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=38, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.62068966 0.36494253 0.55316092 0.7        0.69736842 0.60526316\n",
      " 0.44883041 0.48830409 0.51461988 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 542\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 59, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=59,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36781609 0.40517241 0.4137931  0.58275862 0.53216374 0.55994152\n",
      " 0.48391813 0.5380117  0.42397661 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 543\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            n_estimators=95, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.37643678 0.43965517 0.41235632 0.53103448 0.72076023 0.5497076\n",
      " 0.3377193  0.5380117  0.49415205 0.40935673]\n",
      "----------------------------------------\n",
      "Trial 544\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 43, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=43,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61781609 0.58333333 0.58045977 0.54137931 0.71345029 0.40204678\n",
      " 0.44152047 0.63157895 0.61695906 0.57894737]\n",
      "----------------------------------------\n",
      "Trial 545\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 104, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=104,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.3362069  0.66235632 0.57241379 0.68274854 0.49415205\n",
      " 0.38450292 0.51461988 0.28070175 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 546\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 157, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=157, random_state=100))])\n",
      "cv score: [0.47988506 0.43390805 0.52586207 0.51724138 0.55116959 0.54385965\n",
      " 0.4371345  0.54678363 0.49122807 0.4502924 ]\n",
      "----------------------------------------\n",
      "Trial 547\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 31, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=31, random_state=100))])\n",
      "cv score: [0.4066092  0.42528736 0.50431034 0.57586207 0.65935673 0.47076023\n",
      " 0.35233918 0.5497076  0.48245614 0.42105263]\n",
      "----------------------------------------\n",
      "Trial 548\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 189, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=189,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39942529 0.40804598 0.49281609 0.53793103 0.51315789 0.5497076\n",
      " 0.56578947 0.58479532 0.42690058 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 549\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 96, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            n_estimators=96, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.46551724 0.44971264 0.5387931  0.50517241 0.63157895 0.63888889\n",
      " 0.36842105 0.57017544 0.52046784 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 550\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 37, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=37,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52298851 0.36781609 0.64224138 0.56551724 0.56578947 0.45321637\n",
      " 0.38450292 0.60233918 0.33040936 0.29532164]\n",
      "----------------------------------------\n",
      "Trial 551\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 86, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=86,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53304598 0.46982759 0.49568966 0.68103448 0.60672515 0.58625731\n",
      " 0.33040936 0.50877193 0.51754386 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 552\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 32, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=32, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.45689655 0.58333333 0.77298851 0.49310345 0.64473684 0.28362573\n",
      " 0.48099415 0.4122807  0.45614035 0.33479532]\n",
      "----------------------------------------\n",
      "Trial 553\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 190, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=190,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.26149425 0.33908046 0.38074713 0.58965517 0.47807018 0.57309942\n",
      " 0.61842105 0.49122807 0.46637427 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 554\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 138, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=138,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.36206897 0.63936782 0.63103448 0.53070175 0.62719298\n",
      " 0.55701754 0.35233918 0.42982456 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 555\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 167, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=167,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51724138 0.54885057 0.54597701 0.51034483 0.66081871 0.50730994\n",
      " 0.48830409 0.66081871 0.60526316 0.53070175]\n",
      "----------------------------------------\n",
      "Trial 556\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 154, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=154, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.47701149 0.54310345 0.5704023  0.5862069  0.64473684 0.57894737\n",
      " 0.29093567 0.54678363 0.35964912 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 557\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 96, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=96,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.37068966 0.30747126 0.65948276 0.65517241 0.60380117 0.51461988\n",
      " 0.42836257 0.50292398 0.37426901 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 558\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 32, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=32,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.31178161 0.37643678 0.47988506 0.55344828 0.52923977 0.61695906\n",
      " 0.58333333 0.41520468 0.4619883  0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 559\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.41954023 0.44252874 0.54166667 0.59310345 0.6125731  0.44152047\n",
      " 0.22953216 0.41812865 0.47368421 0.43567251]\n",
      "----------------------------------------\n",
      "Trial 560\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 150, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=150, random_state=100))])\n",
      "cv score: [0.47701149 0.44109195 0.50287356 0.61034483 0.67105263 0.46345029\n",
      " 0.31140351 0.61403509 0.36695906 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 561\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 105, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=105,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6091954  0.5862069  0.6091954  0.52758621 0.69298246 0.55994152\n",
      " 0.49122807 0.64035088 0.60526316 0.57017544]\n",
      "----------------------------------------\n",
      "Trial 562\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 116, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=116, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.72126437 0.46551724 0.47557471 0.48793103 0.67836257 0.43567251\n",
      " 0.57017544 0.34064327 0.55555556 0.52631579]\n",
      "----------------------------------------\n",
      "Trial 563\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5        0.49137931 0.49137931 0.48275862 0.48245614 0.43274854\n",
      " 0.5        0.5        0.48245614 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 564\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 44, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=44, random_state=100))])\n",
      "cv score: [0.5316092  0.45402299 0.58764368 0.66034483 0.51023392 0.56140351\n",
      " 0.3874269  0.5877193  0.47076023 0.35233918]\n",
      "----------------------------------------\n",
      "Trial 565\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 153, 'gb__subsample': 1.0, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            n_estimators=153,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.52298851 0.35344828 0.65948276 0.65172414 0.59502924 0.47076023\n",
      " 0.2997076  0.45321637 0.55847953 0.40350877]\n",
      "----------------------------------------\n",
      "Trial 566\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 76, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=76,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49281609 0.44252874 0.51867816 0.43965517 0.63157895 0.4751462\n",
      " 0.51315789 0.61549708 0.58333333 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 567\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 13, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=13, random_state=100,\n",
      "                                            subsample=0.65))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.52873563 0.58908046 0.44396552 0.66206897 0.61988304 0.54093567\n",
      " 0.3494152  0.60818713 0.48830409 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 568\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 145, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=145,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49568966 0.46551724 0.54597701 0.4862069  0.62573099 0.50146199\n",
      " 0.47953216 0.65789474 0.59210526 0.51461988]\n",
      "----------------------------------------\n",
      "Trial 569\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 22, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=22, random_state=100))])\n",
      "cv score: [0.29885057 0.4841954  0.41235632 0.61034483 0.5994152  0.56871345\n",
      " 0.45175439 0.58479532 0.57602339 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 570\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 185, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=185, random_state=100))])\n",
      "cv score: [0.52873563 0.45402299 0.58477011 0.68965517 0.6125731  0.5994152\n",
      " 0.2880117  0.53216374 0.42397661 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 571\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 72, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=72, random_state=100))])\n",
      "cv score: [0.50574713 0.4454023  0.53591954 0.60689655 0.67690058 0.52339181\n",
      " 0.31871345 0.56578947 0.38888889 0.28508772]\n",
      "----------------------------------------\n",
      "Trial 572\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 37, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=37, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.51149425 0.54022989 0.4841954  0.61896552 0.64473684 0.62280702\n",
      " 0.49269006 0.61988304 0.63157895 0.52339181]\n",
      "----------------------------------------\n",
      "Trial 573\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 126, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=126,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.53017241 0.54885057 0.57471264 0.50862069 0.6871345  0.4619883\n",
      " 0.50292398 0.66081871 0.62280702 0.52339181]\n",
      "----------------------------------------\n",
      "Trial 574\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 95, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=95,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.48850575 0.45689655 0.59913793 0.64827586 0.74122807 0.57894737\n",
      " 0.30116959 0.45321637 0.47953216 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 575\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 85, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=85,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50574713 0.41666667 0.55172414 0.48103448 0.6374269  0.5248538\n",
      " 0.5497076  0.64912281 0.59356725 0.44152047]\n",
      "----------------------------------------\n",
      "Trial 576\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 22, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=22,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.40229885 0.56178161 0.47270115 0.56896552 0.65789474 0.56725146\n",
      " 0.48538012 0.60380117 0.58479532 0.55409357]\n",
      "----------------------------------------\n",
      "Trial 577\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 158, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features=None, n_estimators=158,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55747126 0.45689655 0.53591954 0.28793103 0.59502924 0.49853801\n",
      " 0.34356725 0.39912281 0.42982456 0.39035088]\n",
      "----------------------------------------\n",
      "Trial 578\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 80, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=80,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.42241379 0.38505747 0.5933908  0.55862069 0.60964912 0.52631579\n",
      " 0.32602339 0.57894737 0.26608187 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 579\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 42, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=42,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56609195 0.56609195 0.49137931 0.51551724 0.48245614 0.43274854\n",
      " 0.46491228 0.64035088 0.46491228 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 580\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 190, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=190,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38793103 0.36206897 0.74856322 0.55517241 0.60087719 0.55263158\n",
      " 0.47807018 0.53216374 0.35380117 0.28362573]\n",
      "----------------------------------------\n",
      "Trial 581\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 92, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=92,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57758621 0.45689655 0.56752874 0.39137931 0.70321637 0.49561404\n",
      " 0.3245614  0.40350877 0.31578947 0.4254386 ]\n",
      "----------------------------------------\n",
      "Trial 582\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 64, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=64,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3045977  0.43390805 0.47413793 0.57931034 0.62426901 0.51461988\n",
      " 0.45467836 0.54824561 0.48830409 0.47076023]\n",
      "----------------------------------------\n",
      "Trial 583\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 153, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=153, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.52011494 0.47413793 0.52442529 0.70344828 0.62134503 0.66666667\n",
      " 0.36695906 0.54385965 0.48391813 0.29239766]\n",
      "----------------------------------------\n",
      "Trial 584\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 113, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            n_estimators=113, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.47413793 0.42528736 0.45833333 0.55172414 0.65350877 0.42690058\n",
      " 0.30555556 0.50584795 0.54678363 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 585\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.45689655 0.4454023  0.45258621 0.59310345 0.77631579 0.51754386\n",
      " 0.26754386 0.54385965 0.52046784 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 586\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 130, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=130, random_state=100))])\n",
      "cv score: [0.46551724 0.50862069 0.50143678 0.66896552 0.53947368 0.59064327\n",
      " 0.39035088 0.58187135 0.46783626 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 587\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 64, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=64,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.34626437 0.43390805 0.52586207 0.57931034 0.53947368 0.61842105\n",
      " 0.42251462 0.55555556 0.49269006 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 588\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 118, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=118,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.39655172 0.59051724 0.56206897 0.7002924  0.47660819\n",
      " 0.41081871 0.53508772 0.39181287 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 589\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 99, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, max_features='log2',\n",
      "                                            n_estimators=99, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.50574713 0.49712644 0.54741379 0.56206897 0.67982456 0.52339181\n",
      " 0.31725146 0.5380117  0.42105263 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 590\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.57183908 0.61637931 0.53735632 0.46896552 0.50438596 0.45906433\n",
      " 0.42251462 0.30116959 0.46052632 0.47368421]\n",
      "----------------------------------------\n",
      "Trial 591\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 103, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=103,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.52586207 0.47126437 0.61063218 0.64827586 0.70906433 0.60818713\n",
      " 0.26169591 0.47660819 0.49122807 0.40935673]\n",
      "----------------------------------------\n",
      "Trial 592\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=68, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.58045977 0.4454023  0.46982759 0.66551724 0.57163743 0.6374269\n",
      " 0.36403509 0.56725146 0.51754386 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 593\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 116, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            n_estimators=116, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.4683908  0.47701149 0.47557471 0.57931034 0.67397661 0.45906433\n",
      " 0.34649123 0.5        0.50584795 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 594\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 25, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=25, random_state=100))])\n",
      "cv score: [0.5545977  0.44683908 0.55316092 0.58448276 0.7002924  0.53216374\n",
      " 0.3377193  0.43274854 0.47660819 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 595\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 179, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=179,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3908046  0.40229885 0.70258621 0.6862069  0.66520468 0.55263158\n",
      " 0.41666667 0.44736842 0.39766082 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 596\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 149, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=149,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43103448 0.32471264 0.64798851 0.64137931 0.6505848  0.54678363\n",
      " 0.40497076 0.52631579 0.29824561 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 597\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 44, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=44,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.45114943 0.5387931  0.48706897 0.37413793 0.58187135 0.35672515\n",
      " 0.39327485 0.40350877 0.62719298 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 598\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 150, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=150, random_state=100))])\n",
      "cv score: [0.44827586 0.52011494 0.4841954  0.60689655 0.59795322 0.59649123\n",
      " 0.39619883 0.57894737 0.45614035 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 599\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 105, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=105,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.29022989 0.38793103 0.56465517 0.59655172 0.54824561 0.62573099\n",
      " 0.44005848 0.51169591 0.43567251 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 600\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 20, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=20,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61781609 0.58333333 0.58045977 0.54137931 0.71345029 0.40204678\n",
      " 0.44152047 0.63157895 0.61695906 0.57894737]\n",
      "----------------------------------------\n",
      "Trial 601\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 168, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=168,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52729885 0.56321839 0.49856322 0.60344828 0.63450292 0.60964912\n",
      " 0.38888889 0.59064327 0.54824561 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 602\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 88, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=88,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37931034 0.38218391 0.64798851 0.63103448 0.59795322 0.50584795\n",
      " 0.45760234 0.45614035 0.33333333 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 603\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 19, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=11,\n",
      "                                            n_estimators=19, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.47126437 0.32471264 0.30890805 0.55172414 0.72660819 0.42397661\n",
      " 0.28216374 0.36549708 0.52046784 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 604\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 154, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=154,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.60632184 0.5        0.32068966 0.59064327 0.41374269\n",
      " 0.37719298 0.29532164 0.55116959 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 605\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34770115 0.37356322 0.66522989 0.62758621 0.65350877 0.47076023\n",
      " 0.38450292 0.5497076  0.4005848  0.25730994]\n",
      "----------------------------------------\n",
      "Trial 606\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 21, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=21,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.45689655 0.54885057 0.49137931 0.43965517 0.45614035 0.55409357\n",
      " 0.56432749 0.67251462 0.57309942 0.43859649]\n",
      "----------------------------------------\n",
      "Trial 607\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 24, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=24, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.63505747 0.49425287 0.55028736 0.72413793 0.64766082 0.61403509\n",
      " 0.25       0.50877193 0.50877193 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 608\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 105, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=105,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33045977 0.38218391 0.49568966 0.56206897 0.54824561 0.55555556\n",
      " 0.54824561 0.57309942 0.44152047 0.39181287]\n",
      "----------------------------------------\n",
      "Trial 609\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 161, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=161, random_state=100))])\n",
      "cv score: [0.53448276 0.43390805 0.58477011 0.67241379 0.62134503 0.57017544\n",
      " 0.31432749 0.57894737 0.39181287 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 610\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 150, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=150,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51867816 0.4612069  0.54597701 0.45       0.5628655  0.50877193\n",
      " 0.55847953 0.64912281 0.6125731  0.47076023]\n",
      "----------------------------------------\n",
      "Trial 611\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 14, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=14, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.61781609 0.55603448 0.51149425 0.70689655 0.5248538  0.60526316\n",
      " 0.34356725 0.63011696 0.54678363 0.36403509]\n",
      "----------------------------------------\n",
      "Trial 612\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 62, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=62,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56752874 0.50574713 0.57471264 0.48965517 0.66374269 0.4619883\n",
      " 0.50292398 0.63157895 0.46491228 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 613\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 31, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=31,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56609195 0.54885057 0.57471264 0.5137931  0.66374269 0.4619883\n",
      " 0.48830409 0.66666667 0.62865497 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 614\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 92, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=92,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55316092 0.52298851 0.50287356 0.68448276 0.62280702 0.60818713\n",
      " 0.39766082 0.5497076  0.51023392 0.29532164]\n",
      "----------------------------------------\n",
      "Trial 615\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 153, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=153,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60632184 0.43103448 0.57471264 0.49827586 0.66959064 0.50730994\n",
      " 0.5497076  0.67397661 0.55994152 0.47660819]\n",
      "----------------------------------------\n",
      "Trial 616\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 191, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=191, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.54022989 0.45402299 0.56465517 0.64827586 0.66520468 0.59649123\n",
      " 0.27046784 0.54093567 0.46783626 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 617\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 18, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=18, random_state=100))])\n",
      "cv score: [0.43103448 0.42816092 0.39511494 0.6137931  0.65350877 0.47076023\n",
      " 0.35087719 0.61403509 0.4751462  0.45614035]\n",
      "----------------------------------------\n",
      "Trial 618\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 107, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=107,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36494253 0.3908046  0.65086207 0.64137931 0.6125731  0.47368421\n",
      " 0.37573099 0.52339181 0.39181287 0.23684211]\n",
      "----------------------------------------\n",
      "Trial 619\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 146, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=146, random_state=100))])\n",
      "cv score: [0.43103448 0.42816092 0.44971264 0.62758621 0.6622807  0.54093567\n",
      " 0.33187135 0.52339181 0.44444444 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 620\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 157, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=157,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3908046  0.28735632 0.5704023  0.55517241 0.65350877 0.51169591\n",
      " 0.37865497 0.4619883  0.32163743 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 621\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 89, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=89, random_state=100))])\n",
      "cv score: [0.52011494 0.42241379 0.55316092 0.62068966 0.67836257 0.52923977\n",
      " 0.31432749 0.5877193  0.41812865 0.27339181]\n",
      "----------------------------------------\n",
      "Trial 622\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 184, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=184,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37787356 0.43534483 0.39224138 0.54827586 0.59064327 0.59064327\n",
      " 0.59064327 0.62865497 0.58918129 0.28216374]\n",
      "----------------------------------------\n",
      "Trial 623\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 197, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=197,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.46264368 0.47988506 0.61063218 0.67586207 0.70614035 0.62573099\n",
      " 0.31725146 0.45321637 0.5        0.35964912]\n",
      "----------------------------------------\n",
      "Trial 624\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.37931034 0.28735632 0.66810345 0.62758621 0.50438596 0.6871345\n",
      " 0.62426901 0.38011696 0.44736842 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 625\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 75, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=75,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36206897 0.29885057 0.7112069  0.65517241 0.6505848  0.5\n",
      " 0.45760234 0.49707602 0.34795322 0.24853801]\n",
      "----------------------------------------\n",
      "Trial 626\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 38, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=12, max_features='log2',\n",
      "                                            n_estimators=38, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.52011494 0.39655172 0.51867816 0.66206897 0.60964912 0.58187135\n",
      " 0.32309942 0.49707602 0.51461988 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 627\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 20, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=20, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.5545977  0.43678161 0.51293103 0.5862069  0.62719298 0.50584795\n",
      " 0.26461988 0.52339181 0.51169591 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 628\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 195, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            n_estimators=195, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.47413793 0.4683908  0.38362069 0.55517241 0.6754386  0.52777778\n",
      " 0.52777778 0.45321637 0.47076023 0.35526316]\n",
      "----------------------------------------\n",
      "Trial 629\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 181, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=181, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.5        0.41954023 0.54454023 0.65517241 0.64181287 0.55847953\n",
      " 0.31725146 0.49415205 0.47076023 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 630\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 129, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=129,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.51436782 0.4454023  0.60488506 0.67413793 0.66520468 0.5994152\n",
      " 0.29093567 0.44736842 0.44736842 0.39181287]\n",
      "----------------------------------------\n",
      "Trial 631\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 144, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=144, random_state=100))])\n",
      "cv score: [0.48275862 0.50574713 0.50718391 0.64827586 0.54239766 0.5877193\n",
      " 0.39327485 0.57309942 0.46491228 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 632\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 21, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=21,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54454023 0.54310345 0.49425287 0.62931034 0.6125731  0.55847953\n",
      " 0.46052632 0.49707602 0.5380117  0.3494152 ]\n",
      "----------------------------------------\n",
      "Trial 633\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 67, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=67, random_state=100))])\n",
      "cv score: [0.50287356 0.51149425 0.44683908 0.58275862 0.54385965 0.55555556\n",
      " 0.4254386  0.5628655  0.5380117  0.47660819]\n",
      "----------------------------------------\n",
      "Trial 634\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 28, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=28,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.56321839 0.51724138 0.48706897 0.68793103 0.62573099 0.60672515\n",
      " 0.41666667 0.53508772 0.52631579 0.28362573]\n",
      "----------------------------------------\n",
      "Trial 635\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 164, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=164, random_state=100))])\n",
      "cv score: [0.5316092  0.47413793 0.58189655 0.64137931 0.65789474 0.52046784\n",
      " 0.28508772 0.57309942 0.39619883 0.29385965]\n",
      "----------------------------------------\n",
      "Trial 636\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 154, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=154,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.45114943 0.5158046  0.32931034 0.53362573 0.46345029\n",
      " 0.38157895 0.32748538 0.48391813 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 637\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=174,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49712644 0.60632184 0.5        0.32068966 0.59064327 0.41374269\n",
      " 0.37719298 0.29532164 0.55116959 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 638\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 43, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=14,\n",
      "                                            n_estimators=43, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.47988506 0.45114943 0.50143678 0.5862069  0.69444444 0.45321637\n",
      " 0.33333333 0.4619883  0.51461988 0.26900585]\n",
      "----------------------------------------\n",
      "Trial 639\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 94, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=94,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45114943 0.35057471 0.69109195 0.62413793 0.62426901 0.57894737\n",
      " 0.46637427 0.4619883  0.36549708 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 640\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 1.0, 'gb__learning_rate': 0.3, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=145,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.61781609 0.3908046  0.60488506 0.65862069 0.55701754 0.61988304\n",
      " 0.4254386  0.4619883  0.42982456 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 641\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 181, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=181, random_state=100))])\n",
      "cv score: [0.50287356 0.45689655 0.4683908  0.57068966 0.5877193  0.56432749\n",
      " 0.45467836 0.57017544 0.49707602 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 642\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 49, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=49,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.46408046 0.43534483 0.50143678 0.49827586 0.55847953 0.63304094\n",
      " 0.4502924  0.61695906 0.48538012 0.39912281]\n",
      "----------------------------------------\n",
      "Trial 643\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 186, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=186,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.45114943 0.5158046  0.33275862 0.53362573 0.46345029\n",
      " 0.38157895 0.32748538 0.48391813 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 644\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 54, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=54,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.40229885 0.59913793 0.54827586 0.61842105 0.47660819\n",
      " 0.46052632 0.47953216 0.33918129 0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 645\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 17, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=17,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.45114943 0.5158046  0.3362069  0.53362573 0.46345029\n",
      " 0.38157895 0.32748538 0.48391813 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 646\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 130, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=6,\n",
      "                                            n_estimators=130,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.54022989 0.44109195 0.54022989 0.54827586 0.65935673 0.47222222\n",
      " 0.33187135 0.45321637 0.5628655  0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 647\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 13, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=2,\n",
      "                                            n_estimators=13, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.60344828 0.60201149 0.59482759 0.53448276 0.69444444 0.62134503\n",
      " 0.44298246 0.57748538 0.60818713 0.5248538 ]\n",
      "----------------------------------------\n",
      "Trial 648\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 87, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=87,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.37068966 0.44827586 0.51293103 0.56206897 0.53362573 0.51754386\n",
      " 0.49269006 0.50584795 0.35380117 0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 649\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 75, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=75,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.46551724 0.49425287 0.54454023 0.66551724 0.7002924  0.57017544\n",
      " 0.27339181 0.47076023 0.46491228 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 650\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 23, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=23, random_state=100))])\n",
      "cv score: [0.43390805 0.44109195 0.5316092  0.53103448 0.68567251 0.51461988\n",
      " 0.29532164 0.48830409 0.46345029 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 651\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 34, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=34, random_state=100))])\n",
      "cv score: [0.55172414 0.4612069  0.54454023 0.58275862 0.67397661 0.48976608\n",
      " 0.31432749 0.46637427 0.48538012 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 652\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 136, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=136,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.31896552 0.28448276 0.53017241 0.6        0.48391813 0.63157895\n",
      " 0.60672515 0.36842105 0.42982456 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 653\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 37, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=37,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5545977  0.52873563 0.57471264 0.47758621 0.62865497 0.46052632\n",
      " 0.54532164 0.68128655 0.57894737 0.5248538 ]\n",
      "----------------------------------------\n",
      "Trial 654\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 106, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=106, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.50287356 0.39367816 0.57902299 0.64137931 0.58040936 0.65497076\n",
      " 0.36403509 0.49707602 0.48830409 0.40935673]\n",
      "----------------------------------------\n",
      "Trial 655\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 164, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=164,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48563218 0.41954023 0.74856322 0.58965517 0.55116959 0.66081871\n",
      " 0.58333333 0.34210526 0.42690058 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 656\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 158, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=158, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.51436782 0.43678161 0.51293103 0.66206897 0.6622807  0.60233918\n",
      " 0.32602339 0.54093567 0.4619883  0.32748538]\n",
      "----------------------------------------\n",
      "Trial 657\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 175, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=175,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52586207 0.56321839 0.49568966 0.6137931  0.63450292 0.60380117\n",
      " 0.39181287 0.59064327 0.54239766 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 658\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43390805 0.40804598 0.68247126 0.63793103 0.5248538  0.63157895\n",
      " 0.64473684 0.40643275 0.43274854 0.41520468]\n",
      "----------------------------------------\n",
      "Trial 659\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35632184 0.37068966 0.59913793 0.63793103 0.49853801 0.54385965\n",
      " 0.46929825 0.44152047 0.3625731  0.27192982]\n",
      "----------------------------------------\n",
      "Trial 660\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 192, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=192,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55747126 0.53448276 0.50143678 0.67413793 0.60818713 0.59649123\n",
      " 0.38888889 0.55847953 0.50730994 0.29532164]\n",
      "----------------------------------------\n",
      "Trial 661\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 41, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=41, random_state=100))])\n",
      "cv score: [0.54310345 0.45114943 0.55890805 0.67758621 0.49853801 0.56432749\n",
      " 0.37573099 0.56725146 0.4619883  0.36111111]\n",
      "----------------------------------------\n",
      "Trial 662\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 124, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=124, random_state=100))])\n",
      "cv score: [0.51436782 0.44827586 0.58189655 0.7        0.62426901 0.56725146\n",
      " 0.30555556 0.56432749 0.42690058 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 663\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 145, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=145,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.60632184 0.5        0.32068966 0.59064327 0.41374269\n",
      " 0.37719298 0.29532164 0.55116959 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 664\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 31, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=31,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56609195 0.58045977 0.57471264 0.5137931  0.66374269 0.4619883\n",
      " 0.46491228 0.62719298 0.47368421 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 665\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.47988506 0.4454023  0.52155172 0.71034483 0.64766082 0.65497076\n",
      " 0.29678363 0.53508772 0.50584795 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 666\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 91, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=91,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.47701149 0.38362069 0.39310345 0.60380117 0.33918129\n",
      " 0.40350877 0.57017544 0.62573099 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 667\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 34, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=34,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55028736 0.55172414 0.50574713 0.63965517 0.63304094 0.56725146\n",
      " 0.4122807  0.54093567 0.54093567 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 668\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 165, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=165, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.38793103 0.37068966 0.4612069  0.48275862 0.40935673 0.38304094\n",
      " 0.60526316 0.39035088 0.35964912 0.44590643]\n",
      "----------------------------------------\n",
      "Trial 669\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 128, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=128, random_state=100))])\n",
      "cv score: [0.44252874 0.51436782 0.47557471 0.6137931  0.60672515 0.59356725\n",
      " 0.39035088 0.56432749 0.45906433 0.42105263]\n",
      "----------------------------------------\n",
      "Trial 670\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 82, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=82, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.42816092 0.39367816 0.42385057 0.6        0.64181287 0.52046784\n",
      " 0.32309942 0.52923977 0.44736842 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 671\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=70, random_state=100))])\n",
      "cv score: [0.42241379 0.4683908  0.51005747 0.57586207 0.58040936 0.51461988\n",
      " 0.3874269  0.55555556 0.51169591 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 672\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 55, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=55,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38793103 0.34195402 0.59051724 0.55862069 0.52777778 0.49707602\n",
      " 0.47222222 0.52339181 0.31578947 0.29532164]\n",
      "----------------------------------------\n",
      "Trial 673\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 159, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=159, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.48275862 0.45114943 0.61350575 0.62068966 0.64473684 0.5497076\n",
      " 0.30263158 0.50584795 0.44736842 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 674\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 163, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=163,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.54885057 0.4454023  0.53017241 0.65862069 0.62426901 0.45906433\n",
      " 0.40204678 0.50292398 0.51169591 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 675\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36781609 0.3908046  0.55316092 0.57241379 0.51608187 0.53508772\n",
      " 0.4371345  0.5497076  0.34795322 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 676\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 128, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=128,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53017241 0.57183908 0.50143678 0.62413793 0.63450292 0.60672515\n",
      " 0.39473684 0.59356725 0.55409357 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 677\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 34, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=34,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36063218 0.33333333 0.51005747 0.54310345 0.50584795 0.55847953\n",
      " 0.43128655 0.60233918 0.32309942 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 678\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 19, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=19,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5387931  0.49281609 0.52442529 0.46206897 0.58187135 0.57163743\n",
      " 0.55701754 0.55994152 0.57748538 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 679\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 109, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=109,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.36494253 0.37356322 0.49856322 0.57931034 0.49561404 0.59649123\n",
      " 0.4371345  0.5380117  0.37426901 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 680\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 11, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=11, random_state=100))])\n",
      "cv score: [0.55028736 0.47701149 0.5158046  0.62241379 0.57748538 0.53508772\n",
      " 0.36695906 0.40643275 0.53070175 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 681\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 56, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=56,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49568966 0.46551724 0.55747126 0.51551724 0.64912281 0.51608187\n",
      " 0.53508772 0.65204678 0.62134503 0.52777778]\n",
      "----------------------------------------\n",
      "Trial 682\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 139, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=139,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37356322 0.38793103 0.58189655 0.58275862 0.53654971 0.45614035\n",
      " 0.39912281 0.52923977 0.33625731 0.23099415]\n",
      "----------------------------------------\n",
      "Trial 683\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 43, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=43, random_state=100))])\n",
      "cv score: [0.45977011 0.37068966 0.54166667 0.60344828 0.69152047 0.50877193\n",
      " 0.25438596 0.57017544 0.37719298 0.26461988]\n",
      "----------------------------------------\n",
      "Trial 684\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 81, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=81,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56321839 0.47701149 0.49137931 0.44827586 0.57309942 0.53947368\n",
      " 0.61403509 0.66374269 0.44736842 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 685\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 61, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=61,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49281609 0.46551724 0.52729885 0.63448276 0.68567251 0.60233918\n",
      " 0.3128655  0.51754386 0.47953216 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 686\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 191, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            n_estimators=191, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.65229885 0.64367816 0.59626437 0.75172414 0.57748538 0.38304094\n",
      " 0.50146199 0.38596491 0.7119883  0.38304094]\n",
      "----------------------------------------\n",
      "Trial 687\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=198, random_state=100))])\n",
      "cv score: [0.40804598 0.42816092 0.44396552 0.62413793 0.64181287 0.54385965\n",
      " 0.32017544 0.52339181 0.4619883  0.30409357]\n",
      "----------------------------------------\n",
      "Trial 688\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 150, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            n_estimators=150, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.46551724 0.46551724 0.4841954  0.58275862 0.73830409 0.53216374\n",
      " 0.30263158 0.5        0.47076023 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 689\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 163, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=163, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.55747126 0.44252874 0.55028736 0.63793103 0.64181287 0.54678363\n",
      " 0.25877193 0.58479532 0.42397661 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 690\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 140, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=140,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.38505747 0.37643678 0.66522989 0.62068966 0.67690058 0.60818713\n",
      " 0.50146199 0.52631579 0.38596491 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 691\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 41, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=41, random_state=100))])\n",
      "cv score: [0.6091954  0.51149425 0.56752874 0.62758621 0.58479532 0.52339181\n",
      " 0.38450292 0.57309942 0.42690058 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 692\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 122, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=2, max_features='log2',\n",
      "                                            n_estimators=122, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.52298851 0.54310345 0.58477011 0.67586207 0.52777778 0.64619883\n",
      " 0.33187135 0.59210526 0.54678363 0.39327485]\n",
      "----------------------------------------\n",
      "Trial 693\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 93, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=93,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40229885 0.42528736 0.7887931  0.65517241 0.61842105 0.49707602\n",
      " 0.32894737 0.5380117  0.32748538 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 694\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 28, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=28,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53735632 0.47270115 0.48706897 0.69655172 0.59210526 0.65643275\n",
      " 0.34502924 0.50584795 0.51754386 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 695\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 59, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=59, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.47126437 0.56896552 0.51867816 0.60344828 0.51608187 0.66959064\n",
      " 0.55116959 0.39619883 0.61695906 0.52046784]\n",
      "----------------------------------------\n",
      "Trial 696\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 35, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=35, random_state=100))])\n",
      "cv score: [0.55172414 0.45114943 0.57614943 0.67241379 0.50438596 0.53216374\n",
      " 0.35526316 0.63157895 0.48684211 0.30263158]\n",
      "----------------------------------------\n",
      "Trial 697\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 15, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=15, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.50431034 0.40229885 0.47844828 0.67413793 0.72368421 0.64912281\n",
      " 0.35526316 0.48538012 0.54824561 0.24853801]\n",
      "----------------------------------------\n",
      "Trial 698\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 146, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=146, random_state=100))])\n",
      "cv score: [0.47701149 0.44109195 0.50287356 0.61034483 0.67105263 0.46345029\n",
      " 0.31140351 0.61403509 0.36988304 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 699\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 68, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=68,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4841954  0.42097701 0.48275862 0.44655172 0.45906433 0.52777778\n",
      " 0.58333333 0.67690058 0.47076023 0.4502924 ]\n",
      "----------------------------------------\n",
      "Trial 700\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 89, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=89, random_state=100))])\n",
      "cv score: [0.43534483 0.44827586 0.53017241 0.53448276 0.55701754 0.53508772\n",
      " 0.46052632 0.5497076  0.53508772 0.48538012]\n",
      "----------------------------------------\n",
      "Trial 701\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 143, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=143,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.50287356 0.50862069 0.57758621 0.45       0.51461988 0.59502924\n",
      " 0.49415205 0.64035088 0.52631579 0.43421053]\n",
      "----------------------------------------\n",
      "Trial 702\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 195, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=195,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37931034 0.33908046 0.67385057 0.66551724 0.53947368 0.66959064\n",
      " 0.51900585 0.3625731  0.47660819 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 703\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 198, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=198,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44827586 0.34770115 0.5933908  0.51034483 0.66812865 0.54678363\n",
      " 0.49561404 0.55263158 0.23099415 0.42690058]\n",
      "----------------------------------------\n",
      "Trial 704\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 11, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=11,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.59770115 0.55028736 0.60344828 0.63793103 0.73099415 0.34356725\n",
      " 0.29093567 0.50584795 0.40204678 0.37865497]\n",
      "----------------------------------------\n",
      "Trial 705\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 71, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=71, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.44827586 0.40229885 0.59626437 0.64137931 0.69736842 0.56432749\n",
      " 0.30263158 0.45614035 0.42690058 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 706\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 35, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=35,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44252874 0.41091954 0.69971264 0.75862069 0.48684211 0.63450292\n",
      " 0.55994152 0.45906433 0.46783626 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 707\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 150, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=150,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41666667 0.29597701 0.58764368 0.56551724 0.66812865 0.54678363\n",
      " 0.31432749 0.53508772 0.30701754 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 708\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 28, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=28, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.54885057 0.4454023  0.46408046 0.72413793 0.68274854 0.57894737\n",
      " 0.2997076  0.55555556 0.52046784 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 709\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 80, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=80,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.3591954  0.35344828 0.625      0.59655172 0.58333333 0.57309942\n",
      " 0.48684211 0.47953216 0.32748538 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 710\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=171,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51867816 0.4454023  0.55316092 0.65172414 0.70321637 0.61111111\n",
      " 0.31871345 0.49707602 0.45906433 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 711\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 172, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            n_estimators=172, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.40517241 0.4683908  0.54166667 0.69137931 0.59795322 0.40497076\n",
      " 0.60672515 0.26315789 0.56140351 0.49415205]\n",
      "----------------------------------------\n",
      "Trial 712\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 74, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='log2', n_estimators=74,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49281609 0.45977011 0.5387931  0.64482759 0.69152047 0.61111111\n",
      " 0.31871345 0.51169591 0.47953216 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 713\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 40, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=40, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.5316092  0.30747126 0.67097701 0.55862069 0.58918129 0.42105263\n",
      " 0.44590643 0.38888889 0.5        0.36549708]\n",
      "----------------------------------------\n",
      "Trial 714\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            n_estimators=68, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.48275862 0.5316092  0.51005747 0.60344828 0.75877193 0.46783626\n",
      " 0.31432749 0.5        0.48830409 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 715\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 164, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, n_estimators=164,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.47988506 0.47701149 0.44971264 0.5862069  0.66812865 0.57017544\n",
      " 0.31432749 0.46491228 0.51461988 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 716\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 72, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=72, random_state=100))])\n",
      "cv score: [0.50287356 0.45114943 0.49712644 0.53103448 0.64766082 0.48830409\n",
      " 0.32309942 0.5497076  0.39912281 0.28947368]\n",
      "----------------------------------------\n",
      "Trial 717\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=38,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.49425287 0.5387931  0.63448276 0.73391813 0.54093567\n",
      " 0.23830409 0.49415205 0.47076023 0.39327485]\n",
      "----------------------------------------\n",
      "Trial 718\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 25, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=25,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36781609 0.36494253 0.56465517 0.43793103 0.54093567 0.49122807\n",
      " 0.33625731 0.63450292 0.37865497 0.26315789]\n",
      "----------------------------------------\n",
      "Trial 719\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 62, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=62, random_state=100))])\n",
      "cv score: [0.51867816 0.45689655 0.52155172 0.54827586 0.65350877 0.49707602\n",
      " 0.33187135 0.5628655  0.43128655 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 720\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            n_estimators=170, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.46264368 0.47126437 0.52155172 0.57931034 0.71783626 0.45321637\n",
      " 0.27923977 0.47368421 0.5        0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 721\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.38793103 0.3908046  0.58477011 0.55517241 0.58625731 0.5497076\n",
      " 0.44590643 0.5497076  0.42690058 0.26315789]\n",
      "----------------------------------------\n",
      "Trial 722\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 49, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=49, random_state=100))])\n",
      "cv score: [0.5316092  0.49425287 0.55028736 0.56551724 0.66520468 0.47076023\n",
      " 0.30409357 0.53654971 0.42982456 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 723\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 47, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=47, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.51149425 0.42816092 0.52155172 0.65172414 0.69152047 0.56432749\n",
      " 0.30263158 0.54385965 0.44152047 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 724\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 103, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=103,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.60632184 0.5        0.32068966 0.59064327 0.41374269\n",
      " 0.37719298 0.29532164 0.55116959 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 725\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 100, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt',\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52873563 0.47701149 0.57614943 0.62413793 0.73099415 0.57602339\n",
      " 0.22953216 0.45906433 0.47076023 0.41812865]\n",
      "----------------------------------------\n",
      "Trial 726\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 35, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, max_features='sqrt',\n",
      "                                            n_estimators=35, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.54597701 0.41091954 0.57902299 0.6137931  0.63304094 0.58187135\n",
      " 0.25877193 0.52339181 0.3128655  0.40643275]\n",
      "----------------------------------------\n",
      "Trial 727\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 23, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            n_estimators=23, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.46551724 0.45977011 0.56321839 0.55344828 0.47076023 0.36403509\n",
      " 0.51754386 0.52777778 0.64035088 0.67982456]\n",
      "----------------------------------------\n",
      "Trial 728\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=38,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50718391 0.47844828 0.51436782 0.66551724 0.68567251 0.57017544\n",
      " 0.30263158 0.51754386 0.47953216 0.34649123]\n",
      "----------------------------------------\n",
      "Trial 729\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 61, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=61,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50431034 0.50574713 0.51436782 0.57413793 0.64181287 0.61842105\n",
      " 0.45467836 0.60233918 0.55701754 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 730\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 53, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            n_estimators=53, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.51149425 0.5        0.47413793 0.57931034 0.28362573 0.48684211\n",
      " 0.56140351 0.46783626 0.48684211 0.41520468]\n",
      "----------------------------------------\n",
      "Trial 731\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 107, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=107,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.45114943 0.5387931  0.48706897 0.37413793 0.58187135 0.35672515\n",
      " 0.39327485 0.40350877 0.62719298 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 732\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47413793 0.31609195 0.59913793 0.65172414 0.57748538 0.54385965\n",
      " 0.5628655  0.4502924  0.37134503 0.48538012]\n",
      "----------------------------------------\n",
      "Trial 733\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 10, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=10,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49856322 0.43965517 0.57471264 0.46551724 0.66666667 0.59064327\n",
      " 0.50438596 0.64181287 0.53216374 0.51461988]\n",
      "----------------------------------------\n",
      "Trial 734\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 180, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=180,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52011494 0.40948276 0.54597701 0.47758621 0.57309942 0.53508772\n",
      " 0.53362573 0.66666667 0.52046784 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 735\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=168, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.54597701 0.43678161 0.56178161 0.64827586 0.66812865 0.60233918\n",
      " 0.26754386 0.5380117  0.45614035 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 736\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 124, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=124, random_state=100))])\n",
      "cv score: [0.51436782 0.44827586 0.58189655 0.7        0.62426901 0.56725146\n",
      " 0.30555556 0.56432749 0.42690058 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 737\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 192, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=192,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34770115 0.3591954  0.60201149 0.59310345 0.54532164 0.58479532\n",
      " 0.42251462 0.47076023 0.4122807  0.29824561]\n",
      "----------------------------------------\n",
      "Trial 738\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 72, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=72, random_state=100))])\n",
      "cv score: [0.54597701 0.38362069 0.57614943 0.62068966 0.64473684 0.53216374\n",
      " 0.37573099 0.50292398 0.39619883 0.31432749]\n",
      "----------------------------------------\n",
      "Trial 739\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 120, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=120, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.47988506 0.44252874 0.50143678 0.72413793 0.63596491 0.61111111\n",
      " 0.37280702 0.53216374 0.44152047 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 740\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 184, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=184, random_state=100))])\n",
      "cv score: [0.5        0.49425287 0.49281609 0.64137931 0.53654971 0.61111111\n",
      " 0.40497076 0.58479532 0.45906433 0.39181287]\n",
      "----------------------------------------\n",
      "Trial 741\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 130, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            n_estimators=130, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.52586207 0.45977011 0.5704023  0.62413793 0.68567251 0.42690058\n",
      " 0.36111111 0.4005848  0.40643275 0.4502924 ]\n",
      "----------------------------------------\n",
      "Trial 742\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 34, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=34, random_state=100))])\n",
      "cv score: [0.5545977  0.44252874 0.61206897 0.64137931 0.65935673 0.51461988\n",
      " 0.24853801 0.54239766 0.48099415 0.30847953]\n",
      "----------------------------------------\n",
      "Trial 743\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44252874 0.25862069 0.77442529 0.65172414 0.5628655  0.62280702\n",
      " 0.68859649 0.36549708 0.44736842 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 744\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 43, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=43,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.40229885 0.37356322 0.67385057 0.61034483 0.55116959 0.64912281\n",
      " 0.43421053 0.52631579 0.45467836 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 745\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 79, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=79,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60344828 0.56321839 0.57471264 0.52758621 0.48245614 0.43274854\n",
      " 0.46491228 0.64035088 0.47368421 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 746\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51724138 0.43821839 0.54597701 0.44482759 0.56871345 0.56578947\n",
      " 0.52923977 0.63450292 0.54385965 0.46345029]\n",
      "----------------------------------------\n",
      "Trial 747\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 42, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=42,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57758621 0.45689655 0.56752874 0.39137931 0.70321637 0.49561404\n",
      " 0.3245614  0.40350877 0.31578947 0.4254386 ]\n",
      "----------------------------------------\n",
      "Trial 748\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 161, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=12,\n",
      "                                            n_estimators=161, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.70977011 0.62643678 0.4066092  0.55862069 0.54239766 0.5877193\n",
      " 0.35818713 0.4005848  0.3625731  0.52339181]\n",
      "----------------------------------------\n",
      "Trial 749\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 110, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=110, random_state=100))])\n",
      "cv score: [0.48275862 0.44252874 0.5        0.55517241 0.62719298 0.4619883\n",
      " 0.31432749 0.61111111 0.40350877 0.30263158]\n",
      "----------------------------------------\n",
      "Trial 750\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 180, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=180, random_state=100))])\n",
      "cv score: [0.47988506 0.44252874 0.51005747 0.56551724 0.64766082 0.45906433\n",
      " 0.29532164 0.61403509 0.38304094 0.30847953]\n",
      "----------------------------------------\n",
      "Trial 751\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=58, random_state=100))])\n",
      "cv score: [0.46264368 0.37643678 0.53591954 0.58965517 0.7002924  0.51169591\n",
      " 0.25292398 0.54093567 0.4122807  0.26023392]\n",
      "----------------------------------------\n",
      "Trial 752\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 186, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=186, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.54310345 0.5316092  0.48994253 0.65862069 0.54385965 0.63450292\n",
      " 0.37573099 0.5994152  0.49415205 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 753\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 187, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            n_estimators=187, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.50574713 0.48275862 0.49568966 0.58275862 0.7119883  0.56140351\n",
      " 0.23245614 0.43859649 0.55555556 0.43859649]\n",
      "----------------------------------------\n",
      "Trial 754\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 69, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            n_estimators=69, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.45689655 0.53735632 0.53591954 0.56896552 0.74122807 0.55263158\n",
      " 0.39619883 0.52631579 0.38596491 0.29532164]\n",
      "----------------------------------------\n",
      "Trial 755\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 91, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=91,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43103448 0.37068966 0.60488506 0.69310345 0.63304094 0.57309942\n",
      " 0.45760234 0.52923977 0.28362573 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 756\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 50, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=50, random_state=100))])\n",
      "cv score: [0.51724138 0.39655172 0.5933908  0.63103448 0.65204678 0.51608187\n",
      " 0.27923977 0.52923977 0.41666667 0.29678363]\n",
      "----------------------------------------\n",
      "Trial 757\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 70, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=70,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57758621 0.47701149 0.54022989 0.38275862 0.62573099 0.5\n",
      " 0.36403509 0.4122807  0.30701754 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 758\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 113, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=113, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.52873563 0.23132184 0.55028736 0.35517241 0.44444444 0.45906433\n",
      " 0.3494152  0.42836257 0.54239766 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 759\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 78, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=78,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55316092 0.55603448 0.59195402 0.45689655 0.63157895 0.51023392\n",
      " 0.53508772 0.62134503 0.58040936 0.47807018]\n",
      "----------------------------------------\n",
      "Trial 760\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 30, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=30,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53735632 0.49137931 0.69396552 0.68275862 0.73538012 0.5628655\n",
      " 0.25877193 0.47660819 0.41812865 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 761\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 131, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=131, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.49712644 0.51436782 0.5158046  0.57241379 0.63888889 0.49707602\n",
      " 0.3377193  0.57602339 0.41812865 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 762\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=38,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.49425287 0.5387931  0.63448276 0.73391813 0.54093567\n",
      " 0.23830409 0.49415205 0.47076023 0.39327485]\n",
      "----------------------------------------\n",
      "Trial 763\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 63, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=63,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36781609 0.33908046 0.5933908  0.60344828 0.58040936 0.52046784\n",
      " 0.52777778 0.5        0.36842105 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 764\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 87, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.3, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=87,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55316092 0.54022989 0.54310345 0.4862069  0.64327485 0.51023392\n",
      " 0.49269006 0.6622807  0.64327485 0.53654971]\n",
      "----------------------------------------\n",
      "Trial 765\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 26, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=11,\n",
      "                                            n_estimators=26, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.46551724 0.51436782 0.51293103 0.55172414 0.75       0.50877193\n",
      " 0.28947368 0.46783626 0.45614035 0.43274854]\n",
      "----------------------------------------\n",
      "Trial 766\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 27, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=27,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56321839 0.52011494 0.49137931 0.49310345 0.66374269 0.43274854\n",
      " 0.46491228 0.65935673 0.40350877 0.44736842]\n",
      "----------------------------------------\n",
      "Trial 767\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 183, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=183, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.57471264 0.38218391 0.59051724 0.6862069  0.55116959 0.60233918\n",
      " 0.36695906 0.44736842 0.47076023 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 768\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 40, 'gb__subsample': 0.75, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=40, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.55747126 0.44827586 0.54454023 0.64482759 0.53070175 0.59356725\n",
      " 0.32602339 0.47076023 0.46783626 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 769\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 150, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=150, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.50574713 0.43678161 0.49568966 0.65172414 0.64473684 0.5380117\n",
      " 0.30555556 0.50877193 0.45906433 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 770\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 168, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=168,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.5316092  0.51005747 0.66724138 0.62573099 0.58187135\n",
      " 0.38596491 0.55555556 0.50146199 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 771\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 45, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=45, random_state=100))])\n",
      "cv score: [0.42241379 0.44827586 0.41235632 0.66551724 0.73538012 0.50877193\n",
      " 0.31140351 0.5380117  0.42982456 0.2997076 ]\n",
      "----------------------------------------\n",
      "Trial 772\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 87, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=87,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40517241 0.31034483 0.74281609 0.67586207 0.51608187 0.65497076\n",
      " 0.63011696 0.42982456 0.47076023 0.41520468]\n",
      "----------------------------------------\n",
      "Trial 773\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 58, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=58, random_state=100))])\n",
      "cv score: [0.52586207 0.45402299 0.54022989 0.55172414 0.6622807  0.50730994\n",
      " 0.33479532 0.51315789 0.4371345  0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 774\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 197, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=197, random_state=100))])\n",
      "cv score: [0.43390805 0.40517241 0.50431034 0.63793103 0.67982456 0.50877193\n",
      " 0.26461988 0.47076023 0.42982456 0.28362573]\n",
      "----------------------------------------\n",
      "Trial 775\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 153, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=153,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.38505747 0.42241379 0.59913793 0.54827586 0.6505848  0.46783626\n",
      " 0.31725146 0.55555556 0.40643275 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 776\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 63, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            n_estimators=63, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.39367816 0.45402299 0.31321839 0.4137931  0.61549708 0.43567251\n",
      " 0.50146199 0.51754386 0.56432749 0.41520468]\n",
      "----------------------------------------\n",
      "Trial 777\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 29, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=29,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56752874 0.48275862 0.49137931 0.47413793 0.48245614 0.43274854\n",
      " 0.46491228 0.5        0.47368421 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 778\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=159,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52729885 0.56321839 0.50431034 0.60344828 0.6374269  0.60672515\n",
      " 0.38888889 0.60526316 0.54239766 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 779\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 46, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=46,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4137931  0.42528736 0.66522989 0.62758621 0.6622807  0.45906433\n",
      " 0.38450292 0.53508772 0.38011696 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 780\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 50, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=50,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57183908 0.54885057 0.57471264 0.51551724 0.48245614 0.4619883\n",
      " 0.46491228 0.63888889 0.46491228 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 781\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=121, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.43390805 0.48994253 0.65517241 0.46896552 0.46052632 0.46929825\n",
      " 0.46345029 0.63596491 0.37573099 0.48391813]\n",
      "----------------------------------------\n",
      "Trial 782\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 18, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=18, random_state=100))])\n",
      "cv score: [0.41666667 0.46551724 0.38218391 0.59137931 0.70321637 0.46637427\n",
      " 0.30555556 0.57017544 0.48245614 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 783\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 173, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07,\n",
      "                                            n_estimators=173, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.4454023  0.35632184 0.51005747 0.66896552 0.6505848  0.61695906\n",
      " 0.35526316 0.42105263 0.52046784 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 784\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 21, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=21, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.55172414 0.22701149 0.48706897 0.36206897 0.49707602 0.25438596\n",
      " 0.44883041 0.5877193  0.39181287 0.27192982]\n",
      "----------------------------------------\n",
      "Trial 785\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 188, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=188, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49712644 0.40804598 0.53017241 0.61034483 0.65935673 0.49415205\n",
      " 0.28654971 0.55847953 0.38011696 0.30555556]\n",
      "----------------------------------------\n",
      "Trial 786\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34770115 0.39655172 0.59626437 0.57241379 0.54678363 0.63450292\n",
      " 0.4254386  0.5        0.45760234 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 787\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 36, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=36,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39942529 0.35344828 0.69396552 0.63793103 0.6505848  0.64912281\n",
      " 0.34356725 0.4502924  0.54385965 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 788\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 83, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=83, random_state=100))])\n",
      "cv score: [0.48850575 0.44252874 0.52729885 0.52068966 0.56725146 0.52192982\n",
      " 0.43567251 0.54093567 0.48099415 0.48391813]\n",
      "----------------------------------------\n",
      "Trial 789\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 0.65, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='log2',\n",
      "                                            n_estimators=68, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.50287356 0.44827586 0.55316092 0.70344828 0.59502924 0.60526316\n",
      " 0.36403509 0.61695906 0.51169591 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 790\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 42, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=42,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.54885057 0.57471264 0.46896552 0.48245614 0.43274854\n",
      " 0.55555556 0.67251462 0.46491228 0.44736842]\n",
      "----------------------------------------\n",
      "Trial 791\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 77, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='sqrt',\n",
      "                                            n_estimators=77, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.53735632 0.43390805 0.63074713 0.73793103 0.58625731 0.63450292\n",
      " 0.39619883 0.53508772 0.52046784 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 792\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=108, random_state=100))])\n",
      "cv score: [0.53735632 0.43965517 0.57614943 0.65172414 0.6754386  0.52631579\n",
      " 0.29678363 0.59064327 0.40935673 0.28362573]\n",
      "----------------------------------------\n",
      "Trial 793\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 45, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=45,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43678161 0.51005747 0.40517241 0.52068966 0.62280702 0.54385965\n",
      " 0.59649123 0.64181287 0.51461988 0.4619883 ]\n",
      "----------------------------------------\n",
      "Trial 794\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 44, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=44, random_state=100))])\n",
      "cv score: [0.46264368 0.3591954  0.53304598 0.61034483 0.69444444 0.50877193\n",
      " 0.25438596 0.56725146 0.37426901 0.25877193]\n",
      "----------------------------------------\n",
      "Trial 795\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 58, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            n_estimators=58,\n",
      "                                            random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49137931 0.46551724 0.50143678 0.57586207 0.67105263 0.5877193\n",
      " 0.31432749 0.47953216 0.47953216 0.4005848 ]\n",
      "----------------------------------------\n",
      "Trial 796\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 153, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=153,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.38218391 0.66235632 0.67241379 0.63888889 0.52339181\n",
      " 0.38157895 0.49415205 0.30409357 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 797\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 151, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=151,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51436782 0.48563218 0.59051724 0.62758621 0.74707602 0.57163743\n",
      " 0.22368421 0.4502924  0.49415205 0.40935673]\n",
      "----------------------------------------\n",
      "Trial 798\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 16, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=16, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.53304598 0.46695402 0.55603448 0.65517241 0.71052632 0.7119883\n",
      " 0.23245614 0.41959064 0.42397661 0.42251462]\n",
      "----------------------------------------\n",
      "Trial 799\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 18, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, n_estimators=18,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.43390805 0.46264368 0.53304598 0.56206897 0.69152047 0.43421053\n",
      " 0.42836257 0.52046784 0.58333333 0.41081871]\n",
      "----------------------------------------\n",
      "Trial 800\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=133, random_state=100))])\n",
      "cv score: [0.51149425 0.42241379 0.54741379 0.60689655 0.66812865 0.48099415\n",
      " 0.26754386 0.58479532 0.38888889 0.2880117 ]\n",
      "----------------------------------------\n",
      "Trial 801\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 189, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=10, n_estimators=189,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.50574713 0.42241379 0.41810345 0.60344828 0.64473684 0.54678363\n",
      " 0.29678363 0.50292398 0.52339181 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 802\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 126, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=126,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52873563 0.39798851 0.53735632 0.46034483 0.56871345 0.50730994\n",
      " 0.50877193 0.66666667 0.55994152 0.49707602]\n",
      "----------------------------------------\n",
      "Trial 803\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 166, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            n_estimators=166, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.4454023  0.39942529 0.44683908 0.59310345 0.7002924  0.55847953\n",
      " 0.29385965 0.50292398 0.46783626 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 804\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 100, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.45689655 0.40229885 0.47557471 0.53793103 0.72660819 0.46783626\n",
      " 0.33918129 0.52046784 0.45906433 0.22807018]\n",
      "----------------------------------------\n",
      "Trial 805\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 165, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            n_estimators=165, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.44827586 0.53448276 0.43534483 0.57931034 0.68859649 0.52923977\n",
      " 0.39912281 0.53216374 0.58479532 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 806\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 67, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=67,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50862069 0.45689655 0.65086207 0.63275862 0.72807018 0.56725146\n",
      " 0.20906433 0.42982456 0.49415205 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 807\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 73, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=73,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.30316092 0.56752874 0.40373563 0.54310345 0.54532164 0.42690058\n",
      " 0.44152047 0.67690058 0.63450292 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 808\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 124, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            n_estimators=124, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.46264368 0.4137931  0.54454023 0.60344828 0.7002924  0.47076023\n",
      " 0.30555556 0.50292398 0.52339181 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 809\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 180, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=180, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.51005747 0.60057471 0.46982759 0.56896552 0.63157895 0.59795322\n",
      " 0.4502924  0.66374269 0.61549708 0.53216374]\n",
      "----------------------------------------\n",
      "Trial 810\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=14, random_state=100))])\n",
      "cv score: [0.64942529 0.4612069  0.58189655 0.71034483 0.6622807  0.59210526\n",
      " 0.38888889 0.50292398 0.51754386 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 811\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 150, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=150, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.47701149 0.39367816 0.50143678 0.73448276 0.69444444 0.53508772\n",
      " 0.50877193 0.47368421 0.44298246 0.50730994]\n",
      "----------------------------------------\n",
      "Trial 812\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 177, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=177, random_state=100))])\n",
      "cv score: [0.5        0.41954023 0.53017241 0.61724138 0.6622807  0.48538012\n",
      " 0.28362573 0.55847953 0.38011696 0.2997076 ]\n",
      "----------------------------------------\n",
      "Trial 813\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5158046  0.36781609 0.57902299 0.51034483 0.49122807 0.55994152\n",
      " 0.5745614  0.55409357 0.48830409 0.41666667]\n",
      "----------------------------------------\n",
      "Trial 814\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 66, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='sqrt', n_estimators=66,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52873563 0.56896552 0.50431034 0.62758621 0.62865497 0.57602339\n",
      " 0.38304094 0.56725146 0.54532164 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 815\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 164, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=164, random_state=100))])\n",
      "cv score: [0.52586207 0.46551724 0.58764368 0.7        0.60672515 0.59649123\n",
      " 0.29385965 0.55263158 0.43567251 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 816\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 133, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=14, n_estimators=133,\n",
      "                                            random_state=100, subsample=0.8))])\n",
      "cv score: [0.5316092  0.4683908  0.53017241 0.56896552 0.68274854 0.42397661\n",
      " 0.38157895 0.54385965 0.46783626 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 817\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 79, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=79,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42816092 0.3908046  0.74281609 0.63793103 0.65935673 0.60233918\n",
      " 0.53654971 0.49707602 0.42690058 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 818\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 177, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=177, random_state=100))])\n",
      "cv score: [0.48563218 0.43534483 0.49568966 0.60344828 0.67105263 0.47953216\n",
      " 0.31140351 0.59064327 0.35526316 0.26900585]\n",
      "----------------------------------------\n",
      "Trial 819\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 18, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=18,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.51724138 0.54885057 0.57471264 0.4137931  0.4122807  0.54824561\n",
      " 0.53508772 0.68421053 0.54385965 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 820\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3591954  0.35057471 0.61925287 0.54827586 0.56871345 0.5497076\n",
      " 0.41374269 0.52923977 0.44444444 0.28947368]\n",
      "----------------------------------------\n",
      "Trial 821\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 188, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=188,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38218391 0.47557471 0.54454023 0.48965517 0.5877193  0.58625731\n",
      " 0.50292398 0.61111111 0.5380117  0.44152047]\n",
      "----------------------------------------\n",
      "Trial 822\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 26, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=26,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.47413793 0.57471264 0.47413793 0.48245614 0.43274854\n",
      " 0.46491228 0.5        0.47368421 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 823\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 135, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=135, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.52155172 0.38218391 0.43965517 0.67413793 0.57602339 0.46052632\n",
      " 0.64912281 0.5497076  0.59649123 0.49122807]\n",
      "----------------------------------------\n",
      "Trial 824\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 95, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features=None,\n",
      "                                        n_estimators=95, random_state=100))])\n",
      "cv score: [0.45114943 0.40517241 0.46408046 0.54827586 0.70321637 0.47368421\n",
      " 0.29824561 0.51169591 0.45321637 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 825\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 145, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=145, random_state=100))])\n",
      "cv score: [0.50287356 0.45258621 0.52442529 0.6137931  0.66812865 0.47807018\n",
      " 0.27923977 0.57309942 0.37719298 0.29093567]\n",
      "----------------------------------------\n",
      "Trial 826\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 53, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=53, random_state=100))])\n",
      "cv score: [0.47844828 0.40804598 0.53304598 0.55862069 0.69444444 0.52046784\n",
      " 0.2880117  0.55847953 0.38596491 0.24122807]\n",
      "----------------------------------------\n",
      "Trial 827\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 114, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=114, random_state=100))])\n",
      "cv score: [0.48850575 0.40229885 0.44971264 0.58965517 0.73245614 0.48245614\n",
      " 0.32602339 0.49707602 0.46783626 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 828\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 166, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=166, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.54885057 0.47126437 0.56178161 0.6862069  0.55701754 0.65204678\n",
      " 0.3377193  0.55263158 0.50584795 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 829\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.38218391 0.4137931  0.73994253 0.62068966 0.63011696 0.49707602\n",
      " 0.36403509 0.50877193 0.33333333 0.24269006]\n",
      "----------------------------------------\n",
      "Trial 830\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 135, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=135, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.52873563 0.48275862 0.54741379 0.64827586 0.65350877 0.57309942\n",
      " 0.28508772 0.50877193 0.44736842 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 831\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 18, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=18,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.50574713 0.49137931 0.48965517 0.43859649 0.54824561\n",
      " 0.51169591 0.66374269 0.5497076  0.42982456]\n",
      "----------------------------------------\n",
      "Trial 832\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 161, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=161, random_state=100))])\n",
      "cv score: [0.5545977  0.46551724 0.56752874 0.69655172 0.56871345 0.57309942\n",
      " 0.35233918 0.56432749 0.40935673 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 833\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=115,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.4841954  0.44827586 0.58189655 0.64827586 0.70906433 0.61695906\n",
      " 0.32748538 0.52339181 0.4619883  0.33625731]\n",
      "----------------------------------------\n",
      "Trial 834\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 84, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            n_estimators=84, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.49425287 0.45689655 0.5387931  0.52413793 0.7002924  0.48538012\n",
      " 0.31432749 0.52339181 0.48538012 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 835\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.51149425 0.45114943 0.5704023  0.67931034 0.66812865 0.5994152\n",
      " 0.29678363 0.5        0.48538012 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 836\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 105, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=105, random_state=100))])\n",
      "cv score: [0.52586207 0.45114943 0.56752874 0.71034483 0.6125731  0.56140351\n",
      " 0.31140351 0.57017544 0.4122807  0.34502924]\n",
      "----------------------------------------\n",
      "Trial 837\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=183, random_state=100))])\n",
      "cv score: [0.43103448 0.43390805 0.49281609 0.63103448 0.67690058 0.50877193\n",
      " 0.2997076  0.51169591 0.47660819 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 838\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 121, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=121,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34195402 0.32471264 0.56178161 0.57931034 0.49269006 0.61111111\n",
      " 0.69444444 0.39473684 0.42397661 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 839\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=101,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.43103448 0.53591954 0.48994253 0.55517241 0.63450292 0.56725146\n",
      " 0.47660819 0.67105263 0.57017544 0.52046784]\n",
      "----------------------------------------\n",
      "Trial 840\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 91, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=91,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.35344828 0.27873563 0.64798851 0.63448276 0.59210526 0.57309942\n",
      " 0.48684211 0.49707602 0.41812865 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 841\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 88, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=88,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52442529 0.56034483 0.50574713 0.62068966 0.64327485 0.5994152\n",
      " 0.4005848  0.59356725 0.55409357 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 842\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.52011494 0.48275862 0.55890805 0.51896552 0.6505848  0.51754386\n",
      " 0.31725146 0.45614035 0.48538012 0.49415205]\n",
      "----------------------------------------\n",
      "Trial 843\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 159, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=159,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33908046 0.29885057 0.56178161 0.6        0.47222222 0.62280702\n",
      " 0.66520468 0.38888889 0.42105263 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 844\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 129, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=129,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52586207 0.5387931  0.49568966 0.55517241 0.63450292 0.56725146\n",
      " 0.45321637 0.66812865 0.5877193  0.51461988]\n",
      "----------------------------------------\n",
      "Trial 845\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 85, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=85,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53304598 0.46982759 0.49568966 0.68448276 0.60087719 0.58625731\n",
      " 0.33333333 0.50877193 0.51169591 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 846\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52442529 0.43678161 0.51867816 0.42241379 0.51461988 0.54532164\n",
      " 0.5628655  0.63450292 0.49122807 0.50146199]\n",
      "----------------------------------------\n",
      "Trial 847\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 127, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=127, random_state=100))])\n",
      "cv score: [0.50862069 0.42816092 0.54741379 0.6137931  0.69444444 0.50584795\n",
      " 0.30263158 0.59356725 0.39619883 0.2880117 ]\n",
      "----------------------------------------\n",
      "Trial 848\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 159, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=159, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.47988506 0.43965517 0.56178161 0.68275862 0.63888889 0.63450292\n",
      " 0.30847953 0.45614035 0.48830409 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 849\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 51, 'gb__subsample': 0.6, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            n_estimators=51, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.43534483 0.51005747 0.4295977  0.60344828 0.87134503 0.42105263\n",
      " 0.36403509 0.36111111 0.33479532 0.59502924]\n",
      "----------------------------------------\n",
      "Trial 850\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 116, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=116, random_state=100))])\n",
      "cv score: [0.49281609 0.45402299 0.51867816 0.52758621 0.55994152 0.53362573\n",
      " 0.44736842 0.5497076  0.48830409 0.46345029]\n",
      "----------------------------------------\n",
      "Trial 851\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 12, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=12,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.47270115 0.60775862 0.54166667 0.50517241 0.64619883 0.56578947\n",
      " 0.4254386  0.65497076 0.5497076  0.51461988]\n",
      "----------------------------------------\n",
      "Trial 852\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 167, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=167,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40229885 0.33333333 0.69683908 0.62758621 0.62719298 0.52046784\n",
      " 0.40789474 0.47660819 0.34210526 0.28947368]\n",
      "----------------------------------------\n",
      "Trial 853\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=16, random_state=100))])\n",
      "cv score: [0.53448276 0.40373563 0.63936782 0.69655172 0.60964912 0.55263158\n",
      " 0.40350877 0.64327485 0.52923977 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 854\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 36, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=36,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5        0.49137931 0.49137931 0.48275862 0.48245614 0.48245614\n",
      " 0.5        0.5        0.48245614 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 855\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 15, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=15,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3362069  0.3591954  0.40948276 0.54137931 0.54239766 0.58625731\n",
      " 0.48245614 0.61695906 0.21929825 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 856\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 135, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=135,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.45114943 0.5387931  0.48706897 0.37413793 0.58187135 0.35672515\n",
      " 0.39327485 0.40350877 0.62719298 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 857\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 59, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=59,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37356322 0.4137931  0.53304598 0.4862069  0.46052632 0.52046784\n",
      " 0.54239766 0.5497076  0.40935673 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 858\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            random_state=100, subsample=0.9))])\n",
      "cv score: [0.37643678 0.51436782 0.51724138 0.61206897 0.66812865 0.54385965\n",
      " 0.43128655 0.54678363 0.60526316 0.40350877]\n",
      "----------------------------------------\n",
      "Trial 859\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 168, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=168,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.40229885 0.3908046  0.62212644 0.57931034 0.66520468 0.38888889\n",
      " 0.29678363 0.59649123 0.38888889 0.24853801]\n",
      "----------------------------------------\n",
      "Trial 860\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 101, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=101,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35057471 0.3362069  0.50718391 0.58275862 0.51608187 0.65789474\n",
      " 0.60964912 0.39766082 0.45175439 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 861\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 160, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=160,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57758621 0.45689655 0.56752874 0.39137931 0.70321637 0.49561404\n",
      " 0.3245614  0.38596491 0.31578947 0.4254386 ]\n",
      "----------------------------------------\n",
      "Trial 862\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 72, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=72, random_state=100))])\n",
      "cv score: [0.48706897 0.44827586 0.53591954 0.52068966 0.55263158 0.5248538\n",
      " 0.45175439 0.5380117  0.48391813 0.50146199]\n",
      "----------------------------------------\n",
      "Trial 863\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 77, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=77, random_state=100))])\n",
      "cv score: [0.50574713 0.41954023 0.51867816 0.59310345 0.67982456 0.50292398\n",
      " 0.32748538 0.57017544 0.38157895 0.28216374]\n",
      "----------------------------------------\n",
      "Trial 864\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 33, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            n_estimators=33,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.59482759 0.52011494 0.59051724 0.42758621 0.64327485 0.39766082\n",
      " 0.34210526 0.47953216 0.3128655  0.39035088]\n",
      "----------------------------------------\n",
      "Trial 865\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 154, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=154, random_state=100))])\n",
      "cv score: [0.5        0.43965517 0.54454023 0.6137931  0.6505848  0.47807018\n",
      " 0.27777778 0.56432749 0.37719298 0.2880117 ]\n",
      "----------------------------------------\n",
      "Trial 866\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 165, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=165,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50862069 0.46408046 0.64511494 0.63275862 0.73538012 0.58479532\n",
      " 0.22660819 0.44005848 0.48099415 0.36695906]\n",
      "----------------------------------------\n",
      "Trial 867\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 66, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=14,\n",
      "                                            n_estimators=66, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.56034483 0.44252874 0.62787356 0.53448276 0.74707602 0.58479532\n",
      " 0.37573099 0.33040936 0.50292398 0.5497076 ]\n",
      "----------------------------------------\n",
      "Trial 868\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 47, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=47,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40804598 0.30747126 0.64511494 0.6137931  0.61549708 0.51754386\n",
      " 0.63888889 0.51754386 0.30994152 0.53216374]\n",
      "----------------------------------------\n",
      "Trial 869\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 46, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=46,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.51724138 0.46551724 0.57327586 0.66206897 0.6622807  0.62134503\n",
      " 0.32017544 0.49415205 0.45906433 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 870\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 44, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=44,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.39655172 0.27586207 0.64798851 0.59655172 0.58625731 0.62280702\n",
      " 0.62134503 0.37719298 0.44152047 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 871\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 106, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=106,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60632184 0.5        0.57471264 0.4637931  0.43859649 0.4619883\n",
      " 0.48684211 0.67397661 0.52777778 0.50438596]\n",
      "----------------------------------------\n",
      "Trial 872\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 82, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=82, random_state=100))])\n",
      "cv score: [0.42816092 0.39367816 0.42385057 0.6        0.64181287 0.52046784\n",
      " 0.32309942 0.52923977 0.44736842 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 873\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 61, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=61,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.53017241 0.55747126 0.56034483 0.66959064 0.43859649\n",
      " 0.37280702 0.61549708 0.61988304 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 874\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 62, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=62, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.5        0.43390805 0.55603448 0.64137931 0.69444444 0.56725146\n",
      " 0.32602339 0.54678363 0.49122807 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 875\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=101,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54454023 0.47557471 0.49281609 0.67758621 0.60380117 0.59210526\n",
      " 0.35087719 0.50584795 0.51754386 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 876\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 11, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=11, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.50287356 0.42241379 0.66235632 0.65344828 0.52046784 0.58918129\n",
      " 0.37280702 0.63596491 0.50146199 0.50438596]\n",
      "----------------------------------------\n",
      "Trial 877\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 65, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=65,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41954023 0.37643678 0.625      0.60344828 0.62719298 0.48830409\n",
      " 0.44883041 0.52339181 0.33333333 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 878\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 130, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            n_estimators=130, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.4137931  0.47988506 0.48850575 0.53965517 0.61111111 0.57309942\n",
      " 0.38157895 0.56725146 0.56871345 0.44298246]\n",
      "----------------------------------------\n",
      "Trial 879\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 39, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=39, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.52873563 0.48275862 0.6566092  0.67931034 0.64181287 0.61988304\n",
      " 0.29093567 0.47660819 0.58187135 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 880\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.41091954 0.30747126 0.5704023  0.54137931 0.62134503 0.49415205\n",
      " 0.3874269  0.5994152  0.29239766 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 881\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=198, random_state=100))])\n",
      "cv score: [0.56609195 0.45977011 0.57902299 0.72068966 0.57163743 0.59064327\n",
      " 0.32309942 0.53216374 0.40935673 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 882\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 111, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=111,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51005747 0.54022989 0.51724138 0.57413793 0.62719298 0.61842105\n",
      " 0.43567251 0.59649123 0.55116959 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 883\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 117, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=117, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.52586207 0.45689655 0.60201149 0.73103448 0.50438596 0.65204678\n",
      " 0.37865497 0.42982456 0.51461988 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 884\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 163, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=163, random_state=100))])\n",
      "cv score: [0.46264368 0.52011494 0.46695402 0.60689655 0.60380117 0.59649123\n",
      " 0.40497076 0.58187135 0.4619883  0.40350877]\n",
      "----------------------------------------\n",
      "Trial 885\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 89, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=89,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.35344828 0.53017241 0.58275862 0.47807018 0.55555556\n",
      " 0.54824561 0.54093567 0.32163743 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 886\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 169, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=169,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61781609 0.58333333 0.58045977 0.54137931 0.71345029 0.40204678\n",
      " 0.44152047 0.63157895 0.61695906 0.57894737]\n",
      "----------------------------------------\n",
      "Trial 887\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 55, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=2,\n",
      "                                            n_estimators=55, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.46551724 0.38793103 0.47988506 0.57241379 0.59356725 0.4371345\n",
      " 0.27046784 0.44444444 0.47953216 0.34649123]\n",
      "----------------------------------------\n",
      "Trial 888\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=178, random_state=100))])\n",
      "cv score: [0.51436782 0.43534483 0.54166667 0.63793103 0.68567251 0.51754386\n",
      " 0.29824561 0.58479532 0.38011696 0.30263158]\n",
      "----------------------------------------\n",
      "Trial 889\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 152, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=152,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52586207 0.5387931  0.50431034 0.55517241 0.63450292 0.56432749\n",
      " 0.47368421 0.66812865 0.59064327 0.51461988]\n",
      "----------------------------------------\n",
      "Trial 890\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 59, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=59,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4137931  0.43678161 0.40948276 0.55862069 0.59795322 0.54824561\n",
      " 0.39912281 0.53508772 0.42836257 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 891\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 62, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=62, random_state=100))])\n",
      "cv score: [0.52586207 0.53735632 0.4683908  0.60517241 0.57309942 0.59356725\n",
      " 0.41081871 0.51169591 0.46929825 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 892\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 127, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=127, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.47270115 0.42816092 0.45258621 0.56896552 0.69152047 0.4502924\n",
      " 0.3377193  0.54678363 0.4619883  0.24707602]\n",
      "----------------------------------------\n",
      "Trial 893\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 169, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features=None,\n",
      "                                        n_estimators=169, random_state=100))])\n",
      "cv score: [0.41666667 0.42816092 0.43821839 0.61724138 0.64473684 0.53216374\n",
      " 0.32017544 0.52046784 0.46783626 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 894\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 88, 'gb__subsample': 0.8, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=88, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.52298851 0.39655172 0.55890805 0.66896552 0.68567251 0.60233918\n",
      " 0.31725146 0.49415205 0.46491228 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 895\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 15, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=15, random_state=100))])\n",
      "cv score: [0.55603448 0.59626437 0.43821839 0.51034483 0.50730994 0.6374269\n",
      " 0.50584795 0.58040936 0.50146199 0.39035088]\n",
      "----------------------------------------\n",
      "Trial 896\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 53, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=53, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.54597701 0.43103448 0.58477011 0.71206897 0.58625731 0.67836257\n",
      " 0.35818713 0.4619883  0.47368421 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 897\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 196, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=196, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.52873563 0.36494253 0.58764368 0.55862069 0.61549708 0.52339181\n",
      " 0.32017544 0.52631579 0.42105263 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 898\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=102,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.4454023  0.59051724 0.64827586 0.74415205 0.57017544\n",
      " 0.29824561 0.45321637 0.47807018 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 899\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 138, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=138,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56609195 0.54885057 0.57471264 0.5137931  0.48245614 0.4619883\n",
      " 0.50292398 0.67397661 0.46491228 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 900\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 121, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=121, random_state=100))])\n",
      "cv score: [0.47557471 0.42816092 0.45833333 0.55862069 0.68859649 0.45321637\n",
      " 0.3377193  0.53508772 0.4619883  0.24415205]\n",
      "----------------------------------------\n",
      "Trial 901\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 97, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            n_estimators=97,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.4066092  0.58045977 0.51436782 0.37241379 0.63596491 0.41520468\n",
      " 0.37865497 0.30994152 0.56725146 0.30555556]\n",
      "----------------------------------------\n",
      "Trial 902\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36781609 0.44827586 0.39511494 0.53965517 0.54532164 0.54532164\n",
      " 0.49415205 0.58479532 0.45906433 0.39619883]\n",
      "----------------------------------------\n",
      "Trial 903\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 77, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=6,\n",
      "                                            n_estimators=77, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.49137931 0.37643678 0.46695402 0.37586207 0.58040936 0.51754386\n",
      " 0.48830409 0.4502924  0.73099415 0.24707602]\n",
      "----------------------------------------\n",
      "Trial 904\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=8, max_features='log2',\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.4454023  0.46264368 0.47557471 0.65517241 0.62134503 0.5994152\n",
      " 0.35818713 0.48245614 0.5        0.35380117]\n",
      "----------------------------------------\n",
      "Trial 905\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 34, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=34,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35632184 0.35632184 0.625      0.62758621 0.63304094 0.47368421\n",
      " 0.4371345  0.50584795 0.33625731 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 906\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3908046  0.31034483 0.64798851 0.64827586 0.59795322 0.47953216\n",
      " 0.37865497 0.52046784 0.40643275 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 907\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 57, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, n_estimators=57,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.46551724 0.59913793 0.56609195 0.49655172 0.7002924  0.46783626\n",
      " 0.43421053 0.54385965 0.61111111 0.4619883 ]\n",
      "----------------------------------------\n",
      "Trial 908\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 132, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=132, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.45402299 0.18390805 0.34626437 0.47931034 0.44444444 0.60818713\n",
      " 0.36988304 0.82748538 0.27777778 0.42690058]\n",
      "----------------------------------------\n",
      "Trial 909\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 62, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=62,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3591954  0.41954023 0.73994253 0.66551724 0.7119883  0.47368421\n",
      " 0.36695906 0.52923977 0.34795322 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 910\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 69, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=69,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.29885057 0.33045977 0.5387931  0.60344828 0.53362573 0.61695906\n",
      " 0.44883041 0.49707602 0.44152047 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 911\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 186, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=186, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.47126437 0.4683908  0.47270115 0.67931034 0.61549708 0.57017544\n",
      " 0.31140351 0.49707602 0.49415205 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 912\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 49, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=49, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.39367816 0.58045977 0.47988506 0.64482759 0.42251462 0.36403509\n",
      " 0.5248538  0.59356725 0.65204678 0.44152047]\n",
      "----------------------------------------\n",
      "Trial 913\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 94, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=94, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49425287 0.44827586 0.52442529 0.64482759 0.51900585 0.5877193\n",
      " 0.3494152  0.54678363 0.43859649 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 914\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 97, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=97,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.53017241 0.55747126 0.56034483 0.66959064 0.43859649\n",
      " 0.37280702 0.61549708 0.61988304 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 915\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 82, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=82,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.49137931 0.47701149 0.48275862 0.41206897 0.55263158 0.57309942\n",
      " 0.61111111 0.66081871 0.47076023 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 916\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 83, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=83, random_state=100))])\n",
      "cv score: [0.52873563 0.43821839 0.5316092  0.5862069  0.68274854 0.47660819\n",
      " 0.29093567 0.55555556 0.3874269  0.28947368]\n",
      "----------------------------------------\n",
      "Trial 917\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 74, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=74,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.61781609 0.58333333 0.58045977 0.54137931 0.71345029 0.40204678\n",
      " 0.44152047 0.63157895 0.61695906 0.57894737]\n",
      "----------------------------------------\n",
      "Trial 918\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 118, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=118, random_state=100))])\n",
      "cv score: [0.48275862 0.43678161 0.48994253 0.56551724 0.72368421 0.45906433\n",
      " 0.33040936 0.51461988 0.45614035 0.23391813]\n",
      "----------------------------------------\n",
      "Trial 919\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 141, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=141,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.59626437 0.48275862 0.66522989 0.60172414 0.73976608 0.5877193\n",
      " 0.25       0.46491228 0.46491228 0.37573099]\n",
      "----------------------------------------\n",
      "Trial 920\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 165, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=165, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.53448276 0.41091954 0.55890805 0.7        0.64181287 0.60526316\n",
      " 0.36988304 0.47660819 0.44444444 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 921\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=178, random_state=100))])\n",
      "cv score: [0.55747126 0.45402299 0.55316092 0.7137931  0.57163743 0.58479532\n",
      " 0.34064327 0.5380117  0.41520468 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 922\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58189655 0.56034483 0.57471264 0.50172414 0.66374269 0.4619883\n",
      " 0.49269006 0.67982456 0.62280702 0.49707602]\n",
      "----------------------------------------\n",
      "Trial 923\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 59, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=59,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47844828 0.42097701 0.49137931 0.46724138 0.45906433 0.57163743\n",
      " 0.58918129 0.67690058 0.47076023 0.4502924 ]\n",
      "----------------------------------------\n",
      "Trial 924\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 172, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=172,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.39367816 0.3908046  0.59913793 0.57241379 0.53362573 0.54385965\n",
      " 0.4254386  0.50877193 0.36549708 0.29239766]\n",
      "----------------------------------------\n",
      "Trial 925\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42816092 0.46264368 0.51293103 0.56206897 0.56871345 0.59064327\n",
      " 0.51169591 0.56140351 0.4619883  0.45175439]\n",
      "----------------------------------------\n",
      "Trial 926\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 117, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=117, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.50862069 0.43103448 0.54166667 0.67241379 0.6622807  0.59649123\n",
      " 0.34064327 0.48245614 0.46491228 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 927\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 141, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            n_estimators=141, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.46551724 0.47701149 0.47270115 0.59655172 0.72076023 0.51754386\n",
      " 0.2997076  0.53508772 0.48538012 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 928\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 67, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=67, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.56896552 0.48563218 0.54166667 0.67241379 0.57163743 0.66374269\n",
      " 0.33479532 0.52339181 0.52192982 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 929\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36494253 0.31609195 0.70545977 0.63448276 0.63011696 0.46783626\n",
      " 0.37280702 0.45321637 0.33040936 0.28362573]\n",
      "----------------------------------------\n",
      "Trial 930\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 169, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=169,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52586207 0.55890805 0.50431034 0.55517241 0.63450292 0.56432749\n",
      " 0.48245614 0.67105263 0.59356725 0.52046784]\n",
      "----------------------------------------\n",
      "Trial 931\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 20, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=20, random_state=100))])\n",
      "cv score: [0.65517241 0.45114943 0.61350575 0.62931034 0.69298246 0.50877193\n",
      " 0.38450292 0.52923977 0.44736842 0.39619883]\n",
      "----------------------------------------\n",
      "Trial 932\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 109, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=109, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.51436782 0.40517241 0.67816092 0.55344828 0.30116959 0.26754386\n",
      " 0.53508772 0.49707602 0.31725146 0.52339181]\n",
      "----------------------------------------\n",
      "Trial 933\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 136, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=136,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41091954 0.33045977 0.61925287 0.58965517 0.61549708 0.48245614\n",
      " 0.43421053 0.43567251 0.32163743 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 934\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 48, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=48,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.45689655 0.28448276 0.60201149 0.5862069  0.51900585 0.45321637\n",
      " 0.42836257 0.53216374 0.33625731 0.24269006]\n",
      "----------------------------------------\n",
      "Trial 935\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 60, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=60,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3045977  0.3591954  0.45545977 0.55517241 0.44298246 0.59649123\n",
      " 0.62719298 0.45321637 0.42982456 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 936\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 85, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=85, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.4683908  0.6637931  0.50431034 0.64137931 0.28947368 0.33918129\n",
      " 0.57163743 0.28070175 0.48245614 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 937\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 19, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=19,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.46982759 0.63074713 0.65517241 0.71637427 0.58918129\n",
      " 0.29678363 0.43567251 0.52631579 0.36403509]\n",
      "----------------------------------------\n",
      "Trial 938\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42241379 0.32758621 0.65948276 0.68965517 0.59795322 0.52046784\n",
      " 0.48976608 0.47368421 0.28362573 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 939\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 52, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=52,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52873563 0.54885057 0.50431034 0.63793103 0.63157895 0.55847953\n",
      " 0.4005848  0.58479532 0.55994152 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 940\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 116, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=8,\n",
      "                                            n_estimators=116, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.45402299 0.45689655 0.47844828 0.59310345 0.72660819 0.50292398\n",
      " 0.2997076  0.48830409 0.47660819 0.40935673]\n",
      "----------------------------------------\n",
      "Trial 941\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 191, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=191, random_state=100))])\n",
      "cv score: [0.43678161 0.42241379 0.49568966 0.64482759 0.67690058 0.49707602\n",
      " 0.26461988 0.47660819 0.43567251 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 942\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 100, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2',\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53591954 0.5545977  0.50143678 0.63448276 0.63157895 0.60087719\n",
      " 0.39473684 0.59356725 0.55116959 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 943\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 177, 'gb__subsample': 0.95, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, max_features='log2',\n",
      "                                            n_estimators=177, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.48850575 0.4454023  0.49856322 0.74137931 0.65643275 0.65497076\n",
      " 0.38450292 0.48830409 0.48830409 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 944\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 168, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=168,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.38505747 0.33908046 0.65948276 0.6137931  0.60087719 0.47660819\n",
      " 0.37573099 0.54678363 0.33918129 0.28362573]\n",
      "----------------------------------------\n",
      "Trial 945\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 145, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=145,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58764368 0.48275862 0.66522989 0.60517241 0.73976608 0.5877193\n",
      " 0.25       0.45906433 0.46491228 0.37573099]\n",
      "----------------------------------------\n",
      "Trial 946\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40373563 0.47126437 0.46551724 0.46034483 0.57894737 0.55409357\n",
      " 0.59502924 0.57602339 0.59502924 0.39912281]\n",
      "----------------------------------------\n",
      "Trial 947\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 95, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=95,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33333333 0.35344828 0.5387931  0.57931034 0.57163743 0.50292398\n",
      " 0.39619883 0.57017544 0.39766082 0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 948\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 113, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features=None,\n",
      "                                        n_estimators=113, random_state=100))])\n",
      "cv score: [0.41954023 0.43965517 0.47844828 0.57241379 0.60087719 0.52339181\n",
      " 0.35818713 0.53508772 0.51461988 0.41520468]\n",
      "----------------------------------------\n",
      "Trial 949\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 79, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=79, random_state=100))])\n",
      "cv score: [0.5316092  0.47988506 0.55890805 0.65517241 0.62134503 0.53508772\n",
      " 0.31140351 0.59356725 0.42690058 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 950\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 113, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=113, random_state=100))])\n",
      "cv score: [0.48275862 0.43678161 0.50574713 0.55517241 0.62719298 0.45906433\n",
      " 0.31140351 0.60818713 0.4005848  0.30263158]\n",
      "----------------------------------------\n",
      "Trial 951\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43965517 0.32758621 0.79166667 0.63793103 0.64473684 0.54385965\n",
      " 0.47222222 0.4619883  0.34210526 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 952\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 84, 'rf__max_depth': 12, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='log2',\n",
      "                                        n_estimators=84, random_state=100))])\n",
      "cv score: [0.52586207 0.43534483 0.52873563 0.57586207 0.68274854 0.47660819\n",
      " 0.28216374 0.55555556 0.3874269  0.28947368]\n",
      "----------------------------------------\n",
      "Trial 953\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 126, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=126,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33045977 0.38793103 0.54741379 0.57241379 0.53654971 0.50584795\n",
      " 0.4254386  0.4619883  0.32163743 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 954\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 170, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='log2', n_estimators=170,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.50862069 0.46695402 0.63649425 0.62931034 0.73830409 0.58479532\n",
      " 0.23245614 0.44590643 0.48099415 0.36695906]\n",
      "----------------------------------------\n",
      "Trial 955\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 101, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=101,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.43103448 0.53591954 0.48994253 0.55517241 0.63450292 0.56725146\n",
      " 0.47660819 0.67105263 0.57017544 0.52046784]\n",
      "----------------------------------------\n",
      "Trial 956\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 55, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=55,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.27873563 0.36206897 0.43678161 0.59655172 0.59210526 0.52923977\n",
      " 0.52192982 0.45175439 0.36988304 0.37573099]\n",
      "----------------------------------------\n",
      "Trial 957\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 37, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=37,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51005747 0.54741379 0.50287356 0.60517241 0.64766082 0.64473684\n",
      " 0.46929825 0.56871345 0.57163743 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 958\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 193, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=193, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.58189655 0.68534483 0.56465517 0.7        0.67836257 0.45321637\n",
      " 0.58625731 0.3128655  0.5248538  0.63304094]\n",
      "----------------------------------------\n",
      "Trial 959\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40804598 0.41954023 0.60488506 0.54482759 0.61549708 0.49707602\n",
      " 0.4371345  0.50877193 0.35964912 0.26608187]\n",
      "----------------------------------------\n",
      "Trial 960\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 164, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=164,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40517241 0.3362069  0.67672414 0.63103448 0.63596491 0.59064327\n",
      " 0.37865497 0.52046784 0.40350877 0.23684211]\n",
      "----------------------------------------\n",
      "Trial 961\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 136, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=136, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.54310345 0.45402299 0.57902299 0.58275862 0.63011696 0.55555556\n",
      " 0.29678363 0.5877193  0.38888889 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 962\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=198, random_state=100))])\n",
      "cv score: [0.5        0.43390805 0.5316092  0.54137931 0.53947368 0.54678363\n",
      " 0.41959064 0.53508772 0.47953216 0.43859649]\n",
      "----------------------------------------\n",
      "Trial 963\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 73, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=73, random_state=100))])\n",
      "cv score: [0.52011494 0.50574713 0.44396552 0.59137931 0.55263158 0.57017544\n",
      " 0.44590643 0.57602339 0.54093567 0.47368421]\n",
      "----------------------------------------\n",
      "Trial 964\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.65))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.51436782 0.40517241 0.67816092 0.55344828 0.30116959 0.26754386\n",
      " 0.53508772 0.49707602 0.31725146 0.52339181]\n",
      "----------------------------------------\n",
      "Trial 965\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 100, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        random_state=100))])\n",
      "cv score: [0.47126437 0.52298851 0.45545977 0.61724138 0.58040936 0.59649123\n",
      " 0.40497076 0.52923977 0.4371345  0.41812865]\n",
      "----------------------------------------\n",
      "Trial 966\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 189, 'xgb__subsample': 1.0, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=189,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36781609 0.31609195 0.7341954  0.69310345 0.6622807  0.57309942\n",
      " 0.3874269  0.48245614 0.4005848  0.27777778]\n",
      "----------------------------------------\n",
      "Trial 967\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 114, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=114,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.43390805 0.53591954 0.49568966 0.55517241 0.63450292 0.56725146\n",
      " 0.47368421 0.67105263 0.57017544 0.51461988]\n",
      "----------------------------------------\n",
      "Trial 968\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 115, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=115,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41091954 0.38505747 0.71695402 0.66206897 0.66520468 0.48245614\n",
      " 0.37280702 0.52339181 0.37719298 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 969\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34482759 0.34770115 0.63362069 0.61724138 0.63304094 0.5497076\n",
      " 0.3494152  0.52631579 0.40935673 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 970\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 88, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='log2', n_estimators=88,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.43390805 0.53591954 0.48994253 0.55517241 0.63450292 0.56725146\n",
      " 0.47660819 0.66812865 0.57017544 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 971\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 70, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=9,\n",
      "                                            n_estimators=70, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.42528736 0.45114943 0.61206897 0.68793103 0.55701754 0.35672515\n",
      " 0.36988304 0.50292398 0.41081871 0.53216374]\n",
      "----------------------------------------\n",
      "Trial 972\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 23, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=23, random_state=100))])\n",
      "cv score: [0.42241379 0.43390805 0.53591954 0.56896552 0.71345029 0.50584795\n",
      " 0.14619883 0.54239766 0.45175439 0.28947368]\n",
      "----------------------------------------\n",
      "Trial 973\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 152, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=152, random_state=100))])\n",
      "cv score: [0.5        0.43390805 0.54166667 0.6137931  0.66520468 0.48099415\n",
      " 0.27777778 0.57017544 0.37426901 0.2880117 ]\n",
      "----------------------------------------\n",
      "Trial 974\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 132, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=132, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.57183908 0.51149425 0.52298851 0.64827586 0.60964912 0.61695906\n",
      " 0.3874269  0.56725146 0.5        0.28362573]\n",
      "----------------------------------------\n",
      "Trial 975\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 197, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            n_estimators=197, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.42672414 0.65229885 0.55316092 0.65862069 0.51023392 0.2997076\n",
      " 0.40789474 0.42690058 0.65789474 0.64035088]\n",
      "----------------------------------------\n",
      "Trial 976\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 135, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=135,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57758621 0.45689655 0.56752874 0.39137931 0.70321637 0.49561404\n",
      " 0.3245614  0.38596491 0.31578947 0.4254386 ]\n",
      "----------------------------------------\n",
      "Trial 977\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 74, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=74, random_state=100))])\n",
      "cv score: [0.52011494 0.51149425 0.44971264 0.59137931 0.55263158 0.57017544\n",
      " 0.44590643 0.57602339 0.54093567 0.47368421]\n",
      "----------------------------------------\n",
      "Trial 978\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=198, random_state=100))])\n",
      "cv score: [0.43390805 0.4454023  0.47557471 0.62413793 0.72660819 0.48830409\n",
      " 0.29385965 0.50292398 0.41812865 0.27192982]\n",
      "----------------------------------------\n",
      "Trial 979\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 190, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=190, random_state=100))])\n",
      "cv score: [0.54597701 0.43390805 0.55316092 0.66206897 0.64181287 0.58187135\n",
      " 0.32017544 0.57894737 0.38888889 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 980\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 60, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=60, random_state=100))])\n",
      "cv score: [0.43965517 0.39655172 0.47270115 0.63103448 0.72660819 0.52631579\n",
      " 0.31432749 0.56140351 0.46491228 0.28947368]\n",
      "----------------------------------------\n",
      "Trial 981\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, max_features='sqrt',\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.5316092  0.44252874 0.57327586 0.67241379 0.64181287 0.57309942\n",
      " 0.3377193  0.50292398 0.47368421 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 982\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 94, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=94, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.49712644 0.54310345 0.49568966 0.57586207 0.65643275 0.54093567\n",
      " 0.25877193 0.57602339 0.46783626 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 983\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 15, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='sqrt', n_estimators=15,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55747126 0.54166667 0.49856322 0.59827586 0.64473684 0.61549708\n",
      " 0.46345029 0.61403509 0.55116959 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 984\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 115, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=115,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54454023 0.47988506 0.49856322 0.68103448 0.60672515 0.58625731\n",
      " 0.35087719 0.52631579 0.51169591 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 985\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 110, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=110, random_state=100))])\n",
      "cv score: [0.47701149 0.38218391 0.45833333 0.5862069  0.73245614 0.48245614\n",
      " 0.32602339 0.50877193 0.45906433 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 986\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 194, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=194, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.47701149 0.37931034 0.60775862 0.6137931  0.56871345 0.58479532\n",
      " 0.3377193  0.47368421 0.45321637 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 987\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 50, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, max_features='sqrt',\n",
      "                                            n_estimators=50, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.5862069  0.33908046 0.51005747 0.63793103 0.63888889 0.65497076\n",
      " 0.34064327 0.4619883  0.46783626 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 988\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 154, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=154,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52586207 0.5387931  0.50431034 0.55517241 0.63450292 0.56432749\n",
      " 0.48245614 0.66812865 0.59356725 0.51461988]\n",
      "----------------------------------------\n",
      "Trial 989\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.50862069 0.42816092 0.50718391 0.68275862 0.46783626 0.56725146\n",
      " 0.40935673 0.48099415 0.57602339 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 990\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 18, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=2, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=18,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56321839 0.52011494 0.49137931 0.45689655 0.66374269 0.43274854\n",
      " 0.46491228 0.58333333 0.47368421 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 991\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 123, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=123, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.55747126 0.41091954 0.49568966 0.51034483 0.60380117 0.49707602\n",
      " 0.26169591 0.41812865 0.45321637 0.43859649]\n",
      "----------------------------------------\n",
      "Trial 992\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 73, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=73,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41091954 0.41666667 0.61925287 0.59310345 0.60380117 0.44736842\n",
      " 0.36403509 0.5994152  0.35672515 0.25146199]\n",
      "----------------------------------------\n",
      "Trial 993\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 152, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=152, random_state=100))])\n",
      "cv score: [0.41954023 0.45114943 0.45833333 0.62068966 0.71491228 0.47368421\n",
      " 0.29093567 0.52046784 0.39766082 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 994\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 112, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=112,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51005747 0.54022989 0.51724138 0.57413793 0.62719298 0.61842105\n",
      " 0.43567251 0.59649123 0.55409357 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 995\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 38, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=38, random_state=100))])\n",
      "cv score: [0.45977011 0.36206897 0.5316092  0.60344828 0.65350877 0.48830409\n",
      " 0.24561404 0.59064327 0.35087719 0.25584795]\n",
      "----------------------------------------\n",
      "Trial 996\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 129, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=129, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.45833333 0.3591954  0.5158046  0.47068966 0.59210526 0.57017544\n",
      " 0.52339181 0.42690058 0.34795322 0.54093567]\n",
      "----------------------------------------\n",
      "Trial 997\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 34, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=34,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49425287 0.44683908 0.62787356 0.7        0.73684211 0.59356725\n",
      " 0.30263158 0.45614035 0.49561404 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 998\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 55, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=55,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49137931 0.4612069  0.61637931 0.64137931 0.73976608 0.56578947\n",
      " 0.29824561 0.44152047 0.50584795 0.38157895]\n",
      "----------------------------------------\n",
      "Trial 999\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 114, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=114, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.50574713 0.40229885 0.50143678 0.68965517 0.73245614 0.53508772\n",
      " 0.47076023 0.49707602 0.44298246 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 1000\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 84, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=84,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.36494253 0.45114943 0.54741379 0.46206897 0.56432749 0.55847953\n",
      " 0.53362573 0.58918129 0.51169591 0.43274854]\n",
      "----------------------------------------\n",
      "Trial 1001\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 164, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=164, random_state=100))])\n",
      "cv score: [0.5316092  0.47413793 0.58189655 0.64137931 0.65789474 0.52046784\n",
      " 0.28508772 0.57309942 0.39619883 0.29385965]\n",
      "----------------------------------------\n",
      "Trial 1002\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            n_estimators=74,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.47701149 0.55028736 0.38074713 0.52758621 0.6754386  0.43567251\n",
      " 0.53070175 0.60087719 0.65643275 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 1003\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 13, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=13,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42528736 0.3045977  0.47557471 0.51896552 0.52192982 0.59649123\n",
      " 0.63011696 0.57602339 0.28654971 0.4619883 ]\n",
      "----------------------------------------\n",
      "Trial 1004\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=81, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.56321839 0.49712644 0.50431034 0.64482759 0.67105263 0.54678363\n",
      " 0.26461988 0.5380117  0.40350877 0.38888889]\n",
      "----------------------------------------\n",
      "Trial 1005\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 14, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=14, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.48563218 0.36350575 0.57327586 0.65517241 0.51461988 0.30847953\n",
      " 0.43274854 0.55116959 0.43421053 0.39619883]\n",
      "----------------------------------------\n",
      "Trial 1006\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 79, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=79, random_state=100))])\n",
      "cv score: [0.4841954  0.4454023  0.52729885 0.52068966 0.55847953 0.51900585\n",
      " 0.44736842 0.54093567 0.49269006 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 1007\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 5, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=5,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.54022989 0.40804598 0.50718391 0.70344828 0.63888889 0.64327485\n",
      " 0.34649123 0.49415205 0.43859649 0.4122807 ]\n",
      "----------------------------------------\n",
      "Trial 1008\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 76, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=76,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.47701149 0.51293103 0.42586207 0.60233918 0.53654971\n",
      " 0.5628655  0.65497076 0.50584795 0.40497076]\n",
      "----------------------------------------\n",
      "Trial 1009\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 119, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=119,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5158046  0.47126437 0.62787356 0.64310345 0.7251462  0.56578947\n",
      " 0.22076023 0.4502924  0.49853801 0.37280702]\n",
      "----------------------------------------\n",
      "Trial 1010\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 21, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=8, max_features='log2',\n",
      "                                            n_estimators=21, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.59770115 0.43390805 0.53304598 0.71034483 0.68567251 0.62865497\n",
      " 0.30555556 0.45321637 0.48538012 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 1011\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.39942529 0.35057471 0.66810345 0.61724138 0.55116959 0.59064327\n",
      " 0.46929825 0.45906433 0.38304094 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 1012\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 31, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=31,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38505747 0.41091954 0.54741379 0.58965517 0.5745614  0.60818713\n",
      " 0.53070175 0.49707602 0.32748538 0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 1013\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 49, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=49, random_state=100))])\n",
      "cv score: [0.51149425 0.53448276 0.52729885 0.67413793 0.53654971 0.59356725\n",
      " 0.39912281 0.59064327 0.4502924  0.35964912]\n",
      "----------------------------------------\n",
      "Trial 1014\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 59, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=59, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.48563218 0.48850575 0.61063218 0.64827586 0.68859649 0.56432749\n",
      " 0.27631579 0.54678363 0.44444444 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 1015\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 68, 'rf__max_depth': 4, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='sqrt',\n",
      "                                        n_estimators=68, random_state=100))])\n",
      "cv score: [0.51149425 0.51436782 0.51293103 0.63448276 0.51900585 0.5877193\n",
      " 0.39035088 0.57017544 0.45321637 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 1016\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 46, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=46, random_state=100))])\n",
      "cv score: [0.50574713 0.40229885 0.61206897 0.63448276 0.65643275 0.52631579\n",
      " 0.27339181 0.52923977 0.4371345  0.31871345]\n",
      "----------------------------------------\n",
      "Trial 1017\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 50, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=50, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.52729885 0.60057471 0.46982759 0.58275862 0.62719298 0.61111111\n",
      " 0.44590643 0.68421053 0.63157895 0.52923977]\n",
      "----------------------------------------\n",
      "Trial 1018\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 96, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=96, random_state=100))])\n",
      "cv score: [0.48563218 0.45402299 0.4683908  0.55517241 0.57748538 0.56725146\n",
      " 0.41959064 0.57894737 0.52339181 0.46929825]\n",
      "----------------------------------------\n",
      "Trial 1019\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 149, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=149, random_state=100))])\n",
      "cv score: [0.4683908  0.4454023  0.5933908  0.65517241 0.53947368 0.61403509\n",
      " 0.39035088 0.53508772 0.44736842 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 1020\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 199, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            n_estimators=199, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.38505747 0.44252874 0.48706897 0.64137931 0.61549708 0.59649123\n",
      " 0.30555556 0.52923977 0.53508772 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 1021\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 30, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=30,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49856322 0.48706897 0.53448276 0.65517241 0.65935673 0.61403509\n",
      " 0.33187135 0.52631579 0.47660819 0.36403509]\n",
      "----------------------------------------\n",
      "Trial 1022\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 141, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=141,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5545977  0.53448276 0.51005747 0.67068966 0.62280702 0.59210526\n",
      " 0.39181287 0.54678363 0.50730994 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 1023\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 87, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=87,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57471264 0.45977011 0.56896552 0.49827586 0.48245614 0.50730994\n",
      " 0.54239766 0.67251462 0.55994152 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 1024\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 49, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            n_estimators=49, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.47701149 0.47988506 0.49856322 0.52068966 0.77046784 0.52046784\n",
      " 0.31432749 0.55555556 0.46491228 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1025\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 83, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            n_estimators=83, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.59195402 0.41666667 0.50718391 0.57586207 0.4751462  0.58479532\n",
      " 0.41081871 0.41520468 0.57894737 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 1026\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=95, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.54022989 0.45402299 0.54454023 0.66206897 0.65935673 0.59356725\n",
      " 0.29093567 0.56140351 0.49122807 0.4005848 ]\n",
      "----------------------------------------\n",
      "Trial 1027\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 20, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=20, random_state=100))])\n",
      "cv score: [0.65804598 0.41091954 0.56752874 0.7        0.62426901 0.54385965\n",
      " 0.35964912 0.64619883 0.52339181 0.39619883]\n",
      "----------------------------------------\n",
      "Trial 1028\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 92, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            n_estimators=92, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.50574713 0.45689655 0.53017241 0.55862069 0.67397661 0.48245614\n",
      " 0.27339181 0.56140351 0.42397661 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 1029\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 172, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=172,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40229885 0.38505747 0.7658046  0.64482759 0.65643275 0.46491228\n",
      " 0.41374269 0.50584795 0.29532164 0.24269006]\n",
      "----------------------------------------\n",
      "Trial 1030\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 36, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=36,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.54885057 0.57471264 0.49655172 0.51461988 0.43274854\n",
      " 0.60672515 0.65935673 0.46491228 0.49707602]\n",
      "----------------------------------------\n",
      "Trial 1031\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 116, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=116,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42241379 0.35632184 0.61925287 0.64482759 0.56871345 0.5380117\n",
      " 0.44590643 0.47076023 0.36549708 0.28362573]\n",
      "----------------------------------------\n",
      "Trial 1032\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 169, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=169,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.53017241 0.55747126 0.56034483 0.66959064 0.43859649\n",
      " 0.37280702 0.61549708 0.61988304 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 1033\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 135, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=135,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49137931 0.45114943 0.58764368 0.65862069 0.73245614 0.57309942\n",
      " 0.30116959 0.44152047 0.47807018 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 1034\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 192, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=192,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35632184 0.32183908 0.57327586 0.60344828 0.48391813 0.60233918\n",
      " 0.67397661 0.35380117 0.42982456 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 1035\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50718391 0.54885057 0.57471264 0.5137931  0.6871345  0.4619883\n",
      " 0.50146199 0.63888889 0.61403509 0.53070175]\n",
      "----------------------------------------\n",
      "Trial 1036\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 83, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            n_estimators=83, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.41091954 0.41666667 0.60488506 0.56551724 0.45321637 0.50292398\n",
      " 0.47807018 0.4005848  0.56140351 0.5994152 ]\n",
      "----------------------------------------\n",
      "Trial 1037\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=102, random_state=100))])\n",
      "cv score: [0.55172414 0.43390805 0.53304598 0.67931034 0.6125731  0.59649123\n",
      " 0.36111111 0.57894737 0.37134503 0.30555556]\n",
      "----------------------------------------\n",
      "Trial 1038\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 146, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=146,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43103448 0.39367816 0.53304598 0.48275862 0.52631579 0.53947368\n",
      " 0.46052632 0.59064327 0.51608187 0.44736842]\n",
      "----------------------------------------\n",
      "Trial 1039\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=198,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57758621 0.45689655 0.56752874 0.39137931 0.70321637 0.49561404\n",
      " 0.3245614  0.38596491 0.31578947 0.4254386 ]\n",
      "----------------------------------------\n",
      "Trial 1040\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 46, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=46, random_state=100))])\n",
      "cv score: [0.38793103 0.43390805 0.52442529 0.64827586 0.72076023 0.50292398\n",
      " 0.27923977 0.54678363 0.38596491 0.28947368]\n",
      "----------------------------------------\n",
      "Trial 1041\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 105, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=105,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.30316092 0.56752874 0.40373563 0.54310345 0.54532164 0.42690058\n",
      " 0.44152047 0.67690058 0.63450292 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 1042\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 192, 'gb__subsample': 0.95, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=192, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.47988506 0.43678161 0.54454023 0.68275862 0.60380117 0.60526316\n",
      " 0.34064327 0.47368421 0.49415205 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 1043\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 39, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=39,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.50574713 0.46695402 0.63362069 0.43103448 0.5994152  0.52046784\n",
      " 0.60087719 0.64327485 0.5        0.42105263]\n",
      "----------------------------------------\n",
      "Trial 1044\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 76, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=76,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5        0.49137931 0.49137931 0.48275862 0.5        0.43274854\n",
      " 0.5        0.5        0.48245614 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 1045\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 170, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=5,\n",
      "                                            n_estimators=170, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.46695402 0.4612069  0.59051724 0.50344828 0.44005848 0.47076023\n",
      " 0.3128655  0.59210526 0.4122807  0.61988304]\n",
      "----------------------------------------\n",
      "Trial 1046\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36206897 0.34195402 0.63362069 0.62413793 0.53362573 0.54678363\n",
      " 0.42836257 0.45614035 0.37426901 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 1047\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 121, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=121,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38218391 0.38505747 0.58477011 0.55862069 0.53070175 0.50877193\n",
      " 0.45175439 0.53508772 0.31871345 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 1048\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 58, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, max_features='sqrt',\n",
      "                                            n_estimators=58,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.41666667 0.48563218 0.58189655 0.61724138 0.68274854 0.59649123\n",
      " 0.27923977 0.4122807  0.45906433 0.42690058]\n",
      "----------------------------------------\n",
      "Trial 1049\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 27, 'gb__subsample': 1.0, 'gb__learning_rate': 0.1, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=5, max_features='log2',\n",
      "                                            n_estimators=27,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.54597701 0.38218391 0.47270115 0.74827586 0.71491228 0.64327485\n",
      " 0.38157895 0.4502924  0.4751462  0.4005848 ]\n",
      "----------------------------------------\n",
      "Trial 1050\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 54, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=54,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54166667 0.46982759 0.57183908 0.68448276 0.62426901 0.60233918\n",
      " 0.35380117 0.48830409 0.51315789 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 1051\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 51, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=51, random_state=100))])\n",
      "cv score: [0.45689655 0.40948276 0.51867816 0.57931034 0.67397661 0.48245614\n",
      " 0.3128655  0.55994152 0.36842105 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 1052\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 179, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=179,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.38505747 0.3045977  0.69396552 0.64137931 0.50730994 0.61403509\n",
      " 0.71783626 0.34795322 0.44152047 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 1053\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.48275862 0.57471264 0.47413793 0.48245614 0.43274854\n",
      " 0.46491228 0.63157895 0.47368421 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 1054\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 170, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=170,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.55890805 0.46551724 0.54597701 0.50172414 0.6871345  0.45614035\n",
      " 0.50292398 0.67836257 0.53947368 0.52046784]\n",
      "----------------------------------------\n",
      "Trial 1055\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=174, random_state=100))])\n",
      "cv score: [0.42816092 0.42816092 0.46982759 0.63103448 0.68567251 0.50292398\n",
      " 0.2997076  0.52046784 0.48538012 0.28362573]\n",
      "----------------------------------------\n",
      "Trial 1056\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 185, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=185, random_state=100))])\n",
      "cv score: [0.43103448 0.43965517 0.48706897 0.62758621 0.68274854 0.50877193\n",
      " 0.29678363 0.50877193 0.47660819 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 1057\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 54, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=54, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.5316092  0.5704023  0.50718391 0.56034483 0.62134503 0.59502924\n",
      " 0.42836257 0.6374269  0.52923977 0.43859649]\n",
      "----------------------------------------\n",
      "Trial 1058\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 14, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            n_estimators=14, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.44827586 0.4137931  0.54741379 0.48275862 0.6505848  0.57163743\n",
      " 0.27777778 0.47953216 0.48538012 0.42690058]\n",
      "----------------------------------------\n",
      "Trial 1059\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 30, 'gb__subsample': 0.6, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=30, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.44971264 0.49712644 0.5158046  0.55344828 0.60672515 0.55555556\n",
      " 0.43859649 0.57894737 0.55555556 0.50730994]\n",
      "----------------------------------------\n",
      "Trial 1060\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 127, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=127,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.45114943 0.5158046  0.33275862 0.53362573 0.46345029\n",
      " 0.38157895 0.32748538 0.48391813 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 1061\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 130, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=130,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43247126 0.42241379 0.50431034 0.46896552 0.56871345 0.54239766\n",
      " 0.43859649 0.60233918 0.49561404 0.4005848 ]\n",
      "----------------------------------------\n",
      "Trial 1062\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 110, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=110,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.6091954  0.5862069  0.6091954  0.52758621 0.69298246 0.55994152\n",
      " 0.49122807 0.64035088 0.60526316 0.57017544]\n",
      "----------------------------------------\n",
      "Trial 1063\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 124, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=124,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45402299 0.51149425 0.5316092  0.44482759 0.57309942 0.51754386\n",
      " 0.41081871 0.60818713 0.52192982 0.38157895]\n",
      "----------------------------------------\n",
      "Trial 1064\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 139, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=139, random_state=100))])\n",
      "cv score: [0.46551724 0.44827586 0.46264368 0.56206897 0.68859649 0.45614035\n",
      " 0.3494152  0.53508772 0.4502924  0.24415205]\n",
      "----------------------------------------\n",
      "Trial 1065\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 27, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=27,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33189655 0.21264368 0.49856322 0.58275862 0.47660819 0.62280702\n",
      " 0.60964912 0.50292398 0.35380117 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 1066\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 27, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='sqrt',\n",
      "                                        n_estimators=27, random_state=100))])\n",
      "cv score: [0.52298851 0.5        0.42385057 0.59655172 0.59210526 0.5877193\n",
      " 0.42836257 0.5497076  0.55994152 0.45175439]\n",
      "----------------------------------------\n",
      "Trial 1067\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 122, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=122,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36494253 0.4454023  0.4066092  0.46896552 0.50146199 0.50584795\n",
      " 0.51315789 0.57602339 0.38011696 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 1068\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='sqrt',\n",
      "                                        n_estimators=159, random_state=100))])\n",
      "cv score: [0.56034483 0.46551724 0.57614943 0.70689655 0.57163743 0.57602339\n",
      " 0.3494152  0.55847953 0.40935673 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 1069\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 89, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=89, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.50862069 0.44827586 0.60488506 0.65172414 0.67690058 0.56140351\n",
      " 0.28508772 0.56725146 0.41812865 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 1070\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 148, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=148, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.5316092  0.47126437 0.56465517 0.56206897 0.64473684 0.54678363\n",
      " 0.32017544 0.56725146 0.43567251 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 1071\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 122, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=122, random_state=100))])\n",
      "cv score: [0.47988506 0.44683908 0.50574713 0.54827586 0.63596491 0.46491228\n",
      " 0.30847953 0.61111111 0.4122807  0.30263158]\n",
      "----------------------------------------\n",
      "Trial 1072\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.50574713 0.41666667 0.55172414 0.46896552 0.6374269  0.46929825\n",
      " 0.5497076  0.64912281 0.59502924 0.44152047]\n",
      "----------------------------------------\n",
      "Trial 1073\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 145, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features=None,\n",
      "                                        n_estimators=145, random_state=100))])\n",
      "cv score: [0.47126437 0.43965517 0.44827586 0.55862069 0.67982456 0.45906433\n",
      " 0.35672515 0.54093567 0.4502924  0.23976608]\n",
      "----------------------------------------\n",
      "Trial 1074\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 20, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=20,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38505747 0.39655172 0.58189655 0.55344828 0.48830409 0.5380117\n",
      " 0.49561404 0.56140351 0.29532164 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 1075\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 150, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=150,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.47701149 0.45689655 0.58764368 0.64482759 0.72953216 0.57602339\n",
      " 0.30409357 0.44444444 0.47807018 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 1076\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 188, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=188,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.47413793 0.45402299 0.59051724 0.64482759 0.72953216 0.58479532\n",
      " 0.30701754 0.44152047 0.47807018 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 1077\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 133, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=133, random_state=100))])\n",
      "cv score: [0.47988506 0.45114943 0.49281609 0.61034483 0.67982456 0.46637427\n",
      " 0.32748538 0.60233918 0.37280702 0.24561404]\n",
      "----------------------------------------\n",
      "Trial 1078\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 167, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=167, random_state=100))])\n",
      "cv score: [0.51436782 0.4295977  0.5387931  0.63103448 0.68859649 0.51169591\n",
      " 0.29824561 0.58187135 0.38596491 0.2997076 ]\n",
      "----------------------------------------\n",
      "Trial 1079\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 65, 'gb__subsample': 0.6, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            n_estimators=65, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.48850575 0.43103448 0.5387931  0.59655172 0.74122807 0.54678363\n",
      " 0.27339181 0.51169591 0.57894737 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 1080\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 18, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=18,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.59482759 0.56321839 0.57471264 0.52758621 0.71637427 0.46783626\n",
      " 0.46491228 0.63888889 0.6374269  0.53362573]\n",
      "----------------------------------------\n",
      "Trial 1081\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 131, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=131, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.41235632 0.57327586 0.65948276 0.5637931  0.73830409 0.53654971\n",
      " 0.59210526 0.51754386 0.41374269 0.6871345 ]\n",
      "----------------------------------------\n",
      "Trial 1082\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48994253 0.35488506 0.51867816 0.45172414 0.5380117  0.53508772\n",
      " 0.54385965 0.5994152  0.52631579 0.41812865]\n",
      "----------------------------------------\n",
      "Trial 1083\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 12, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=12,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.48275862 0.48275862 0.49137931 0.48275862 0.48245614 0.43274854\n",
      " 0.46491228 0.5        0.47368421 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 1084\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 38, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=38,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37931034 0.33333333 0.54741379 0.4862069  0.50877193 0.5994152\n",
      " 0.53070175 0.53216374 0.39327485 0.29532164]\n",
      "----------------------------------------\n",
      "Trial 1085\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 141, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=141,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40804598 0.35632184 0.6795977  0.64827586 0.60087719 0.5\n",
      " 0.40789474 0.51169591 0.35087719 0.26315789]\n",
      "----------------------------------------\n",
      "Trial 1086\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 20, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            n_estimators=20, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.65517241 0.52586207 0.51293103 0.55517241 0.74122807 0.60380117\n",
      " 0.55994152 0.51169591 0.45614035 0.34649123]\n",
      "----------------------------------------\n",
      "Trial 1087\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 103, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            n_estimators=103, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.47413793 0.43965517 0.51867816 0.55517241 0.70321637 0.45906433\n",
      " 0.26461988 0.49122807 0.49415205 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 1088\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 88, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=88,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56465517 0.54885057 0.54597701 0.49482759 0.48245614 0.50730994\n",
      " 0.54824561 0.67251462 0.57309942 0.52631579]\n",
      "----------------------------------------\n",
      "Trial 1089\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 67, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=67, random_state=100))])\n",
      "cv score: [0.53591954 0.46264368 0.58333333 0.58275862 0.68567251 0.5\n",
      " 0.3128655  0.54385965 0.39912281 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 1090\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 158, 'rf__max_depth': 10, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=None,\n",
      "                                        n_estimators=158, random_state=100))])\n",
      "cv score: [0.47126437 0.41954023 0.47844828 0.59655172 0.7119883  0.47076023\n",
      " 0.31140351 0.50584795 0.42982456 0.26900585]\n",
      "----------------------------------------\n",
      "Trial 1091\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=16, random_state=100))])\n",
      "cv score: [0.49568966 0.52729885 0.50143678 0.60172414 0.54093567 0.64912281\n",
      " 0.40204678 0.73538012 0.50292398 0.39035088]\n",
      "----------------------------------------\n",
      "Trial 1092\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 173, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=173,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.51436782 0.46264368 0.61063218 0.66206897 0.72660819 0.60526316\n",
      " 0.29093567 0.47368421 0.47368421 0.40350877]\n",
      "----------------------------------------\n",
      "Trial 1093\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 111, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=111,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43390805 0.33045977 0.51005747 0.69655172 0.60087719 0.55555556\n",
      " 0.36988304 0.54678363 0.45906433 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 1094\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 192, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=192,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.56896552 0.48850575 0.65086207 0.63448276 0.73830409 0.57602339\n",
      " 0.22807018 0.47807018 0.47953216 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 1095\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.47126437 0.47126437 0.59051724 0.5137931  0.70614035 0.52339181\n",
      " 0.27923977 0.58479532 0.42690058 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 1096\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43247126 0.34195402 0.49568966 0.49310345 0.50146199 0.62865497\n",
      " 0.57017544 0.64473684 0.51754386 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 1097\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 82, 'gb__subsample': 0.75, 'gb__learning_rate': 0.3, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=4,\n",
      "                                            n_estimators=82, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.49712644 0.48563218 0.63074713 0.5862069  0.73245614 0.5497076\n",
      " 0.33479532 0.52046784 0.5497076  0.23684211]\n",
      "----------------------------------------\n",
      "Trial 1098\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=52,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.56034483 0.45689655 0.45833333 0.6862069  0.58625731 0.64035088\n",
      " 0.31140351 0.48830409 0.46783626 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 1099\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 54, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=54,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37068966 0.32471264 0.60201149 0.6        0.6505848  0.54678363\n",
      " 0.40789474 0.46491228 0.41520468 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 1100\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 56, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=56,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4137931  0.26436782 0.75143678 0.53793103 0.7002924  0.5877193\n",
      " 0.45175439 0.5        0.28070175 0.47076023]\n",
      "----------------------------------------\n",
      "Trial 1101\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 187, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=187, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.52873563 0.47126437 0.52442529 0.65517241 0.6505848  0.59356725\n",
      " 0.29093567 0.50877193 0.45614035 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 1102\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 122, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=122, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.55316092 0.51436782 0.46408046 0.65862069 0.4371345  0.93859649\n",
      " 0.53947368 0.47660819 0.34356725 0.42397661]\n",
      "----------------------------------------\n",
      "Trial 1103\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 17, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=17, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49425287 0.45977011 0.53304598 0.56206897 0.62280702 0.48538012\n",
      " 0.25877193 0.50877193 0.50292398 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 1104\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 12, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=12,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50574713 0.46695402 0.54597701 0.66551724 0.69005848 0.56140351\n",
      " 0.27777778 0.40935673 0.54532164 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 1105\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 196, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=196,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.32758621 0.3362069  0.66810345 0.58965517 0.48391813 0.68421053\n",
      " 0.52192982 0.45321637 0.43859649 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 1106\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 195, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=14,\n",
      "                                            n_estimators=195, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.47126437 0.50574713 0.45833333 0.6        0.74415205 0.61111111\n",
      " 0.55116959 0.3128655  0.57163743 0.55847953]\n",
      "----------------------------------------\n",
      "Trial 1107\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 65, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            n_estimators=65, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.3362069  0.67528736 0.53304598 0.6        0.46637427 0.38888889\n",
      " 0.37865497 0.24122807 0.57894737 0.42690058]\n",
      "----------------------------------------\n",
      "Trial 1108\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 109, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=109, random_state=100))])\n",
      "cv score: [0.53735632 0.38936782 0.56752874 0.64827586 0.62719298 0.56725146\n",
      " 0.34064327 0.50292398 0.39035088 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 1109\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 161, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=7,\n",
      "                                            n_estimators=161, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.41954023 0.4137931  0.44109195 0.66896552 0.74707602 0.59064327\n",
      " 0.26169591 0.51754386 0.52631579 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 1110\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 170, 'xgb__subsample': 0.9, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=170,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37356322 0.39655172 0.72844828 0.67931034 0.61842105 0.51754386\n",
      " 0.45175439 0.52923977 0.30116959 0.29532164]\n",
      "----------------------------------------\n",
      "Trial 1111\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 79, 'gb__subsample': 0.6, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=79, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.48850575 0.43390805 0.51293103 0.56896552 0.58625731 0.45906433\n",
      " 0.2997076  0.36549708 0.4619883  0.37134503]\n",
      "----------------------------------------\n",
      "Trial 1112\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 157, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=157, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.54885057 0.43390805 0.56465517 0.69655172 0.52192982 0.67836257\n",
      " 0.39035088 0.51461988 0.47660819 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 1113\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 29, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=29,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.45689655 0.52011494 0.49137931 0.43793103 0.45614035 0.62426901\n",
      " 0.59649123 0.58333333 0.42105263 0.4122807 ]\n",
      "----------------------------------------\n",
      "Trial 1114\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 83, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            n_estimators=83, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.43103448 0.4683908  0.49425287 0.52758621 0.64766082 0.54824561\n",
      " 0.30994152 0.51754386 0.57017544 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1115\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 186, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=186,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.32471264 0.70258621 0.60344828 0.57748538 0.54385965\n",
      " 0.47807018 0.49707602 0.35087719 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 1116\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 63, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=63, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.45402299 0.47126437 0.39224138 0.73448276 0.6505848  0.45614035\n",
      " 0.32894737 0.49707602 0.65350877 0.53362573]\n",
      "----------------------------------------\n",
      "Trial 1117\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=101, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.5316092  0.47413793 0.63362069 0.61034483 0.68859649 0.57309942\n",
      " 0.29093567 0.49707602 0.43859649 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 1118\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 179, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=179, random_state=100))])\n",
      "cv score: [0.47988506 0.4454023  0.51005747 0.56551724 0.64766082 0.45906433\n",
      " 0.29532164 0.61403509 0.38304094 0.30847953]\n",
      "----------------------------------------\n",
      "Trial 1119\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 107, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=107,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56896552 0.54885057 0.57471264 0.51896552 0.62280702 0.4619883\n",
      " 0.50146199 0.63888889 0.61403509 0.52192982]\n",
      "----------------------------------------\n",
      "Trial 1120\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 109, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=109,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.49712644 0.43103448 0.55603448 0.68275862 0.6622807  0.63450292\n",
      " 0.32017544 0.42982456 0.45906433 0.4122807 ]\n",
      "----------------------------------------\n",
      "Trial 1121\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 130, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            n_estimators=130,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.51436782 0.43534483 0.51436782 0.35862069 0.53362573 0.48538012\n",
      " 0.32602339 0.34210526 0.47076023 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 1122\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 193, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=193,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50574713 0.5545977  0.53448276 0.57413793 0.63011696 0.60672515\n",
      " 0.43859649 0.5994152  0.54532164 0.42397661]\n",
      "----------------------------------------\n",
      "Trial 1123\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='log2', n_estimators=198,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51149425 0.47413793 0.61350575 0.60689655 0.75292398 0.56871345\n",
      " 0.20906433 0.48976608 0.5        0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1124\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 72, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features=None, n_estimators=72,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.61781609 0.58333333 0.58045977 0.54137931 0.71345029 0.40204678\n",
      " 0.44152047 0.63157895 0.61695906 0.57894737]\n",
      "----------------------------------------\n",
      "Trial 1125\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 40, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=40,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49856322 0.47844828 0.54310345 0.66551724 0.68274854 0.59649123\n",
      " 0.31140351 0.50292398 0.48245614 0.34356725]\n",
      "----------------------------------------\n",
      "Trial 1126\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 174, 'gb__subsample': 0.85, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=174, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.39367816 0.40373563 0.47988506 0.64482759 0.42251462 0.36403509\n",
      " 0.58040936 0.66959064 0.65204678 0.44152047]\n",
      "----------------------------------------\n",
      "Trial 1127\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 179, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=179,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.53448276 0.4137931  0.56178161 0.68275862 0.67105263 0.62280702\n",
      " 0.34356725 0.42982456 0.52923977 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 1128\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 176, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=176, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.52298851 0.48850575 0.55890805 0.57241379 0.66812865 0.5380117\n",
      " 0.36695906 0.56432749 0.40935673 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 1129\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 93, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=93,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.54885057 0.54597701 0.5545977  0.70344828 0.64181287 0.64327485\n",
      " 0.39181287 0.49122807 0.52923977 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 1130\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 30, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=30,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.59482759 0.52011494 0.56465517 0.43965517 0.65350877 0.43128655\n",
      " 0.40350877 0.46345029 0.36842105 0.46052632]\n",
      "----------------------------------------\n",
      "Trial 1131\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 186, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=186,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37931034 0.31609195 0.64511494 0.58275862 0.64473684 0.45614035\n",
      " 0.29385965 0.49122807 0.30701754 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 1132\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 176, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='sqrt', n_estimators=176,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54166667 0.4683908  0.55603448 0.66724138 0.64766082 0.59064327\n",
      " 0.34210526 0.47660819 0.50584795 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 1133\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 46, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=46,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40229885 0.41954023 0.55603448 0.58275862 0.51608187 0.63157895\n",
      " 0.51023392 0.47076023 0.41812865 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 1134\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 40, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=7, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=40,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56321839 0.47413793 0.49137931 0.46551724 0.48245614 0.43274854\n",
      " 0.46491228 0.5        0.46491228 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 1135\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 170, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=14, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=170,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60344828 0.56321839 0.57471264 0.53275862 0.48245614 0.46783626\n",
      " 0.46491228 0.63157895 0.6374269  0.5380117 ]\n",
      "----------------------------------------\n",
      "Trial 1136\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.51724138 0.50287356 0.59626437 0.5862069  0.6622807  0.56432749\n",
      " 0.26461988 0.57894737 0.43274854 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 1137\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 43, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=43,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.48706897 0.46982759 0.52586207 0.65172414 0.66812865 0.60233918\n",
      " 0.2997076  0.51169591 0.47076023 0.34064327]\n",
      "----------------------------------------\n",
      "Trial 1138\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 47, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=47, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.51149425 0.45114943 0.55316092 0.72413793 0.69152047 0.60233918\n",
      " 0.34649123 0.47368421 0.51461988 0.42397661]\n",
      "----------------------------------------\n",
      "Trial 1139\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='sqrt',\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.57471264 0.41091954 0.5158046  0.65172414 0.60964912 0.64035088\n",
      " 0.42251462 0.48538012 0.43859649 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1140\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 47, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=47,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40229885 0.36206897 0.50287356 0.55172414 0.58333333 0.5877193\n",
      " 0.53947368 0.50584795 0.53070175 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 1141\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 47, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='sqrt', n_estimators=47,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50431034 0.45545977 0.62787356 0.64482759 0.74269006 0.5628655\n",
      " 0.30116959 0.42105263 0.50292398 0.37280702]\n",
      "----------------------------------------\n",
      "Trial 1142\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 109, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=109,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.57327586 0.46551724 0.54597701 0.49310345 0.63450292 0.50146199\n",
      " 0.53947368 0.67836257 0.53654971 0.51900585]\n",
      "----------------------------------------\n",
      "Trial 1143\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 104, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=104, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.54454023 0.59913793 0.5        0.62241379 0.62865497 0.62280702\n",
      " 0.40497076 0.61111111 0.5380117  0.38596491]\n",
      "----------------------------------------\n",
      "Trial 1144\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 173, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=173, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.52298851 0.4683908  0.59051724 0.7        0.6125731  0.60233918\n",
      " 0.29678363 0.53216374 0.42982456 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 1145\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 184, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=184, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.39798851 0.51436782 0.45833333 0.62931034 0.60818713 0.60964912\n",
      " 0.40497076 0.62134503 0.56871345 0.47076023]\n",
      "----------------------------------------\n",
      "Trial 1146\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 22, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            n_estimators=22, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.44396552 0.5158046  0.40373563 0.5362069  0.73830409 0.38450292\n",
      " 0.39181287 0.45906433 0.54385965 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 1147\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 14, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=14, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.48706897 0.56178161 0.43678161 0.59827586 0.54678363 0.5497076\n",
      " 0.4005848  0.51900585 0.51315789 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 1148\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 95, 'rf__max_depth': 2, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features='log2',\n",
      "                                        n_estimators=95, random_state=100))])\n",
      "cv score: [0.48563218 0.45114943 0.46264368 0.56896552 0.56871345 0.56432749\n",
      " 0.41081871 0.58187135 0.52046784 0.4751462 ]\n",
      "----------------------------------------\n",
      "Trial 1149\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 94, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=94, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.51436782 0.48850575 0.56178161 0.71034483 0.54093567 0.63157895\n",
      " 0.38450292 0.45906433 0.5        0.31871345]\n",
      "----------------------------------------\n",
      "Trial 1150\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 113, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=113, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.52298851 0.46264368 0.53304598 0.67586207 0.6622807  0.60233918\n",
      " 0.30555556 0.5        0.47076023 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 1151\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 193, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=193,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58764368 0.48850575 0.65517241 0.60344828 0.73976608 0.58479532\n",
      " 0.23830409 0.44736842 0.4619883  0.3494152 ]\n",
      "----------------------------------------\n",
      "Trial 1152\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 78, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=78, random_state=100))])\n",
      "cv score: [0.50143678 0.44827586 0.49281609 0.52758621 0.64766082 0.47076023\n",
      " 0.31140351 0.53070175 0.39181287 0.29093567]\n",
      "----------------------------------------\n",
      "Trial 1153\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 101, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='log2',\n",
      "                                            n_estimators=101, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.5545977  0.40517241 0.56752874 0.62068966 0.65350877 0.60818713\n",
      " 0.44883041 0.46783626 0.4502924  0.33625731]\n",
      "----------------------------------------\n",
      "Trial 1154\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 34, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            n_estimators=34, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.43678161 0.45114943 0.57327586 0.56551724 0.76461988 0.52046784\n",
      " 0.35526316 0.47953216 0.47368421 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 1155\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 106, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=106,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35344828 0.39942529 0.61350575 0.60689655 0.57748538 0.46783626\n",
      " 0.43128655 0.53508772 0.32163743 0.24853801]\n",
      "----------------------------------------\n",
      "Trial 1156\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 191, 'gb__subsample': 0.9, 'gb__learning_rate': 1.0, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=13,\n",
      "                                            n_estimators=191, random_state=100,\n",
      "                                            subsample=0.9))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.65517241 0.54597701 0.5387931  0.71034483 0.62426901 0.33333333\n",
      " 0.32017544 0.40643275 0.45321637 0.67397661]\n",
      "----------------------------------------\n",
      "Trial 1157\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 100, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_features='log2',\n",
      "                                            random_state=100, subsample=0.7))])\n",
      "cv score: [0.52873563 0.46551724 0.54454023 0.67241379 0.55701754 0.60818713\n",
      " 0.42836257 0.52046784 0.56432749 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 1158\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 129, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=129, random_state=100))])\n",
      "cv score: [0.50574713 0.42816092 0.55890805 0.61724138 0.69444444 0.50292398\n",
      " 0.30847953 0.59356725 0.39327485 0.2880117 ]\n",
      "----------------------------------------\n",
      "Trial 1159\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 26, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=26, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.55172414 0.49137931 0.59051724 0.66551724 0.58333333 0.50584795\n",
      " 0.29385965 0.56140351 0.47368421 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 1160\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 28, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=28,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.56465517 0.48850575 0.5316092  0.6862069  0.5877193  0.62865497\n",
      " 0.35526316 0.58479532 0.5        0.28654971]\n",
      "----------------------------------------\n",
      "Trial 1161\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 92, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=92, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.51436782 0.38362069 0.29741379 0.48448276 0.62573099 0.40350877\n",
      " 0.53070175 0.5248538  0.26608187 0.66812865]\n",
      "----------------------------------------\n",
      "Trial 1162\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 75, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='log2',\n",
      "                                        n_estimators=75, random_state=100))])\n",
      "cv score: [0.47701149 0.46264368 0.53304598 0.63103448 0.53070175 0.58479532\n",
      " 0.36403509 0.54093567 0.45906433 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1163\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.52873563 0.45402299 0.55603448 0.59310345 0.64473684 0.52631579\n",
      " 0.28216374 0.57309942 0.40643275 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 1164\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 154, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.01, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=154,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56178161 0.46551724 0.57471264 0.50689655 0.66374269 0.4619883\n",
      " 0.50292398 0.6622807  0.56725146 0.50877193]\n",
      "----------------------------------------\n",
      "Trial 1165\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 42, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=42, random_state=100))])\n",
      "cv score: [0.3908046  0.45114943 0.49568966 0.64827586 0.70321637 0.49122807\n",
      " 0.29093567 0.55263158 0.4005848  0.27192982]\n",
      "----------------------------------------\n",
      "Trial 1166\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 37, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=37, random_state=100))])\n",
      "cv score: [0.57183908 0.48275862 0.62787356 0.6862069  0.59356725 0.51461988\n",
      " 0.2997076  0.61695906 0.5        0.38450292]\n",
      "----------------------------------------\n",
      "Trial 1167\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 60, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            n_estimators=60, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.43965517 0.40517241 0.38362069 0.63448276 0.74415205 0.54093567\n",
      " 0.25       0.49122807 0.52046784 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 1168\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 77, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=77,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55028736 0.47844828 0.48132184 0.68793103 0.59356725 0.59210526\n",
      " 0.33625731 0.52339181 0.52339181 0.29532164]\n",
      "----------------------------------------\n",
      "Trial 1169\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 20, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=20,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.5        0.48275862 0.49137931 0.48275862 0.48245614 0.43274854\n",
      " 0.46491228 0.5        0.48245614 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 1170\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 15, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=15, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.46264368 0.53304598 0.56034483 0.54655172 0.66812865 0.60380117\n",
      " 0.42397661 0.59210526 0.62280702 0.54385965]\n",
      "----------------------------------------\n",
      "Trial 1171\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 87, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=87,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.45114943 0.5158046  0.33275862 0.53362573 0.46345029\n",
      " 0.38157895 0.33040936 0.48391813 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 1172\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 182, 'gb__subsample': 0.85, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            n_estimators=182, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.49137931 0.46264368 0.51005747 0.61724138 0.65935673 0.53508772\n",
      " 0.34064327 0.50292398 0.46491228 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 1173\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.35488506 0.43103448 0.61034483 0.61842105 0.58187135\n",
      " 0.4751462  0.57309942 0.4254386  0.25584795]\n",
      "----------------------------------------\n",
      "Trial 1174\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 153, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=153, random_state=100))])\n",
      "cv score: [0.48275862 0.44683908 0.50574713 0.60689655 0.66812865 0.4619883\n",
      " 0.31871345 0.61111111 0.35818713 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 1175\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 108, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=108,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.30316092 0.56752874 0.40373563 0.54310345 0.54532164 0.42690058\n",
      " 0.44152047 0.67690058 0.63450292 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 1176\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 96, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=96,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3591954  0.35632184 0.69683908 0.64827586 0.50730994 0.60818713\n",
      " 0.46637427 0.48830409 0.3625731  0.30994152]\n",
      "----------------------------------------\n",
      "Trial 1177\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 17, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            n_estimators=17, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.46551724 0.40229885 0.5933908  0.60689655 0.74707602 0.47076023\n",
      " 0.25877193 0.37134503 0.56432749 0.28654971]\n",
      "----------------------------------------\n",
      "Trial 1178\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 134, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=134, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.50574713 0.42528736 0.58477011 0.63448276 0.69152047 0.57602339\n",
      " 0.27631579 0.49122807 0.44152047 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 1179\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 175, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=175, random_state=100))])\n",
      "cv score: [0.45402299 0.49137931 0.47270115 0.57586207 0.5628655  0.55263158\n",
      " 0.43128655 0.54678363 0.54678363 0.48245614]\n",
      "----------------------------------------\n",
      "Trial 1180\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 37, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=37, random_state=100))])\n",
      "cv score: [0.37643678 0.40517241 0.44971264 0.6137931  0.68859649 0.44444444\n",
      " 0.22953216 0.5994152  0.33918129 0.23976608]\n",
      "----------------------------------------\n",
      "Trial 1181\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 148, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=4,\n",
      "                                            n_estimators=148, random_state=100,\n",
      "                                            subsample=0.65))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.41954023 0.41091954 0.47270115 0.65517241 0.70614035 0.56725146\n",
      " 0.30263158 0.44736842 0.57309942 0.28947368]\n",
      "----------------------------------------\n",
      "Trial 1182\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 153, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=153,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.53017241 0.55747126 0.56034483 0.66959064 0.43859649\n",
      " 0.37280702 0.61549708 0.61988304 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 1183\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.43965517 0.58189655 0.54482759 0.59502924 0.47953216\n",
      " 0.31140351 0.5877193  0.35087719 0.27192982]\n",
      "----------------------------------------\n",
      "Trial 1184\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 199, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=199, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.59195402 0.4454023  0.52155172 0.58965517 0.64181287 0.46491228\n",
      " 0.33187135 0.38596491 0.4005848  0.47660819]\n",
      "----------------------------------------\n",
      "Trial 1185\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 140, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                        n_estimators=140, random_state=100))])\n",
      "cv score: [0.48706897 0.43678161 0.51724138 0.51724138 0.5628655  0.53508772\n",
      " 0.44444444 0.54678363 0.49707602 0.4619883 ]\n",
      "----------------------------------------\n",
      "Trial 1186\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 189, 'gb__subsample': 0.6, 'gb__learning_rate': 0.003, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=189, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.48850575 0.47413793 0.55028736 0.64482759 0.65643275 0.57309942\n",
      " 0.29678363 0.47953216 0.43274854 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 1187\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 186, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.001, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=186,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51724138 0.44252874 0.5545977  0.46896552 0.54824561 0.51461988\n",
      " 0.53362573 0.63157895 0.5628655  0.46637427]\n",
      "----------------------------------------\n",
      "Trial 1188\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 136, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=136,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38793103 0.3045977  0.7112069  0.59655172 0.52192982 0.62573099\n",
      " 0.67690058 0.38596491 0.46783626 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1189\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 187, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=187, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.64224138 0.35344828 0.46982759 0.5        0.25146199 0.70467836\n",
      " 0.59502924 0.37719298 0.25584795 0.47953216]\n",
      "----------------------------------------\n",
      "Trial 1190\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 19, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='sqrt',\n",
      "                                        n_estimators=19, random_state=100))])\n",
      "cv score: [0.59482759 0.37787356 0.60057471 0.66896552 0.66081871 0.57309942\n",
      " 0.4371345  0.36842105 0.48538012 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 1191\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 115, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, max_features='sqrt',\n",
      "                                            n_estimators=115, random_state=100,\n",
      "                                            subsample=0.75))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.51436782 0.4683908  0.5387931  0.5862069  0.63888889 0.47953216\n",
      " 0.30263158 0.51169591 0.4122807  0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1192\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 114, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=114,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34626437 0.3908046  0.46551724 0.5637931  0.58040936 0.54824561\n",
      " 0.48099415 0.53070175 0.5        0.47660819]\n",
      "----------------------------------------\n",
      "Trial 1193\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 69, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=69,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53304598 0.47270115 0.49281609 0.68793103 0.59356725 0.6125731\n",
      " 0.33625731 0.51754386 0.51608187 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 1194\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 131, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=131,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6091954  0.5862069  0.6091954  0.52758621 0.69298246 0.55994152\n",
      " 0.49122807 0.64035088 0.60526316 0.57017544]\n",
      "----------------------------------------\n",
      "Trial 1195\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 195, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=195,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45114943 0.34482759 0.65086207 0.62758621 0.61842105 0.5497076\n",
      " 0.45760234 0.5497076  0.28070175 0.42105263]\n",
      "----------------------------------------\n",
      "Trial 1196\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 20, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=20, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.51005747 0.59195402 0.50431034 0.57758621 0.64912281 0.54678363\n",
      " 0.42397661 0.6374269  0.57017544 0.47660819]\n",
      "----------------------------------------\n",
      "Trial 1197\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 148, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=148, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.54310345 0.52586207 0.46695402 0.74137931 0.60380117 0.64035088\n",
      " 0.34064327 0.52339181 0.52777778 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 1198\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 42, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=42,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45402299 0.40804598 0.59626437 0.71034483 0.58625731 0.55847953\n",
      " 0.54532164 0.41812865 0.30116959 0.43567251]\n",
      "----------------------------------------\n",
      "Trial 1199\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 104, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=104, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.51149425 0.59195402 0.4612069  0.60172414 0.63157895 0.6125731\n",
      " 0.45175439 0.65935673 0.58918129 0.5380117 ]\n",
      "----------------------------------------\n",
      "Trial 1200\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 78, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=78, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.56034483 0.42528736 0.56465517 0.58965517 0.64181287 0.47953216\n",
      " 0.29678363 0.51754386 0.39181287 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 1201\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 76, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=76, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.48275862 0.47126437 0.53017241 0.6862069  0.69152047 0.66959064\n",
      " 0.35233918 0.46491228 0.46491228 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 1202\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 29, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=29, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.57183908 0.41666667 0.56752874 0.65172414 0.68274854 0.57017544\n",
      " 0.28508772 0.44444444 0.42982456 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1203\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=2,\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.51005747 0.48706897 0.5545977  0.53448276 0.62280702 0.69444444\n",
      " 0.42251462 0.52339181 0.53654971 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 1204\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 182, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=182,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39367816 0.41666667 0.46408046 0.52758621 0.52192982 0.58479532\n",
      " 0.48976608 0.56140351 0.38011696 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 1205\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 113, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=13,\n",
      "                                            n_estimators=113,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.47701149 0.42528736 0.54885057 0.54655172 0.73538012 0.42397661\n",
      " 0.40350877 0.47953216 0.33625731 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1206\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 17, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=17,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55028736 0.55316092 0.5        0.60172414 0.58918129 0.53216374\n",
      " 0.45175439 0.5497076  0.5380117  0.33625731]\n",
      "----------------------------------------\n",
      "Trial 1207\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 93, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=93, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.57758621 0.40229885 0.52442529 0.42413793 0.57163743 0.5380117\n",
      " 0.40789474 0.4005848  0.41520468 0.45906433]\n",
      "----------------------------------------\n",
      "Trial 1208\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 27, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=27,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6091954  0.53304598 0.63649425 0.64655172 0.72807018 0.54824561\n",
      " 0.24415205 0.49707602 0.4619883  0.38011696]\n",
      "----------------------------------------\n",
      "Trial 1209\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 11, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            n_estimators=11, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.45402299 0.47126437 0.43247126 0.48448276 0.68128655 0.58918129\n",
      " 0.20614035 0.32748538 0.54824561 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 1210\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 140, 'gb__subsample': 0.75, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            n_estimators=140, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.50287356 0.45402299 0.41235632 0.51724138 0.69444444 0.5\n",
      " 0.30847953 0.5497076  0.50584795 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 1211\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 136, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=136,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42528736 0.33908046 0.63074713 0.63448276 0.64473684 0.57894737\n",
      " 0.36111111 0.51754386 0.4005848  0.29239766]\n",
      "----------------------------------------\n",
      "Trial 1212\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 56, 'gb__subsample': 0.75, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=56, random_state=100,\n",
      "                                            subsample=0.75))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56609195 0.41954023 0.54741379 0.64827586 0.66812865 0.56140351\n",
      " 0.23830409 0.55555556 0.45906433 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 1213\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=102,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51005747 0.54022989 0.51724138 0.57413793 0.63304094 0.61842105\n",
      " 0.44152047 0.59649123 0.55409357 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 1214\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.47413793 0.44827586 0.54166667 0.7        0.65350877 0.61403509\n",
      " 0.28216374 0.47953216 0.4619883  0.38888889]\n",
      "----------------------------------------\n",
      "Trial 1215\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 138, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=138,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33477011 0.40517241 0.46551724 0.57413793 0.58625731 0.55701754\n",
      " 0.48099415 0.50584795 0.47076023 0.46783626]\n",
      "----------------------------------------\n",
      "Trial 1216\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 190, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.003, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=190,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37931034 0.31034483 0.7341954  0.64482759 0.52192982 0.64912281\n",
      " 0.65643275 0.33625731 0.4502924  0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1217\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 37, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=37, random_state=100))])\n",
      "cv score: [0.55172414 0.52298851 0.63362069 0.6137931  0.71345029 0.51023392\n",
      " 0.27777778 0.51900585 0.4371345  0.31871345]\n",
      "----------------------------------------\n",
      "Trial 1218\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 27, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=27,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43103448 0.44252874 0.70833333 0.65517241 0.66812865 0.56140351\n",
      " 0.41959064 0.55555556 0.3245614  0.22807018]\n",
      "----------------------------------------\n",
      "Trial 1219\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 168, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=168, random_state=100))])\n",
      "cv score: [0.42816092 0.42241379 0.48132184 0.62758621 0.68274854 0.50292398\n",
      " 0.30263158 0.52046784 0.48830409 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 1220\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 86, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=86, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.56321839 0.42528736 0.60775862 0.58275862 0.67982456 0.62573099\n",
      " 0.30555556 0.54678363 0.42982456 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 1221\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 169, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=169, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.48275862 0.42528736 0.55890805 0.66551724 0.62426901 0.5994152\n",
      " 0.33187135 0.4502924  0.45906433 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 1222\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 83, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=83, random_state=100,\n",
      "                                            subsample=0.95))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.5316092  0.44827586 0.56465517 0.60689655 0.69444444 0.52339181\n",
      " 0.31432749 0.44152047 0.46491228 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 1223\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 140, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=140, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.47701149 0.4683908  0.42672414 0.73103448 0.59210526 0.52923977\n",
      " 0.37865497 0.5        0.5        0.37719298]\n",
      "----------------------------------------\n",
      "Trial 1224\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 138, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=138, random_state=100))])\n",
      "cv score: [0.53448276 0.45977011 0.55890805 0.64827586 0.66081871 0.51754386\n",
      " 0.29093567 0.5994152  0.39035088 0.27046784]\n",
      "----------------------------------------\n",
      "Trial 1225\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 23, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=23,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58908046 0.51293103 0.59626437 0.42413793 0.64766082 0.39181287\n",
      " 0.35087719 0.44590643 0.33333333 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 1226\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=171,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.48850575 0.42816092 0.61063218 0.67586207 0.71491228 0.5994152\n",
      " 0.3128655  0.4619883  0.47953216 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 1227\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 86, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=86,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53304598 0.46982759 0.49568966 0.68103448 0.60672515 0.58625731\n",
      " 0.33040936 0.50877193 0.51754386 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 1228\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.7, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.41954023 0.50574713 0.59626437 0.65862069 0.52192982 0.64619883\n",
      " 0.44005848 0.52923977 0.5994152  0.38011696]\n",
      "----------------------------------------\n",
      "Trial 1229\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 46, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=46, random_state=100))])\n",
      "cv score: [0.51293103 0.48275862 0.49568966 0.61034483 0.7002924  0.49122807\n",
      " 0.28654971 0.49561404 0.39327485 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 1230\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 24, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=24, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.54022989 0.45402299 0.55316092 0.63448276 0.65350877 0.55847953\n",
      " 0.28508772 0.39473684 0.48245614 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 1231\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 44, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=44,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.5        0.55172414 0.50718391 0.57068966 0.62134503 0.62719298\n",
      " 0.44298246 0.60818713 0.53947368 0.42397661]\n",
      "----------------------------------------\n",
      "Trial 1232\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 82, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=82,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5862069  0.50862069 0.62643678 0.62931034 0.72076023 0.58187135\n",
      " 0.2119883  0.4619883  0.51754386 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 1233\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 40, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.3, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=40,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42528736 0.47270115 0.4066092  0.53965517 0.66959064 0.47807018\n",
      " 0.46345029 0.57602339 0.55409357 0.44736842]\n",
      "----------------------------------------\n",
      "Trial 1234\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 98, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=98, random_state=100))])\n",
      "cv score: [0.49281609 0.43965517 0.46264368 0.55862069 0.64473684 0.46929825\n",
      " 0.31432749 0.57894737 0.41081871 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 1235\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 151, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features=None,\n",
      "                                        n_estimators=151, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.42241379 0.40804598 0.49281609 0.63103448 0.70321637 0.47660819\n",
      " 0.26754386 0.48245614 0.42690058 0.27192982]\n",
      "----------------------------------------\n",
      "Trial 1236\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.52298851 0.34913793 0.55890805 0.62931034 0.37573099 0.44736842\n",
      " 0.50146199 0.3377193  0.47076023 0.51754386]\n",
      "----------------------------------------\n",
      "Trial 1237\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 23, 'gb__subsample': 0.65, 'gb__learning_rate': 0.003, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=23, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.63074713 0.53304598 0.46982759 0.61896552 0.62280702 0.60964912\n",
      " 0.33479532 0.64912281 0.48976608 0.40935673]\n",
      "----------------------------------------\n",
      "Trial 1238\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 97, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=97,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34195402 0.32183908 0.55603448 0.68275862 0.4751462  0.5877193\n",
      " 0.49561404 0.46783626 0.36842105 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 1239\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 156, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=156,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56178161 0.4066092  0.50574713 0.48103448 0.5745614  0.50730994\n",
      " 0.50584795 0.65204678 0.58918129 0.43128655]\n",
      "----------------------------------------\n",
      "Trial 1240\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 164, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=164,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48563218 0.43965517 0.77442529 0.55862069 0.56871345 0.63157895\n",
      " 0.55409357 0.35087719 0.42982456 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 1241\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 103, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=103, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.51436782 0.43965517 0.60775862 0.63103448 0.64766082 0.5994152\n",
      " 0.27046784 0.53216374 0.39473684 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 1242\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 119, 'gb__subsample': 0.9, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=119, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.51149425 0.47701149 0.61925287 0.64827586 0.64473684 0.57017544\n",
      " 0.2997076  0.52046784 0.4502924  0.4005848 ]\n",
      "----------------------------------------\n",
      "Trial 1243\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 1.0, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=145,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.51724138 0.59195402 0.45833333 0.61206897 0.63011696 0.61111111\n",
      " 0.39619883 0.60233918 0.56140351 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 1244\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 169, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=169,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.39942529 0.39655172 0.78591954 0.63793103 0.68567251 0.62280702\n",
      " 0.46052632 0.44736842 0.34210526 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 1245\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 196, 'xgb__subsample': 0.95, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=196,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43965517 0.3362069  0.7341954  0.65172414 0.58040936 0.64619883\n",
      " 0.62426901 0.32748538 0.48538012 0.38596491]\n",
      "----------------------------------------\n",
      "Trial 1246\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 87, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=87,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.4841954  0.44827586 0.56465517 0.64827586 0.7002924  0.61111111\n",
      " 0.3245614  0.52631579 0.48245614 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 1247\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 35, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=35,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38218391 0.38793103 0.43534483 0.6        0.64766082 0.52339181\n",
      " 0.3874269  0.52631579 0.30701754 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 1248\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 75, 'rf__max_depth': 5, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features=None, n_estimators=75,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.30316092 0.56752874 0.40373563 0.54310345 0.54532164 0.42690058\n",
      " 0.44152047 0.67690058 0.63450292 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 1249\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 176, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=176, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.5        0.43965517 0.60201149 0.67586207 0.7119883  0.61695906\n",
      " 0.30555556 0.47953216 0.44444444 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 1250\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 116, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=116,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.47988506 0.4454023  0.58477011 0.70689655 0.66812865 0.61695906\n",
      " 0.33187135 0.40643275 0.53216374 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 1251\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 85, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=85,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.47701149 0.38362069 0.39310345 0.60380117 0.33918129\n",
      " 0.40350877 0.57017544 0.62573099 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 1252\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 109, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=109,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.32183908 0.68534483 0.61034483 0.53362573 0.63450292\n",
      " 0.62426901 0.39766082 0.44736842 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 1253\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 195, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=195, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.52873563 0.5        0.55316092 0.71034483 0.52777778 0.64912281\n",
      " 0.32309942 0.52046784 0.51461988 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1254\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 30, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=30,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.60344828 0.56321839 0.57471264 0.52413793 0.48245614 0.43274854\n",
      " 0.46491228 0.64035088 0.5877193  0.45614035]\n",
      "----------------------------------------\n",
      "Trial 1255\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 161, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='log2',\n",
      "                                            n_estimators=161, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.55747126 0.38505747 0.55316092 0.70344828 0.60964912 0.61111111\n",
      " 0.3494152  0.48830409 0.4502924  0.35380117]\n",
      "----------------------------------------\n",
      "Trial 1256\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 127, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=127,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.25718391 0.55890805 0.42816092 0.4862069  0.67836257 0.50292398\n",
      " 0.61549708 0.61695906 0.57309942 0.44883041]\n",
      "----------------------------------------\n",
      "Trial 1257\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 163, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features='log2',\n",
      "                                        n_estimators=163, random_state=100))])\n",
      "cv score: [0.55747126 0.45977011 0.5704023  0.7        0.56578947 0.57602339\n",
      " 0.35233918 0.55847953 0.40935673 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 1258\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 173, 'gb__subsample': 0.8, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=173, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.51149425 0.42816092 0.53017241 0.67931034 0.68274854 0.61111111\n",
      " 0.32894737 0.51461988 0.45321637 0.39181287]\n",
      "----------------------------------------\n",
      "Trial 1259\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 67, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=67, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.52298851 0.47701149 0.58477011 0.69310345 0.7002924  0.61988304\n",
      " 0.29093567 0.47368421 0.47076023 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 1260\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 0.85, 'gb__learning_rate': 0.7, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=95, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.55028736 0.52011494 0.62212644 0.66206897 0.62719298 0.58187135\n",
      " 0.48976608 0.51754386 0.54678363 0.43567251]\n",
      "----------------------------------------\n",
      "Trial 1261\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 95, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=95, random_state=100))])\n",
      "cv score: [0.4137931  0.39367816 0.44109195 0.59655172 0.74415205 0.46491228\n",
      " 0.30263158 0.5497076  0.39181287 0.25438596]\n",
      "----------------------------------------\n",
      "Trial 1262\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 72, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=72,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.34482759 0.63074713 0.63103448 0.60672515 0.49122807\n",
      " 0.45760234 0.48538012 0.31578947 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 1263\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 163, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=163,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41666667 0.3591954  0.67672414 0.65517241 0.67982456 0.54093567\n",
      " 0.40789474 0.53508772 0.33040936 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 1264\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 64, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=64,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.58908046 0.51293103 0.59626437 0.42068966 0.64766082 0.39181287\n",
      " 0.35087719 0.44590643 0.33333333 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 1265\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 61, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=61,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40804598 0.42528736 0.58764368 0.52241379 0.61111111 0.58187135\n",
      " 0.3377193  0.57309942 0.4122807  0.26608187]\n",
      "----------------------------------------\n",
      "Trial 1266\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 29, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            n_estimators=29, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.45689655 0.44827586 0.44396552 0.57241379 0.75584795 0.46783626\n",
      " 0.34356725 0.46491228 0.50877193 0.29532164]\n",
      "----------------------------------------\n",
      "Trial 1267\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 195, 'gb__subsample': 0.95, 'gb__learning_rate': 0.1, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=11, max_features='log2',\n",
      "                                            n_estimators=195, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.53448276 0.4137931  0.58477011 0.64137931 0.64181287 0.5380117\n",
      " 0.35526316 0.49415205 0.47076023 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 1268\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 72, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=72,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37356322 0.35632184 0.57902299 0.67931034 0.49561404 0.64619883\n",
      " 0.44883041 0.40350877 0.39181287 0.26900585]\n",
      "----------------------------------------\n",
      "Trial 1269\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 199, 'gb__subsample': 0.8, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=199, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.51436782 0.41666667 0.52155172 0.66896552 0.66520468 0.58187135\n",
      " 0.35526316 0.49707602 0.4502924  0.34795322]\n",
      "----------------------------------------\n",
      "Trial 1270\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 124, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.01, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=124,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42528736 0.43965517 0.48132184 0.44655172 0.51900585 0.51754386\n",
      " 0.45614035 0.64035088 0.44005848 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 1271\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 177, 'gb__subsample': 0.65, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=177, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.47126437 0.37643678 0.51293103 0.45344828 0.61842105 0.62280702\n",
      " 0.36988304 0.47660819 0.51754386 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 1272\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 40, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=40,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.47126437 0.54310345 0.46896552 0.59356725 0.56725146\n",
      " 0.58479532 0.66666667 0.48830409 0.47953216]\n",
      "----------------------------------------\n",
      "Trial 1273\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 177, 'rf__max_depth': 9, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='sqrt', n_estimators=177,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.49137931 0.42528736 0.61350575 0.67586207 0.71783626 0.5994152\n",
      " 0.30994152 0.46491228 0.47953216 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 1274\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 84, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=84,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36206897 0.27586207 0.73994253 0.69310345 0.59502924 0.57017544\n",
      " 0.45175439 0.50292398 0.50292398 0.25146199]\n",
      "----------------------------------------\n",
      "Trial 1275\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 162, 'gb__subsample': 0.7, 'gb__learning_rate': 0.001, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=10,\n",
      "                                            n_estimators=162, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.47126437 0.48275862 0.47557471 0.56896552 0.72368421 0.49415205\n",
      " 0.27923977 0.52046784 0.43274854 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 1276\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=5,\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.45977011 0.46551724 0.5158046  0.65862069 0.6622807  0.55555556\n",
      " 0.37426901 0.52631579 0.55263158 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 1277\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 1.0, 'gb__learning_rate': 0.001, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=81,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.57471264 0.48275862 0.64224138 0.58275862 0.69152047 0.5994152\n",
      " 0.23830409 0.48830409 0.49707602 0.44005848]\n",
      "----------------------------------------\n",
      "Trial 1278\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 60, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=60,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45114943 0.47701149 0.625      0.57586207 0.64181287 0.60818713\n",
      " 0.42251462 0.52631579 0.35964912 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 1279\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 165, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            n_estimators=165, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.43965517 0.4454023  0.54166667 0.6137931  0.69444444 0.5497076\n",
      " 0.27631579 0.50877193 0.51754386 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 1280\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 78, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=6, max_features=None,\n",
      "                                        n_estimators=78, random_state=100))])\n",
      "cv score: [0.42816092 0.36494253 0.41810345 0.6        0.70906433 0.50877193\n",
      " 0.30555556 0.56140351 0.46783626 0.26608187]\n",
      "----------------------------------------\n",
      "Trial 1281\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 147, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=147, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.52011494 0.43678161 0.58477011 0.6137931  0.65643275 0.5497076\n",
      " 0.24707602 0.5497076  0.42397661 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 1282\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 44, 'rf__max_depth': 14, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features=None, n_estimators=44,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.59482759 0.52011494 0.56465517 0.43965517 0.65350877 0.43128655\n",
      " 0.40350877 0.46345029 0.36842105 0.46052632]\n",
      "----------------------------------------\n",
      "Trial 1283\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 139, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=139,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.29597701 0.3045977  0.46982759 0.58965517 0.42836257 0.60526316\n",
      " 0.64181287 0.42397661 0.4502924  0.33625731]\n",
      "----------------------------------------\n",
      "Trial 1284\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 129, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=129,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.30172414 0.38505747 0.39942529 0.57931034 0.49561404 0.6374269\n",
      " 0.60672515 0.37865497 0.44444444 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 1285\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 118, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=118,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37931034 0.42528736 0.58477011 0.62413793 0.54824561 0.49707602\n",
      " 0.3874269  0.54385965 0.32748538 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 1286\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 173, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=173,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39942529 0.42528736 0.76005747 0.61724138 0.59795322 0.53508772\n",
      " 0.43128655 0.47953216 0.4005848  0.34795322]\n",
      "----------------------------------------\n",
      "Trial 1287\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 166, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, n_estimators=166,\n",
      "                                            random_state=100, subsample=0.9))])\n",
      "cv score: [0.49712644 0.37068966 0.55890805 0.64137931 0.72953216 0.48830409\n",
      " 0.29678363 0.56140351 0.61111111 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 1288\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 61, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=61,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38793103 0.38793103 0.63649425 0.63793103 0.64473684 0.48830409\n",
      " 0.37280702 0.51461988 0.30701754 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 1289\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 35, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.03, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=35,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47844828 0.54022989 0.41666667 0.47241379 0.5497076  0.57602339\n",
      " 0.51315789 0.60818713 0.49707602 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 1290\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 198, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=198,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55316092 0.47413793 0.5        0.68275862 0.60233918 0.57748538\n",
      " 0.34502924 0.52339181 0.50438596 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 1291\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 186, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.01, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=186,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.39655172 0.37643678 0.62787356 0.5862069  0.61549708 0.47368421\n",
      " 0.39912281 0.55555556 0.29532164 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 1292\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 130, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=130,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33045977 0.28448276 0.53304598 0.61724138 0.47807018 0.61695906\n",
      " 0.60380117 0.36842105 0.42690058 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 1293\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 107, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=107,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35632184 0.33908046 0.63362069 0.62758621 0.5628655  0.55263158\n",
      " 0.46637427 0.44152047 0.4005848  0.26900585]\n",
      "----------------------------------------\n",
      "Trial 1294\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 174, 'rf__max_depth': 11, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='log2',\n",
      "                                        n_estimators=174, random_state=100))])\n",
      "cv score: [0.51436782 0.43821839 0.5387931  0.63103448 0.68859649 0.51461988\n",
      " 0.29824561 0.5877193  0.38011696 0.30263158]\n",
      "----------------------------------------\n",
      "Trial 1295\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 10, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=3, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=10,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48275862 0.48275862 0.49137931 0.48275862 0.48245614 0.43274854\n",
      " 0.46491228 0.5        0.47368421 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 1296\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 82, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=82,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3908046  0.35344828 0.61350575 0.61034483 0.60964912 0.47368421\n",
      " 0.46345029 0.46783626 0.29532164 0.26900585]\n",
      "----------------------------------------\n",
      "Trial 1297\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 71, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=71,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.54310345 0.46551724 0.57471264 0.5        0.60233918 0.50730994\n",
      " 0.54532164 0.67251462 0.61695906 0.50730994]\n",
      "----------------------------------------\n",
      "Trial 1298\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=4,\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.47701149 0.44252874 0.59913793 0.61034483 0.64181287 0.58479532\n",
      " 0.31140351 0.42397661 0.53654971 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 1299\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 145, 'rf__max_depth': 6, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='sqrt', n_estimators=145,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.54166667 0.4683908  0.5        0.68275862 0.61111111 0.5745614\n",
      " 0.34502924 0.52631579 0.50730994 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 1300\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 167, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=167, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.5316092  0.38793103 0.57327586 0.54137931 0.66812865 0.48830409\n",
      " 0.29093567 0.55847953 0.43859649 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 1301\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 39, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=39,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.48563218 0.68247126 0.65862069 0.73245614 0.56432749\n",
      " 0.25       0.47076023 0.40789474 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 1302\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 119, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=119, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.51149425 0.40229885 0.625      0.62068966 0.66812865 0.55555556\n",
      " 0.23830409 0.51754386 0.47076023 0.37134503]\n",
      "----------------------------------------\n",
      "Trial 1303\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 32, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=32, random_state=100))])\n",
      "cv score: [0.60057471 0.43965517 0.63362069 0.69310345 0.62865497 0.51169591\n",
      " 0.31140351 0.62573099 0.51461988 0.36988304]\n",
      "----------------------------------------\n",
      "Trial 1304\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 120, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=120,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.3362069  0.36781609 0.57902299 0.56896552 0.48976608 0.52046784\n",
      " 0.55994152 0.54678363 0.32163743 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 1305\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 86, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=13,\n",
      "                                            n_estimators=86,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.44252874 0.39798851 0.4841954  0.53793103 0.67690058 0.54385965\n",
      " 0.24707602 0.46783626 0.55263158 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 1306\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 72, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=72,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38793103 0.3362069  0.63649425 0.66551724 0.60964912 0.53508772\n",
      " 0.4751462  0.50584795 0.43859649 0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 1307\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 78, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=78,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54454023 0.47126437 0.57183908 0.68103448 0.62719298 0.59356725\n",
      " 0.34210526 0.50584795 0.5        0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 1308\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 95, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.3, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=95,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33908046 0.44252874 0.58477011 0.58965517 0.59502924 0.42397661\n",
      " 0.32894737 0.55847953 0.37719298 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 1309\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 180, 'gb__subsample': 0.8, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=180, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.52873563 0.44827586 0.62212644 0.66896552 0.67690058 0.62865497\n",
      " 0.32017544 0.54678363 0.46491228 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 1310\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 99, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=99,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.60632184 0.5        0.32068966 0.59064327 0.41374269\n",
      " 0.37719298 0.29532164 0.55116959 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1311\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 141, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.03, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=141,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36206897 0.37643678 0.65373563 0.63103448 0.61549708 0.47660819\n",
      " 0.41959064 0.52339181 0.34795322 0.25146199]\n",
      "----------------------------------------\n",
      "Trial 1312\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 42, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=42,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44252874 0.29022989 0.53304598 0.68275862 0.54532164 0.50292398\n",
      " 0.55116959 0.49415205 0.42982456 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 1313\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 0.75, 'gb__learning_rate': 0.003, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=2,\n",
      "                                            n_estimators=95, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.47126437 0.46408046 0.52442529 0.54482759 0.64327485 0.64035088\n",
      " 0.37280702 0.57894737 0.51023392 0.46929825]\n",
      "----------------------------------------\n",
      "Trial 1314\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 187, 'gb__subsample': 0.6, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=187, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.39224138 0.42816092 0.21695402 0.51724138 0.72660819 0.29532164\n",
      " 0.27631579 0.45321637 0.42105263 0.41520468]\n",
      "----------------------------------------\n",
      "Trial 1315\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 165, 'rf__max_depth': 2, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features=None, n_estimators=165,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6091954  0.5862069  0.6091954  0.52758621 0.69298246 0.55994152\n",
      " 0.49122807 0.64035088 0.60526316 0.57017544]\n",
      "----------------------------------------\n",
      "Trial 1316\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 14, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=14,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38505747 0.52155172 0.48706897 0.48275862 0.56432749 0.58918129\n",
      " 0.50584795 0.64766082 0.59502924 0.47953216]\n",
      "----------------------------------------\n",
      "Trial 1317\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 145, 'gb__subsample': 0.85, 'gb__learning_rate': 0.03, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=145, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.55747126 0.44252874 0.53591954 0.69655172 0.62719298 0.60818713\n",
      " 0.36403509 0.4619883  0.48245614 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 1318\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 160, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=9,\n",
      "                                            n_estimators=160,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.56896552 0.4454023  0.50431034 0.52758621 0.59210526 0.47076023\n",
      " 0.3377193  0.47660819 0.47368421 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 1319\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.8))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56034483 0.36206897 0.5387931  0.68965517 0.62426901 0.59649123\n",
      " 0.36403509 0.48538012 0.43859649 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 1320\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 64, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=64,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37643678 0.35632184 0.68821839 0.64137931 0.65350877 0.46783626\n",
      " 0.35526316 0.5        0.33040936 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 1321\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 16, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=16, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.53448276 0.5158046  0.51724138 0.62413793 0.71491228 0.52631579\n",
      " 0.23538012 0.39181287 0.45614035 0.30701754]\n",
      "----------------------------------------\n",
      "Trial 1322\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 169, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=169,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50574713 0.46408046 0.64224138 0.62931034 0.73538012 0.58479532\n",
      " 0.23245614 0.44590643 0.48099415 0.36695906]\n",
      "----------------------------------------\n",
      "Trial 1323\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 52, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=52, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.43390805 0.55747126 0.38936782 0.33103448 0.72076023 0.42982456\n",
      " 0.34064327 0.60233918 0.46491228 0.44152047]\n",
      "----------------------------------------\n",
      "Trial 1324\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 96, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=96, random_state=100))])\n",
      "cv score: [0.49712644 0.43821839 0.44109195 0.6        0.66812865 0.48391813\n",
      " 0.3128655  0.55263158 0.36695906 0.24853801]\n",
      "----------------------------------------\n",
      "Trial 1325\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 144, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=144,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33333333 0.37356322 0.56178161 0.65172414 0.50438596 0.63157895\n",
      " 0.43421053 0.50584795 0.43567251 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 1326\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 120, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=120, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.58477011 0.43103448 0.51436782 0.65172414 0.57748538 0.49707602\n",
      " 0.46052632 0.41812865 0.41812865 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 1327\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 188, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=188, random_state=100))])\n",
      "cv score: [0.48132184 0.44109195 0.52873563 0.56896552 0.6505848  0.45614035\n",
      " 0.30116959 0.60233918 0.38888889 0.30847953]\n",
      "----------------------------------------\n",
      "Trial 1328\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 138, 'gb__subsample': 0.9, 'gb__learning_rate': 0.1, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=5, max_features='log2',\n",
      "                                            n_estimators=138, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.49137931 0.41091954 0.62212644 0.7        0.67105263 0.61988304\n",
      " 0.40204678 0.45614035 0.41812865 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 1329\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 175, 'gb__subsample': 0.65, 'gb__learning_rate': 0.001, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=175, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.53735632 0.4454023  0.59913793 0.66206897 0.60964912 0.63157895\n",
      " 0.32017544 0.52046784 0.46491228 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 1330\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 168, 'gb__subsample': 0.85, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=168, random_state=100,\n",
      "                                            subsample=0.85))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.5        0.45402299 0.60201149 0.67241379 0.68859649 0.65497076\n",
      " 0.33187135 0.50877193 0.47953216 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 1331\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 90, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=90, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.49712644 0.45402299 0.4841954  0.66551724 0.6505848  0.64619883\n",
      " 0.2880117  0.47660819 0.47076023 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 1332\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 37, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            n_estimators=37, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.50574713 0.39655172 0.62787356 0.66896552 0.55116959 0.43859649\n",
      " 0.32017544 0.30409357 0.63304094 0.40350877]\n",
      "----------------------------------------\n",
      "Trial 1333\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 153, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            n_estimators=153, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.36781609 0.51724138 0.4841954  0.6137931  0.6505848  0.54385965\n",
      " 0.38450292 0.55555556 0.58333333 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1334\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 80, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=80,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.56034483 0.48850575 0.6795977  0.61551724 0.71052632 0.57163743\n",
      " 0.25       0.46783626 0.42836257 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 1335\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 159, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features=None, n_estimators=159,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57758621 0.47701149 0.54022989 0.37931034 0.62573099 0.5\n",
      " 0.36403509 0.40350877 0.30701754 0.5       ]\n",
      "----------------------------------------\n",
      "Trial 1336\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 14, 'rf__max_depth': 5, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='log2', n_estimators=14,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5316092  0.53735632 0.46695402 0.6137931  0.58918129 0.60526316\n",
      " 0.40350877 0.53216374 0.50292398 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 1337\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 198, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=198,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40517241 0.34770115 0.75143678 0.63448276 0.62134503 0.53508772\n",
      " 0.38157895 0.49122807 0.33040936 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 1338\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50431034 0.40948276 0.54022989 0.4362069  0.50584795 0.58040936\n",
      " 0.5745614  0.66959064 0.52339181 0.45760234]\n",
      "----------------------------------------\n",
      "Trial 1339\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 77, 'gb__subsample': 0.65, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, n_estimators=77,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.34770115 0.44252874 0.47557471 0.55862069 0.66812865 0.57017544\n",
      " 0.39766082 0.5380117  0.57602339 0.43859649]\n",
      "----------------------------------------\n",
      "Trial 1340\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 105, 'gb__subsample': 0.95, 'gb__learning_rate': 0.03, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=5,\n",
      "                                            n_estimators=105, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.45689655 0.43678161 0.59051724 0.64482759 0.73830409 0.59064327\n",
      " 0.32163743 0.45321637 0.55263158 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 1341\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 68, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=68,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.38218391 0.36206897 0.47844828 0.63793103 0.51900585 0.55555556\n",
      " 0.47222222 0.46783626 0.37719298 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 1342\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 69, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features=None,\n",
      "                                        n_estimators=69, random_state=100))])\n",
      "cv score: [0.41091954 0.43390805 0.49281609 0.6        0.74122807 0.47953216\n",
      " 0.29532164 0.5877193  0.37719298 0.24853801]\n",
      "----------------------------------------\n",
      "Trial 1343\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 10, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='log2', n_estimators=10,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60775862 0.55028736 0.61206897 0.64482759 0.72807018 0.34356725\n",
      " 0.29678363 0.50877193 0.40204678 0.37865497]\n",
      "----------------------------------------\n",
      "Trial 1344\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 98, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=98,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37931034 0.36206897 0.52442529 0.59655172 0.50146199 0.57017544\n",
      " 0.49269006 0.49122807 0.34795322 0.26900585]\n",
      "----------------------------------------\n",
      "Trial 1345\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 119, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.003, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=119,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56178161 0.54885057 0.54597701 0.50517241 0.48245614 0.45614035\n",
      " 0.50292398 0.68274854 0.57309942 0.49707602]\n",
      "----------------------------------------\n",
      "Trial 1346\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 37, 'rf__max_depth': 11, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features=None,\n",
      "                                        n_estimators=37, random_state=100))])\n",
      "cv score: [0.47557471 0.37068966 0.49712644 0.56206897 0.6622807  0.50584795\n",
      " 0.25292398 0.52923977 0.39473684 0.26900585]\n",
      "----------------------------------------\n",
      "Trial 1347\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 167, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=167, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.48275862 0.50574713 0.60775862 0.61034483 0.64473684 0.54678363\n",
      " 0.32309942 0.53508772 0.44444444 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 1348\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 80, 'gb__subsample': 0.95, 'gb__learning_rate': 0.001, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=6,\n",
      "                                            n_estimators=80, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.50574713 0.47844828 0.39798851 0.49482759 0.65350877 0.37426901\n",
      " 0.36988304 0.50292398 0.58625731 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 1349\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 12, 'gb__subsample': 0.9, 'gb__learning_rate': 0.001, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=5,\n",
      "                                            n_estimators=12, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.46408046 0.49568966 0.38362069 0.59827586 0.68274854 0.41812865\n",
      " 0.37865497 0.51169591 0.6125731  0.39035088]\n",
      "----------------------------------------\n",
      "Trial 1350\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 138, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=138,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52586207 0.36781609 0.70833333 0.63103448 0.65350877 0.53508772\n",
      " 0.50146199 0.40350877 0.40935673 0.41812865]\n",
      "----------------------------------------\n",
      "Trial 1351\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 112, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=112,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56465517 0.46551724 0.54597701 0.49310345 0.48245614 0.50730994\n",
      " 0.54824561 0.67251462 0.57309942 0.5248538 ]\n",
      "----------------------------------------\n",
      "Trial 1352\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 165, 'gb__subsample': 0.95, 'gb__learning_rate': 0.1, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=6, n_estimators=165,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.43678161 0.42816092 0.54454023 0.54827586 0.63304094 0.56725146\n",
      " 0.30263158 0.56725146 0.49122807 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 1353\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 120, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=120, random_state=100))])\n",
      "cv score: [0.53735632 0.40804598 0.55316092 0.65172414 0.63011696 0.56140351\n",
      " 0.33479532 0.50584795 0.39473684 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 1354\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 57, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=9, max_features='log2',\n",
      "                                        n_estimators=57, random_state=100))])\n",
      "cv score: [0.56321839 0.34626437 0.60488506 0.63103448 0.64473684 0.55263158\n",
      " 0.38157895 0.48830409 0.41081871 0.31432749]\n",
      "----------------------------------------\n",
      "Trial 1355\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 129, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=129, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.49712644 0.45977011 0.57614943 0.67586207 0.67690058 0.60818713\n",
      " 0.28508772 0.44736842 0.44736842 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 1356\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 149, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=149,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40517241 0.31896552 0.75431034 0.60689655 0.5628655  0.63157895\n",
      " 0.64473684 0.37719298 0.4619883  0.35087719]\n",
      "----------------------------------------\n",
      "Trial 1357\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 65, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=65, random_state=100))])\n",
      "cv score: [0.55172414 0.42385057 0.58477011 0.62758621 0.65350877 0.53070175\n",
      " 0.32894737 0.54385965 0.43859649 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 1358\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 93, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=93, random_state=100))])\n",
      "cv score: [0.5545977  0.43965517 0.52442529 0.67241379 0.6125731  0.59356725\n",
      " 0.34064327 0.60818713 0.39181287 0.30263158]\n",
      "----------------------------------------\n",
      "Trial 1359\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 138, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            n_estimators=138, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.60344828 0.17816092 0.43821839 0.52413793 0.53508772 0.47368421\n",
      " 0.4254386  0.23976608 0.6505848  0.53216374]\n",
      "----------------------------------------\n",
      "Trial 1360\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 15, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=15,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38505747 0.37356322 0.55603448 0.54482759 0.46783626 0.61695906\n",
      " 0.4371345  0.60233918 0.33918129 0.27192982]\n",
      "----------------------------------------\n",
      "Trial 1361\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 47, 'gb__subsample': 0.85, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            n_estimators=47, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.42816092 0.39655172 0.47270115 0.57241379 0.71491228 0.47660819\n",
      " 0.3377193  0.4502924  0.52339181 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1362\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 36, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=36,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.44827586 0.45114943 0.58045977 0.66206897 0.62719298 0.62573099\n",
      " 0.31725146 0.48538012 0.49269006 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 1363\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 17, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features='sqrt', n_estimators=17,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.57183908 0.50287356 0.5387931  0.67931034 0.76023392 0.49415205\n",
      " 0.25292398 0.50584795 0.5        0.44883041]\n",
      "----------------------------------------\n",
      "Trial 1364\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 183, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=183, random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.48563218 0.43247126 0.49281609 0.59655172 0.67397661 0.47953216\n",
      " 0.30847953 0.57602339 0.35526316 0.26608187]\n",
      "----------------------------------------\n",
      "Trial 1365\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 62, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=62, random_state=100))])\n",
      "cv score: [0.5158046  0.48275862 0.4841954  0.58275862 0.67982456 0.49122807\n",
      " 0.32309942 0.57602339 0.39035088 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 1366\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 25, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=25,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43390805 0.43965517 0.53591954 0.58275862 0.50584795 0.58479532\n",
      " 0.58479532 0.57017544 0.34795322 0.2748538 ]\n",
      "----------------------------------------\n",
      "Trial 1367\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 116, 'gb__subsample': 0.8, 'gb__learning_rate': 0.003, 'gb__max_depth': 7, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=7,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=116, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.5        0.44252874 0.57327586 0.67931034 0.6622807  0.64912281\n",
      " 0.31140351 0.51461988 0.47660819 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 1368\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 164, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=164,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.56034483 0.5316092  0.51005747 0.66724138 0.62573099 0.58187135\n",
      " 0.38888889 0.55555556 0.49853801 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 1369\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 22, 'gb__subsample': 0.6, 'gb__learning_rate': 0.03, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=22, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.5        0.47988506 0.49568966 0.59655172 0.56578947 0.55555556\n",
      " 0.14766082 0.59356725 0.44444444 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 1370\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, max_features='log2',\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.5316092  0.45977011 0.58764368 0.68275862 0.64181287 0.55847953\n",
      " 0.33479532 0.52046784 0.48830409 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 1371\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 84, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.001, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=84,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.31896552 0.35057471 0.58908046 0.60689655 0.58040936 0.64327485\n",
      " 0.51608187 0.48830409 0.44590643 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 1372\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 154, 'rf__max_depth': 2, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=2,\n",
      "                                        max_features='sqrt', n_estimators=154,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52586207 0.5387931  0.50431034 0.55517241 0.63450292 0.56432749\n",
      " 0.48245614 0.66812865 0.59356725 0.51461988]\n",
      "----------------------------------------\n",
      "Trial 1373\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 39, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=39, random_state=100))])\n",
      "cv score: [0.60632184 0.43534483 0.59913793 0.67931034 0.61111111 0.57309942\n",
      " 0.35818713 0.57017544 0.4122807  0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 1374\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 48, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.1, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=48,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.43390805 0.42816092 0.61350575 0.54827586 0.64766082 0.49561404\n",
      " 0.27339181 0.5994152  0.40350877 0.23391813]\n",
      "----------------------------------------\n",
      "Trial 1375\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 125, 'gb__subsample': 0.9, 'gb__learning_rate': 0.07, 'gb__max_depth': 9, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=9,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=125, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.51724138 0.45402299 0.54454023 0.65517241 0.62719298 0.59356725\n",
      " 0.35233918 0.47953216 0.49707602 0.3625731 ]\n",
      "----------------------------------------\n",
      "Trial 1376\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 114, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=114, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.49137931 0.41666667 0.60775862 0.6137931  0.69152047 0.55263158\n",
      " 0.30847953 0.51461988 0.45614035 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1377\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 95, 'gb__subsample': 0.9, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=95, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.38793103 0.50574713 0.52586207 0.65172414 0.5248538  0.50292398\n",
      " 0.60964912 0.36695906 0.46783626 0.34502924]\n",
      "----------------------------------------\n",
      "Trial 1378\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 155, 'xgb__subsample': 0.7, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=155,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43965517 0.42816092 0.78591954 0.54137931 0.69736842 0.55555556\n",
      " 0.47222222 0.50584795 0.36842105 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 1379\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 22, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=22,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.29022989 0.43534483 0.52873563 0.53448276 0.56140351 0.55555556\n",
      " 0.58040936 0.60380117 0.57309942 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 1380\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 89, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=89,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36781609 0.40804598 0.52729885 0.56206897 0.60964912 0.49122807\n",
      " 0.30555556 0.57309942 0.37719298 0.24561404]\n",
      "----------------------------------------\n",
      "Trial 1381\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 85, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=85,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.50862069 0.48132184 0.47270115 0.45862069 0.59502924 0.56725146\n",
      " 0.52923977 0.6622807  0.5        0.41081871]\n",
      "----------------------------------------\n",
      "Trial 1382\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 164, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=164, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.4137931  0.53448276 0.49856322 0.67241379 0.60087719 0.60526316\n",
      " 0.34356725 0.62573099 0.52046784 0.45906433]\n",
      "----------------------------------------\n",
      "Trial 1383\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 126, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=126,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.36494253 0.4683908  0.42672414 0.5137931  0.52923977 0.56578947\n",
      " 0.52046784 0.57309942 0.45467836 0.42105263]\n",
      "----------------------------------------\n",
      "Trial 1384\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 93, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=93,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56321839 0.54885057 0.54597701 0.50517241 0.62280702 0.4619883\n",
      " 0.50146199 0.66959064 0.62280702 0.53216374]\n",
      "----------------------------------------\n",
      "Trial 1385\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 69, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=69,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53304598 0.47270115 0.49281609 0.68793103 0.59356725 0.6125731\n",
      " 0.33625731 0.51754386 0.51608187 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 1386\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 28, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=28,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44396552 0.41522989 0.43103448 0.44827586 0.53070175 0.52777778\n",
      " 0.51023392 0.59649123 0.55409357 0.39619883]\n",
      "----------------------------------------\n",
      "Trial 1387\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 60, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=60, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.52873563 0.41666667 0.5158046  0.64482759 0.7002924  0.57602339\n",
      " 0.29385965 0.46783626 0.46783626 0.39181287]\n",
      "----------------------------------------\n",
      "Trial 1388\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 132, 'xgb__subsample': 0.75, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=132,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.4454023  0.38793103 0.72270115 0.59655172 0.57748538 0.5380117\n",
      " 0.44005848 0.53216374 0.4122807  0.40935673]\n",
      "----------------------------------------\n",
      "Trial 1389\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 171, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='log2',\n",
      "                                        n_estimators=171, random_state=100))])\n",
      "cv score: [0.52873563 0.47126437 0.57327586 0.64827586 0.65497076 0.52046784\n",
      " 0.2880117  0.57894737 0.39912281 0.29385965]\n",
      "----------------------------------------\n",
      "Trial 1390\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 109, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=109,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33045977 0.37356322 0.56465517 0.56551724 0.45175439 0.55555556\n",
      " 0.55409357 0.56140351 0.38596491 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 1391\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 193, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=193, random_state=100))])\n",
      "cv score: [0.54310345 0.46551724 0.5933908  0.69310345 0.61549708 0.60526316\n",
      " 0.29385965 0.52339181 0.42397661 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 1392\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=81, random_state=100,\n",
      "                                            subsample=0.65))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.52011494 0.47126437 0.55890805 0.6862069  0.64766082 0.4619883\n",
      " 0.33187135 0.58187135 0.42690058 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 1393\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 80, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=80,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.56609195 0.57471264 0.48965517 0.48245614 0.43274854\n",
      " 0.5497076  0.63157895 0.46491228 0.49707602]\n",
      "----------------------------------------\n",
      "Trial 1394\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 74, 'rf__max_depth': 10, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features='sqrt',\n",
      "                                        n_estimators=74, random_state=100))])\n",
      "cv score: [0.52873563 0.41810345 0.56178161 0.62068966 0.64181287 0.5380117\n",
      " 0.32602339 0.56432749 0.42690058 0.28362573]\n",
      "----------------------------------------\n",
      "Trial 1395\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 120, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=120, random_state=100))])\n",
      "cv score: [0.47988506 0.45689655 0.50287356 0.60689655 0.67397661 0.47076023\n",
      " 0.32602339 0.5877193  0.37573099 0.25730994]\n",
      "----------------------------------------\n",
      "Trial 1396\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 20, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=20,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.26436782 0.37931034 0.47270115 0.55172414 0.40497076 0.66959064\n",
      " 0.6622807  0.32163743 0.48245614 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 1397\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 172, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=172,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.47988506 0.45114943 0.59051724 0.64827586 0.72953216 0.5877193\n",
      " 0.30409357 0.44152047 0.47807018 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 1398\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 152, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=4,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=152, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.5387931  0.54885057 0.48994253 0.6362069  0.6374269  0.59356725\n",
      " 0.40497076 0.57309942 0.50292398 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 1399\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 87, 'gb__subsample': 0.75, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, n_estimators=87,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.30747126 0.51149425 0.47126437 0.55172414 0.62280702 0.59064327\n",
      " 0.39619883 0.55263158 0.60526316 0.41520468]\n",
      "----------------------------------------\n",
      "Trial 1400\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 46, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 12, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=12,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=46,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.55172414 0.34770115 0.53017241 0.63448276 0.5745614  0.56725146\n",
      " 0.38450292 0.53508772 0.42105263 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 1401\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 32, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 10, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=10,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=32,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.47988506 0.4137931  0.55028736 0.67586207 0.73245614 0.60526316\n",
      " 0.30847953 0.50584795 0.43274854 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 1402\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 167, 'rf__max_depth': 8, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features='sqrt', n_estimators=167,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51293103 0.44827586 0.55316092 0.65172414 0.7002924  0.61111111\n",
      " 0.31871345 0.49707602 0.46491228 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 1403\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=102, random_state=100))])\n",
      "cv score: [0.48994253 0.44827586 0.45402299 0.55517241 0.64181287 0.46491228\n",
      " 0.32309942 0.60233918 0.41081871 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 1404\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 172, 'gb__subsample': 0.75, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, n_estimators=172,\n",
      "                                            random_state=100,\n",
      "                                            subsample=0.75))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.48563218 0.47988506 0.44109195 0.57586207 0.66520468 0.56725146\n",
      " 0.31432749 0.45614035 0.51754386 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 1405\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 66, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.003, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=66,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33045977 0.28735632 0.48994253 0.54482759 0.44590643 0.56725146\n",
      " 0.66812865 0.4005848  0.35087719 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 1406\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 16, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=16, random_state=100))])\n",
      "cv score: [0.51149425 0.46408046 0.45258621 0.63275862 0.64912281 0.5745614\n",
      " 0.36695906 0.41081871 0.47368421 0.33625731]\n",
      "----------------------------------------\n",
      "Trial 1407\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 33, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='log2',\n",
      "                                        n_estimators=33, random_state=100))])\n",
      "cv score: [0.58908046 0.43103448 0.64224138 0.69655172 0.62865497 0.51461988\n",
      " 0.31140351 0.61695906 0.50584795 0.37865497]\n",
      "----------------------------------------\n",
      "Trial 1408\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 138, 'rf__max_depth': 14, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='log2',\n",
      "                                        n_estimators=138, random_state=100))])\n",
      "cv score: [0.48275862 0.45545977 0.49712644 0.53793103 0.6505848  0.4619883\n",
      " 0.3128655  0.62573099 0.4122807  0.28508772]\n",
      "----------------------------------------\n",
      "Trial 1409\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 76, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=76,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52298851 0.56034483 0.50718391 0.62413793 0.64327485 0.57017544\n",
      " 0.39181287 0.59356725 0.5628655  0.29239766]\n",
      "----------------------------------------\n",
      "Trial 1410\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 92, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 14, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=14,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=92,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41091954 0.38505747 0.65086207 0.64482759 0.63888889 0.47660819\n",
      " 0.40204678 0.5380117  0.33918129 0.30409357]\n",
      "----------------------------------------\n",
      "Trial 1411\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 141, 'gb__subsample': 0.7, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            n_estimators=141, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.43103448 0.47413793 0.48706897 0.58275862 0.63888889 0.51169591\n",
      " 0.29385965 0.5        0.47953216 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1412\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 82, 'xgb__subsample': 0.8, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.1, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=82,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40804598 0.30172414 0.7112069  0.60689655 0.69444444 0.5380117\n",
      " 0.40497076 0.51461988 0.35380117 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 1413\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 164, 'rf__max_depth': 7, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=7, max_features='sqrt',\n",
      "                                        n_estimators=164, random_state=100))])\n",
      "cv score: [0.52586207 0.46551724 0.58764368 0.7        0.60672515 0.59649123\n",
      " 0.29385965 0.55263158 0.43567251 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 1414\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 118, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=5, max_features='sqrt',\n",
      "                                        n_estimators=118, random_state=100))])\n",
      "cv score: [0.47413793 0.4454023  0.55603448 0.66551724 0.5248538  0.60526316\n",
      " 0.38157895 0.52923977 0.44444444 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 1415\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 154, 'xgb__subsample': 0.6, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.001, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=154,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.48275862 0.33908046 0.71695402 0.6        0.64473684 0.58187135\n",
      " 0.51608187 0.50877193 0.48830409 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 1416\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 141, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=141,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56752874 0.47413793 0.49137931 0.5137931  0.48245614 0.43274854\n",
      " 0.46491228 0.5        0.46491228 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 1417\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 199, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=199,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.60632184 0.5        0.32068966 0.59064327 0.41374269\n",
      " 0.37719298 0.29532164 0.55116959 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1418\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 107, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=11,\n",
      "                                        max_features='sqrt', n_estimators=107,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51005747 0.47988506 0.63936782 0.65       0.73099415 0.57602339\n",
      " 0.22660819 0.45614035 0.50438596 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 1419\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 90, 'rf__max_depth': 13, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='sqrt',\n",
      "                                        n_estimators=90, random_state=100))])\n",
      "cv score: [0.48563218 0.44827586 0.44109195 0.5862069  0.67397661 0.46637427\n",
      " 0.27631579 0.57309942 0.36842105 0.25146199]\n",
      "----------------------------------------\n",
      "Trial 1420\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 75, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=75,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.50574713 0.43103448 0.57327586 0.72068966 0.67397661 0.6374269\n",
      " 0.32309942 0.45321637 0.49122807 0.37719298]\n",
      "----------------------------------------\n",
      "Trial 1421\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 139, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=139,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41810345 0.44827586 0.42385057 0.51206897 0.55701754 0.49415205\n",
      " 0.41520468 0.6374269  0.48538012 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 1422\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 137, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            n_estimators=137, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.4137931  0.45114943 0.41522989 0.6137931  0.57748538 0.64035088\n",
      " 0.35526316 0.43274854 0.54093567 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 1423\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 185, 'rf__max_depth': 9, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features='log2', n_estimators=185,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.42528736 0.60488506 0.67931034 0.72368421 0.60233918\n",
      " 0.30994152 0.4619883  0.48245614 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 1424\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43390805 0.39942529 0.78304598 0.64482759 0.63011696 0.56140351\n",
      " 0.43128655 0.54093567 0.38596491 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 1425\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 196, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=196, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56034483 0.48563218 0.4841954  0.7        0.58040936 0.64619883\n",
      " 0.36695906 0.54385965 0.51754386 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 1426\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 134, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.3, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=134,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.48563218 0.4137931  0.69109195 0.66551724 0.63304094 0.61111111\n",
      " 0.45467836 0.47660819 0.40350877 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 1427\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 109, 'gb__subsample': 0.95, 'gb__learning_rate': 1.0, 'gb__max_depth': 3, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=109, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.59770115 0.72988506 0.37212644 0.75862069 0.65935673 0.46783626\n",
      " 0.31140351 0.47076023 0.39473684 0.63450292]\n",
      "----------------------------------------\n",
      "Trial 1428\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 73, 'gb__subsample': 0.65, 'gb__learning_rate': 0.03, 'gb__max_depth': 3, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=73, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.52873563 0.55747126 0.47270115 0.67413793 0.5745614  0.59064327\n",
      " 0.34649123 0.61403509 0.52923977 0.43421053]\n",
      "----------------------------------------\n",
      "Trial 1429\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 87, 'gb__subsample': 0.6, 'gb__learning_rate': 0.01, 'gb__max_depth': 3, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, n_estimators=87,\n",
      "                                            random_state=100, subsample=0.6))])\n",
      "cv score: [0.34195402 0.4454023  0.48706897 0.54137931 0.62134503 0.54385965\n",
      " 0.40497076 0.5380117  0.53947368 0.44736842]\n",
      "----------------------------------------\n",
      "Trial 1430\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 88, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=13,\n",
      "                                        max_features=None, n_estimators=88,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.58908046 0.51293103 0.59626437 0.42068966 0.64766082 0.39181287\n",
      " 0.35087719 0.44590643 0.33333333 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 1431\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 178, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=178,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.47701149 0.38362069 0.39310345 0.60380117 0.33918129\n",
      " 0.40350877 0.57017544 0.62573099 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 1432\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 129, 'rf__max_depth': 13, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features='log2',\n",
      "                                        n_estimators=129, random_state=100))])\n",
      "cv score: [0.4683908  0.45114943 0.5        0.59310345 0.67982456 0.46345029\n",
      " 0.3377193  0.61111111 0.37573099 0.24561404]\n",
      "----------------------------------------\n",
      "Trial 1433\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 166, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.3, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=166,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35344828 0.39942529 0.66810345 0.60689655 0.55116959 0.54678363\n",
      " 0.43128655 0.48245614 0.39181287 0.30994152]\n",
      "----------------------------------------\n",
      "Trial 1434\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 177, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=177,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.41091954 0.31609195 0.69109195 0.5862069  0.61842105 0.49415205\n",
      " 0.39035088 0.47953216 0.34795322 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 1435\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 162, 'rf__max_depth': 12, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features=None, n_estimators=162,\n",
      "                                        random_state=100))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.57758621 0.45689655 0.56752874 0.39137931 0.70321637 0.49561404\n",
      " 0.3245614  0.38596491 0.31578947 0.4254386 ]\n",
      "----------------------------------------\n",
      "Trial 1436\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 75, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=4, max_features='log2',\n",
      "                                        n_estimators=75, random_state=100))])\n",
      "cv score: [0.47988506 0.51149425 0.5158046  0.64137931 0.50877193 0.5877193\n",
      " 0.3874269  0.59649123 0.43274854 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1437\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 159, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.07, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=159,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.5158046  0.41522989 0.54022989 0.42931034 0.52339181 0.53216374\n",
      " 0.59210526 0.67251462 0.5380117  0.46929825]\n",
      "----------------------------------------\n",
      "Trial 1438\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 62, 'gb__subsample': 0.65, 'gb__learning_rate': 1.0, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=62, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.61781609 0.3362069  0.41522989 0.42758621 0.39619883 0.51169591\n",
      " 0.46052632 0.37134503 0.45614035 0.4122807 ]\n",
      "----------------------------------------\n",
      "Trial 1439\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 72, 'gb__subsample': 0.85, 'gb__learning_rate': 0.3, 'gb__max_depth': 2, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=2,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=72, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.45402299 0.45402299 0.59913793 0.7        0.58918129 0.64327485\n",
      " 0.41666667 0.51900585 0.53947368 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 1440\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.1, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=13, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56178161 0.54885057 0.57471264 0.51206897 0.48245614 0.4619883\n",
      " 0.48830409 0.63888889 0.62280702 0.52046784]\n",
      "----------------------------------------\n",
      "Trial 1441\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 189, 'gb__subsample': 0.8, 'gb__learning_rate': 0.1, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=9, n_estimators=189,\n",
      "                                            random_state=100, subsample=0.8))])\n",
      "cv score: [0.46551724 0.48850575 0.48706897 0.6137931  0.63011696 0.52631579\n",
      " 0.32894737 0.45321637 0.54385965 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 1442\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 151, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 2, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=2,\n",
      "                                            n_estimators=151, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.48275862 0.56465517 0.53304598 0.57586207 0.65935673 0.62573099\n",
      " 0.37426901 0.56725146 0.59649123 0.44005848]\n",
      "----------------------------------------\n",
      "Trial 1443\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 111, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=111, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.4454023  0.52011494 0.75862069 0.5862069  0.48684211 0.52046784\n",
      " 0.50584795 0.61111111 0.47076023 0.25584795]\n",
      "----------------------------------------\n",
      "Trial 1444\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 138, 'rf__max_depth': 13, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=13, max_features=None,\n",
      "                                        n_estimators=138, random_state=100))])\n",
      "cv score: [0.46695402 0.43678161 0.45258621 0.55862069 0.70906433 0.44736842\n",
      " 0.31871345 0.54385965 0.46783626 0.23684211]\n",
      "----------------------------------------\n",
      "Trial 1445\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 133, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.003, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=133,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.36781609 0.43103448 0.57327586 0.53448276 0.55116959 0.5\n",
      " 0.44298246 0.54093567 0.31578947 0.26023392]\n",
      "----------------------------------------\n",
      "Trial 1446\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 198, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=198,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.45689655 0.35632184 0.71695402 0.62413793 0.68274854 0.60233918\n",
      " 0.53654971 0.48245614 0.46491228 0.44444444]\n",
      "----------------------------------------\n",
      "Trial 1447\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 92, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.01, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=92,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38505747 0.43678161 0.64224138 0.63103448 0.64473684 0.51169591\n",
      " 0.40204678 0.47368421 0.35964912 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 1448\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 108, 'gb__subsample': 0.65, 'gb__learning_rate': 0.7, 'gb__max_depth': 7, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=7,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=108, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.51436782 0.38362069 0.29741379 0.48448276 0.69298246 0.40350877\n",
      " 0.53070175 0.48976608 0.33187135 0.66812865]\n",
      "----------------------------------------\n",
      "Trial 1449\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 194, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=194,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40373563 0.48706897 0.53735632 0.48103448 0.63888889 0.49853801\n",
      " 0.57748538 0.53070175 0.60964912 0.47076023]\n",
      "----------------------------------------\n",
      "Trial 1450\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 178, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=178, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.57471264 0.40804598 0.53591954 0.5862069  0.66812865 0.42982456\n",
      " 0.36111111 0.34502924 0.32163743 0.43859649]\n",
      "----------------------------------------\n",
      "Trial 1451\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 81, 'gb__subsample': 0.9, 'gb__learning_rate': 0.003, 'gb__max_depth': 14, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=14,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=81, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.49137931 0.40517241 0.625      0.63793103 0.68567251 0.64619883\n",
      " 0.24122807 0.51754386 0.3625731  0.33918129]\n",
      "----------------------------------------\n",
      "Trial 1452\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 193, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=193, random_state=100))])\n",
      "cv score: [0.45977011 0.49137931 0.46982759 0.57241379 0.5745614  0.56140351\n",
      " 0.42836257 0.54678363 0.54385965 0.48830409]\n",
      "----------------------------------------\n",
      "Trial 1453\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 136, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=136,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.53017241 0.55747126 0.56034483 0.66959064 0.43859649\n",
      " 0.37280702 0.61549708 0.61988304 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 1454\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 45, 'gb__subsample': 0.9, 'gb__learning_rate': 0.01, 'gb__max_depth': 13, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=13,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=45, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.56896552 0.41666667 0.64798851 0.57931034 0.7119883  0.57309942\n",
      " 0.28216374 0.37719298 0.47368421 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 1455\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 28, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 10, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=10,\n",
      "                                            n_estimators=28, random_state=100,\n",
      "                                            subsample=0.7))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.44252874 0.41666667 0.55603448 0.60344828 0.78508772 0.52046784\n",
      " 0.31140351 0.52923977 0.51754386 0.35964912]\n",
      "----------------------------------------\n",
      "Trial 1456\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 155, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=10, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=155,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.47988506 0.44683908 0.48850575 0.47413793 0.53070175 0.54093567\n",
      " 0.57748538 0.59064327 0.47807018 0.44298246]\n",
      "----------------------------------------\n",
      "Trial 1457\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 33, 'gb__subsample': 0.65, 'gb__learning_rate': 0.07, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=5,\n",
      "                                            n_estimators=33, random_state=100,\n",
      "                                            subsample=0.65))])\n",
      "cv score: [0.4454023  0.39367816 0.60201149 0.66206897 0.62719298 0.53508772\n",
      " 0.28216374 0.49415205 0.53508772 0.29239766]\n",
      "----------------------------------------\n",
      "Trial 1458\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 118, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 14, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=14,\n",
      "                                            n_estimators=118, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.49137931 0.43965517 0.54454023 0.62758621 0.72368421 0.46491228\n",
      " 0.3625731  0.30409357 0.33918129 0.60526316]\n",
      "----------------------------------------\n",
      "Trial 1459\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 31, 'gb__subsample': 0.95, 'gb__learning_rate': 0.3, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=31, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.55172414 0.47701149 0.63074713 0.70344828 0.66520468 0.61403509\n",
      " 0.26169591 0.48245614 0.57309942 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 1460\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 122, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=14,\n",
      "                                        max_features='sqrt', n_estimators=122,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.60775862 0.47988506 0.66235632 0.60172414 0.74853801 0.58625731\n",
      " 0.24707602 0.45614035 0.46491228 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 1461\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 64, 'rf__max_depth': 7, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features='log2', n_estimators=64,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5387931  0.46695402 0.56896552 0.66724138 0.60380117 0.5994152\n",
      " 0.35672515 0.49122807 0.51169591 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 1462\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 68, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=9, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=68,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60344828 0.56321839 0.57471264 0.52758621 0.48245614 0.43274854\n",
      " 0.46491228 0.64035088 0.47368421 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 1463\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 140, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=140,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.34195402 0.69683908 0.63103448 0.54532164 0.60818713\n",
      " 0.41374269 0.47660819 0.4005848  0.30701754]\n",
      "----------------------------------------\n",
      "Trial 1464\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 197, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=197,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.41091954 0.3362069  0.75431034 0.62758621 0.56578947 0.64912281\n",
      " 0.65350877 0.34210526 0.44152047 0.38304094]\n",
      "----------------------------------------\n",
      "Trial 1465\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 11, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=11,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56609195 0.56321839 0.57471264 0.52586207 0.48245614 0.43274854\n",
      " 0.46491228 0.64035088 0.63888889 0.46491228]\n",
      "----------------------------------------\n",
      "Trial 1466\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 173, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.003, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=173,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39367816 0.39942529 0.69971264 0.65862069 0.57163743 0.59649123\n",
      " 0.41959064 0.45614035 0.47368421 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 1467\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 93, 'rf__max_depth': 6, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features=None, n_estimators=93,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5        0.47701149 0.38362069 0.39310345 0.60380117 0.33918129\n",
      " 0.40350877 0.57017544 0.62573099 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 1468\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 154, 'gb__subsample': 0.6, 'gb__learning_rate': 0.1, 'gb__max_depth': 4, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=4, max_features='log2',\n",
      "                                            n_estimators=154, random_state=100,\n",
      "                                            subsample=0.6))])\n",
      "cv score: [0.60344828 0.43103448 0.48994253 0.67586207 0.6505848  0.69298246\n",
      " 0.43421053 0.48830409 0.43567251 0.33918129]\n",
      "----------------------------------------\n",
      "Trial 1469\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 102, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=102,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.27155172 0.37356322 0.35775862 0.46896552 0.44152047 0.55116959\n",
      " 0.58040936 0.60818713 0.50292398 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 1470\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 89, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=89,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.56321839 0.54885057 0.60344828 0.49827586 0.48245614 0.50730994\n",
      " 0.5497076  0.67397661 0.46491228 0.52631579]\n",
      "----------------------------------------\n",
      "Trial 1471\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 97, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=97,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50718391 0.54022989 0.51724138 0.57413793 0.63304094 0.61842105\n",
      " 0.43859649 0.59649123 0.55994152 0.40350877]\n",
      "----------------------------------------\n",
      "Trial 1472\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 118, 'rf__max_depth': 3, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features=None,\n",
      "                                        n_estimators=118, random_state=100))])\n",
      "cv score: [0.45689655 0.47701149 0.50718391 0.55172414 0.56871345 0.5380117\n",
      " 0.46052632 0.52631579 0.52339181 0.48245614]\n",
      "----------------------------------------\n",
      "Trial 1473\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 82, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=82,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.5316092  0.5704023  0.49712644 0.45862069 0.62280702 0.57017544\n",
      " 0.46929825 0.60818713 0.56871345 0.46637427]\n",
      "----------------------------------------\n",
      "Trial 1474\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 62, 'rf__max_depth': 4, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features='log2', n_estimators=62,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.52586207 0.56034483 0.50431034 0.62413793 0.64327485 0.58187135\n",
      " 0.38596491 0.59356725 0.55116959 0.27777778]\n",
      "----------------------------------------\n",
      "Trial 1475\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 183, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=183,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.51293103 0.37212644 0.56896552 0.42931034 0.57894737 0.5745614\n",
      " 0.65643275 0.66374269 0.47368421 0.40350877]\n",
      "----------------------------------------\n",
      "Trial 1476\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 182, 'rf__max_depth': 4, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=4,\n",
      "                                        max_features=None, n_estimators=182,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53448276 0.53017241 0.55747126 0.56034483 0.66959064 0.43859649\n",
      " 0.37280702 0.61549708 0.61988304 0.51023392]\n",
      "----------------------------------------\n",
      "Trial 1477\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 80, 'gb__subsample': 0.95, 'gb__learning_rate': 0.7, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=80, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.52298851 0.6637931  0.61494253 0.52068966 0.60964912 0.58479532\n",
      " 0.39327485 0.49707602 0.73391813 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 1478\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 143, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 6, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=6,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=143,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.51149425 0.40229885 0.55028736 0.72413793 0.67982456 0.66081871\n",
      " 0.34064327 0.4502924  0.52631579 0.39181287]\n",
      "----------------------------------------\n",
      "Trial 1479\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 160, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.003, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=160,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.21264368 0.42528736 0.36781609 0.50862069 0.54678363 0.57748538\n",
      " 0.55701754 0.5497076  0.51315789 0.41374269]\n",
      "----------------------------------------\n",
      "Trial 1480\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 0.7, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.7, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.46264368 0.35632184 0.63074713 0.61724138 0.68567251 0.57017544\n",
      " 0.44883041 0.50292398 0.42397661 0.42397661]\n",
      "----------------------------------------\n",
      "Trial 1481\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 174, 'gb__subsample': 0.95, 'gb__learning_rate': 0.01, 'gb__max_depth': 8, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=8,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=174, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.50287356 0.45402299 0.56465517 0.7        0.68567251 0.62573099\n",
      " 0.34649123 0.43859649 0.48830409 0.34795322]\n",
      "----------------------------------------\n",
      "Trial 1482\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 147, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=147,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.3591954  0.36206897 0.62787356 0.60344828 0.57748538 0.54678363\n",
      " 0.40789474 0.5        0.39473684 0.28070175]\n",
      "----------------------------------------\n",
      "Trial 1483\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 102, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=102,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.4454023  0.59051724 0.64827586 0.74415205 0.57017544\n",
      " 0.29824561 0.45321637 0.47807018 0.36549708]\n",
      "----------------------------------------\n",
      "Trial 1484\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 25, 'gb__subsample': 1.0, 'gb__learning_rate': 0.003, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=8,\n",
      "                                            n_estimators=25,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.40517241 0.61925287 0.51436782 0.3137931  0.59064327 0.39619883\n",
      " 0.37719298 0.28216374 0.50438596 0.39619883]\n",
      "----------------------------------------\n",
      "Trial 1485\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 28, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.07, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=28,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.32471264 0.33333333 0.68534483 0.67586207 0.57748538 0.56432749\n",
      " 0.40789474 0.52923977 0.4502924  0.37134503]\n",
      "----------------------------------------\n",
      "Trial 1486\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 125, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.03, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=125,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44827586 0.33045977 0.63362069 0.69655172 0.5248538  0.54678363\n",
      " 0.47222222 0.47953216 0.36842105 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 1487\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 131, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=131, random_state=100))])\n",
      "cv score: [0.44252874 0.50862069 0.47270115 0.61034483 0.6125731  0.59064327\n",
      " 0.39035088 0.57017544 0.45614035 0.40935673]\n",
      "----------------------------------------\n",
      "Trial 1488\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 117, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=117,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40229885 0.27298851 0.80603448 0.66206897 0.49561404 0.65204678\n",
      " 0.68859649 0.39473684 0.4502924  0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1489\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 73, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='log2',\n",
      "                                        n_estimators=73, random_state=100))])\n",
      "cv score: [0.52011494 0.5316092  0.4612069  0.59310345 0.56140351 0.59649123\n",
      " 0.3874269  0.53508772 0.44298246 0.41520468]\n",
      "----------------------------------------\n",
      "Trial 1490\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 32, 'rf__max_depth': 14, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=14, max_features='sqrt',\n",
      "                                        n_estimators=32, random_state=100))])\n",
      "cv score: [0.55028736 0.41522989 0.52155172 0.58275862 0.66812865 0.48538012\n",
      " 0.33040936 0.46783626 0.49269006 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 1491\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 165, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.1, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=5, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=165,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58908046 0.54885057 0.57471264 0.51206897 0.48245614 0.4619883\n",
      " 0.46491228 0.64035088 0.46491228 0.51169591]\n",
      "----------------------------------------\n",
      "Trial 1492\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 126, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=126, random_state=100,\n",
      "                                            subsample=0.75))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.4454023  0.52011494 0.56321839 0.5862069  0.48684211 0.52046784\n",
      " 0.50584795 0.61111111 0.45906433 0.25584795]\n",
      "----------------------------------------\n",
      "Trial 1493\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 187, 'rf__max_depth': 7, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=7,\n",
      "                                        max_features=None, n_estimators=187,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.45114943 0.5387931  0.48706897 0.37413793 0.58187135 0.35672515\n",
      " 0.39327485 0.40350877 0.62719298 0.38450292]\n",
      "----------------------------------------\n",
      "Trial 1494\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 36, 'gb__subsample': 1.0, 'gb__learning_rate': 0.03, 'gb__max_depth': 11, 'gb__max_features': 'sqrt', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=11,\n",
      "                                            max_features='sqrt',\n",
      "                                            n_estimators=36,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.54597701 0.45114943 0.58477011 0.69655172 0.72953216 0.60233918\n",
      " 0.27046784 0.47368421 0.47076023 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 1495\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 41, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=12,\n",
      "                                        max_features='sqrt', n_estimators=41,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.6091954  0.51724138 0.63505747 0.66034483 0.73538012 0.5745614\n",
      " 0.24707602 0.47660819 0.48245614 0.35380117]\n",
      "----------------------------------------\n",
      "Trial 1496\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 86, 'gb__subsample': 0.75, 'gb__learning_rate': 1.0, 'gb__max_depth': 6, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=6,\n",
      "                                            n_estimators=86, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.65229885 0.50862069 0.49856322 0.51034483 0.58625731 0.40350877\n",
      " 0.25584795 0.5745614  0.7251462  0.29239766]\n",
      "----------------------------------------\n",
      "Trial 1497\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 45, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.07, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=12,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=45,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.34770115 0.31034483 0.54741379 0.57931034 0.5248538  0.57017544\n",
      " 0.46345029 0.53508772 0.2748538  0.30116959]\n",
      "----------------------------------------\n",
      "Trial 1498\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 47, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=47,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.53017241 0.49281609 0.47844828 0.69137931 0.57894737 0.60672515\n",
      " 0.34795322 0.52046784 0.51608187 0.32163743]\n",
      "----------------------------------------\n",
      "Trial 1499\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 70, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=70,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40517241 0.33045977 0.50143678 0.6        0.64473684 0.36842105\n",
      " 0.36111111 0.54093567 0.32163743 0.32748538]\n",
      "----------------------------------------\n",
      "Trial 1500\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 131, 'gb__subsample': 0.7, 'gb__learning_rate': 0.03, 'gb__max_depth': 8, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.03, max_depth=8,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=131, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.47701149 0.44252874 0.52155172 0.71034483 0.64181287 0.64912281\n",
      " 0.30847953 0.52923977 0.51754386 0.35672515]\n",
      "----------------------------------------\n",
      "Trial 1501\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 96, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.07, 'xgb__gamma': 0.01, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.07,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=96,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42816092 0.42816092 0.63074713 0.58965517 0.68567251 0.42397661\n",
      " 0.30116959 0.59064327 0.42397661 0.20467836]\n",
      "----------------------------------------\n",
      "Trial 1502\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 199, 'xgb__subsample': 0.85, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.03, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=199,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.42816092 0.33333333 0.72844828 0.6137931  0.56578947 0.6754386\n",
      " 0.60672515 0.35380117 0.45614035 0.42397661]\n",
      "----------------------------------------\n",
      "Trial 1503\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 163, 'rf__max_depth': 8, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=8,\n",
      "                                        max_features=None, n_estimators=163,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.49712644 0.60632184 0.5        0.32068966 0.59064327 0.41374269\n",
      " 0.37719298 0.29532164 0.55116959 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1504\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 103, 'rf__max_depth': 3, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
      "                                        max_features='log2', n_estimators=103,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.51005747 0.54022989 0.51724138 0.57413793 0.63304094 0.62134503\n",
      " 0.44444444 0.59649123 0.55116959 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 1505\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 173, 'rf__max_depth': 5, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=5,\n",
      "                                        max_features='sqrt', n_estimators=173,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.5545977  0.53448276 0.50718391 0.66034483 0.62573099 0.5877193\n",
      " 0.38596491 0.55263158 0.50438596 0.29824561]\n",
      "----------------------------------------\n",
      "Trial 1506\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 136, 'rf__max_depth': 9, 'rf__max_features': None, 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=9,\n",
      "                                        max_features=None, n_estimators=136,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.55172414 0.45114943 0.5158046  0.33275862 0.53362573 0.46345029\n",
      " 0.38157895 0.32748538 0.48391813 0.42982456]\n",
      "----------------------------------------\n",
      "Trial 1507\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 187, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 12, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=12,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=187,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.49712644 0.49137931 0.54166667 0.67586207 0.64181287 0.63450292\n",
      " 0.36111111 0.49415205 0.41812865 0.4502924 ]\n",
      "----------------------------------------\n",
      "Trial 1508\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 83, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.03, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=83,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.33045977 0.31609195 0.71408046 0.64827586 0.50438596 0.66666667\n",
      " 0.58333333 0.53508772 0.4619883  0.42982456]\n",
      "----------------------------------------\n",
      "Trial 1509\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 187, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.003, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=6, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=187,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.60344828 0.56321839 0.57471264 0.52758621 0.71637427 0.46783626\n",
      " 0.50146199 0.63888889 0.63888889 0.53362573]\n",
      "----------------------------------------\n",
      "Trial 1510\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 39, 'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=39, random_state=100))])\n",
      "cv score: [0.60632184 0.43534483 0.59913793 0.67931034 0.61111111 0.57309942\n",
      " 0.35818713 0.57017544 0.4122807  0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 1511\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 31, 'rf__max_depth': 10, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2', n_estimators=31,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.50143678 0.43821839 0.63649425 0.64655172 0.74561404 0.56578947\n",
      " 0.32163743 0.43274854 0.50877193 0.39327485]\n",
      "----------------------------------------\n",
      "Trial 1512\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 126, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=11, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=126,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.56609195 0.46551724 0.54597701 0.48965517 0.48245614 0.50730994\n",
      " 0.54824561 0.67251462 0.57309942 0.5248538 ]\n",
      "----------------------------------------\n",
      "Trial 1513\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 26, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.1, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=26,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.36206897 0.34195402 0.57327586 0.59310345 0.55701754 0.66374269\n",
      " 0.34064327 0.54678363 0.4371345  0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 1514\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 194, 'rf__max_depth': 3, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_features='sqrt',\n",
      "                                        n_estimators=194, random_state=100))])\n",
      "cv score: [0.49137931 0.52011494 0.4841954  0.61034483 0.6125731  0.61111111\n",
      " 0.4254386  0.59649123 0.46491228 0.40643275]\n",
      "----------------------------------------\n",
      "Trial 1515\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 154, 'gb__subsample': 0.8, 'gb__learning_rate': 0.3, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=5,\n",
      "                                            n_estimators=154, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.47413793 0.40517241 0.43821839 0.55172414 0.63304094 0.50877193\n",
      " 0.30555556 0.65789474 0.52339181 0.3128655 ]\n",
      "----------------------------------------\n",
      "Trial 1516\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 11, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 13, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=13,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=11, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.46264368 0.43678161 0.5387931  0.6        0.64181287 0.52046784\n",
      " 0.30263158 0.55263158 0.35964912 0.3245614 ]\n",
      "----------------------------------------\n",
      "Trial 1517\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 90, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=90,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42097701 0.47413793 0.49281609 0.49310345 0.51315789 0.5248538\n",
      " 0.50584795 0.61988304 0.44883041 0.41520468]\n",
      "----------------------------------------\n",
      "Trial 1518\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 172, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.001, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=172,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.40229885 0.41666667 0.69109195 0.6137931  0.51023392 0.66959064\n",
      " 0.4371345  0.42397661 0.44152047 0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1519\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 30, 'rf__max_depth': 11, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=11, max_features='sqrt',\n",
      "                                        n_estimators=30, random_state=100))])\n",
      "cv score: [0.56321839 0.43390805 0.65373563 0.62413793 0.73538012 0.53362573\n",
      " 0.29093567 0.48976608 0.4254386  0.32163743]\n",
      "----------------------------------------\n",
      "Trial 1520\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 131, 'gb__subsample': 0.7, 'gb__learning_rate': 0.01, 'gb__max_depth': 4, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01, max_depth=4,\n",
      "                                            n_estimators=131, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.37356322 0.48275862 0.46982759 0.62413793 0.61842105 0.57309942\n",
      " 0.34064327 0.52923977 0.54239766 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 1521\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 86, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.03, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=86,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.36781609 0.41954023 0.65086207 0.6137931  0.68859649 0.50292398\n",
      " 0.34064327 0.52631579 0.39766082 0.24269006]\n",
      "----------------------------------------\n",
      "Trial 1522\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 116, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.01, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=8, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=116,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.52873563 0.43965517 0.54597701 0.45       0.57017544 0.50877193\n",
      " 0.54824561 0.6374269  0.6125731  0.49122807]\n",
      "----------------------------------------\n",
      "Trial 1523\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 161, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=161,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.24712644 0.47988506 0.35057471 0.48965517 0.55701754 0.57309942\n",
      " 0.57602339 0.55994152 0.53654971 0.4254386 ]\n",
      "----------------------------------------\n",
      "Trial 1524\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 113, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=113,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38218391 0.33908046 0.59626437 0.67931034 0.58625731 0.5497076\n",
      " 0.45760234 0.52046784 0.36842105 0.38011696]\n",
      "----------------------------------------\n",
      "Trial 1525\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 45, 'gb__subsample': 0.9, 'gb__learning_rate': 0.3, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.3, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=45, random_state=100,\n",
      "                                            subsample=0.9))])\n",
      "cv score: [0.53448276 0.43965517 0.59051724 0.59655172 0.5745614  0.61111111\n",
      " 0.35818713 0.47660819 0.50292398 0.39473684]\n",
      "----------------------------------------\n",
      "Trial 1526\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 166, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 10, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=10,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=166,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.42816092 0.41091954 0.66235632 0.65862069 0.58625731 0.58187135\n",
      " 0.4254386  0.48830409 0.33625731 0.31578947]\n",
      "----------------------------------------\n",
      "Trial 1527\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 106, 'gb__subsample': 1.0, 'gb__learning_rate': 0.07, 'gb__max_depth': 10, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.07, max_depth=10,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=106,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.45977011 0.4683908  0.57902299 0.68965517 0.66520468 0.6754386\n",
      " 0.3494152  0.45321637 0.49415205 0.40935673]\n",
      "----------------------------------------\n",
      "Trial 1528\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 147, 'gb__subsample': 0.8, 'gb__learning_rate': 0.7, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=13,\n",
      "                                            n_estimators=147, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.60057471 0.3045977  0.58477011 0.6137931  0.55263158 0.4122807\n",
      " 0.34064327 0.37719298 0.53508772 0.53216374]\n",
      "----------------------------------------\n",
      "Trial 1529\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 37, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__max_depth': 8, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.3, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=None, max_depth=8,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=37,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.37356322 0.36494253 0.48994253 0.59310345 0.54093567 0.56140351\n",
      " 0.53362573 0.45321637 0.35964912 0.28362573]\n",
      "----------------------------------------\n",
      "Trial 1530\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 26, 'gb__subsample': 0.75, 'gb__learning_rate': 0.7, 'gb__max_depth': 8, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=8,\n",
      "                                            n_estimators=26, random_state=100,\n",
      "                                            subsample=0.75))])\n",
      "cv score: [0.58333333 0.40229885 0.78304598 0.53103448 0.60087719 0.60526316\n",
      " 0.15350877 0.33333333 0.64327485 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 1531\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 40, 'rf__max_depth': 6, 'rf__max_features': 'log2', 'rf__random_state': 100, 'rf__bootstrap': False}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=6,\n",
      "                                        max_features='log2', n_estimators=40,\n",
      "                                        random_state=100))])\n",
      "cv score: [0.54166667 0.46695402 0.49568966 0.69482759 0.58333333 0.63011696\n",
      " 0.34210526 0.51754386 0.52192982 0.33333333]\n",
      "----------------------------------------\n",
      "Trial 1532\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 45, 'xgb__subsample': 0.8, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.07, 'xgb__max_depth': 3, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=3,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=45,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.8, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.35632184 0.50574713 0.41810345 0.60862069 0.64327485 0.50730994\n",
      " 0.61695906 0.58625731 0.5        0.41520468]\n",
      "----------------------------------------\n",
      "Trial 1533\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 194, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.07, 'xgb__max_depth': 7, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=7,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=194,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.22557471 0.37356322 0.40804598 0.60517241 0.55555556 0.53362573\n",
      " 0.59795322 0.52631579 0.4619883  0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1534\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 68, 'gb__subsample': 1.0, 'gb__learning_rate': 0.7, 'gb__max_depth': 5, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.7, max_depth=5,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=68,\n",
      "                                            random_state=100))])\n",
      "cv score: [0.51149425 0.5        0.53591954 0.64137931 0.60380117 0.62865497\n",
      " 0.45760234 0.5        0.46491228 0.35087719]\n",
      "----------------------------------------\n",
      "Trial 1535\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 135, 'gb__subsample': 0.7, 'gb__learning_rate': 0.003, 'gb__max_depth': 9, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=9,\n",
      "                                            n_estimators=135, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.42528736 0.4683908  0.47270115 0.57931034 0.74122807 0.5\n",
      " 0.2880117  0.49707602 0.47368421 0.31871345]\n",
      "----------------------------------------\n",
      "Trial 1536\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 118, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.001, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=118,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38074713 0.46551724 0.45402299 0.49310345 0.56578947 0.59356725\n",
      " 0.51900585 0.60233918 0.54824561 0.4122807 ]\n",
      "----------------------------------------\n",
      "Trial 1537\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 74, 'gb__subsample': 0.95, 'gb__learning_rate': 0.003, 'gb__max_depth': 5, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.003, max_depth=5,\n",
      "                                            n_estimators=74, random_state=100,\n",
      "                                            subsample=0.95))])\n",
      "cv score: [0.43678161 0.57902299 0.40086207 0.53275862 0.67836257 0.44883041\n",
      " 0.48538012 0.55263158 0.62865497 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 1538\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 189, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.03, 'xgb__gamma': 0.01, 'xgb__max_depth': 2, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.01, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.03,\n",
      "                               max_delta_step=None, max_depth=2,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=189,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.29597701 0.4683908  0.47270115 0.58275862 0.57163743 0.60526316\n",
      " 0.50438596 0.52631579 0.42982456 0.43567251]\n",
      "----------------------------------------\n",
      "Trial 1539\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 112, 'xgb__subsample': 1.0, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.003, 'xgb__max_depth': 5, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.003, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=5,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=112,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=1.0, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.39655172 0.32758621 0.73994253 0.64482759 0.56578947 0.66081871\n",
      " 0.65350877 0.29239766 0.44736842 0.34210526]\n",
      "----------------------------------------\n",
      "Trial 1540\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 188, 'xgb__subsample': 0.6, 'xgb__learning_rate': 0.003, 'xgb__gamma': 0.03, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.03, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.003, max_delta_step=None,\n",
      "                               max_depth=4, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=188,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.6, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.43821839 0.34482759 0.49568966 0.53275862 0.51315789 0.63157895\n",
      " 0.56578947 0.6505848  0.50877193 0.39766082]\n",
      "----------------------------------------\n",
      "Trial 1541\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 174, 'xgb__subsample': 0.75, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 13, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=13,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=174,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.75, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.44252874 0.33908046 0.56752874 0.57931034 0.61842105 0.44152047\n",
      " 0.44883041 0.53216374 0.27192982 0.30116959]\n",
      "----------------------------------------\n",
      "Trial 1542\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 142, 'xgb__subsample': 0.95, 'xgb__learning_rate': 0.001, 'xgb__gamma': 0.001, 'xgb__max_depth': 12, 'xgb__colsample_bytree': 0.8, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.8, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None,\n",
      "                               learning_rate=0.001, max_delta_step=None,\n",
      "                               max_depth=12, min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=142,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.95, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.58908046 0.54885057 0.57471264 0.51206897 0.48245614 0.4619883\n",
      " 0.46491228 0.5        0.46491228 0.45614035]\n",
      "----------------------------------------\n",
      "Trial 1543\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 48, 'gb__subsample': 0.85, 'gb__learning_rate': 0.001, 'gb__max_depth': 12, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=0.001, max_depth=12,\n",
      "                                            n_estimators=48, random_state=100,\n",
      "                                            subsample=0.85))])\n",
      "cv score: [0.45402299 0.36781609 0.51867816 0.59310345 0.70906433 0.55263158\n",
      " 0.29678363 0.47368421 0.4619883  0.30994152]\n",
      "----------------------------------------\n",
      "Trial 1544\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 25, 'xgb__subsample': 0.85, 'xgb__learning_rate': 0.7, 'xgb__gamma': 0.1, 'xgb__max_depth': 9, 'xgb__colsample_bytree': 0.9, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.9, gamma=0.1, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.7,\n",
      "                               max_delta_step=None, max_depth=9,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=25,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.85, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.38793103 0.3908046  0.64798851 0.65517241 0.5745614  0.52923977\n",
      " 0.37865497 0.55263158 0.36549708 0.25146199]\n",
      "----------------------------------------\n",
      "Trial 1545\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 121, 'gb__subsample': 0.8, 'gb__learning_rate': 1.0, 'gb__max_depth': 7, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=7,\n",
      "                                            n_estimators=121, random_state=100,\n",
      "                                            subsample=0.8))])\n",
      "cv score: [0.57758621 0.51436782 0.46695402 0.6137931  0.43859649 0.50292398\n",
      " 0.39473684 0.21783626 0.35380117 0.37426901]\n",
      "----------------------------------------\n",
      "Trial 1546\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 191, 'xgb__subsample': 0.65, 'xgb__learning_rate': 1.0, 'xgb__gamma': 0.07, 'xgb__max_depth': 11, 'xgb__colsample_bytree': 1.0, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=1.0, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=1.0,\n",
      "                               max_delta_step=None, max_depth=11,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=191,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: [0.47413793 0.33908046 0.65086207 0.64827586 0.73538012 0.51461988\n",
      " 0.54824561 0.53216374 0.3245614  0.36842105]\n",
      "----------------------------------------\n",
      "Trial 1547\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 188, 'gb__subsample': 0.7, 'gb__learning_rate': 1.0, 'gb__max_depth': 14, 'gb__max_features': 'log2', 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=14,\n",
      "                                            max_features='log2',\n",
      "                                            n_estimators=188, random_state=100,\n",
      "                                            subsample=0.7))])\n",
      "cv score: [0.70977011 0.36206897 0.59051724 0.5862069  0.54824561 0.44444444\n",
      " 0.27339181 0.3128655  0.30409357 0.41812865]\n",
      "----------------------------------------\n",
      "Trial 1548\n",
      "----------------------------------------\n",
      "Parameters {'gb__n_estimators': 32, 'gb__subsample': 0.7, 'gb__learning_rate': 0.1, 'gb__max_depth': 13, 'gb__max_features': None, 'gb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('gb',\n",
      "                 GradientBoostingClassifier(max_depth=13, n_estimators=32,\n",
      "                                            random_state=100, subsample=0.7))])\n",
      "cv score: [0.46264368 0.4454023  0.51005747 0.54827586 0.72368421 0.52923977\n",
      " 0.26169591 0.52923977 0.51461988 0.45321637]\n",
      "----------------------------------------\n",
      "Trial 1549\n",
      "----------------------------------------\n",
      "Parameters {'rf__n_estimators': 98, 'rf__max_depth': 12, 'rf__max_features': 'sqrt', 'rf__random_state': 100, 'rf__bootstrap': True}\n",
      "Pipeline: Pipeline(steps=[('rf',\n",
      "                 RandomForestClassifier(max_depth=12, max_features='sqrt',\n",
      "                                        n_estimators=98, random_state=100))])\n",
      "cv score: [0.52011494 0.4295977  0.56752874 0.59655172 0.6622807  0.47660819\n",
      " 0.29385965 0.56432749 0.38011696 0.26754386]\n",
      "----------------------------------------\n",
      "Trial 1550\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 93, 'xgb__subsample': 0.65, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.07, 'xgb__max_depth': 4, 'xgb__colsample_bytree': 0.7, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.7, gamma=0.07, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=4,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=93,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.65, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n",
      "cv score: [0.37068966 0.25287356 0.64798851 0.68275862 0.46345029 0.59064327\n",
      " 0.51023392 0.44152047 0.42397661 0.33040936]\n",
      "----------------------------------------\n",
      "Trial 1551\n",
      "----------------------------------------\n",
      "Parameters {'xgb__n_estimators': 58, 'xgb__subsample': 0.9, 'xgb__learning_rate': 0.3, 'xgb__gamma': 0.001, 'xgb__max_depth': 6, 'xgb__colsample_bytree': 0.6, 'xgb__random_state': 100}\n",
      "Pipeline: Pipeline(steps=[('xgb',\n",
      "                 XGBClassifier(base_score=None, booster=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.6, gamma=0.001, gpu_id=None,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.3,\n",
      "                               max_delta_step=None, max_depth=6,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=58,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               random_state=100, reg_alpha=None,\n",
      "                               reg_lambda=None, scale_pos_weight=None,\n",
      "                               subsample=0.9, tree_method=None,\n",
      "                               validate_parameters=None, verbosity=None))])\n"
     ]
    }
   ],
   "source": [
    "# do the search\n",
    "_,_, best_estimator_rec = mmh.randomized_search_cv(X_rec_rest, y_rec_rest, \n",
    "                                                   search_space, \n",
    "                                                   cv=cv_10,\n",
    "                                                   refit=True,\n",
    "                                                   n_iter=5000, \n",
    "                                                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9df39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.get_test_scores(X_rec_rest, y_rec_rest, X_rec_test, y_rec_test, best_estimator_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rec_test = confusion_matrix(y_rec_test, best_estimator_rec.predict(X_rec_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_rec_test, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "plot_roc_curve(best_estimator_rec, X_rec_test, y_rec_test, ax=ax)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45527874",
   "metadata": {},
   "source": [
    "---\n",
    "## Predicting $T$ (drain) from controls $X, W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bff2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_drain_full = csdh_min['drain']\n",
    "X_drain_full = csdh_min.drop(['drain', 'recurrence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation set and rest\n",
    "X_drain_rest, X_drain_val, y_drain_rest, y_drain_val = train_test_split(X_drain_full, y_drain_full, \n",
    "                                                                        test_size=0.15,\n",
    "                                                                        random_state=random_state,\n",
    "                                                                        stratify=y_drain_full)\n",
    "\n",
    "# Split rest into train and test set\n",
    "X_drain_train, X_drain_test, y_drain_train, y_drain_test = train_test_split(X_drain_rest, y_drain_rest, \n",
    "                                                                            test_size=0.15,\n",
    "                                                                            random_state=random_state,\n",
    "                                                                            stratify=y_drain_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3991e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drain_training_scores, drain_val_scores = mmh.train_and_validate_classifiers(X_drain_train, \n",
    "                                                                             y_drain_train,\n",
    "                                                                             X_drain_val,\n",
    "                                                                             y_drain_val,\n",
    "                                                                             names,\n",
    "                                                                             classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94310f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.print_metrics_table(drain_training_scores, drain_val_scores, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23873943",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_drain_test = confusion_matrix(y_drain_test, classifiers[5].predict(X_drain_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_drain_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27fba2",
   "metadata": {},
   "source": [
    "\n",
    "## `model_t` K-Fold cross validation for hyperparameter tuning and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68241f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the search\n",
    "_,_, best_estimator_drain = mmh.randomized_search_cv(X_drain_rest, y_drain_rest, \n",
    "                                                     search_space, \n",
    "                                                     cv=cv_10,\n",
    "                                                     refit=True,\n",
    "                                                     score='roc_auc',\n",
    "                                                     n_iter=5000, \n",
    "                                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a449caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUROC OF 1 ON TEST SET\n",
    "# best_estimator = GradientBoostingClassifier(max_depth=10, n_estimators=21,\n",
    "#                                             random_state=100, subsample=0.7)\n",
    "\n",
    "# AUROC OF 1 ON TEST SET\n",
    "# GradientBoostingClassifier(max_depth=13, n_estimators=174,\n",
    "#                                             random_state=42, subsample=0.85)\n",
    "\n",
    "# GradientBoostingClassifier(max_depth=9, max_features='log2',\n",
    "#                                             n_estimators=68,\n",
    "#                                             random_state=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.get_test_scores(X_drain_rest, y_drain_rest, X_drain_test, y_drain_test, best_estimator_drain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f5612c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm_drain_test = confusion_matrix(y_drain_test, best_estimator_drain.predict(X_drain_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_drain_test, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e36289",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "plot_roc_curve(best_estimator_drain, X_drain_test, y_drain_test, ax=ax)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c6cb62",
   "metadata": {},
   "source": [
    "# _Doubly Robust Learning_: include `drain` as a feature into `model_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809df153",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full = csdh_min['recurrence']\n",
    "X_full = csdh_min.drop(['recurrence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation set and rest\n",
    "X_rest, X_val, y_rest, y_val = train_test_split(X_full, y_full, \n",
    "                                                test_size=0.15,\n",
    "                                                random_state=random_state,\n",
    "                                                stratify=y_full)\n",
    "\n",
    "# Split rest into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rest, y_rest, \n",
    "                                                    test_size=0.15,\n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=y_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea1515",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores, val_scores = mmh.train_and_validate_classifiers(X_train, \n",
    "                                                                 y_train,\n",
    "                                                                 X_val,\n",
    "                                                                 y_val,\n",
    "                                                                 names,\n",
    "                                                                 classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e18ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.print_metrics_table(training_scores, val_scores, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a90b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test, classifiers[5].predict(X_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_test, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4165a4",
   "metadata": {},
   "source": [
    "## `model_t` K-Fold cross validation for hyperparameter tuning and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6dd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the search\n",
    "_,_, best_estimator = mmh.randomized_search_cv(X_rest, y_rest, \n",
    "                                               search_space, \n",
    "                                               cv=cv_10,\n",
    "                                               refit=True,\n",
    "                                               score='roc_auc',\n",
    "                                               n_iter=5000, \n",
    "                                               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f57b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmh.get_test_scores(X_rest, y_rest, X_test, y_test, best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc62d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test, best_estimator.predict(X_test), normalize='true')\n",
    "mmh.plot_confusion_matrix(cm_test, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "plot_roc_curve(best_estimator, X_test, y_test, ax=ax)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78951c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
