@article{Johnson2016,
abstract = {MIMIC-III (Medical Information Mart for Intensive Care) is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework.},
author = {Johnson, Alistair E.W. and Pollard, Tom J. and Shen, Lu and Lehman, Li Wei H. and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and {Anthony Celi}, Leo and Mark, Roger G.},
doi = {10.1038/sdata.2016.35},
issn = {20524463},
journal = {Scientific Data},
title = {{MIMIC-III, a freely accessible critical care database}},
volume = {3},
year = {2016}
}
@article{Guo2020,
abstract = {The era of big data provides researchers with convenient access to copious data. However, we often have little knowledge of such data. The increasing prevalence of massive data challenges the traditional methods of learning causality because they were developed for the cases with limited amount of data and strong prior causal knowledge. This survey aims to close the gap between big data and learning causality with a comprehensive and structured review of both traditional and frontier methods followed by a discussion about some open problems of learning causality. We begin with preliminaries of learning causality. Then we categorize and revisit methods of learning causality for typical problems and different data types. After that, we discuss the connections between learning causality and machine learning. At the end, some open problems are presented to show the great potential of learning causality with data.},
author = {Guo, Ruocheng and Cheng, Lu and Li, Jundong and Hahn, P. Richard and Liu, Huan},
doi = {10.1145/3397269},
issn = {0360-0300},
journal = {ACM Computing Surveys},
number = {4},
title = {{A Survey of Learning Causality with Data}},
volume = {53},
year = {2020}
}
@article{Bareinboim2020,
abstract = {Cause and effect relationships play a central role in how we perceive and make sense of the world around us, how we act upon it, and ultimately, how we understand ourselves. Almost two decades ago, computer scientist Judea Pearl made a breakthrough in understanding causality by discovering and systematically studying the “Ladder of Causation” [Pearl and Mackenzie 2018], a framework that highlights the distinct roles of seeing, doing, and imagining. In honor of this landmark discovery, we name this the Pearl Causal Hierarchy (PCH). In this chapter, we develop a novel and comprehensive treatment of the PCH through two complementary lenses, one logical-probabilistic and another inferential-graphical. Following Pearl's own presentation of the hierarchy, we begin by showing how the PCH organically emerges from a well-specified collection of causal mechanisms (a structural causal model, or SCM). We then turn to the logical lens. Our first result, the Causal Hierarchy Theorem (CHT), demonstrates that the three layers of the hierarchy almost always separate in a measure-theoretic sense. Roughly speaking, the CHT says that data at one layer virtually always underdetermines information at higher layers. Since in most practical settings the scientist does not have access to the precise form of the underlying causal mechanisms – only to data generated by them with respect to some of PCH's layers – this motivates us to study inferences within the PCH through the graphical lens. Specifically, we explore a set of methods known as causal inference that enable inferences bridging PCH's layers given a partial specification of the SCM. For instance, one may want to infer what would happen had an intervention been performed in the environment (second-layer statement) when only passive observations (first-layer data) are available. We introduce a family of graphical models that allows the scientist to represent such a partial specification of the SCM in a cognitively meaningful and parsimonious way. Finally, we investigate an inferential system known as docalculus, showing how it can be sufficient, and in many cases necessary, to allow inferences across PCH's layers. We believe that connecting with the essential dimensions of human experience as delineated by the PCH is a critical step towards creating the next generation of AI systems that will be safe, robust, human-compatible, and aligned with the social good.},
author = {Bareinboim, Elias and Correa, Juan D. and Ibelind, Duligur and Icard, Thomas},
journal = {Probabilistic and Causal Inference: The Works of Judea Pearl},
title = {{On Pearl's Hierarchy and the Foundations of Causal Inference}},
year = {2020}
}
@article{Johnson2016a,
abstract = {MIMIC-III (Medical Information Mart for Intensive Care) is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework.},
author = {Johnson, Alistair E.W. and Pollard, Tom J. and Shen, Lu and Lehman, Li Wei H. and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and {Anthony Celi}, Leo and Mark, Roger G.},
doi = {10.1038/sdata.2016.35},
issn = {20524463},
journal = {Scientific Data},
title = {{MIMIC-III, a freely accessible critical care database}},
volume = {3},
year = {2016}
}
@inproceedings{Cheng2020,
abstract = {The recent success in machine learning (ML) has led to a massive emergence of AI applications and the increases in expectations for AI systems to achieve human-level intelligence. Nevertheless, these expectations have met with multi-faceted obstacles. One major obstacle is ML aims to predict future observations given real-world data dependencies while human-level intelligence AI is often beyond prediction and seeks the underlying causal mechanism. Another major obstacle is that the availability of large-scale datasets has significantly influenced causal study in various disciplines. It is crucial to leverage effective ML techniques to advance causal learning with big data. Existing benchmark datasets for causal inference have limited use as they are too “ideal”, i.e., small, clean, homogeneous, low-dimensional, to describe real-world scenarios where data is often large, noisy, heterogeneous and high-dimensional. It, therefore, severely hinders the successful marriage of causal inference and ML. In this paper, we formally address this issue by systematically investigating existing datasets for two fundamental tasks in causal inference: causal discovery and causal effect estimation. We also review the datasets for two ML tasks naturally connected to causal inference. We then provide hindsight regarding the advantages, disadvantages and the limitations of these datasets. Please refer to our github repository (https://github.com/rguo12/awesome-causality-data) for all the discussed datasets in this work.},
author = {Cheng, Lu and Guo, Ruocheng and Moraffah, Raha and Candan, K. Sel{\c{c}}uk and Raglin, Adrienne and Liu, Huan},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-49556-5_23},
issn = {16113349},
title = {{A practical data repository for causal learning with big data}},
volume = {12093 LNCS},
year = {2020}
}
@article{Huang1996,
abstract = {Belief networks are popular tools for encoding uncertainty in expert systems. These networks rely on inference algorithms to compute beliefs in the context of observed evidence. One established method for exact inference on belief networks is the probability propagation in trees of clusters (PPTC) algorithm, as developed by Lauritzen and Spiegelhalter and refined by Jensen et al PPTC converts the belief network into a secondary structure, then computes probabilities by manipulating the secondary structure. In this document, we provide a self-contained, procedural guide to understanding and implementing PPTC. We synthesize various optimizations to PPTC that are scattered throughout the literature. We articulate undocumented "open secrets" that are vital to producing a robust and efficient implementation of PPTC. We hope that this document makes probabilistic inference more accessible and affordable to those without extensive prior exposure. {\textcopyright} 1996 Elsevier Science Inc.},
author = {Huang, Cecil and Darwiche, Adnan},
doi = {10.1016/s0888-613x(96)00069-2},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
number = {3},
title = {{Inference in belief networks: A procedural guide}},
volume = {15},
year = {1996}
}
@misc{Sharma2020,
abstract = {In addition to efficient statistical estimators of a treatment's effect, successful application of causal inference requires specifying assumptions about the mechanisms underlying observed data and testing whether they are valid, and to what extent. However, most libraries for causal inference focus only on the task of providing powerful statistical estimators. We describe DoWhy, an open-source Python library that is built with causal assumptions as its first-class citizens, based on the formal framework of causal graphs to specify and test causal assumptions. DoWhy presents an API for the four steps common to any causal analysis—1) modeling the data using a causal graph and structural assumptions, 2) identifying whether the desired effect is estimable under the causal model, 3) estimating the effect using statistical estimators, and finally 4) refuting the obtained estimate through robustness checks and sensitivity analyses. In particular, DoWhy implements a number of robustness checks including placebo tests, bootstrap tests, and tests for unoberved confounding. DoWhy is an extensible library that supports interoperability with other implementations, such as EconML and CausalML for the the estimation step. The library is available at https://github.com/microsoft/dowhy.},
author = {Sharma, Amit and Kiciman, Emre},
booktitle = {arXiv},
issn = {23318422},
title = {{DoWhy: An end-to-end library for causal inference}},
year = {2020}
}
@misc{Chen2020,
abstract = {CausalML is a Python implementation of algorithms related to causal inference and machine learning. Algorithms combining causal inference and machine learning have been a trending topic in recent years. This package tries to bridge the gap between theoretical work on methodology and practical applications by making a collection of methods in this field available in Python. This paper introduces the key concepts, scope, and use cases of this package.},
author = {Chen, Huigang and Harinen, Totte and Lee, Jeong Yoon and Yung, Mike and Zhao, Zhenyu},
booktitle = {arXiv},
issn = {23318422},
title = {{CausalML: Python package for causal machine learning}},
year = {2020}
}

@article{Ke2019,
   abstract = {Meta-learning over a set of distributions can be interpreted as learning different types of parameters corresponding to short-term vs long-term aspects of the mechanisms underlying the generation of data. These are respectively captured by quickly-changing parameters and slowly-changing meta-parameters. We present a new framework for meta-learning causal models where the relationship between each variable and its parents is modeled by a neural network, modulated by structural meta-parameters which capture the overall topology of a directed graphical model. Our approach avoids a discrete search over models in favour of a continuous optimization procedure. We study a setting where interventional distributions are induced as a result of a random intervention on a single unknown variable of an unknown ground truth causal model, and the observations arising after such an intervention constitute one meta-example. To disentangle the slow-changing aspects of each conditional from the fast-changing adaptations to each intervention, we parametrize the neural network into fast parameters and slow meta-parameters. We introduce a meta-learning objective that favours solutions robust to frequent but sparse interventional distribution change, and which generalize well to previously unseen interventions. Optimizing this objective is shown experimentally to recover the structure of the causal graph. Finally, we find that when the learner is unaware of the intervention variable, it is able to infer that information, improving results further and focusing the parameter and meta-parameter updates where needed.},
   author = {Nan Rosemary Ke and Olexa Bilaniuk and Anirudh Goyal and Stefan Bauer and Hugo Larochelle and Chris Pal and Yoshua Bengio},
   issn = {23318422},
   journal = {arXiv},
   title = {Learning neural causal models from unknown interventions},
   year = {2019},
}
@article{Goudet2017,
   abstract = {We present Causal Generative Neural Networks (CGNNs) to learn functional causal models from observational data. CGNNs leverage conditional independencies and distributional asymmetries to discover bivariate and multivariate causal structures. CGNNs make no assumption regarding the lack of confounders, and learn a differentiable generative model of the data by using backpropagation. Extensive experiments show their good performances comparatively to the state of the art in observational causal discovery on both simulated and real data, with respect to cause-effect inference, v-structure identification, and multivariate causal discovery.},
   author = {Olivier Goudet and Diviyan Kalainathan and Philippe Caillou and Isabelle Guyon and David Lopez-Paz and Michèle Sebag},
   issn = {23318422},
   journal = {arXiv},
   title = {Causal generative neural networks},
   year = {2017},
}

@article{DBLP:journals/corr/abs-1907-08322,
  author    = {Shirly Wang and
               Matthew B. A. McDermott and
               Geeticka Chauhan and
               Michael C. Hughes and
               Tristan Naumann and
               Marzyeh Ghassemi},
  title     = {MIMIC-Extract: {A} Data Extraction, Preprocessing, and Representation
               Pipeline for {MIMIC-III}},
  journal   = {CoRR},
  volume    = {abs/1907.08322},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.08322},
  archivePrefix = {arXiv},
  eprint    = {1907.08322},
  timestamp = {Tue, 23 Jul 2019 10:54:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-08322.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{pmlr-v104-andrews19a, 
  title = {Learning High-dimensional Directed Acyclic Graphs with Mixed Data-types}, 
  author = {Andrews, Bryan and Ramsey, Joseph and Cooper, Gregory F.}, 
  booktitle = {Proceedings of Machine Learning Research}, 
  pages = {4--21}, 
  year = {2019}, 
  editor = {Thuc Duy Le and Jiuyong Li and Kun Zhang and Emre Kıcıman Peng Cui and Aapo Hyvärinen}, 
  volume = {104}, 
  series = {Proceedings of Machine Learning Research}, 
  address = {Anchorage, Alaska, USA}, 
  month = {05 Aug}, 
  publisher = {PMLR}, 
  pdf = {http://proceedings.mlr.press/v104/andrews19a/andrews19a.pdf}, 
  url = {http://proceedings.mlr.press/v104/andrews19a.html}
}

@InProceedings{pmlr-v92-raghu18a, 
  title = {Evaluation of Causal Structure Learning Methods on Mixed Data Types}, 
  author = {Vineet K. Raghu and Allen Poon and Panayiotis V. Benos}, 
  booktitle = {Proceedings of 2018 ACM SIGKDD Workshop on Causal Disocvery}, 
  pages = {48--65}, 
  year = {2018}, 
  editor = {Thuc Duy Le and Kun Zhang and Emre Kıcıman and Aapo Hyvärinen and Lin Liu}, 
  volume = {92}, 
  series = {Proceedings of Machine Learning Research}, 
  address = {London, UK}, 
  month = {20 Aug}, 
  publisher = {PMLR}, 
  pdf = {http://proceedings.mlr.press/v92/raghu18a/raghu18a.pdf}, 
  url = {http://proceedings.mlr.press/v92/raghu18a.html}, 
}

@article{Richens2020,
abstract = {Machine learning promises to revolutionize clinical decision making and diagnosis. In medical diagnosis a doctor aims to explain a patient's symptoms by determining the diseases causing them. However, existing machine learning approaches to diagnosis are purely associative, identifying diseases that are strongly correlated with a patients symptoms. We show that this inability to disentangle correlation from causation can result in sub-optimal or dangerous diagnoses. To overcome this, we reformulate diagnosis as a counterfactual inference task and derive counterfactual diagnostic algorithms. We compare our counterfactual algorithms to the standard associative algorithm and 44 doctors using a test set of clinical vignettes. While the associative algorithm achieves an accuracy placing in the top 48% of doctors in our cohort, our counterfactual algorithm places in the top 25% of doctors, achieving expert clinical accuracy. Our results show that causal reasoning is a vital missing ingredient for applying machine learning to medical diagnosis.},
author = {Richens, Jonathan G and Lee, Ciar{\'{a}}n M and Johri, Saurabh},
doi = {10.1038/s41467-020-17419-7},
issn = {2041-1723},
journal = {Nature Communications},
number = {1},
pages = {3923},
title = {{Improving the accuracy of medical diagnosis with causal machine learning}},
url = {https://doi.org/10.1038/s41467-020-17419-7},
volume = {11},
year = {2020}
}

@article{sepsis-def,
title = {Definitions for Sepsis and Organ Failure and Guidelines for the Use of Innovative Therapies in Sepsis},
journal = {Chest},
volume = {101},
number = {6},
pages = {1644-1655},
year = {1992},
issn = {0012-3692},
doi = {https://doi.org/10.1378/chest.101.6.1644},
url = {https://www.sciencedirect.com/science/article/pii/S001236921638415X},
author = {Roger C. Bone and Robert A. Balk and Frank B. Cerra and R. Phillip Dellinger and Alan M. Fein and William A. Knaus and Roland M.H. Schein and William J. Sibbald},
abstract = {An American College of Chest Physicians/Society of Critical Care Medicine Consensus Conference was held in Northbrook in August 1991 with the goal of agreeing on a set of definitions that could be applied to patients with sepsis and its sequelae. New definitions were offered for some terms, while others were discarded. Broad definitions of sepsis and the systemic inflammatory response syndrome were proposed, along with detailed physiologic parameters by which a patient may be categorized. Definitions for severe sepsis, septic shock, hypotension, and multiple organ dysfunction syndrome were also offered. The use of severity scoring methods when dealing with septic patients was recommended as an adjunctive tool to assess mortality. Appropriate methods and applications for the use and testing of new therapies were recommended. The use of these terms and techniques should assist clinicians and researchers who deal with sepsis and its sequelae.}
}

